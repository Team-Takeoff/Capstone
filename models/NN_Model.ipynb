{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Team-Takeoff/Capstone/blob/Dave/models/NN_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHskAm2JitYi"
      },
      "source": [
        "## Step 0:  Install and import necessary packages (if not currently in run-time)\n",
        "\n",
        "Some packages were installed and run on a local machine due to constrains in the free colab environment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1w9Rqf6ifCyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTEPhzBF5mNu",
        "outputId": "372c8a72-d3f2-4818-e363-708c6e5f1d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzyiJ-eeduqn",
        "outputId": "2e4af37f-7108-4bc3-8777-33427b85ec1f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.11.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WWNefhditYm",
        "outputId": "459e9ff0-63e2-4c81-a84b-a627e12f7000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-rocm\n",
            "  Downloading tensorflow_rocm-2.12.0.560-cp310-cp310-manylinux2014_x86_64.whl (497.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.7/497.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (0.4.13)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (1.56.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (2.12.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-rocm) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow-rocm) (0.41.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow-rocm) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow-rocm) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-rocm) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-rocm) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-rocm) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-rocm) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-rocm) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow-rocm) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-rocm) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-rocm) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-rocm) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-rocm) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-rocm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-rocm) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-rocm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-rocm) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-rocm) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-rocm) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-rocm) (3.2.2)\n",
            "Installing collected packages: tensorflow-rocm\n",
            "Successfully installed tensorflow-rocm-2.12.0.560\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-rocm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "q8ZcprsuitYm"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow #run only if necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ_oDh8S5oxC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "b9b5d8a6-9758-4686-be48-50145ff335bd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f0b59c88d911>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mself_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/self_check.py\u001b[0m in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# incompatibilities before we trigger them (which would typically result in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# SIGILL).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_cpu_feature_guard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0m_pywrap_cpu_feature_guard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInfoAboutUnusedCPUFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: libhsa-runtime64.so.1: cannot open shared object file: No such file or directory",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Reshape, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "import keras.metrics\n",
        "import keras.losses\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pyarrow.parquet as pq\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split,cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import confusion_matrix, f1_score,roc_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay,accuracy_score, RocCurveDisplay\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
        "from sklearn.metrics import make_scorer\n",
        "import tensor_transformer\n",
        "from NN_model import custom_f1, XTransform\n",
        "# recall_m, precision_m, f1_new\n",
        "import joblib\n",
        "from copy import deepcopy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLCfEcpyitYn"
      },
      "outputs": [],
      "source": [
        "metrics_path =''\n",
        "files = json.load(open('files.json','r'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zcaXzRwitYo"
      },
      "source": [
        "## Step 1: Data Inspection and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSuKivQLmbJX"
      },
      "source": [
        "### The code for this notebook draws from the following source:\n",
        "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE1Zee6R-mpO"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "pd.set_option('display.max_columns', 130)\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.options.display.min_rows = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meqvwfoX9exp"
      },
      "outputs": [],
      "source": [
        "# Toggling between a few different datasets\n",
        "# df = pd.read_parquet('/content/drive/Shareddrives/STUDENT-Capstone SS23/BTS_data/OnTime_WithWeather/Training_set.parquet')\n",
        "df_all = pd.read_parquet(files['Final_Sets']['Training']['Train_All'])\n",
        "X = pd.read_parquet('data/X.parquet')\n",
        "X_train = pd.read_parquet('data/X_train.parquet')\n",
        "X_val = pd.read_parquet('data/X_dev.parquet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbkjBbGxitYp",
        "outputId": "dba6ad93-0986-42bb-f190-55726ac17fd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([288826,   4346])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.bincount(df_all.Weather_Label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BtMOzcbitYp"
      },
      "outputs": [],
      "source": [
        "train_cols = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'OriginAirportSeqID', 'DestAirportSeqID', 'Dest', 'DestStateFips', 'CRSElapsedTime', 'Distance', 'DistanceGroup', 'Reporting_Airline_AA',\n",
        " 'Reporting_Airline_AS', 'Reporting_Airline_B6', 'Reporting_Airline_CO', 'Reporting_Airline_DL', 'Reporting_Airline_F9', 'Reporting_Airline_FL', 'Reporting_Airline_MQ', 'Reporting_Airline_NK',\n",
        " 'Reporting_Airline_UA', 'Reporting_Airline_US', 'Reporting_Airline_VX', 'mfr_AIRBUS', 'mfr_BOEING', 'mfr_MCDONNELL', 'mfr_nan', 'engine_type_Reciprocating',\n",
        " 'engine_type_Turbofan', 'engine_type_Turbojet', 'w_type_9', 'w_type_C', 'w_type_N', 'w_type_V', 'sky_c_det_9', 'sky_c_det_C', 'sky_c_det_M', 'sky_c_det_W',\n",
        " 'sky_cov_00', 'sky_cov_02', 'sky_cov_04', 'sky_cov_07', 'sky_cov_08', 'sky_cov_09', 'sky_cov_10', 'sky_obs_tot_cov_00', 'sky_obs_tot_cov_01',\n",
        " 'sky_obs_tot_cov_02', 'sky_obs_tot_cov_04', 'sky_obs_tot_cov_06', 'sky_obs_tot_cov_07', 'sky_obs_tot_cov_08', 'sky_obs_tot_cov_09', 'w_type_d_9',\n",
        " 'w_type_d_C', 'w_type_d_N', 'w_type_d_V', 'sky_c_det_d_9', 'sky_c_det_d_C', 'sky_c_det_d_M', 'sky_c_det_d_W', 'sky_cov_d_00', 'sky_cov_d_02',\n",
        " 'sky_cov_d_04', 'sky_cov_d_07', 'sky_cov_d_08', 'sky_cov_d_09', 'sky_cov_d_10', 'sky_obs_tot_cov_d_00', 'sky_obs_tot_cov_d_01', 'sky_obs_tot_cov_d_02',\n",
        " 'sky_obs_tot_cov_d_03', 'sky_obs_tot_cov_d_04', 'sky_obs_tot_cov_d_06', 'sky_obs_tot_cov_d_07', 'sky_obs_tot_cov_d_08', 'sky_obs_tot_cov_d_09', 'CRSDepHour',\n",
        " 'passengers', 'no_engines', 'w_dir_angle', 'w_speed_rate', 'sky_c_hgt', 'vis_dist', 'tmp_air', 'tmp_dew', 'sea_lvl_p', 'liq_precip_qty', 'liq_precip_dim',\n",
        " 'liq_precip_cond', 'sky_cov_base_hgt', 'sky_cov_cld', 'sky_sum_cov', 'sky_sum_hgt', 'sky_low_cld_base_hgt', 'at_pres_altimeter_rate', 'at_pres_stn_rate',\n",
        " 'w_dir_angle_d', 'w_speed_rate_d', 'sky_c_hgt_d', 'vis_dist_d', 'tmp_air_d', 'tmp_dew_d', 'sea_lvl_p_d', 'liq_precip_qty_d', 'liq_precip_dim_d', 'liq_precip_cond_d',\n",
        " 'sky_cov_base_hgt_d', 'sky_cov_cld_d', 'sky_sum_cov_d', 'sky_sum_hgt_d', 'sky_low_cld_base_hgt_d', 'at_pres_altimeter_rate_d', 'at_pres_stn_rate_d']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZptmHo2bcCu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# We initially had our train/validation split in the following manner: 2010-end of 2018 was our training data and 2019 was our validation when planning for Time sequence RNN\n",
        "# We later combined the data and split using train_test_split. Furthermore, different datasets had weights vs didn't.\n",
        "\n",
        "y_train = X_train['Weather_Label']\n",
        "\n",
        "if 'weights' in X_train.columns:\n",
        "    weights = X_train['weights']\n",
        "    if 'Weather_Label' in X_train.columns:\n",
        "        X_train = X_train.drop(['Weather_Label','weights'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "else:\n",
        "    weights = np.ones(len(y_train))\n",
        "    weights[y_train == 0] = len(y_train) / sum(y_train == 0)\n",
        "    if 'Weather_Label' in X_train.columns:\n",
        "        X_train = X_train.drop(['Weather_Label'], axis=1)\n",
        "\n",
        "\n",
        "y_val = X_val['Weather_Label']\n",
        "X_val.drop('Weather_Label',axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9hSKYx1itYq"
      },
      "outputs": [],
      "source": [
        "# weights = np.ones(len(y_train))\n",
        "# weights[y_train == 1] = len(y_train) / sum(y_train == 1)\n",
        "# X_train = df_all[df_all.index.isin(X_indexes)][train_cols]\n",
        "# X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NFF2xCSitYq"
      },
      "outputs": [],
      "source": [
        "# This plugs all of the weights for both train/dev into one\n",
        "# dev_weights = np.ones(len(y_val))\n",
        "# dev_weights[y_val==0] = .6\n",
        "\n",
        "# all_weights = np.concatenate([weights.values, dev_weights])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJg9Dr6ogvhQ",
        "outputId": "b172b0bb-529d-42c8-b204-c7f13c1b3b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Breakdown of Non-Delay(0) and Delay(1)\n",
            "[17407  3482]\n"
          ]
        }
      ],
      "source": [
        "print('Breakdown of Non-Delay(0) and Delay(1)')\n",
        "print(np.bincount(y_train.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTzzN8WDitYr",
        "outputId": "bc6d5e2a-4bd4-42f9-bc96-c177d4a622c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((20889, 115), (5223, 115))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# shape comparison btn training and val data\n",
        "X_train.shape, X_val.shape,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNXlTXLhitYr"
      },
      "source": [
        "## Step 2: Model Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx4RySZli-dc"
      },
      "outputs": [],
      "source": [
        "# Creation of model function that will be called by keras classifier instance.\n",
        "# We can set initial variables here or pass them through the classifier\n",
        "\n",
        "\n",
        "\n",
        "neurons = 115\n",
        "batch_size = 64\n",
        "epochs=100\n",
        "dropout_rate = .01\n",
        "k=5\n",
        "\n",
        "\n",
        "metrics=[\n",
        "            custom_f1\n",
        "        ]\n",
        "\n",
        "\n",
        "def create_model(dropout_rate=.01,learning_rate=.01, batch_size=512, output_bias=-4.19656855):\n",
        "    if output_bias is not None:\n",
        "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "    model= Sequential()\n",
        "    model.add(Dense(neurons, input_shape=(neurons,), activation='relu'))\n",
        "    # model.add(Dense(100, activation='relu'))\n",
        "    # model.add(Dense(75, activation='relu'))\n",
        "    # model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid', bias_initializer=output_bias))\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(\n",
        "                  # loss=keras.losses.BinaryFocalCrossentropy(alpha=.02, apply_class_balancing=True),\n",
        "                  loss='binary_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=metrics,\n",
        "                  weighted_metrics=metrics\n",
        "                )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8A-PsHhitYr",
        "outputId": "eed875e8-a0f2-449a-edcf-bf0f100e4d71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-4.19656855])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get initial bias and class weights\n",
        "# formula & code obtained from https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data\n",
        "\n",
        "y_all = df_all['Weather_Label']\n",
        "\n",
        "neg, pos = np.bincount(y_all)\n",
        "total = len(y_all)\n",
        "weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "initial_bias = np.log([pos/neg])\n",
        "initial_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSBnoF3zitYr",
        "outputId": "52e879a6-18fe-4f6f-c8a0-3d0f88d8586c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(33.728946157386105, 0.5075235608982571)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check weights\n",
        "weight_for_1,weight_for_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyQL9KPn-IVB"
      },
      "outputs": [],
      "source": [
        "# Create the KerasClassifier object so we have access to sklearn functionality\n",
        "\n",
        "estimator = KerasClassifier(model=create_model,\n",
        "                            epochs=100,\n",
        "                            verbose=1,\n",
        "                            dropout_rate=0.001,\n",
        "                            learning_rate=0.001,\n",
        "                            batch_size=512,\n",
        "                            validation_split=.2,\n",
        "                            shuffle=True,\n",
        "                            random_state=42,\n",
        "                            class_weight=None,\n",
        "                            # weight_decay=1,\n",
        "                            output_bias=-4.19656855)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glzGTve7LKVA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create Pipeline,parameters and the metrics we'd like to iterate on.\n",
        "\n",
        "\n",
        "params =  {\n",
        "          'model__learning_rate': [.001,.005,.01,.05,.1],\n",
        "          'model__dropout_rate': [.001, .01, .05,.1],\n",
        "          'model__batch_size': [128]\n",
        "\n",
        "        }\n",
        "\n",
        "\n",
        "rep_cols = {\n",
        "        'dub_cols' : ['liq_precip_qty_d'],\n",
        "        'trip_cols' : ['w_dir_angle', 'w_dir_angle_d'],\n",
        "        'quad_cols' : ['w_speed_rate','tmp_air','tmp_dew','liq_precip_dim','w_speed_rate_d','tmp_air_d','tmp_dew_d','liq_precip_dim_d'],\n",
        "        'quin_cols' : ['sky_c_hgt','sea_lvl_p','sky_cov_base_hgt','sky_sum_hgt','sky_low_cld_base_hgt',\n",
        "                     'at_pres_altimeter_rate','at_pres_stn_rate','sky_c_hgt_d', 'sea_lvl_p_d','sky_cov_base_hgt_d',\n",
        "                     'sky_sum_hgt_d','sky_low_cld_base_hgt_d','at_pres_altimeter_rate_d','at_pres_stn_rate_d'],\n",
        "        'sext_cols' :  ['vis_dist','vis_dist_d']}\n",
        "\n",
        "\n",
        "scale_cols = ['CRSElapsedTime', 'Distance', 'passengers', 'OriginAirportSeqID','DestAirportSeqID',\n",
        "               'w_dir_angle','w_speed_rate','sky_c_hgt','vis_dist','tmp_air','tmp_dew',\n",
        "              'sea_lvl_p','liq_precip_qty','liq_precip_dim','sky_cov_base_hgt','sky_cov_cld','sky_sum_cov','sky_sum_hgt',\n",
        "              'sky_low_cld_base_hgt','at_pres_altimeter_rate','at_pres_stn_rate','w_dir_angle_d',\n",
        "              'w_speed_rate_d','sky_c_hgt_d','vis_dist_d','tmp_air_d','tmp_dew_d',\n",
        "              'sea_lvl_p_d','liq_precip_qty_d','liq_precip_dim_d','liq_precip_cond_d','sky_cov_base_hgt_d',\n",
        "              'sky_cov_cld_d', 'sky_sum_cov_d','sky_sum_hgt_d','sky_low_cld_base_hgt_d','at_pres_altimeter_rate_d',\n",
        "              'at_pres_stn_rate_d','Year'\n",
        "             ]\n",
        "\n",
        "\n",
        "stdscales = ColumnTransformer(transformers=[('scalers',StandardScaler(),scale_cols)],\n",
        "                              remainder='passthrough',\n",
        "                              verbose_feature_names_out=False).set_output(transform='pandas')\n",
        "\n",
        "pipe = Pipeline(steps=[\n",
        "                       # ('replace',mis_replace),\n",
        "                       ('scale', stdscales),\n",
        "                       ('tensor',XTransform()),\n",
        "                       ('model',estimator)\n",
        "                      ])\n",
        "\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score, average='macro', zero_division=1),\n",
        "    'recall': make_scorer(recall_score, average='macro',zero_division=1),\n",
        "    'f1': make_scorer(f1_score,greater_is_better=True, average='weighted'),\n",
        "}\n",
        "\n",
        "\n",
        "# Can use RandomizedSearch or GridSearch (see below)\n",
        "rand_search = RandomizedSearchCV(estimator,\n",
        "                                 param_distributions=params,\n",
        "                                 n_iter=10,\n",
        "                                 scoring=scoring,\n",
        "                                 n_jobs=-1,\n",
        "                                 refit='f1',\n",
        "                                 cv=5,\n",
        "                                 random_state=42,\n",
        "                                 return_train_score=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqp9LRBboxWu"
      },
      "outputs": [],
      "source": [
        "# Helper function to see metrics, and visualizations. Used for both training and validation data\n",
        "\n",
        "def generate_matrix(y_true,predictions, y_pred_probability,model):\n",
        "    name='test'\n",
        "    print('Accuracy:', accuracy_score(y_true,predictions))\n",
        "    print('Precision:', precision_score(y_true, predictions, average='weighted'))\n",
        "    print('Recall:', recall_score(y_true, predictions, average='weighted'))\n",
        "    print('F1 Score:', f1_score(y_true, predictions, average='weighted'))\n",
        "    print('AUC Score:', roc_auc_score(y_true,y_pred_probability,average='weighted'))\n",
        "    fpr, tpr, thres = roc_curve(y_true, y_pred_probability)\n",
        "    roc = RocCurveDisplay(fpr=fpr, tpr=tpr,estimator_name=name)\n",
        "    p,r,t = precision_recall_curve(y_true,y_pred_probability)\n",
        "    prplot = PrecisionRecallDisplay(p,r)\n",
        "    cm = confusion_matrix(y_true,predictions,labels=[0,1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                display_labels=[0,1])\n",
        "\n",
        "    disp.plot()\n",
        "    prplot.plot()\n",
        "    roc.plot()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peg0Q9J1itYs"
      },
      "source": [
        "## Run GridSearch on Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "Reh8E1VxitYs",
        "outputId": "49ae8998-34ce-4a0f-868a-d3e5634d518c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-31 23:26:01.125622: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.155073: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.160681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.164062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.178057: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.178474: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.194209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.198795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.202952: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.206960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.225365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.261955: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.277107: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.309563: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.321682: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-31 23:26:01.330133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 1.2766 - custom_f1: 0.3637 - weighted_custom_f1: 0.3677 - val_loss: 1.0825 - val_custom_f1: 0.4207 - val_weighted_custom_f1: 0.4259\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 1.2552 - custom_f1: 0.3808 - weighted_custom_f1: 0.3846 - val_loss: 1.0982 - val_custom_f1: 0.4041 - val_weighted_custom_f1: 0.4014\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 1.2599 - custom_f1: 0.3688 - weighted_custom_f1: 0.3724 - val_loss: 1.0711 - val_custom_f1: 0.4093 - val_weighted_custom_f1: 0.4197\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 1.2484 - custom_f1: 0.3700 - weighted_custom_f1: 0.3745 - val_loss: 1.1180 - val_custom_f1: 0.3705 - val_weighted_custom_f1: 0.3809\n",
            "Epoch 2/100\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 1.2162 - custom_f1: 0.4042 - weighted_custom_f1: 0.4081 - val_loss: 1.1143 - val_custom_f1: 0.3997 - val_weighted_custom_f1: 0.3992\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 2s 12ms/step - loss: 1.2276 - custom_f1: 0.3983 - weighted_custom_f1: 0.4027 - val_loss: 1.2014 - val_custom_f1: 0.3540 - val_weighted_custom_f1: 0.3646\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 1.2723 - custom_f1: 0.3897 - weighted_custom_f1: 0.3925 - val_loss: 1.0572 - val_custom_f1: 0.4037 - val_weighted_custom_f1: 0.4134\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 11ms/step - loss: 1.2471 - custom_f1: 0.3709 - weighted_custom_f1: 0.3752 - val_loss: 1.0990 - val_custom_f1: 0.3840 - val_weighted_custom_f1: 0.3942\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 1.0568 - custom_f1: 0.4412 - weighted_custom_f1: 0.4472Epoch 2/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 1.5921 - custom_f1: 0.3801 - weighted_custom_f1: 0.3827 - val_loss: 1.1512 - val_custom_f1: 0.3715 - val_weighted_custom_f1: 0.3828\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 1.2340 - custom_f1: 0.3936 - weighted_custom_f1: 0.3993Epoch 2/100\n",
            "105/105 [==============================] - 3s 11ms/step - loss: 1.4124 - custom_f1: 0.3866 - weighted_custom_f1: 0.3910 - val_loss: 1.1778 - val_custom_f1: 0.3717 - val_weighted_custom_f1: 0.3817\n",
            "  3/105 [..............................] - ETA: 2s - loss: 1.2669 - custom_f1: 0.3988 - weighted_custom_f1: 0.4090Epoch 2/100\n",
            "105/105 [==============================] - 3s 11ms/step - loss: 1.2606 - custom_f1: 0.3967 - weighted_custom_f1: 0.4008 - val_loss: 1.0423 - val_custom_f1: 0.4174 - val_weighted_custom_f1: 0.4266\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 11ms/step - loss: 2.5100 - custom_f1: 0.3644 - weighted_custom_f1: 0.3679 - val_loss: 1.0867 - val_custom_f1: 0.4322 - val_weighted_custom_f1: 0.4396\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1668 - custom_f1: 0.4286 - weighted_custom_f1: 0.4286Epoch 2/100\n",
            "105/105 [==============================] - 3s 11ms/step - loss: 1.5334 - custom_f1: 0.3824 - weighted_custom_f1: 0.3874 - val_loss: 1.0229 - val_custom_f1: 0.4388 - val_weighted_custom_f1: 0.4453\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 11ms/step - loss: 1.2393 - custom_f1: 0.3873 - weighted_custom_f1: 0.3911 - val_loss: 1.0531 - val_custom_f1: 0.4040 - val_weighted_custom_f1: 0.4151\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1906 - custom_f1: 0.4250 - weighted_custom_f1: 0.4250Epoch 2/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 1.3925 - custom_f1: 0.4056 - weighted_custom_f1: 0.4095 - val_loss: 1.0994 - val_custom_f1: 0.4109 - val_weighted_custom_f1: 0.4109\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 1.5989 - custom_f1: 0.3740 - weighted_custom_f1: 0.3774 - val_loss: 1.2110 - val_custom_f1: 0.3584 - val_weighted_custom_f1: 0.3699\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 1.1524 - custom_f1: 0.4281 - weighted_custom_f1: 0.4329Epoch 2/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0743 - custom_f1: 0.4198 - weighted_custom_f1: 0.4247 - val_loss: 1.0396 - val_custom_f1: 0.4075 - val_weighted_custom_f1: 0.4173\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 1.2427 - custom_f1: 0.3987 - weighted_custom_f1: 0.4043Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0268 - custom_f1: 0.4413 - weighted_custom_f1: 0.4470 - val_loss: 1.0586 - val_custom_f1: 0.4525 - val_weighted_custom_f1: 0.4509\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0459 - custom_f1: 0.4280 - weighted_custom_f1: 0.4329 - val_loss: 1.0767 - val_custom_f1: 0.3933 - val_weighted_custom_f1: 0.4028\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 1.1328 - custom_f1: 0.4396 - weighted_custom_f1: 0.4448Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0685 - custom_f1: 0.4275 - weighted_custom_f1: 0.4321 - val_loss: 1.0948 - val_custom_f1: 0.3792 - val_weighted_custom_f1: 0.3896\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 1.1477 - custom_f1: 0.4155 - weighted_custom_f1: 0.4203Epoch 3/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0447 - custom_f1: 0.4466 - weighted_custom_f1: 0.4522 - val_loss: 1.0699 - val_custom_f1: 0.4065 - val_weighted_custom_f1: 0.4057\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 1.0497 - custom_f1: 0.4289 - weighted_custom_f1: 0.4339Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.1425 - custom_f1: 0.4183 - weighted_custom_f1: 0.4228 - val_loss: 1.1996 - val_custom_f1: 0.3578 - val_weighted_custom_f1: 0.3694\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 1.0485 - custom_f1: 0.4330 - weighted_custom_f1: 0.4381Epoch 3/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0524 - custom_f1: 0.4256 - weighted_custom_f1: 0.4290 - val_loss: 1.0572 - val_custom_f1: 0.4033 - val_weighted_custom_f1: 0.4132\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.9970 - custom_f1: 0.4559 - weighted_custom_f1: 0.4615Epoch 3/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.1319 - custom_f1: 0.4239 - weighted_custom_f1: 0.4276 - val_loss: 1.0623 - val_custom_f1: 0.3891 - val_weighted_custom_f1: 0.3998\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.1568 - custom_f1: 0.4186 - weighted_custom_f1: 0.4223 - val_loss: 1.3656 - val_custom_f1: 0.3337 - val_weighted_custom_f1: 0.3445\n",
            "Epoch 3/100\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0878 - custom_f1: 0.4385 - weighted_custom_f1: 0.4434 - val_loss: 1.0231 - val_custom_f1: 0.4321 - val_weighted_custom_f1: 0.4426\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.1563 - custom_f1: 0.4092 - weighted_custom_f1: 0.4135 - val_loss: 1.0571 - val_custom_f1: 0.3838 - val_weighted_custom_f1: 0.3954\n",
            "Epoch 3/100\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0469 - custom_f1: 0.4343 - weighted_custom_f1: 0.4392 - val_loss: 1.0951 - val_custom_f1: 0.3859 - val_weighted_custom_f1: 0.3973\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 1.0517 - custom_f1: 0.4379 - weighted_custom_f1: 0.4397Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0629 - custom_f1: 0.4392 - weighted_custom_f1: 0.4438 - val_loss: 1.0312 - val_custom_f1: 0.4183 - val_weighted_custom_f1: 0.4283\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 1.0521 - custom_f1: 0.4330 - weighted_custom_f1: 0.4383Epoch 3/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.1053 - custom_f1: 0.4354 - weighted_custom_f1: 0.4390 - val_loss: 1.0511 - val_custom_f1: 0.4030 - val_weighted_custom_f1: 0.4140\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0668 - custom_f1: 0.4433 - weighted_custom_f1: 0.4483 - val_loss: 1.0923 - val_custom_f1: 0.4006 - val_weighted_custom_f1: 0.4005\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0741 - custom_f1: 0.4434 - weighted_custom_f1: 0.4469 - val_loss: 1.0212 - val_custom_f1: 0.4154 - val_weighted_custom_f1: 0.4257\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 1.0017 - custom_f1: 0.4720 - weighted_custom_f1: 0.4767Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0341 - custom_f1: 0.4407 - weighted_custom_f1: 0.4446 - val_loss: 1.0232 - val_custom_f1: 0.4462 - val_weighted_custom_f1: 0.4530\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0227 - custom_f1: 0.4417 - weighted_custom_f1: 0.4448 - val_loss: 1.0150 - val_custom_f1: 0.4461 - val_weighted_custom_f1: 0.4568\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 1.0097 - custom_f1: 0.4538 - weighted_custom_f1: 0.4594Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9972 - custom_f1: 0.4542 - weighted_custom_f1: 0.4599 - val_loss: 1.0396 - val_custom_f1: 0.4568 - val_weighted_custom_f1: 0.4563\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.9969 - custom_f1: 0.4538 - weighted_custom_f1: 0.4566Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0383 - custom_f1: 0.4369 - weighted_custom_f1: 0.4409 - val_loss: 1.0381 - val_custom_f1: 0.4016 - val_weighted_custom_f1: 0.4134\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 1.0196 - custom_f1: 0.4564 - weighted_custom_f1: 0.4589Epoch 4/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9980 - custom_f1: 0.4681 - weighted_custom_f1: 0.4735 - val_loss: 1.1365 - val_custom_f1: 0.4604 - val_weighted_custom_f1: 0.4619\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.9553 - custom_f1: 0.4658 - weighted_custom_f1: 0.4706Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0140 - custom_f1: 0.4526 - weighted_custom_f1: 0.4557 - val_loss: 0.9951 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.4819\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 1.0237 - custom_f1: 0.4477 - weighted_custom_f1: 0.4532Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0129 - custom_f1: 0.4525 - weighted_custom_f1: 0.4573 - val_loss: 0.9679 - val_custom_f1: 0.4727 - val_weighted_custom_f1: 0.4828\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0205 - custom_f1: 0.4444 - weighted_custom_f1: 0.4493 - val_loss: 1.0534 - val_custom_f1: 0.3955 - val_weighted_custom_f1: 0.4076\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 1.0148 - custom_f1: 0.4489 - weighted_custom_f1: 0.4536Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9944 - custom_f1: 0.4586 - weighted_custom_f1: 0.4617 - val_loss: 0.9670 - val_custom_f1: 0.4820 - val_weighted_custom_f1: 0.4923\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9100 - custom_f1: 0.4255 - weighted_custom_f1: 0.4255Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0244 - custom_f1: 0.4510 - weighted_custom_f1: 0.4554 - val_loss: 0.9987 - val_custom_f1: 0.4804 - val_weighted_custom_f1: 0.4866\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0240 - custom_f1: 0.4500 - weighted_custom_f1: 0.4547 - val_loss: 1.0170 - val_custom_f1: 0.4763 - val_weighted_custom_f1: 0.4842\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9947 - custom_f1: 0.4552 - weighted_custom_f1: 0.4591 - val_loss: 0.9819 - val_custom_f1: 0.4482 - val_weighted_custom_f1: 0.4595\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 1.0174 - custom_f1: 0.4417 - weighted_custom_f1: 0.4478Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0197 - custom_f1: 0.4457 - weighted_custom_f1: 0.4504 - val_loss: 0.9923 - val_custom_f1: 0.4682 - val_weighted_custom_f1: 0.4764\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9444 - custom_f1: 0.4750 - weighted_custom_f1: 0.4750Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0250 - custom_f1: 0.4493 - weighted_custom_f1: 0.4532 - val_loss: 1.0020 - val_custom_f1: 0.4761 - val_weighted_custom_f1: 0.4825\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0091 - custom_f1: 0.4626 - weighted_custom_f1: 0.4681 - val_loss: 1.0765 - val_custom_f1: 0.4778 - val_weighted_custom_f1: 0.4717\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9953 - custom_f1: 0.4576 - weighted_custom_f1: 0.4614 - val_loss: 1.0133 - val_custom_f1: 0.4596 - val_weighted_custom_f1: 0.4660\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9994 - custom_f1: 0.4599 - weighted_custom_f1: 0.4641 - val_loss: 0.9797 - val_custom_f1: 0.4907 - val_weighted_custom_f1: 0.4972\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.9549 - custom_f1: 0.4699 - weighted_custom_f1: 0.4700Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0015 - custom_f1: 0.4475 - weighted_custom_f1: 0.4550 - val_loss: 1.0410 - val_custom_f1: 0.4683 - val_weighted_custom_f1: 0.4756\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0167 - custom_f1: 0.4460 - weighted_custom_f1: 0.4513 - val_loss: 1.0724 - val_custom_f1: 0.4798 - val_weighted_custom_f1: 0.4793\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.9828 - custom_f1: 0.4732 - weighted_custom_f1: 0.4776Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9748 - custom_f1: 0.4686 - weighted_custom_f1: 0.4729 - val_loss: 1.0336 - val_custom_f1: 0.4642 - val_weighted_custom_f1: 0.4623\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9537 - custom_f1: 0.4855 - weighted_custom_f1: 0.4891 - val_loss: 0.9893 - val_custom_f1: 0.4654 - val_weighted_custom_f1: 0.4626\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.9660 - custom_f1: 0.4656 - weighted_custom_f1: 0.4699Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9974 - custom_f1: 0.4613 - weighted_custom_f1: 0.4687 - val_loss: 0.9838 - val_custom_f1: 0.4790 - val_weighted_custom_f1: 0.4866\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9851 - custom_f1: 0.4587 - weighted_custom_f1: 0.4648 - val_loss: 1.0280 - val_custom_f1: 0.4924 - val_weighted_custom_f1: 0.4941\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0003 - custom_f1: 0.4506 - weighted_custom_f1: 0.4566 - val_loss: 1.0104 - val_custom_f1: 0.4650 - val_weighted_custom_f1: 0.4737\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9649 - custom_f1: 0.4669 - weighted_custom_f1: 0.4742 - val_loss: 0.9772 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5078\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9770 - custom_f1: 0.4676 - weighted_custom_f1: 0.4721 - val_loss: 0.9789 - val_custom_f1: 0.4538 - val_weighted_custom_f1: 0.4613\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9888 - custom_f1: 0.4671 - weighted_custom_f1: 0.4733 - val_loss: 1.0623 - val_custom_f1: 0.4909 - val_weighted_custom_f1: 0.4919\n",
            "Epoch 5/100\n",
            "Epoch 5/100\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9678 - custom_f1: 0.4716 - weighted_custom_f1: 0.4782 - val_loss: 0.9779 - val_custom_f1: 0.4888 - val_weighted_custom_f1: 0.4959\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9818 - custom_f1: 0.4688 - weighted_custom_f1: 0.4755 - val_loss: 0.9510 - val_custom_f1: 0.4581 - val_weighted_custom_f1: 0.4699\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0022 - custom_f1: 0.4516 - weighted_custom_f1: 0.4516Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9678 - custom_f1: 0.4709 - weighted_custom_f1: 0.4748 - val_loss: 0.9837 - val_custom_f1: 0.4783 - val_weighted_custom_f1: 0.4858\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9652 - custom_f1: 0.4753 - weighted_custom_f1: 0.4792 - val_loss: 0.9855 - val_custom_f1: 0.4672 - val_weighted_custom_f1: 0.4644\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.9235 - custom_f1: 0.4797 - weighted_custom_f1: 0.4809Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9646 - custom_f1: 0.4738 - weighted_custom_f1: 0.4803 - val_loss: 0.9484 - val_custom_f1: 0.4828 - val_weighted_custom_f1: 0.4944\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.9524 - custom_f1: 0.4557 - weighted_custom_f1: 0.4623Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9916 - custom_f1: 0.4608 - weighted_custom_f1: 0.4646 - val_loss: 0.9983 - val_custom_f1: 0.4639 - val_weighted_custom_f1: 0.4706\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9913 - custom_f1: 0.4609 - weighted_custom_f1: 0.4666 - val_loss: 1.0444 - val_custom_f1: 0.3944 - val_weighted_custom_f1: 0.4067\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9578 - custom_f1: 0.4751 - weighted_custom_f1: 0.4811 - val_loss: 1.0373 - val_custom_f1: 0.4650 - val_weighted_custom_f1: 0.4634\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0262 - custom_f1: 0.4515 - weighted_custom_f1: 0.4563 - val_loss: 1.0299 - val_custom_f1: 0.4641 - val_weighted_custom_f1: 0.4715\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9344 - custom_f1: 0.4925 - weighted_custom_f1: 0.4993 - val_loss: 0.9689 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5016\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9680 - custom_f1: 0.4761 - weighted_custom_f1: 0.4815 - val_loss: 0.9641 - val_custom_f1: 0.4483 - val_weighted_custom_f1: 0.4591\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9763 - custom_f1: 0.4731 - weighted_custom_f1: 0.4800 - val_loss: 0.9807 - val_custom_f1: 0.4473 - val_weighted_custom_f1: 0.4586\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9826 - custom_f1: 0.4717 - weighted_custom_f1: 0.4772 - val_loss: 1.0270 - val_custom_f1: 0.4044 - val_weighted_custom_f1: 0.4156\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9923 - custom_f1: 0.4594 - weighted_custom_f1: 0.4645 - val_loss: 0.9914 - val_custom_f1: 0.4393 - val_weighted_custom_f1: 0.4504\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9102 - custom_f1: 0.4946 - weighted_custom_f1: 0.4946Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9725 - custom_f1: 0.4762 - weighted_custom_f1: 0.4820 - val_loss: 1.0076 - val_custom_f1: 0.4123 - val_weighted_custom_f1: 0.4235\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9700 - custom_f1: 0.4775 - weighted_custom_f1: 0.4827 - val_loss: 0.9971 - val_custom_f1: 0.4242 - val_weighted_custom_f1: 0.4362\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9448 - custom_f1: 0.4814 - weighted_custom_f1: 0.4863 - val_loss: 0.9568 - val_custom_f1: 0.4510 - val_weighted_custom_f1: 0.4628\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9621 - custom_f1: 0.4726 - weighted_custom_f1: 0.4795 - val_loss: 1.0227 - val_custom_f1: 0.4078 - val_weighted_custom_f1: 0.4203\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.9075 - custom_f1: 0.4928 - weighted_custom_f1: 0.4961Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9673 - custom_f1: 0.4708 - weighted_custom_f1: 0.4749 - val_loss: 0.9623 - val_custom_f1: 0.4648 - val_weighted_custom_f1: 0.4750\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.9122 - custom_f1: 0.4933 - weighted_custom_f1: 0.4989Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9740 - custom_f1: 0.4676 - weighted_custom_f1: 0.4720 - val_loss: 0.9884 - val_custom_f1: 0.4556 - val_weighted_custom_f1: 0.4651\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9703 - custom_f1: 0.4702 - weighted_custom_f1: 0.4752 - val_loss: 1.0459 - val_custom_f1: 0.3960 - val_weighted_custom_f1: 0.4077\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9382 - custom_f1: 0.4824 - weighted_custom_f1: 0.4890 - val_loss: 0.9630 - val_custom_f1: 0.4696 - val_weighted_custom_f1: 0.4687\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.9113 - custom_f1: 0.5095 - weighted_custom_f1: 0.5121Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9700 - custom_f1: 0.4700 - weighted_custom_f1: 0.4752 - val_loss: 1.0259 - val_custom_f1: 0.4632 - val_weighted_custom_f1: 0.4704\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.9282 - custom_f1: 0.5131 - weighted_custom_f1: 0.5185Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9466 - custom_f1: 0.4770 - weighted_custom_f1: 0.4827 - val_loss: 0.9964 - val_custom_f1: 0.4619 - val_weighted_custom_f1: 0.4616\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.9774 - custom_f1: 0.4667 - weighted_custom_f1: 0.4676Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9880 - custom_f1: 0.4577 - weighted_custom_f1: 0.4618 - val_loss: 1.0631 - val_custom_f1: 0.4693 - val_weighted_custom_f1: 0.4735\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9159 - custom_f1: 0.4945 - weighted_custom_f1: 0.5004 - val_loss: 0.9567 - val_custom_f1: 0.4717 - val_weighted_custom_f1: 0.4715\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9520 - custom_f1: 0.4832 - weighted_custom_f1: 0.4885 - val_loss: 0.9877 - val_custom_f1: 0.4727 - val_weighted_custom_f1: 0.4828\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.9401 - custom_f1: 0.4910 - weighted_custom_f1: 0.4963Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9497 - custom_f1: 0.4904 - weighted_custom_f1: 0.4948 - val_loss: 0.9745 - val_custom_f1: 0.4895 - val_weighted_custom_f1: 0.5000\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9557 - custom_f1: 0.4803 - weighted_custom_f1: 0.4840 - val_loss: 1.0322 - val_custom_f1: 0.4697 - val_weighted_custom_f1: 0.4783\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9731 - custom_f1: 0.4732 - weighted_custom_f1: 0.4774 - val_loss: 1.0086 - val_custom_f1: 0.4703 - val_weighted_custom_f1: 0.4800\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.8966 - custom_f1: 0.4915 - weighted_custom_f1: 0.4990Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9621 - custom_f1: 0.4853 - weighted_custom_f1: 0.4895 - val_loss: 1.0610 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.4793\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0313 - custom_f1: 0.5532 - weighted_custom_f1: 0.5532Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9262 - custom_f1: 0.4897 - weighted_custom_f1: 0.4946 - val_loss: 0.9589 - val_custom_f1: 0.4707 - val_weighted_custom_f1: 0.4816\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9371 - custom_f1: 0.4870 - weighted_custom_f1: 0.4922 - val_loss: 0.9779 - val_custom_f1: 0.4601 - val_weighted_custom_f1: 0.4703\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9521 - custom_f1: 0.4848 - weighted_custom_f1: 0.4883 - val_loss: 0.9877 - val_custom_f1: 0.5005 - val_weighted_custom_f1: 0.5099\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.9369 - custom_f1: 0.4842 - weighted_custom_f1: 0.4878Epoch 7/100\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.9019 - custom_f1: 0.5060 - weighted_custom_f1: 0.5109Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9377 - custom_f1: 0.4904 - weighted_custom_f1: 0.4948 - val_loss: 0.9513 - val_custom_f1: 0.4839 - val_weighted_custom_f1: 0.4944\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7646 - custom_f1: 0.5128 - weighted_custom_f1: 0.5128Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9603 - custom_f1: 0.4754 - weighted_custom_f1: 0.4795 - val_loss: 0.9831 - val_custom_f1: 0.4570 - val_weighted_custom_f1: 0.4667\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.9179 - custom_f1: 0.4885 - weighted_custom_f1: 0.4942Epoch 8/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9358 - custom_f1: 0.4844 - weighted_custom_f1: 0.4909 - val_loss: 1.0095 - val_custom_f1: 0.4686 - val_weighted_custom_f1: 0.4665\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9571 - custom_f1: 0.4698 - weighted_custom_f1: 0.4749 - val_loss: 1.0122 - val_custom_f1: 0.4649 - val_weighted_custom_f1: 0.4714\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9438 - custom_f1: 0.4875 - weighted_custom_f1: 0.4911 - val_loss: 1.0001 - val_custom_f1: 0.4501 - val_weighted_custom_f1: 0.4561\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9848 - custom_f1: 0.4646 - weighted_custom_f1: 0.4703 - val_loss: 0.9922 - val_custom_f1: 0.4412 - val_weighted_custom_f1: 0.4505\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9279 - custom_f1: 0.4917 - weighted_custom_f1: 0.4973 - val_loss: 0.9833 - val_custom_f1: 0.4709 - val_weighted_custom_f1: 0.4710\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9001 - custom_f1: 0.5019 - weighted_custom_f1: 0.5074 - val_loss: 1.0011 - val_custom_f1: 0.5004 - val_weighted_custom_f1: 0.5031\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9175 - custom_f1: 0.4956 - weighted_custom_f1: 0.4995 - val_loss: 1.0090 - val_custom_f1: 0.4838 - val_weighted_custom_f1: 0.4920\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.9210 - custom_f1: 0.5005 - weighted_custom_f1: 0.5041Epoch 8/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9247 - custom_f1: 0.4927 - weighted_custom_f1: 0.4973 - val_loss: 0.9585 - val_custom_f1: 0.4844 - val_weighted_custom_f1: 0.4932\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.9588 - custom_f1: 0.4713 - weighted_custom_f1: 0.4752Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9255 - custom_f1: 0.4974 - weighted_custom_f1: 0.5011 - val_loss: 0.9877 - val_custom_f1: 0.5000 - val_weighted_custom_f1: 0.5094\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.9303 - custom_f1: 0.5047 - weighted_custom_f1: 0.5100Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9245 - custom_f1: 0.5021 - weighted_custom_f1: 0.5056 - val_loss: 0.9548 - val_custom_f1: 0.5027 - val_weighted_custom_f1: 0.5133\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9152 - custom_f1: 0.4953 - weighted_custom_f1: 0.4993 - val_loss: 1.0403 - val_custom_f1: 0.4923 - val_weighted_custom_f1: 0.4996\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.9032 - custom_f1: 0.5001 - weighted_custom_f1: 0.5049Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9522 - custom_f1: 0.4714 - weighted_custom_f1: 0.4775 - val_loss: 0.9793 - val_custom_f1: 0.4692 - val_weighted_custom_f1: 0.4794\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9333 - custom_f1: 0.4913 - weighted_custom_f1: 0.4965 - val_loss: 0.9865 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5030\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9210 - custom_f1: 0.5005 - weighted_custom_f1: 0.5041 - val_loss: 1.0270 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9255 - custom_f1: 0.4908 - weighted_custom_f1: 0.4951 - val_loss: 1.0422 - val_custom_f1: 0.4123 - val_weighted_custom_f1: 0.4109\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9555 - custom_f1: 0.4767 - weighted_custom_f1: 0.4800 - val_loss: 1.1506 - val_custom_f1: 0.4744 - val_weighted_custom_f1: 0.4740\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9420 - custom_f1: 0.4821 - weighted_custom_f1: 0.4875 - val_loss: 0.9794 - val_custom_f1: 0.4524 - val_weighted_custom_f1: 0.4614\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.8847 - custom_f1: 0.5057 - weighted_custom_f1: 0.5109Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9454 - custom_f1: 0.4827 - weighted_custom_f1: 0.4876 - val_loss: 0.9662 - val_custom_f1: 0.4626 - val_weighted_custom_f1: 0.4737\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9166 - custom_f1: 0.4931 - weighted_custom_f1: 0.4981 - val_loss: 1.0119 - val_custom_f1: 0.4957 - val_weighted_custom_f1: 0.5021\n",
            "Epoch 8/100\n",
            " 10/105 [=>............................] - ETA: 0s - loss: 0.8810 - custom_f1: 0.5081 - weighted_custom_f1: 0.5169Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9017 - custom_f1: 0.4971 - weighted_custom_f1: 0.5029 - val_loss: 1.0806 - val_custom_f1: 0.4940 - val_weighted_custom_f1: 0.4893\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.8949 - custom_f1: 0.5111 - weighted_custom_f1: 0.5154Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9584 - custom_f1: 0.4706 - weighted_custom_f1: 0.4752 - val_loss: 0.9849 - val_custom_f1: 0.4752 - val_weighted_custom_f1: 0.4867\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.9463 - custom_f1: 0.4982 - weighted_custom_f1: 0.5009Epoch 9/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9042 - custom_f1: 0.5077 - weighted_custom_f1: 0.5127 - val_loss: 0.9640 - val_custom_f1: 0.4765 - val_weighted_custom_f1: 0.4751\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.9336 - custom_f1: 0.4987 - weighted_custom_f1: 0.5035Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9060 - custom_f1: 0.5005 - weighted_custom_f1: 0.5054 - val_loss: 0.9309 - val_custom_f1: 0.4904 - val_weighted_custom_f1: 0.5015\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9177 - custom_f1: 0.4892 - weighted_custom_f1: 0.4932 - val_loss: 0.9447 - val_custom_f1: 0.4891 - val_weighted_custom_f1: 0.4983\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8891 - custom_f1: 0.5048 - weighted_custom_f1: 0.5109 - val_loss: 1.3043 - val_custom_f1: 0.4098 - val_weighted_custom_f1: 0.4245\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9010 - custom_f1: 0.5002 - weighted_custom_f1: 0.5046 - val_loss: 1.0484 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5155\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9371 - custom_f1: 0.4826 - weighted_custom_f1: 0.4877 - val_loss: 0.9606 - val_custom_f1: 0.4545 - val_weighted_custom_f1: 0.4651\n",
            "Epoch 9/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9077 - custom_f1: 0.5600 - weighted_custom_f1: 0.5600Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8997 - custom_f1: 0.5039 - weighted_custom_f1: 0.5086 - val_loss: 0.9322 - val_custom_f1: 0.4895 - val_weighted_custom_f1: 0.5007\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8709 - custom_f1: 0.4722 - weighted_custom_f1: 0.4722Epoch 9/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9225 - custom_f1: 0.4894 - weighted_custom_f1: 0.4945 - val_loss: 0.9598 - val_custom_f1: 0.4680 - val_weighted_custom_f1: 0.4784\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8862 - custom_f1: 0.5020 - weighted_custom_f1: 0.5077 - val_loss: 1.0898 - val_custom_f1: 0.4889 - val_weighted_custom_f1: 0.4908\n",
            "Epoch 10/100\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.9461 - custom_f1: 0.5048 - weighted_custom_f1: 0.5067Epoch 9/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9009 - custom_f1: 0.5041 - weighted_custom_f1: 0.5086 - val_loss: 1.0645 - val_custom_f1: 0.4985 - val_weighted_custom_f1: 0.5056\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9477 - custom_f1: 0.4876 - weighted_custom_f1: 0.4915 - val_loss: 0.9601 - val_custom_f1: 0.4444 - val_weighted_custom_f1: 0.4549\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9063 - custom_f1: 0.4944 - weighted_custom_f1: 0.4998 - val_loss: 0.9741 - val_custom_f1: 0.4798 - val_weighted_custom_f1: 0.4789\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9385 - custom_f1: 0.4927 - weighted_custom_f1: 0.4975 - val_loss: 1.0008 - val_custom_f1: 0.4906 - val_weighted_custom_f1: 0.4988\n",
            "Epoch 10/100\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8803 - custom_f1: 0.5075 - weighted_custom_f1: 0.5123 - val_loss: 0.9634 - val_custom_f1: 0.4827 - val_weighted_custom_f1: 0.4929\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8951 - custom_f1: 0.5043 - weighted_custom_f1: 0.5089 - val_loss: 0.9324 - val_custom_f1: 0.4703 - val_weighted_custom_f1: 0.4689\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.9414 - custom_f1: 0.4771 - weighted_custom_f1: 0.4779Epoch 9/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9530 - custom_f1: 0.4774 - weighted_custom_f1: 0.4816 - val_loss: 0.9582 - val_custom_f1: 0.4546 - val_weighted_custom_f1: 0.4663\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8834 - custom_f1: 0.5109 - weighted_custom_f1: 0.5154 - val_loss: 1.0389 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5197\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.8939 - custom_f1: 0.4992 - weighted_custom_f1: 0.5027Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8754 - custom_f1: 0.5121 - weighted_custom_f1: 0.5171 - val_loss: 0.9410 - val_custom_f1: 0.4951 - val_weighted_custom_f1: 0.5061\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8906 - custom_f1: 0.5119 - weighted_custom_f1: 0.5153 - val_loss: 0.9283 - val_custom_f1: 0.4917 - val_weighted_custom_f1: 0.5034\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9338 - custom_f1: 0.4893 - weighted_custom_f1: 0.4936 - val_loss: 0.9552 - val_custom_f1: 0.4602 - val_weighted_custom_f1: 0.4708\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8939 - custom_f1: 0.5027 - weighted_custom_f1: 0.5060 - val_loss: 0.9103 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5245\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8988 - custom_f1: 0.4998 - weighted_custom_f1: 0.5035 - val_loss: 0.9005 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4991\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9569 - custom_f1: 0.5634 - weighted_custom_f1: 0.5634Epoch 10/100\n",
            "Epoch 10/100\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9172 - custom_f1: 0.4878 - weighted_custom_f1: 0.4923 - val_loss: 0.9760 - val_custom_f1: 0.4773 - val_weighted_custom_f1: 0.4881\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8676 - custom_f1: 0.5167 - weighted_custom_f1: 0.5195 - val_loss: 0.9376 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5225\n",
            "Epoch 11/100\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9255 - custom_f1: 0.4890 - weighted_custom_f1: 0.4949 - val_loss: 0.9726 - val_custom_f1: 0.4308 - val_weighted_custom_f1: 0.4418\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.8623 - custom_f1: 0.5168 - weighted_custom_f1: 0.5228Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8701 - custom_f1: 0.5121 - weighted_custom_f1: 0.5171 - val_loss: 0.9579 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8813 - custom_f1: 0.5118 - weighted_custom_f1: 0.5156 - val_loss: 0.9258 - val_custom_f1: 0.5019 - val_weighted_custom_f1: 0.5129\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.8608 - custom_f1: 0.5091 - weighted_custom_f1: 0.5150Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8924 - custom_f1: 0.5043 - weighted_custom_f1: 0.5104 - val_loss: 0.9734 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4871\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9031 - custom_f1: 0.5094 - weighted_custom_f1: 0.5133 - val_loss: 0.9354 - val_custom_f1: 0.5073 - val_weighted_custom_f1: 0.5165\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9249 - custom_f1: 0.4848 - weighted_custom_f1: 0.4899 - val_loss: 0.9537 - val_custom_f1: 0.4662 - val_weighted_custom_f1: 0.4761\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.8955 - custom_f1: 0.4931 - weighted_custom_f1: 0.4971Epoch 10/100\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9435 - custom_f1: 0.4742 - weighted_custom_f1: 0.4796 - val_loss: 0.9562 - val_custom_f1: 0.4751 - val_weighted_custom_f1: 0.4848\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.8419 - custom_f1: 0.5120 - weighted_custom_f1: 0.5156Epoch 11/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8799 - custom_f1: 0.5103 - weighted_custom_f1: 0.5158 - val_loss: 0.9783 - val_custom_f1: 0.5312 - val_weighted_custom_f1: 0.5247\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8640 - custom_f1: 0.5112 - weighted_custom_f1: 0.5177 - val_loss: 0.9424 - val_custom_f1: 0.5074 - val_weighted_custom_f1: 0.5077\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9039 - custom_f1: 0.5114 - weighted_custom_f1: 0.5168 - val_loss: 0.9720 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5387\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9142 - custom_f1: 0.4951 - weighted_custom_f1: 0.4990 - val_loss: 0.9737 - val_custom_f1: 0.4589 - val_weighted_custom_f1: 0.4696\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8848 - custom_f1: 0.5076 - weighted_custom_f1: 0.5116 - val_loss: 0.9739 - val_custom_f1: 0.4989 - val_weighted_custom_f1: 0.5201\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8897 - custom_f1: 0.5089 - weighted_custom_f1: 0.5130 - val_loss: 0.9465 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5280\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9065 - custom_f1: 0.5044 - weighted_custom_f1: 0.5083 - val_loss: 1.0073 - val_custom_f1: 0.5319 - val_weighted_custom_f1: 0.5407\n",
            "Epoch 11/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6819 - custom_f1: 0.5532 - weighted_custom_f1: 0.5532Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8725 - custom_f1: 0.5117 - weighted_custom_f1: 0.5159 - val_loss: 0.9564 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5400\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9994 - custom_f1: 0.3721 - weighted_custom_f1: 0.3721Epoch 11/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8907 - custom_f1: 0.5074 - weighted_custom_f1: 0.5121 - val_loss: 0.9768 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5288\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9018 - custom_f1: 0.5060 - weighted_custom_f1: 0.5110 - val_loss: 0.9659 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5068\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8975 - custom_f1: 0.5086 - weighted_custom_f1: 0.5116 - val_loss: 0.9400 - val_custom_f1: 0.5118 - val_weighted_custom_f1: 0.5191\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8741 - custom_f1: 0.5105 - weighted_custom_f1: 0.5137 - val_loss: 0.9835 - val_custom_f1: 0.5208 - val_weighted_custom_f1: 0.5246\n",
            " 13/105 [==>...........................] - ETA: 1s - loss: 0.9100 - custom_f1: 0.4993 - weighted_custom_f1: 0.5053Epoch 11/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9090 - custom_f1: 0.5047 - weighted_custom_f1: 0.5068 - val_loss: 0.9585 - val_custom_f1: 0.4454 - val_weighted_custom_f1: 0.4564\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8823 - custom_f1: 0.5052 - weighted_custom_f1: 0.5108 - val_loss: 1.0207 - val_custom_f1: 0.4215 - val_weighted_custom_f1: 0.4209\n",
            "Epoch 12/100\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9388 - custom_f1: 0.4810 - weighted_custom_f1: 0.4870 - val_loss: 0.9580 - val_custom_f1: 0.4954 - val_weighted_custom_f1: 0.5049\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9240 - custom_f1: 0.4957 - weighted_custom_f1: 0.4992 - val_loss: 0.9458 - val_custom_f1: 0.4572 - val_weighted_custom_f1: 0.4692\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8509 - custom_f1: 0.5130 - weighted_custom_f1: 0.5191 - val_loss: 0.9249 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5282\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.8560 - custom_f1: 0.5264 - weighted_custom_f1: 0.5308Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8578 - custom_f1: 0.5206 - weighted_custom_f1: 0.5261 - val_loss: 0.9689 - val_custom_f1: 0.4724 - val_weighted_custom_f1: 0.4728\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8555 - custom_f1: 0.5253 - weighted_custom_f1: 0.5288 - val_loss: 0.9476 - val_custom_f1: 0.4500 - val_weighted_custom_f1: 0.4610\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9076 - custom_f1: 0.4964 - weighted_custom_f1: 0.5018 - val_loss: 0.9414 - val_custom_f1: 0.4788 - val_weighted_custom_f1: 0.4898\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8740 - custom_f1: 0.5185 - weighted_custom_f1: 0.5224 - val_loss: 0.9496 - val_custom_f1: 0.4401 - val_weighted_custom_f1: 0.4519\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8597 - custom_f1: 0.5202 - weighted_custom_f1: 0.5246 - val_loss: 0.9369 - val_custom_f1: 0.4832 - val_weighted_custom_f1: 0.4936\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.8335 - custom_f1: 0.5196 - weighted_custom_f1: 0.5250Epoch 12/100\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8460 - custom_f1: 0.5227 - weighted_custom_f1: 0.5274 - val_loss: 0.9295 - val_custom_f1: 0.4853 - val_weighted_custom_f1: 0.4954\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6703 - custom_f1: 0.3704 - weighted_custom_f1: 0.3704Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8626 - custom_f1: 0.5268 - weighted_custom_f1: 0.5305 - val_loss: 1.0255 - val_custom_f1: 0.4171 - val_weighted_custom_f1: 0.4274\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8766 - custom_f1: 0.5132 - weighted_custom_f1: 0.5182 - val_loss: 1.0335 - val_custom_f1: 0.4119 - val_weighted_custom_f1: 0.4246\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8941 - custom_f1: 0.5018 - weighted_custom_f1: 0.5069 - val_loss: 0.9542 - val_custom_f1: 0.4937 - val_weighted_custom_f1: 0.5037\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.8155 - custom_f1: 0.5344 - weighted_custom_f1: 0.5394Epoch 12/100\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9218 - custom_f1: 0.4961 - weighted_custom_f1: 0.4988 - val_loss: 0.9845 - val_custom_f1: 0.4346 - val_weighted_custom_f1: 0.4453\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8597 - custom_f1: 0.5230 - weighted_custom_f1: 0.5259 - val_loss: 0.9769 - val_custom_f1: 0.4358 - val_weighted_custom_f1: 0.4479\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8971 - custom_f1: 0.5028 - weighted_custom_f1: 0.5089 - val_loss: 0.9774 - val_custom_f1: 0.4822 - val_weighted_custom_f1: 0.4914\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8583 - custom_f1: 0.5154 - weighted_custom_f1: 0.5205 - val_loss: 0.9652 - val_custom_f1: 0.4744 - val_weighted_custom_f1: 0.4737\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.8146 - custom_f1: 0.5353 - weighted_custom_f1: 0.5404Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8720 - custom_f1: 0.5123 - weighted_custom_f1: 0.5170 - val_loss: 0.9679 - val_custom_f1: 0.4408 - val_weighted_custom_f1: 0.4518\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9288 - custom_f1: 0.4910 - weighted_custom_f1: 0.4955 - val_loss: 0.9638 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5137\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.8487 - custom_f1: 0.5171 - weighted_custom_f1: 0.5210Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8445 - custom_f1: 0.5217 - weighted_custom_f1: 0.5274 - val_loss: 0.9154 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5176\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8200 - custom_f1: 0.5333 - weighted_custom_f1: 0.5385 - val_loss: 0.9869 - val_custom_f1: 0.5337 - val_weighted_custom_f1: 0.5272\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.8543 - custom_f1: 0.5217 - weighted_custom_f1: 0.5254Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8427 - custom_f1: 0.5274 - weighted_custom_f1: 0.5330 - val_loss: 0.9284 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.5033\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8993 - custom_f1: 0.5024 - weighted_custom_f1: 0.5088 - val_loss: 0.9437 - val_custom_f1: 0.4905 - val_weighted_custom_f1: 0.5026\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8821 - custom_f1: 0.5087 - weighted_custom_f1: 0.5140 - val_loss: 0.9488 - val_custom_f1: 0.5096 - val_weighted_custom_f1: 0.5199\n",
            "Epoch 13/100\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8161 - custom_f1: 0.5368 - weighted_custom_f1: 0.5427 - val_loss: 0.9635 - val_custom_f1: 0.4572 - val_weighted_custom_f1: 0.4692\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8444 - custom_f1: 0.5290 - weighted_custom_f1: 0.5349 - val_loss: 0.9542 - val_custom_f1: 0.4642 - val_weighted_custom_f1: 0.4775\n",
            " 10/105 [=>............................] - ETA: 0s - loss: 0.8337 - custom_f1: 0.5235 - weighted_custom_f1: 0.5307Epoch 13/100\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8604 - custom_f1: 0.5277 - weighted_custom_f1: 0.5332 - val_loss: 0.9248 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5163\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8701 - custom_f1: 0.5148 - weighted_custom_f1: 0.5188 - val_loss: 0.9525 - val_custom_f1: 0.4510 - val_weighted_custom_f1: 0.4631\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8533 - custom_f1: 0.5188 - weighted_custom_f1: 0.5246 - val_loss: 0.9843 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5210\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0486 - custom_f1: 0.3810 - weighted_custom_f1: 0.3810Epoch 14/100\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8689 - custom_f1: 0.5138 - weighted_custom_f1: 0.5196 - val_loss: 0.9192 - val_custom_f1: 0.4576 - val_weighted_custom_f1: 0.4677\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8615 - custom_f1: 0.5179 - weighted_custom_f1: 0.5238 - val_loss: 0.9714 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.4952\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.8349 - custom_f1: 0.5317 - weighted_custom_f1: 0.5366Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9251 - custom_f1: 0.4916 - weighted_custom_f1: 0.4964 - val_loss: 0.9752 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5039\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.8529 - custom_f1: 0.5314 - weighted_custom_f1: 0.5356Epoch 13/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8849 - custom_f1: 0.5100 - weighted_custom_f1: 0.5135 - val_loss: 0.9371 - val_custom_f1: 0.4871 - val_weighted_custom_f1: 0.4973\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8630 - custom_f1: 0.5199 - weighted_custom_f1: 0.5263 - val_loss: 0.9194 - val_custom_f1: 0.4770 - val_weighted_custom_f1: 0.4879\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6765 - custom_f1: 0.5312 - weighted_custom_f1: 0.5312Epoch 13/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8932 - custom_f1: 0.5004 - weighted_custom_f1: 0.5036 - val_loss: 0.9285 - val_custom_f1: 0.4703 - val_weighted_custom_f1: 0.4828\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.9234 - custom_f1: 0.4920 - weighted_custom_f1: 0.4968Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8324 - custom_f1: 0.5229 - weighted_custom_f1: 0.5283 - val_loss: 0.9645 - val_custom_f1: 0.5472 - val_weighted_custom_f1: 0.5412\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.8573 - custom_f1: 0.5285 - weighted_custom_f1: 0.5313Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8280 - custom_f1: 0.5336 - weighted_custom_f1: 0.5391 - val_loss: 0.9565 - val_custom_f1: 0.4986 - val_weighted_custom_f1: 0.4972\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8494 - custom_f1: 0.5265 - weighted_custom_f1: 0.5302 - val_loss: 0.9915 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5158\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8160 - custom_f1: 0.5364 - weighted_custom_f1: 0.5400 - val_loss: 0.9205 - val_custom_f1: 0.4796 - val_weighted_custom_f1: 0.4920\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8759 - custom_f1: 0.5142 - weighted_custom_f1: 0.5178 - val_loss: 0.9456 - val_custom_f1: 0.4686 - val_weighted_custom_f1: 0.4806\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.8882 - custom_f1: 0.5070 - weighted_custom_f1: 0.5115Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8519 - custom_f1: 0.5274 - weighted_custom_f1: 0.5300 - val_loss: 0.9226 - val_custom_f1: 0.4873 - val_weighted_custom_f1: 0.5001\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8629 - custom_f1: 0.5103 - weighted_custom_f1: 0.5161 - val_loss: 0.9350 - val_custom_f1: 0.5004 - val_weighted_custom_f1: 0.5114\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8678 - custom_f1: 0.5143 - weighted_custom_f1: 0.5180 - val_loss: 0.9641 - val_custom_f1: 0.5132 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8401 - custom_f1: 0.5321 - weighted_custom_f1: 0.5352 - val_loss: 0.9237 - val_custom_f1: 0.4883 - val_weighted_custom_f1: 0.5014\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8185 - custom_f1: 0.5331 - weighted_custom_f1: 0.5366 - val_loss: 0.9077 - val_custom_f1: 0.4775 - val_weighted_custom_f1: 0.4894\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.8061 - custom_f1: 0.5413 - weighted_custom_f1: 0.5456Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8378 - custom_f1: 0.5277 - weighted_custom_f1: 0.5320 - val_loss: 0.9383 - val_custom_f1: 0.4840 - val_weighted_custom_f1: 0.4936\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8399 - custom_f1: 0.5275 - weighted_custom_f1: 0.5326 - val_loss: 1.0266 - val_custom_f1: 0.5290 - val_weighted_custom_f1: 0.5243\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.8491 - custom_f1: 0.5280 - weighted_custom_f1: 0.5317Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9086 - custom_f1: 0.5018 - weighted_custom_f1: 0.5049 - val_loss: 1.0513 - val_custom_f1: 0.4810 - val_weighted_custom_f1: 0.4861\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.8515 - custom_f1: 0.5181 - weighted_custom_f1: 0.5209Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8129 - custom_f1: 0.5389 - weighted_custom_f1: 0.5428 - val_loss: 0.9405 - val_custom_f1: 0.4765 - val_weighted_custom_f1: 0.4865\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8774 - custom_f1: 0.5095 - weighted_custom_f1: 0.5145 - val_loss: 1.0221 - val_custom_f1: 0.5114 - val_weighted_custom_f1: 0.5193\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.8753 - custom_f1: 0.5157 - weighted_custom_f1: 0.5204Epoch 14/100\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8921 - custom_f1: 0.5036 - weighted_custom_f1: 0.5076 - val_loss: 0.9892 - val_custom_f1: 0.5014 - val_weighted_custom_f1: 0.5081\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.8984 - custom_f1: 0.5137 - weighted_custom_f1: 0.5175Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8362 - custom_f1: 0.5262 - weighted_custom_f1: 0.5308 - val_loss: 0.9497 - val_custom_f1: 0.5282 - val_weighted_custom_f1: 0.5264\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8114 - custom_f1: 0.5392 - weighted_custom_f1: 0.5436 - val_loss: 0.9719 - val_custom_f1: 0.5318 - val_weighted_custom_f1: 0.5252\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8146 - custom_f1: 0.5369 - weighted_custom_f1: 0.5419 - val_loss: 0.9224 - val_custom_f1: 0.4916 - val_weighted_custom_f1: 0.5036\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8459 - custom_f1: 0.5307 - weighted_custom_f1: 0.5344 - val_loss: 0.9040 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5303\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8294 - custom_f1: 0.5320 - weighted_custom_f1: 0.5368 - val_loss: 1.1849 - val_custom_f1: 0.5071 - val_weighted_custom_f1: 0.5151\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8571 - custom_f1: 0.5149 - weighted_custom_f1: 0.5210 - val_loss: 0.9439 - val_custom_f1: 0.4550 - val_weighted_custom_f1: 0.4668\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8674 - custom_f1: 0.5167 - weighted_custom_f1: 0.5214 - val_loss: 0.9573 - val_custom_f1: 0.5031 - val_weighted_custom_f1: 0.5141\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8571 - custom_f1: 0.5196 - weighted_custom_f1: 0.5242 - val_loss: 1.1861 - val_custom_f1: 0.5074 - val_weighted_custom_f1: 0.5098\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8064 - custom_f1: 0.5384 - weighted_custom_f1: 0.5434 - val_loss: 0.9263 - val_custom_f1: 0.4863 - val_weighted_custom_f1: 0.4975\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8299 - custom_f1: 0.5358 - weighted_custom_f1: 0.5400 - val_loss: 0.8927 - val_custom_f1: 0.4892 - val_weighted_custom_f1: 0.5003\n",
            "Epoch 15/100\n",
            "Epoch 15/100\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8277 - custom_f1: 0.5325 - weighted_custom_f1: 0.5363 - val_loss: 0.8981 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5214\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7309 - custom_f1: 0.5246 - weighted_custom_f1: 0.5246Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8140 - custom_f1: 0.5365 - weighted_custom_f1: 0.5410 - val_loss: 0.9274 - val_custom_f1: 0.5083 - val_weighted_custom_f1: 0.5181\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8656 - custom_f1: 0.5152 - weighted_custom_f1: 0.5198 - val_loss: 0.9340 - val_custom_f1: 0.4838 - val_weighted_custom_f1: 0.4951\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8443 - custom_f1: 0.5227 - weighted_custom_f1: 0.5280 - val_loss: 0.9767 - val_custom_f1: 0.5201 - val_weighted_custom_f1: 0.5182\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6552 - custom_f1: 0.5965 - weighted_custom_f1: 0.5965Epoch 16/100\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9138 - custom_f1: 0.4940 - weighted_custom_f1: 0.4985 - val_loss: 1.1908 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.4908\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8812 - custom_f1: 0.5111 - weighted_custom_f1: 0.5154 - val_loss: 0.9247 - val_custom_f1: 0.4690 - val_weighted_custom_f1: 0.4809\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.8449 - custom_f1: 0.5236 - weighted_custom_f1: 0.5266Epoch 16/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8029 - custom_f1: 0.5375 - weighted_custom_f1: 0.5418 - val_loss: 1.0390 - val_custom_f1: 0.5368 - val_weighted_custom_f1: 0.5270\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8287 - custom_f1: 0.5327 - weighted_custom_f1: 0.5377 - val_loss: 0.9731 - val_custom_f1: 0.5104 - val_weighted_custom_f1: 0.5093\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7970 - custom_f1: 0.5375 - weighted_custom_f1: 0.5432 - val_loss: 0.9368 - val_custom_f1: 0.5168 - val_weighted_custom_f1: 0.5275\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8235 - custom_f1: 0.5318 - weighted_custom_f1: 0.5368 - val_loss: 0.9216 - val_custom_f1: 0.4857 - val_weighted_custom_f1: 0.4986\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8717 - custom_f1: 0.5158 - weighted_custom_f1: 0.5203 - val_loss: 0.9278 - val_custom_f1: 0.4651 - val_weighted_custom_f1: 0.4777\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.8240 - custom_f1: 0.5344 - weighted_custom_f1: 0.5405Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8246 - custom_f1: 0.5288 - weighted_custom_f1: 0.5334 - val_loss: 0.9271 - val_custom_f1: 0.5322 - val_weighted_custom_f1: 0.5410\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9224 - custom_f1: 0.5263 - weighted_custom_f1: 0.5263Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8424 - custom_f1: 0.5273 - weighted_custom_f1: 0.5315 - val_loss: 0.9491 - val_custom_f1: 0.4760 - val_weighted_custom_f1: 0.4874\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8400 - custom_f1: 0.5284 - weighted_custom_f1: 0.5338 - val_loss: 0.9124 - val_custom_f1: 0.4778 - val_weighted_custom_f1: 0.4914\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8013 - custom_f1: 0.5445 - weighted_custom_f1: 0.5486 - val_loss: 0.9716 - val_custom_f1: 0.5429 - val_weighted_custom_f1: 0.5469\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.8194 - custom_f1: 0.5391 - weighted_custom_f1: 0.5448Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7880 - custom_f1: 0.5451 - weighted_custom_f1: 0.5508 - val_loss: 0.9901 - val_custom_f1: 0.5122 - val_weighted_custom_f1: 0.5333\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8160 - custom_f1: 0.5355 - weighted_custom_f1: 0.5391 - val_loss: 0.9074 - val_custom_f1: 0.5142 - val_weighted_custom_f1: 0.5220\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9095 - custom_f1: 0.4961 - weighted_custom_f1: 0.5010 - val_loss: 0.9786 - val_custom_f1: 0.4745 - val_weighted_custom_f1: 0.4868\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8698 - custom_f1: 0.5194 - weighted_custom_f1: 0.5239 - val_loss: 0.9395 - val_custom_f1: 0.4750 - val_weighted_custom_f1: 0.4863\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8096 - custom_f1: 0.5367 - weighted_custom_f1: 0.5411 - val_loss: 0.9048 - val_custom_f1: 0.5140 - val_weighted_custom_f1: 0.5218\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8245 - custom_f1: 0.5347 - weighted_custom_f1: 0.5383 - val_loss: 0.9806 - val_custom_f1: 0.4551 - val_weighted_custom_f1: 0.4550\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.8184 - custom_f1: 0.5360 - weighted_custom_f1: 0.5414Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8848 - custom_f1: 0.5075 - weighted_custom_f1: 0.5127 - val_loss: 0.9250 - val_custom_f1: 0.4762 - val_weighted_custom_f1: 0.4875\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.8019 - custom_f1: 0.5663 - weighted_custom_f1: 0.5719Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8186 - custom_f1: 0.5383 - weighted_custom_f1: 0.5430 - val_loss: 0.9489 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5204\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.9009 - custom_f1: 0.5001 - weighted_custom_f1: 0.5049Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7921 - custom_f1: 0.5488 - weighted_custom_f1: 0.5528 - val_loss: 1.0018 - val_custom_f1: 0.4443 - val_weighted_custom_f1: 0.4415\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.7934 - custom_f1: 0.5496 - weighted_custom_f1: 0.5539Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7886 - custom_f1: 0.5442 - weighted_custom_f1: 0.5483 - val_loss: 0.9439 - val_custom_f1: 0.4970 - val_weighted_custom_f1: 0.5068\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8111 - custom_f1: 0.5404 - weighted_custom_f1: 0.5444 - val_loss: 0.9210 - val_custom_f1: 0.4929 - val_weighted_custom_f1: 0.5063\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8507 - custom_f1: 0.5273 - weighted_custom_f1: 0.5332 - val_loss: 0.9075 - val_custom_f1: 0.4742 - val_weighted_custom_f1: 0.4871\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8309 - custom_f1: 0.5331 - weighted_custom_f1: 0.5374 - val_loss: 0.9285 - val_custom_f1: 0.4671 - val_weighted_custom_f1: 0.4793\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8443 - custom_f1: 0.5280 - weighted_custom_f1: 0.5330 - val_loss: 0.9290 - val_custom_f1: 0.4896 - val_weighted_custom_f1: 0.5005\n",
            "Epoch 17/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7792 - custom_f1: 0.4507 - weighted_custom_f1: 0.4507Epoch 18/100\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8117 - custom_f1: 0.5360 - weighted_custom_f1: 0.5415 - val_loss: 0.9146 - val_custom_f1: 0.4637 - val_weighted_custom_f1: 0.4744\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8355 - custom_f1: 0.5288 - weighted_custom_f1: 0.5329 - val_loss: 0.9198 - val_custom_f1: 0.4780 - val_weighted_custom_f1: 0.4903\n",
            "Epoch 17/100\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7964 - custom_f1: 0.5474 - weighted_custom_f1: 0.5515 - val_loss: 0.9484 - val_custom_f1: 0.4990 - val_weighted_custom_f1: 0.5091\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7028 - custom_f1: 0.4348 - weighted_custom_f1: 0.4348Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8610 - custom_f1: 0.5211 - weighted_custom_f1: 0.5270 - val_loss: 0.9337 - val_custom_f1: 0.4535 - val_weighted_custom_f1: 0.4658\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6762 - custom_f1: 0.5429 - weighted_custom_f1: 0.5429Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8998 - custom_f1: 0.4994 - weighted_custom_f1: 0.5036 - val_loss: 0.9998 - val_custom_f1: 0.4645 - val_weighted_custom_f1: 0.4764\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8346 - custom_f1: 0.5360 - weighted_custom_f1: 0.5393 - val_loss: 0.9704 - val_custom_f1: 0.5123 - val_weighted_custom_f1: 0.5237\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8146 - custom_f1: 0.5325 - weighted_custom_f1: 0.5378 - val_loss: 0.9324 - val_custom_f1: 0.4596 - val_weighted_custom_f1: 0.4702\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8213 - custom_f1: 0.5285 - weighted_custom_f1: 0.5349 - val_loss: 0.9924 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5135\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.7872 - custom_f1: 0.5494 - weighted_custom_f1: 0.5555Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8516 - custom_f1: 0.5234 - weighted_custom_f1: 0.5276 - val_loss: 0.9125 - val_custom_f1: 0.4891 - val_weighted_custom_f1: 0.5004\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7895 - custom_f1: 0.5445 - weighted_custom_f1: 0.5483 - val_loss: 0.9826 - val_custom_f1: 0.4602 - val_weighted_custom_f1: 0.4598\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.7949 - custom_f1: 0.5474 - weighted_custom_f1: 0.5523Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7858 - custom_f1: 0.5488 - weighted_custom_f1: 0.5546 - val_loss: 0.9925 - val_custom_f1: 0.5400 - val_weighted_custom_f1: 0.5309\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7927 - custom_f1: 0.5477 - weighted_custom_f1: 0.5521 - val_loss: 0.9243 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.4887\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7858 - custom_f1: 0.5523 - weighted_custom_f1: 0.5555 - val_loss: 0.9658 - val_custom_f1: 0.5221 - val_weighted_custom_f1: 0.5303\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8157 - custom_f1: 0.5255 - weighted_custom_f1: 0.5336 - val_loss: 0.9310 - val_custom_f1: 0.4932 - val_weighted_custom_f1: 0.5046\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8317 - custom_f1: 0.5310 - weighted_custom_f1: 0.5356 - val_loss: 0.9264 - val_custom_f1: 0.4577 - val_weighted_custom_f1: 0.4702\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8066 - custom_f1: 0.5420 - weighted_custom_f1: 0.5450 - val_loss: 0.9360 - val_custom_f1: 0.5205 - val_weighted_custom_f1: 0.5319\n",
            "Epoch 18/100\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8157 - custom_f1: 0.5409 - weighted_custom_f1: 0.5450 - val_loss: 0.9346 - val_custom_f1: 0.5337 - val_weighted_custom_f1: 0.5428\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9046 - custom_f1: 0.5060 - weighted_custom_f1: 0.5090 - val_loss: 0.9959 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5241\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.8209 - custom_f1: 0.5603 - weighted_custom_f1: 0.5621Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8036 - custom_f1: 0.5396 - weighted_custom_f1: 0.5432 - val_loss: 0.9304 - val_custom_f1: 0.5135 - val_weighted_custom_f1: 0.5253\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8089 - custom_f1: 0.5402 - weighted_custom_f1: 0.5451 - val_loss: 0.8893 - val_custom_f1: 0.5049 - val_weighted_custom_f1: 0.5151\n",
            " 11/105 [==>...........................] - ETA: 0s - loss: 0.8218 - custom_f1: 0.5524 - weighted_custom_f1: 0.5564Epoch 18/100\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7933 - custom_f1: 0.5448 - weighted_custom_f1: 0.5493 - val_loss: 0.9535 - val_custom_f1: 0.5362 - val_weighted_custom_f1: 0.5448\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8440 - custom_f1: 0.5308 - weighted_custom_f1: 0.5359 - val_loss: 0.9319 - val_custom_f1: 0.5062 - val_weighted_custom_f1: 0.5176\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.7984 - custom_f1: 0.5399 - weighted_custom_f1: 0.5433Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8006 - custom_f1: 0.5441 - weighted_custom_f1: 0.5491 - val_loss: 0.9257 - val_custom_f1: 0.5148 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8091 - custom_f1: 0.5438 - weighted_custom_f1: 0.5489 - val_loss: 0.9676 - val_custom_f1: 0.5038 - val_weighted_custom_f1: 0.5037\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8524 - custom_f1: 0.5243 - weighted_custom_f1: 0.5289 - val_loss: 0.9100 - val_custom_f1: 0.4850 - val_weighted_custom_f1: 0.4951\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.8071 - custom_f1: 0.5449 - weighted_custom_f1: 0.5497Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7732 - custom_f1: 0.5494 - weighted_custom_f1: 0.5556 - val_loss: 0.9756 - val_custom_f1: 0.5626 - val_weighted_custom_f1: 0.5564\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7837 - custom_f1: 0.5522 - weighted_custom_f1: 0.5566 - val_loss: 1.0059 - val_custom_f1: 0.5044 - val_weighted_custom_f1: 0.5027\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.7846 - custom_f1: 0.5518 - weighted_custom_f1: 0.5571Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7876 - custom_f1: 0.5404 - weighted_custom_f1: 0.5483 - val_loss: 1.0276 - val_custom_f1: 0.5192 - val_weighted_custom_f1: 0.5276\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8222 - custom_f1: 0.5362 - weighted_custom_f1: 0.5410 - val_loss: 1.0109 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5123\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6626 - custom_f1: 0.6531 - weighted_custom_f1: 0.6531Epoch 20/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7952 - custom_f1: 0.5383 - weighted_custom_f1: 0.5434 - val_loss: 0.9463 - val_custom_f1: 0.5297 - val_weighted_custom_f1: 0.5388\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1550 - custom_f1: 0.5517 - weighted_custom_f1: 0.5517Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7870 - custom_f1: 0.5514 - weighted_custom_f1: 0.5565 - val_loss: 0.9794 - val_custom_f1: 0.4828 - val_weighted_custom_f1: 0.4957\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8070 - custom_f1: 0.5468 - weighted_custom_f1: 0.5510 - val_loss: 0.9846 - val_custom_f1: 0.5020 - val_weighted_custom_f1: 0.5125\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8269 - custom_f1: 0.5237 - weighted_custom_f1: 0.5293 - val_loss: 0.9262 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5202\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8258 - custom_f1: 0.5306 - weighted_custom_f1: 0.5355 - val_loss: 0.9154 - val_custom_f1: 0.5078 - val_weighted_custom_f1: 0.5199\n",
            "Epoch 19/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9047 - custom_f1: 0.5397 - weighted_custom_f1: 0.5397Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8994 - custom_f1: 0.5013 - weighted_custom_f1: 0.5060 - val_loss: 0.9612 - val_custom_f1: 0.4898 - val_weighted_custom_f1: 0.5005\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7773 - custom_f1: 0.5489 - weighted_custom_f1: 0.5562 - val_loss: 1.0140 - val_custom_f1: 0.5212 - val_weighted_custom_f1: 0.5314\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7918 - custom_f1: 0.5462 - weighted_custom_f1: 0.5506 - val_loss: 0.9498 - val_custom_f1: 0.4884 - val_weighted_custom_f1: 0.4994\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.7930 - custom_f1: 0.5649 - weighted_custom_f1: 0.5700Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8451 - custom_f1: 0.5267 - weighted_custom_f1: 0.5309 - val_loss: 0.9445 - val_custom_f1: 0.4699 - val_weighted_custom_f1: 0.4812\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.9211 - custom_f1: 0.4959 - weighted_custom_f1: 0.5054Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8121 - custom_f1: 0.5353 - weighted_custom_f1: 0.5405 - val_loss: 0.9782 - val_custom_f1: 0.5177 - val_weighted_custom_f1: 0.5262\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7984 - custom_f1: 0.5366 - weighted_custom_f1: 0.5432 - val_loss: 0.9500 - val_custom_f1: 0.5031 - val_weighted_custom_f1: 0.5030\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8456 - custom_f1: 0.5763 - weighted_custom_f1: 0.5763Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8374 - custom_f1: 0.5262 - weighted_custom_f1: 0.5304 - val_loss: 0.9189 - val_custom_f1: 0.4680 - val_weighted_custom_f1: 0.4797\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.7690 - custom_f1: 0.5753 - weighted_custom_f1: 0.5796Epoch 20/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7757 - custom_f1: 0.5536 - weighted_custom_f1: 0.5584 - val_loss: 0.9675 - val_custom_f1: 0.5268 - val_weighted_custom_f1: 0.5274\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8033 - custom_f1: 0.5436 - weighted_custom_f1: 0.5495 - val_loss: 0.9676 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5298\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7918 - custom_f1: 0.5480 - weighted_custom_f1: 0.5519 - val_loss: 0.9403 - val_custom_f1: 0.4861 - val_weighted_custom_f1: 0.4986\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8087 - custom_f1: 0.5396 - weighted_custom_f1: 0.5441 - val_loss: 0.9266 - val_custom_f1: 0.4896 - val_weighted_custom_f1: 0.5013\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8183 - custom_f1: 0.5449 - weighted_custom_f1: 0.5490 - val_loss: 0.9280 - val_custom_f1: 0.4720 - val_weighted_custom_f1: 0.4841\n",
            "Epoch 21/100\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7935 - custom_f1: 0.5473 - weighted_custom_f1: 0.5500 - val_loss: 0.9563 - val_custom_f1: 0.4916 - val_weighted_custom_f1: 0.5032\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9293 - custom_f1: 0.4906 - weighted_custom_f1: 0.4945 - val_loss: 0.9544 - val_custom_f1: 0.4719 - val_weighted_custom_f1: 0.4831\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8093 - custom_f1: 0.5385 - weighted_custom_f1: 0.5425 - val_loss: 0.9225 - val_custom_f1: 0.4588 - val_weighted_custom_f1: 0.4696\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8272 - custom_f1: 0.5325 - weighted_custom_f1: 0.5383 - val_loss: 0.9219 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5117\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.8392 - custom_f1: 0.5201 - weighted_custom_f1: 0.5266Epoch 20/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8407 - custom_f1: 0.5259 - weighted_custom_f1: 0.5293 - val_loss: 0.9772 - val_custom_f1: 0.4924 - val_weighted_custom_f1: 0.5034\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 0.7539 - custom_f1: 0.5630 - weighted_custom_f1: 0.5692Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7699 - custom_f1: 0.5617 - weighted_custom_f1: 0.5663 - val_loss: 0.9777 - val_custom_f1: 0.5074 - val_weighted_custom_f1: 0.5170\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8160 - custom_f1: 0.5394 - weighted_custom_f1: 0.5452 - val_loss: 0.9275 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5119\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7954 - custom_f1: 0.5439 - weighted_custom_f1: 0.5478 - val_loss: 0.9375 - val_custom_f1: 0.4870 - val_weighted_custom_f1: 0.4985\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.8955 - custom_f1: 0.4952 - weighted_custom_f1: 0.5017Epoch 20/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7888 - custom_f1: 0.5518 - weighted_custom_f1: 0.5565 - val_loss: 0.9750 - val_custom_f1: 0.4729 - val_weighted_custom_f1: 0.4742\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8128 - custom_f1: 0.5437 - weighted_custom_f1: 0.5488 - val_loss: 0.9228 - val_custom_f1: 0.4614 - val_weighted_custom_f1: 0.4732\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7684 - custom_f1: 0.4810 - weighted_custom_f1: 0.4810Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8281 - custom_f1: 0.5287 - weighted_custom_f1: 0.5335 - val_loss: 0.8996 - val_custom_f1: 0.4886 - val_weighted_custom_f1: 0.4996\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.7563 - custom_f1: 0.5642 - weighted_custom_f1: 0.5694Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7579 - custom_f1: 0.5545 - weighted_custom_f1: 0.5593 - val_loss: 1.0128 - val_custom_f1: 0.5094 - val_weighted_custom_f1: 0.5065\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.8028 - custom_f1: 0.5475 - weighted_custom_f1: 0.5522Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7553 - custom_f1: 0.5651 - weighted_custom_f1: 0.5699 - val_loss: 0.9917 - val_custom_f1: 0.4848 - val_weighted_custom_f1: 0.4836\n",
            " 76/105 [====================>.........] - ETA: 0s - loss: 0.7892 - custom_f1: 0.5431 - weighted_custom_f1: 0.5483Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7691 - custom_f1: 0.5509 - weighted_custom_f1: 0.5561 - val_loss: 0.9529 - val_custom_f1: 0.4973 - val_weighted_custom_f1: 0.5071\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8143 - custom_f1: 0.5458 - weighted_custom_f1: 0.5491 - val_loss: 0.9899 - val_custom_f1: 0.4944 - val_weighted_custom_f1: 0.5150\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7871 - custom_f1: 0.5449 - weighted_custom_f1: 0.5494 - val_loss: 0.9465 - val_custom_f1: 0.4544 - val_weighted_custom_f1: 0.4664\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.7743 - custom_f1: 0.5546 - weighted_custom_f1: 0.5575Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9618 - custom_f1: 0.4944 - weighted_custom_f1: 0.5004 - val_loss: 1.0107 - val_custom_f1: 0.5053 - val_weighted_custom_f1: 0.5113\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7943 - custom_f1: 0.5498 - weighted_custom_f1: 0.5543 - val_loss: 0.9115 - val_custom_f1: 0.4925 - val_weighted_custom_f1: 0.5042\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.2386 - custom_f1: 0.4828 - weighted_custom_f1: 0.4828Epoch 21/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8011 - custom_f1: 0.5454 - weighted_custom_f1: 0.5510 - val_loss: 0.9740 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5258\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7687 - custom_f1: 0.5553 - weighted_custom_f1: 0.5614 - val_loss: 0.9468 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5238\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.7667 - custom_f1: 0.5568 - weighted_custom_f1: 0.5626Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7678 - custom_f1: 0.5560 - weighted_custom_f1: 0.5608 - val_loss: 0.9402 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.4901\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.7497 - custom_f1: 0.5777 - weighted_custom_f1: 0.5810Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7805 - custom_f1: 0.5546 - weighted_custom_f1: 0.5596 - val_loss: 0.9156 - val_custom_f1: 0.4926 - val_weighted_custom_f1: 0.5043\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.7597 - custom_f1: 0.5623 - weighted_custom_f1: 0.5659Epoch 21/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8113 - custom_f1: 0.5369 - weighted_custom_f1: 0.5413 - val_loss: 0.9036 - val_custom_f1: 0.4856 - val_weighted_custom_f1: 0.4976\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.7612 - custom_f1: 0.5564 - weighted_custom_f1: 0.5613Epoch 21/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7797 - custom_f1: 0.5447 - weighted_custom_f1: 0.5491 - val_loss: 0.9557 - val_custom_f1: 0.4602 - val_weighted_custom_f1: 0.4728\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8050 - custom_f1: 0.5438 - weighted_custom_f1: 0.5479 - val_loss: 0.9264 - val_custom_f1: 0.4937 - val_weighted_custom_f1: 0.5053\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9499 - custom_f1: 0.5161 - weighted_custom_f1: 0.5161Epoch 21/100\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.7451 - custom_f1: 0.5639 - weighted_custom_f1: 0.5691Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7877 - custom_f1: 0.5464 - weighted_custom_f1: 0.5505 - val_loss: 0.9608 - val_custom_f1: 0.4692 - val_weighted_custom_f1: 0.4697\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.7646 - custom_f1: 0.5562 - weighted_custom_f1: 0.5609Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8218 - custom_f1: 0.5328 - weighted_custom_f1: 0.5369 - val_loss: 0.9111 - val_custom_f1: 0.4823 - val_weighted_custom_f1: 0.4919\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.8052 - custom_f1: 0.5365 - weighted_custom_f1: 0.5413Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7735 - custom_f1: 0.5576 - weighted_custom_f1: 0.5625 - val_loss: 0.9978 - val_custom_f1: 0.4836 - val_weighted_custom_f1: 0.4820\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.7437 - custom_f1: 0.5658 - weighted_custom_f1: 0.5705Epoch 21/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7495 - custom_f1: 0.5670 - weighted_custom_f1: 0.5705 - val_loss: 0.9631 - val_custom_f1: 0.4920 - val_weighted_custom_f1: 0.4896\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8105 - custom_f1: 0.5482 - weighted_custom_f1: 0.5521Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7737 - custom_f1: 0.5533 - weighted_custom_f1: 0.5576 - val_loss: 0.9349 - val_custom_f1: 0.4918 - val_weighted_custom_f1: 0.5039\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7741 - custom_f1: 0.5522 - weighted_custom_f1: 0.5567 - val_loss: 0.9277 - val_custom_f1: 0.4839 - val_weighted_custom_f1: 0.4956\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9777 - custom_f1: 0.5019 - weighted_custom_f1: 0.5069 - val_loss: 0.9397 - val_custom_f1: 0.4860 - val_weighted_custom_f1: 0.4969\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7775 - custom_f1: 0.5558 - weighted_custom_f1: 0.5601 - val_loss: 0.9137 - val_custom_f1: 0.4720 - val_weighted_custom_f1: 0.4845\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7958 - custom_f1: 0.3929 - weighted_custom_f1: 0.3929Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7857 - custom_f1: 0.5489 - weighted_custom_f1: 0.5533 - val_loss: 0.9220 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5197\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.7908 - custom_f1: 0.5630 - weighted_custom_f1: 0.5667Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8088 - custom_f1: 0.5478 - weighted_custom_f1: 0.5518 - val_loss: 0.8986 - val_custom_f1: 0.4833 - val_weighted_custom_f1: 0.4962\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7573 - custom_f1: 0.5634 - weighted_custom_f1: 0.5676 - val_loss: 0.9959 - val_custom_f1: 0.5256 - val_weighted_custom_f1: 0.5345\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8120 - custom_f1: 0.5489 - weighted_custom_f1: 0.5524 - val_loss: 0.9117 - val_custom_f1: 0.4985 - val_weighted_custom_f1: 0.5103\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7461 - custom_f1: 0.5639 - weighted_custom_f1: 0.5680 - val_loss: 0.9533 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.5002\n",
            "Epoch 22/100\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7661 - custom_f1: 0.5608 - weighted_custom_f1: 0.5643 - val_loss: 0.9427 - val_custom_f1: 0.4646 - val_weighted_custom_f1: 0.4768\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7779 - custom_f1: 0.5632 - weighted_custom_f1: 0.5666 - val_loss: 0.9595 - val_custom_f1: 0.4458 - val_weighted_custom_f1: 0.4588\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8141 - custom_f1: 0.5426 - weighted_custom_f1: 0.5455 - val_loss: 0.9354 - val_custom_f1: 0.4634 - val_weighted_custom_f1: 0.4761\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.7394 - custom_f1: 0.5598 - weighted_custom_f1: 0.5622Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7774 - custom_f1: 0.5605 - weighted_custom_f1: 0.5658 - val_loss: 0.9635 - val_custom_f1: 0.4748 - val_weighted_custom_f1: 0.4732\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8047 - custom_f1: 0.5416 - weighted_custom_f1: 0.5453 - val_loss: 0.9029 - val_custom_f1: 0.4755 - val_weighted_custom_f1: 0.4871\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7409 - custom_f1: 0.5669 - weighted_custom_f1: 0.5709 - val_loss: 0.9478 - val_custom_f1: 0.5181 - val_weighted_custom_f1: 0.5142\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.7553 - custom_f1: 0.5562 - weighted_custom_f1: 0.5589Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7347 - custom_f1: 0.5695 - weighted_custom_f1: 0.5742 - val_loss: 1.0179 - val_custom_f1: 0.5340 - val_weighted_custom_f1: 0.5325\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.7254 - custom_f1: 0.5727 - weighted_custom_f1: 0.5769Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7536 - custom_f1: 0.5570 - weighted_custom_f1: 0.5613 - val_loss: 0.9873 - val_custom_f1: 0.5261 - val_weighted_custom_f1: 0.5351\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7783 - custom_f1: 0.5563 - weighted_custom_f1: 0.5600 - val_loss: 0.9467 - val_custom_f1: 0.4990 - val_weighted_custom_f1: 0.5089\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7886 - custom_f1: 0.5534 - weighted_custom_f1: 0.5570 - val_loss: 0.9361 - val_custom_f1: 0.4648 - val_weighted_custom_f1: 0.4769\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8937 - custom_f1: 0.5066 - weighted_custom_f1: 0.5092 - val_loss: 1.0251 - val_custom_f1: 0.4448 - val_weighted_custom_f1: 0.4559\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7825 - custom_f1: 0.5489 - weighted_custom_f1: 0.5512 - val_loss: 0.9478 - val_custom_f1: 0.4654 - val_weighted_custom_f1: 0.4788\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7495 - custom_f1: 0.5595 - weighted_custom_f1: 0.5625 - val_loss: 0.9269 - val_custom_f1: 0.4770 - val_weighted_custom_f1: 0.4879\n",
            "Epoch 23/100\n",
            "Epoch 23/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7819 - custom_f1: 0.4857 - weighted_custom_f1: 0.4857Epoch 23/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7792 - custom_f1: 0.5520 - weighted_custom_f1: 0.5556 - val_loss: 0.8946 - val_custom_f1: 0.5066 - val_weighted_custom_f1: 0.5186\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.7721 - custom_f1: 0.5565 - weighted_custom_f1: 0.5614Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7479 - custom_f1: 0.5656 - weighted_custom_f1: 0.5681 - val_loss: 0.9491 - val_custom_f1: 0.4923 - val_weighted_custom_f1: 0.5026\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7322 - custom_f1: 0.5726 - weighted_custom_f1: 0.5772 - val_loss: 0.9444 - val_custom_f1: 0.4896 - val_weighted_custom_f1: 0.5112\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.7662 - custom_f1: 0.5688 - weighted_custom_f1: 0.5724Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7748 - custom_f1: 0.5506 - weighted_custom_f1: 0.5535 - val_loss: 0.9096 - val_custom_f1: 0.4799 - val_weighted_custom_f1: 0.4908\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.7631 - custom_f1: 0.5773 - weighted_custom_f1: 0.5816Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7980 - custom_f1: 0.5479 - weighted_custom_f1: 0.5520 - val_loss: 0.9220 - val_custom_f1: 0.5053 - val_weighted_custom_f1: 0.5170\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7546 - custom_f1: 0.5645 - weighted_custom_f1: 0.5679 - val_loss: 0.9646 - val_custom_f1: 0.4832 - val_weighted_custom_f1: 0.4820\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7589 - custom_f1: 0.5642 - weighted_custom_f1: 0.5669 - val_loss: 0.9188 - val_custom_f1: 0.4727 - val_weighted_custom_f1: 0.4841\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8057 - custom_f1: 0.5389 - weighted_custom_f1: 0.5477 - val_loss: 0.9003 - val_custom_f1: 0.4964 - val_weighted_custom_f1: 0.5082\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7314 - custom_f1: 0.5694 - weighted_custom_f1: 0.5736 - val_loss: 1.0376 - val_custom_f1: 0.5337 - val_weighted_custom_f1: 0.5330\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.7569 - custom_f1: 0.5644 - weighted_custom_f1: 0.5708Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7188 - custom_f1: 0.5782 - weighted_custom_f1: 0.5825 - val_loss: 1.0174 - val_custom_f1: 0.5001 - val_weighted_custom_f1: 0.4982\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7601 - custom_f1: 0.5702 - weighted_custom_f1: 0.5749 - val_loss: 0.9739 - val_custom_f1: 0.4995 - val_weighted_custom_f1: 0.5068\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7639 - custom_f1: 0.5594 - weighted_custom_f1: 0.5639 - val_loss: 0.9217 - val_custom_f1: 0.4924 - val_weighted_custom_f1: 0.5040\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8937 - custom_f1: 0.5091 - weighted_custom_f1: 0.5138 - val_loss: 0.9983 - val_custom_f1: 0.4852 - val_weighted_custom_f1: 0.4958\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7647 - custom_f1: 0.6076 - weighted_custom_f1: 0.6076Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7712 - custom_f1: 0.5540 - weighted_custom_f1: 0.5603 - val_loss: 1.0333 - val_custom_f1: 0.5351 - val_weighted_custom_f1: 0.5339\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.7179 - custom_f1: 0.5672 - weighted_custom_f1: 0.5714Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7831 - custom_f1: 0.5485 - weighted_custom_f1: 0.5524 - val_loss: 0.9611 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5260\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9289 - custom_f1: 0.5455 - weighted_custom_f1: 0.5455Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7970 - custom_f1: 0.5462 - weighted_custom_f1: 0.5540 - val_loss: 0.9036 - val_custom_f1: 0.4983 - val_weighted_custom_f1: 0.5099\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.8881 - custom_f1: 0.4730 - weighted_custom_f1: 0.4775Epoch 24/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7598 - custom_f1: 0.5691 - weighted_custom_f1: 0.5738 - val_loss: 0.9680 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5211\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7519 - custom_f1: 0.5717 - weighted_custom_f1: 0.5755 - val_loss: 0.9871 - val_custom_f1: 0.5077 - val_weighted_custom_f1: 0.5172\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7849 - custom_f1: 0.5491 - weighted_custom_f1: 0.5560 - val_loss: 0.9315 - val_custom_f1: 0.5293 - val_weighted_custom_f1: 0.5413\n",
            "Epoch 24/100\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7569 - custom_f1: 0.5594 - weighted_custom_f1: 0.5670 - val_loss: 0.9267 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5143\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7695 - custom_f1: 0.5571 - weighted_custom_f1: 0.5640 - val_loss: 0.9968 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5287\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7792 - custom_f1: 0.5531 - weighted_custom_f1: 0.5569 - val_loss: 1.0185 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5397\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7535 - custom_f1: 0.5635 - weighted_custom_f1: 0.5689 - val_loss: 0.9659 - val_custom_f1: 0.5011 - val_weighted_custom_f1: 0.5006\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7903 - custom_f1: 0.5513 - weighted_custom_f1: 0.5562 - val_loss: 1.0315 - val_custom_f1: 0.5458 - val_weighted_custom_f1: 0.5485\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.7389 - custom_f1: 0.5662 - weighted_custom_f1: 0.5710Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7311 - custom_f1: 0.5679 - weighted_custom_f1: 0.5718 - val_loss: 0.9696 - val_custom_f1: 0.5230 - val_weighted_custom_f1: 0.5210\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7319 - custom_f1: 0.5727 - weighted_custom_f1: 0.5774 - val_loss: 1.1876 - val_custom_f1: 0.5148 - val_weighted_custom_f1: 0.5138\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7481 - custom_f1: 0.5678 - weighted_custom_f1: 0.5728 - val_loss: 0.9947 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5158\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8981 - custom_f1: 0.5076 - weighted_custom_f1: 0.5112 - val_loss: 0.9665 - val_custom_f1: 0.4585 - val_weighted_custom_f1: 0.4699\n",
            "Epoch 25/100\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7557 - custom_f1: 0.5636 - weighted_custom_f1: 0.5675 - val_loss: 0.9313 - val_custom_f1: 0.4676 - val_weighted_custom_f1: 0.4807\n",
            " 76/105 [====================>.........] - ETA: 0s - loss: 0.7878 - custom_f1: 0.5524 - weighted_custom_f1: 0.5566Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7674 - custom_f1: 0.5600 - weighted_custom_f1: 0.5644 - val_loss: 0.9507 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5113\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.7273 - custom_f1: 0.5887 - weighted_custom_f1: 0.5926Epoch 25/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7607 - custom_f1: 0.5549 - weighted_custom_f1: 0.5601 - val_loss: 0.9448 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5286\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7449 - custom_f1: 0.5615 - weighted_custom_f1: 0.5659 - val_loss: 0.9745 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5302\n",
            "Epoch 25/100\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7293 - custom_f1: 0.5747 - weighted_custom_f1: 0.5790 - val_loss: 0.9873 - val_custom_f1: 0.5254 - val_weighted_custom_f1: 0.5357\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.7370 - custom_f1: 0.5645 - weighted_custom_f1: 0.5687Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7716 - custom_f1: 0.5549 - weighted_custom_f1: 0.5598 - val_loss: 0.9155 - val_custom_f1: 0.5382 - val_weighted_custom_f1: 0.5495\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7397 - custom_f1: 0.5699 - weighted_custom_f1: 0.5744 - val_loss: 0.9868 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5184\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.7976 - custom_f1: 0.5586 - weighted_custom_f1: 0.5639Epoch 25/100\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.7386 - custom_f1: 0.5618 - weighted_custom_f1: 0.5661Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7378 - custom_f1: 0.5654 - weighted_custom_f1: 0.5706 - val_loss: 0.9725 - val_custom_f1: 0.5395 - val_weighted_custom_f1: 0.5453\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.7212 - custom_f1: 0.5911 - weighted_custom_f1: 0.5939Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7456 - custom_f1: 0.5690 - weighted_custom_f1: 0.5730 - val_loss: 0.9966 - val_custom_f1: 0.5245 - val_weighted_custom_f1: 0.5243\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.7825 - custom_f1: 0.5597 - weighted_custom_f1: 0.5650Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7501 - custom_f1: 0.5638 - weighted_custom_f1: 0.5681 - val_loss: 0.9040 - val_custom_f1: 0.5018 - val_weighted_custom_f1: 0.5115\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7838 - custom_f1: 0.5541 - weighted_custom_f1: 0.5586 - val_loss: 0.9304 - val_custom_f1: 0.4734 - val_weighted_custom_f1: 0.4863\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 0.7594 - custom_f1: 0.5599 - weighted_custom_f1: 0.5646Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7990 - custom_f1: 0.5481 - weighted_custom_f1: 0.5517 - val_loss: 0.8911 - val_custom_f1: 0.4819 - val_weighted_custom_f1: 0.4953\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.7172 - custom_f1: 0.5847 - weighted_custom_f1: 0.5885Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7602 - custom_f1: 0.5582 - weighted_custom_f1: 0.5631 - val_loss: 0.9791 - val_custom_f1: 0.5096 - val_weighted_custom_f1: 0.5089\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7166 - custom_f1: 0.5823 - weighted_custom_f1: 0.5874 - val_loss: 1.0082 - val_custom_f1: 0.5198 - val_weighted_custom_f1: 0.5139\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.7602 - custom_f1: 0.5574 - weighted_custom_f1: 0.5609Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9031 - custom_f1: 0.5067 - weighted_custom_f1: 0.5113 - val_loss: 0.9783 - val_custom_f1: 0.4659 - val_weighted_custom_f1: 0.4781\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.7544 - custom_f1: 0.5655 - weighted_custom_f1: 0.5695Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7498 - custom_f1: 0.5617 - weighted_custom_f1: 0.5644 - val_loss: 0.9880 - val_custom_f1: 0.5030 - val_weighted_custom_f1: 0.5237\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7395 - custom_f1: 0.5705 - weighted_custom_f1: 0.5729 - val_loss: 0.8987 - val_custom_f1: 0.4760 - val_weighted_custom_f1: 0.4882\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7579 - custom_f1: 0.5604 - weighted_custom_f1: 0.5650 - val_loss: 0.9614 - val_custom_f1: 0.4821 - val_weighted_custom_f1: 0.4905\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7918 - custom_f1: 0.5581 - weighted_custom_f1: 0.5607 - val_loss: 0.9035 - val_custom_f1: 0.4852 - val_weighted_custom_f1: 0.4976\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.8911 - custom_f1: 0.5201 - weighted_custom_f1: 0.5271Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7788 - custom_f1: 0.5611 - weighted_custom_f1: 0.5654 - val_loss: 0.9334 - val_custom_f1: 0.4731 - val_weighted_custom_f1: 0.4845\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7125 - custom_f1: 0.5808 - weighted_custom_f1: 0.5846 - val_loss: 0.9284 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5098\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.7689 - custom_f1: 0.5565 - weighted_custom_f1: 0.5596Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7371 - custom_f1: 0.5730 - weighted_custom_f1: 0.5779 - val_loss: 0.9954 - val_custom_f1: 0.4543 - val_weighted_custom_f1: 0.4675\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7595 - custom_f1: 0.5609 - weighted_custom_f1: 0.5637 - val_loss: 0.8929 - val_custom_f1: 0.4716 - val_weighted_custom_f1: 0.4839\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7661 - custom_f1: 0.5596 - weighted_custom_f1: 0.5648 - val_loss: 0.9644 - val_custom_f1: 0.4472 - val_weighted_custom_f1: 0.4592\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7591 - custom_f1: 0.5635 - weighted_custom_f1: 0.5666 - val_loss: 0.9257 - val_custom_f1: 0.4785 - val_weighted_custom_f1: 0.4909\n",
            " 55/105 [==============>...............] - ETA: 0s - loss: 0.7598 - custom_f1: 0.5503 - weighted_custom_f1: 0.5525Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7392 - custom_f1: 0.5740 - weighted_custom_f1: 0.5762 - val_loss: 0.9408 - val_custom_f1: 0.4534 - val_weighted_custom_f1: 0.4658\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.8154 - custom_f1: 0.5412 - weighted_custom_f1: 0.5449Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7480 - custom_f1: 0.5654 - weighted_custom_f1: 0.5707 - val_loss: 0.9659 - val_custom_f1: 0.5070 - val_weighted_custom_f1: 0.5065\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.7347 - custom_f1: 0.5757 - weighted_custom_f1: 0.5816Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7697 - custom_f1: 0.5558 - weighted_custom_f1: 0.5588 - val_loss: 0.8990 - val_custom_f1: 0.4785 - val_weighted_custom_f1: 0.4902\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.7711 - custom_f1: 0.5551 - weighted_custom_f1: 0.5619Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7394 - custom_f1: 0.5697 - weighted_custom_f1: 0.5744 - val_loss: 0.9871 - val_custom_f1: 0.5106 - val_weighted_custom_f1: 0.5067\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7109 - custom_f1: 0.5801 - weighted_custom_f1: 0.5863 - val_loss: 0.9941 - val_custom_f1: 0.5278 - val_weighted_custom_f1: 0.5244\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9002 - custom_f1: 0.5028 - weighted_custom_f1: 0.5085 - val_loss: 1.0034 - val_custom_f1: 0.4444 - val_weighted_custom_f1: 0.4560\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7429 - custom_f1: 0.5644 - weighted_custom_f1: 0.5674 - val_loss: 0.9907 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5096\n",
            "Epoch 27/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5692 - custom_f1: 0.4898 - weighted_custom_f1: 0.4898Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7335 - custom_f1: 0.5683 - weighted_custom_f1: 0.5725 - val_loss: 0.9904 - val_custom_f1: 0.5098 - val_weighted_custom_f1: 0.5311\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7357 - custom_f1: 0.5630 - weighted_custom_f1: 0.5678 - val_loss: 0.9066 - val_custom_f1: 0.4890 - val_weighted_custom_f1: 0.5020\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.6780 - custom_f1: 0.5824 - weighted_custom_f1: 0.5855Epoch 27/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7651 - custom_f1: 0.5580 - weighted_custom_f1: 0.5634 - val_loss: 0.9232 - val_custom_f1: 0.5007 - val_weighted_custom_f1: 0.5122\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6756 - custom_f1: 0.5753 - weighted_custom_f1: 0.5753Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7441 - custom_f1: 0.5636 - weighted_custom_f1: 0.5672 - val_loss: 0.8953 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5266\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6998 - custom_f1: 0.5831 - weighted_custom_f1: 0.5864 - val_loss: 0.9776 - val_custom_f1: 0.4985 - val_weighted_custom_f1: 0.5102\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.7135 - custom_f1: 0.5759 - weighted_custom_f1: 0.5832Epoch 27/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7367 - custom_f1: 0.5744 - weighted_custom_f1: 0.5784 - val_loss: 0.9429 - val_custom_f1: 0.5175 - val_weighted_custom_f1: 0.5232\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.7439 - custom_f1: 0.5766 - weighted_custom_f1: 0.5817Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7547 - custom_f1: 0.5630 - weighted_custom_f1: 0.5674 - val_loss: 0.8887 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5089\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7327 - custom_f1: 0.5750 - weighted_custom_f1: 0.5797 - val_loss: 0.9964 - val_custom_f1: 0.4898 - val_weighted_custom_f1: 0.5012\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7659 - custom_f1: 0.5624 - weighted_custom_f1: 0.5684 - val_loss: 0.9274 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5223\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7300 - custom_f1: 0.5730 - weighted_custom_f1: 0.5783 - val_loss: 0.9044 - val_custom_f1: 0.4887 - val_weighted_custom_f1: 0.4995\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7362 - custom_f1: 0.5733 - weighted_custom_f1: 0.5778 - val_loss: 1.0161 - val_custom_f1: 0.5277 - val_weighted_custom_f1: 0.5272\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.7140 - custom_f1: 0.5666 - weighted_custom_f1: 0.5720Epoch 28/100\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7803 - custom_f1: 0.5468 - weighted_custom_f1: 0.5544 - val_loss: 0.9799 - val_custom_f1: 0.5436 - val_weighted_custom_f1: 0.5516\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7241 - custom_f1: 0.5781 - weighted_custom_f1: 0.5844 - val_loss: 1.0320 - val_custom_f1: 0.5250 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7188 - custom_f1: 0.5785 - weighted_custom_f1: 0.5819 - val_loss: 1.0636 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5319\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.7264 - custom_f1: 0.5649 - weighted_custom_f1: 0.5692Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6922 - custom_f1: 0.5901 - weighted_custom_f1: 0.5951 - val_loss: 1.2125 - val_custom_f1: 0.5415 - val_weighted_custom_f1: 0.5341\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7314 - custom_f1: 0.5730 - weighted_custom_f1: 0.5774 - val_loss: 0.9559 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8946 - custom_f1: 0.5015 - weighted_custom_f1: 0.5083 - val_loss: 1.0134 - val_custom_f1: 0.4662 - val_weighted_custom_f1: 0.4780\n",
            "Epoch 28/100\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7197 - custom_f1: 0.5757 - weighted_custom_f1: 0.5796 - val_loss: 0.9577 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5276\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7641 - custom_f1: 0.5591 - weighted_custom_f1: 0.5652 - val_loss: 0.9363 - val_custom_f1: 0.4988 - val_weighted_custom_f1: 0.5113\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7540 - custom_f1: 0.5609 - weighted_custom_f1: 0.5675 - val_loss: 0.8805 - val_custom_f1: 0.4990 - val_weighted_custom_f1: 0.5089\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.7277 - custom_f1: 0.5664 - weighted_custom_f1: 0.5704Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6832 - custom_f1: 0.5907 - weighted_custom_f1: 0.5937 - val_loss: 1.1482 - val_custom_f1: 0.5205 - val_weighted_custom_f1: 0.5418\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7751 - custom_f1: 0.5559 - weighted_custom_f1: 0.5600Epoch 28/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7418 - custom_f1: 0.5700 - weighted_custom_f1: 0.5748 - val_loss: 0.9818 - val_custom_f1: 0.5245 - val_weighted_custom_f1: 0.5465\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7102 - custom_f1: 0.5768 - weighted_custom_f1: 0.5836 - val_loss: 0.9733 - val_custom_f1: 0.4811 - val_weighted_custom_f1: 0.4933\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7704 - custom_f1: 0.5622 - weighted_custom_f1: 0.5658 - val_loss: 0.9223 - val_custom_f1: 0.4965 - val_weighted_custom_f1: 0.5089\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.6880 - custom_f1: 0.5880 - weighted_custom_f1: 0.5908Epoch 29/100\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7377 - custom_f1: 0.5679 - weighted_custom_f1: 0.5761 - val_loss: 1.0003 - val_custom_f1: 0.5577 - val_weighted_custom_f1: 0.5644\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.7266 - custom_f1: 0.5738 - weighted_custom_f1: 0.5784Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7272 - custom_f1: 0.5764 - weighted_custom_f1: 0.5824 - val_loss: 0.9989 - val_custom_f1: 0.4929 - val_weighted_custom_f1: 0.4901\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.7208 - custom_f1: 0.5568 - weighted_custom_f1: 0.5624Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7302 - custom_f1: 0.5694 - weighted_custom_f1: 0.5748 - val_loss: 0.9394 - val_custom_f1: 0.4829 - val_weighted_custom_f1: 0.4960\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.7129 - custom_f1: 0.5715 - weighted_custom_f1: 0.5761Epoch 28/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7746 - custom_f1: 0.5552 - weighted_custom_f1: 0.5597 - val_loss: 0.8891 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5222\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.7101 - custom_f1: 0.5724 - weighted_custom_f1: 0.5747Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7305 - custom_f1: 0.5714 - weighted_custom_f1: 0.5753 - val_loss: 1.2178 - val_custom_f1: 0.5345 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7051 - custom_f1: 0.5908 - weighted_custom_f1: 0.5954 - val_loss: 1.0797 - val_custom_f1: 0.4943 - val_weighted_custom_f1: 0.4895\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7328 - custom_f1: 0.5719 - weighted_custom_f1: 0.5753 - val_loss: 0.9628 - val_custom_f1: 0.5139 - val_weighted_custom_f1: 0.5191\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9209 - custom_f1: 0.5011 - weighted_custom_f1: 0.5038 - val_loss: 1.0643 - val_custom_f1: 0.5254 - val_weighted_custom_f1: 0.5293\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7164 - custom_f1: 0.5769 - weighted_custom_f1: 0.5806 - val_loss: 0.9205 - val_custom_f1: 0.4988 - val_weighted_custom_f1: 0.5064\n",
            "Epoch 29/100\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7319 - custom_f1: 0.5791 - weighted_custom_f1: 0.5831 - val_loss: 0.9541 - val_custom_f1: 0.4934 - val_weighted_custom_f1: 0.5149\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7726 - custom_f1: 0.5611 - weighted_custom_f1: 0.5642 - val_loss: 1.0007 - val_custom_f1: 0.5293 - val_weighted_custom_f1: 0.5402\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7489 - custom_f1: 0.5708 - weighted_custom_f1: 0.5745 - val_loss: 0.8939 - val_custom_f1: 0.5131 - val_weighted_custom_f1: 0.5243\n",
            "Epoch 29/100\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6927 - custom_f1: 0.5938 - weighted_custom_f1: 0.5979 - val_loss: 0.9461 - val_custom_f1: 0.5136 - val_weighted_custom_f1: 0.5247\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7573 - custom_f1: 0.5710 - weighted_custom_f1: 0.5748 - val_loss: 0.9258 - val_custom_f1: 0.5037 - val_weighted_custom_f1: 0.5163\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7357 - custom_f1: 0.5743 - weighted_custom_f1: 0.5778 - val_loss: 0.9255 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5289\n",
            "Epoch 30/100\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7309 - custom_f1: 0.5735 - weighted_custom_f1: 0.5769 - val_loss: 1.0052 - val_custom_f1: 0.5307 - val_weighted_custom_f1: 0.5413\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7213 - custom_f1: 0.5771 - weighted_custom_f1: 0.5820 - val_loss: 0.9695 - val_custom_f1: 0.4943 - val_weighted_custom_f1: 0.4969\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.7679 - custom_f1: 0.5482 - weighted_custom_f1: 0.5522Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7353 - custom_f1: 0.5730 - weighted_custom_f1: 0.5762 - val_loss: 0.9117 - val_custom_f1: 0.5177 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7424 - custom_f1: 0.5664 - weighted_custom_f1: 0.5699 - val_loss: 0.9005 - val_custom_f1: 0.4881 - val_weighted_custom_f1: 0.4985\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.6835 - custom_f1: 0.6039 - weighted_custom_f1: 0.6046Epoch 29/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7591 - custom_f1: 0.5635 - weighted_custom_f1: 0.5669 - val_loss: 0.8941 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5058\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7137 - custom_f1: 0.5830 - weighted_custom_f1: 0.5877 - val_loss: 1.0373 - val_custom_f1: 0.5156 - val_weighted_custom_f1: 0.5113\n",
            " 76/105 [====================>.........] - ETA: 0s - loss: 0.7064 - custom_f1: 0.5783 - weighted_custom_f1: 0.5828Epoch 29/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6929 - custom_f1: 0.5911 - weighted_custom_f1: 0.5952 - val_loss: 1.0355 - val_custom_f1: 0.5262 - val_weighted_custom_f1: 0.5255\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7175 - custom_f1: 0.5730 - weighted_custom_f1: 0.5798 - val_loss: 0.9353 - val_custom_f1: 0.4788 - val_weighted_custom_f1: 0.4907\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9322 - custom_f1: 0.5017 - weighted_custom_f1: 0.5057 - val_loss: 1.0614 - val_custom_f1: 0.4906 - val_weighted_custom_f1: 0.5010\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7330 - custom_f1: 0.5730 - weighted_custom_f1: 0.5763 - val_loss: 0.9408 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5055\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7186 - custom_f1: 0.5745 - weighted_custom_f1: 0.5805 - val_loss: 0.9982 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5060\n",
            "Epoch 30/100\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7825 - custom_f1: 0.5607 - weighted_custom_f1: 0.5649 - val_loss: 0.9321 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5088\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7639 - custom_f1: 0.5597 - weighted_custom_f1: 0.5642 - val_loss: 0.9596 - val_custom_f1: 0.4956 - val_weighted_custom_f1: 0.5063\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7046 - custom_f1: 0.5870 - weighted_custom_f1: 0.5907 - val_loss: 0.9798 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5147\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.6925 - custom_f1: 0.5856 - weighted_custom_f1: 0.5937Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7434 - custom_f1: 0.5747 - weighted_custom_f1: 0.5790 - val_loss: 0.9069 - val_custom_f1: 0.4946 - val_weighted_custom_f1: 0.5069\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7555 - custom_f1: 0.5690 - weighted_custom_f1: 0.5750 - val_loss: 0.9498 - val_custom_f1: 0.4673 - val_weighted_custom_f1: 0.4809\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.7589 - custom_f1: 0.5933 - weighted_custom_f1: 0.5999Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7254 - custom_f1: 0.5780 - weighted_custom_f1: 0.5817 - val_loss: 0.9962 - val_custom_f1: 0.5131 - val_weighted_custom_f1: 0.5236\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.7865 - custom_f1: 0.5918 - weighted_custom_f1: 0.5970Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7169 - custom_f1: 0.5756 - weighted_custom_f1: 0.5796 - val_loss: 0.9567 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5106\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.7143 - custom_f1: 0.5869 - weighted_custom_f1: 0.5936Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7225 - custom_f1: 0.5830 - weighted_custom_f1: 0.5861 - val_loss: 1.0080 - val_custom_f1: 0.5323 - val_weighted_custom_f1: 0.5281\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.6806 - custom_f1: 0.5841 - weighted_custom_f1: 0.5884Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7495 - custom_f1: 0.5656 - weighted_custom_f1: 0.5693 - val_loss: 0.9498 - val_custom_f1: 0.4965 - val_weighted_custom_f1: 0.5061\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7867 - custom_f1: 0.5556 - weighted_custom_f1: 0.5606 - val_loss: 0.9716 - val_custom_f1: 0.4357 - val_weighted_custom_f1: 0.4476\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6906 - custom_f1: 0.5853 - weighted_custom_f1: 0.5903 - val_loss: 1.1309 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5229\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7251 - custom_f1: 0.5813 - weighted_custom_f1: 0.5863 - val_loss: 0.9759 - val_custom_f1: 0.5065 - val_weighted_custom_f1: 0.5277\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7200 - custom_f1: 0.5744 - weighted_custom_f1: 0.5801 - val_loss: 1.0043 - val_custom_f1: 0.4795 - val_weighted_custom_f1: 0.4914\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6822 - custom_f1: 0.6076 - weighted_custom_f1: 0.6098 - val_loss: 1.2033 - val_custom_f1: 0.5337 - val_weighted_custom_f1: 0.5302\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7186 - custom_f1: 0.5802 - weighted_custom_f1: 0.5850 - val_loss: 0.9475 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5217\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9008 - custom_f1: 0.5091 - weighted_custom_f1: 0.5153 - val_loss: 1.0714 - val_custom_f1: 0.4353 - val_weighted_custom_f1: 0.4466\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8086 - custom_f1: 0.4776 - weighted_custom_f1: 0.4776Epoch 31/100\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7533 - custom_f1: 0.5723 - weighted_custom_f1: 0.5785 - val_loss: 0.9275 - val_custom_f1: 0.4850 - val_weighted_custom_f1: 0.4939\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.6838 - custom_f1: 0.6049 - weighted_custom_f1: 0.6065Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7346 - custom_f1: 0.5755 - weighted_custom_f1: 0.5801 - val_loss: 0.9272 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5441\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7507 - custom_f1: 0.5674 - weighted_custom_f1: 0.5718Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6710 - custom_f1: 0.5940 - weighted_custom_f1: 0.6003 - val_loss: 1.0310 - val_custom_f1: 0.5081 - val_weighted_custom_f1: 0.5206\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.7869 - custom_f1: 0.5702 - weighted_custom_f1: 0.5735Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7431 - custom_f1: 0.5699 - weighted_custom_f1: 0.5756 - val_loss: 0.9391 - val_custom_f1: 0.4900 - val_weighted_custom_f1: 0.5020\n",
            " 53/105 [==============>...............] - ETA: 0s - loss: 0.6979 - custom_f1: 0.5958 - weighted_custom_f1: 0.5991Epoch 32/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7036 - custom_f1: 0.5883 - weighted_custom_f1: 0.5956 - val_loss: 1.0067 - val_custom_f1: 0.4609 - val_weighted_custom_f1: 0.4740\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7499 - custom_f1: 0.5729 - weighted_custom_f1: 0.5776 - val_loss: 0.9137 - val_custom_f1: 0.4751 - val_weighted_custom_f1: 0.4877\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7132 - custom_f1: 0.5797 - weighted_custom_f1: 0.5844 - val_loss: 0.9574 - val_custom_f1: 0.4635 - val_weighted_custom_f1: 0.4748\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.6942 - custom_f1: 0.5907 - weighted_custom_f1: 0.5968Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6990 - custom_f1: 0.5895 - weighted_custom_f1: 0.5929 - val_loss: 0.9889 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5123\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7504 - custom_f1: 0.5655 - weighted_custom_f1: 0.5712 - val_loss: 0.9075 - val_custom_f1: 0.5257 - val_weighted_custom_f1: 0.5336\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7396 - custom_f1: 0.5707 - weighted_custom_f1: 0.5757 - val_loss: 0.9111 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5287\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.6957 - custom_f1: 0.5900 - weighted_custom_f1: 0.5934Epoch 32/100\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6951 - custom_f1: 0.5905 - weighted_custom_f1: 0.5929 - val_loss: 1.0999 - val_custom_f1: 0.5262 - val_weighted_custom_f1: 0.5187\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.6905 - custom_f1: 0.5876 - weighted_custom_f1: 0.5927Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9010 - custom_f1: 0.5003 - weighted_custom_f1: 0.5069 - val_loss: 0.9927 - val_custom_f1: 0.4902 - val_weighted_custom_f1: 0.5027\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.7388 - custom_f1: 0.5687 - weighted_custom_f1: 0.5741Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6975 - custom_f1: 0.5914 - weighted_custom_f1: 0.5946 - val_loss: 0.9778 - val_custom_f1: 0.4827 - val_weighted_custom_f1: 0.5051\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7123 - custom_f1: 0.5822 - weighted_custom_f1: 0.5888 - val_loss: 0.9123 - val_custom_f1: 0.5036 - val_weighted_custom_f1: 0.5116\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7276 - custom_f1: 0.5798 - weighted_custom_f1: 0.5844 - val_loss: 1.0209 - val_custom_f1: 0.5083 - val_weighted_custom_f1: 0.5158\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6665 - custom_f1: 0.6032 - weighted_custom_f1: 0.6063 - val_loss: 1.0690 - val_custom_f1: 0.5113 - val_weighted_custom_f1: 0.5109\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7188 - custom_f1: 0.5795 - weighted_custom_f1: 0.5856 - val_loss: 0.9631 - val_custom_f1: 0.5423 - val_weighted_custom_f1: 0.5482\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7397 - custom_f1: 0.5673 - weighted_custom_f1: 0.5748 - val_loss: 0.9353 - val_custom_f1: 0.4845 - val_weighted_custom_f1: 0.4955\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6926 - custom_f1: 0.5896 - weighted_custom_f1: 0.5953 - val_loss: 1.0102 - val_custom_f1: 0.5114 - val_weighted_custom_f1: 0.5334\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8631 - custom_f1: 0.4412 - weighted_custom_f1: 0.4412Epoch 32/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7238 - custom_f1: 0.5777 - weighted_custom_f1: 0.5847 - val_loss: 0.9234 - val_custom_f1: 0.5403 - val_weighted_custom_f1: 0.5521\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7289 - custom_f1: 0.5743 - weighted_custom_f1: 0.5802 - val_loss: 0.9491 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5215\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.6712 - custom_f1: 0.6041 - weighted_custom_f1: 0.6078Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6949 - custom_f1: 0.5843 - weighted_custom_f1: 0.5915 - val_loss: 1.0339 - val_custom_f1: 0.4790 - val_weighted_custom_f1: 0.4924\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.7023 - custom_f1: 0.5850 - weighted_custom_f1: 0.5899Epoch 32/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7016 - custom_f1: 0.5823 - weighted_custom_f1: 0.5869 - val_loss: 1.0186 - val_custom_f1: 0.5303 - val_weighted_custom_f1: 0.5267\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.6809 - custom_f1: 0.5981 - weighted_custom_f1: 0.6007Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7308 - custom_f1: 0.5728 - weighted_custom_f1: 0.5795 - val_loss: 0.8857 - val_custom_f1: 0.5150 - val_weighted_custom_f1: 0.5232\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7088 - custom_f1: 0.5851 - weighted_custom_f1: 0.5908 - val_loss: 1.0044 - val_custom_f1: 0.5440 - val_weighted_custom_f1: 0.5559\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.6878 - custom_f1: 0.5960 - weighted_custom_f1: 0.5992Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7447 - custom_f1: 0.5658 - weighted_custom_f1: 0.5720 - val_loss: 0.9186 - val_custom_f1: 0.5104 - val_weighted_custom_f1: 0.5185\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.7458 - custom_f1: 0.5637 - weighted_custom_f1: 0.5683Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6935 - custom_f1: 0.5899 - weighted_custom_f1: 0.5934 - val_loss: 1.0790 - val_custom_f1: 0.5276 - val_weighted_custom_f1: 0.5238\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.7082 - custom_f1: 0.5849 - weighted_custom_f1: 0.5898Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8940 - custom_f1: 0.5081 - weighted_custom_f1: 0.5129 - val_loss: 0.9993 - val_custom_f1: 0.5019 - val_weighted_custom_f1: 0.5118\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.6938 - custom_f1: 0.5933 - weighted_custom_f1: 0.5985Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6950 - custom_f1: 0.5869 - weighted_custom_f1: 0.5900 - val_loss: 0.9899 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4944\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8571 - custom_f1: 0.6133 - weighted_custom_f1: 0.6133Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6970 - custom_f1: 0.5915 - weighted_custom_f1: 0.5969 - val_loss: 0.9617 - val_custom_f1: 0.4587 - val_weighted_custom_f1: 0.4800\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6890 - custom_f1: 0.5875 - weighted_custom_f1: 0.5919 - val_loss: 0.9546 - val_custom_f1: 0.4544 - val_weighted_custom_f1: 0.4667\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.8785 - custom_f1: 0.5205 - weighted_custom_f1: 0.5275Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6750 - custom_f1: 0.6006 - weighted_custom_f1: 0.6055 - val_loss: 1.0553 - val_custom_f1: 0.5439 - val_weighted_custom_f1: 0.5384\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.7131 - custom_f1: 0.5850 - weighted_custom_f1: 0.5918Epoch 33/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7528 - custom_f1: 0.5681 - weighted_custom_f1: 0.5732 - val_loss: 1.0006 - val_custom_f1: 0.5485 - val_weighted_custom_f1: 0.5575\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8163 - custom_f1: 0.7077 - weighted_custom_f1: 0.7077Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7216 - custom_f1: 0.5813 - weighted_custom_f1: 0.5868 - val_loss: 0.9852 - val_custom_f1: 0.4554 - val_weighted_custom_f1: 0.4669\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7855 - custom_f1: 0.7097 - weighted_custom_f1: 0.7097Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7087 - custom_f1: 0.5866 - weighted_custom_f1: 0.5907 - val_loss: 0.9102 - val_custom_f1: 0.4873 - val_weighted_custom_f1: 0.4996\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6504 - custom_f1: 0.6063 - weighted_custom_f1: 0.6094 - val_loss: 1.0168 - val_custom_f1: 0.4766 - val_weighted_custom_f1: 0.4885\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7238 - custom_f1: 0.5790 - weighted_custom_f1: 0.5861 - val_loss: 1.0200 - val_custom_f1: 0.5285 - val_weighted_custom_f1: 0.5367\n",
            "Epoch 33/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6787 - custom_f1: 0.5991 - weighted_custom_f1: 0.6039 - val_loss: 1.0879 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5297\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6863 - custom_f1: 0.5931 - weighted_custom_f1: 0.5968 - val_loss: 1.0012 - val_custom_f1: 0.5268 - val_weighted_custom_f1: 0.5267\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.7125 - custom_f1: 0.5837 - weighted_custom_f1: 0.5895Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6899 - custom_f1: 0.5919 - weighted_custom_f1: 0.5970 - val_loss: 0.9483 - val_custom_f1: 0.5094 - val_weighted_custom_f1: 0.5229\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7051 - custom_f1: 0.5827 - weighted_custom_f1: 0.5874 - val_loss: 0.9235 - val_custom_f1: 0.4612 - val_weighted_custom_f1: 0.4743\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.6963 - custom_f1: 0.5797 - weighted_custom_f1: 0.5880Epoch 33/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7252 - custom_f1: 0.5769 - weighted_custom_f1: 0.5840 - val_loss: 0.9029 - val_custom_f1: 0.5117 - val_weighted_custom_f1: 0.5200\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.8993 - custom_f1: 0.5116 - weighted_custom_f1: 0.5174Epoch 34/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6906 - custom_f1: 0.5880 - weighted_custom_f1: 0.5914 - val_loss: 0.9448 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5304\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8984 - custom_f1: 0.5067 - weighted_custom_f1: 0.5141 - val_loss: 1.0662 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5203\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6927 - custom_f1: 0.5939 - weighted_custom_f1: 0.5984 - val_loss: 1.1105 - val_custom_f1: 0.5367 - val_weighted_custom_f1: 0.5298\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7135 - custom_f1: 0.5846 - weighted_custom_f1: 0.5895 - val_loss: 0.9719 - val_custom_f1: 0.4812 - val_weighted_custom_f1: 0.4938\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7085 - custom_f1: 0.5824 - weighted_custom_f1: 0.5892 - val_loss: 1.0144 - val_custom_f1: 0.4340 - val_weighted_custom_f1: 0.4448\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6498 - custom_f1: 0.6115 - weighted_custom_f1: 0.6155 - val_loss: 1.0906 - val_custom_f1: 0.5065 - val_weighted_custom_f1: 0.5066\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.6779 - custom_f1: 0.5964 - weighted_custom_f1: 0.6030Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7380 - custom_f1: 0.5794 - weighted_custom_f1: 0.5863 - val_loss: 0.9601 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5177\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.9018 - custom_f1: 0.5042 - weighted_custom_f1: 0.5108Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6741 - custom_f1: 0.6007 - weighted_custom_f1: 0.6055 - val_loss: 0.9893 - val_custom_f1: 0.4594 - val_weighted_custom_f1: 0.4803\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7548 - custom_f1: 0.5677 - weighted_custom_f1: 0.5752 - val_loss: 1.0354 - val_custom_f1: 0.5255 - val_weighted_custom_f1: 0.5334\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7086 - custom_f1: 0.5857 - weighted_custom_f1: 0.5923 - val_loss: 0.9336 - val_custom_f1: 0.4545 - val_weighted_custom_f1: 0.4665\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.6835 - custom_f1: 0.6050 - weighted_custom_f1: 0.6092Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7271 - custom_f1: 0.5749 - weighted_custom_f1: 0.5800 - val_loss: 0.9573 - val_custom_f1: 0.4682 - val_weighted_custom_f1: 0.4810\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6930 - custom_f1: 0.5864 - weighted_custom_f1: 0.5940 - val_loss: 1.0870 - val_custom_f1: 0.5161 - val_weighted_custom_f1: 0.5241\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6827 - custom_f1: 0.5934 - weighted_custom_f1: 0.6006 - val_loss: 0.9629 - val_custom_f1: 0.4980 - val_weighted_custom_f1: 0.5091\n",
            " 53/105 [==============>...............] - ETA: 0s - loss: 0.6322 - custom_f1: 0.6207 - weighted_custom_f1: 0.6237Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7141 - custom_f1: 0.5731 - weighted_custom_f1: 0.5799 - val_loss: 0.9460 - val_custom_f1: 0.5094 - val_weighted_custom_f1: 0.5216\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6821 - custom_f1: 0.5924 - weighted_custom_f1: 0.5978 - val_loss: 1.0177 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5302\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7368 - custom_f1: 0.5747 - weighted_custom_f1: 0.5792 - val_loss: 0.9888 - val_custom_f1: 0.4347 - val_weighted_custom_f1: 0.4470\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6810 - custom_f1: 0.5949 - weighted_custom_f1: 0.5989 - val_loss: 1.0969 - val_custom_f1: 0.5036 - val_weighted_custom_f1: 0.4986\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8957 - custom_f1: 0.5113 - weighted_custom_f1: 0.5167 - val_loss: 1.0663 - val_custom_f1: 0.4857 - val_weighted_custom_f1: 0.4964\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7052 - custom_f1: 0.5850 - weighted_custom_f1: 0.5891 - val_loss: 1.0425 - val_custom_f1: 0.5151 - val_weighted_custom_f1: 0.5232\n",
            "Epoch 35/100\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.6725 - custom_f1: 0.5986 - weighted_custom_f1: 0.6032Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6815 - custom_f1: 0.5944 - weighted_custom_f1: 0.5976 - val_loss: 0.9403 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5086\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6537 - custom_f1: 0.6116 - weighted_custom_f1: 0.6160 - val_loss: 1.0766 - val_custom_f1: 0.5282 - val_weighted_custom_f1: 0.5260\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.7154 - custom_f1: 0.5819 - weighted_custom_f1: 0.5847Epoch 35/100\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7133 - custom_f1: 0.5933 - weighted_custom_f1: 0.5986 - val_loss: 0.9431 - val_custom_f1: 0.4933 - val_weighted_custom_f1: 0.5159\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7113 - custom_f1: 0.5805 - weighted_custom_f1: 0.5852 - val_loss: 1.0960 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4953\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.7331 - custom_f1: 0.5867 - weighted_custom_f1: 0.5918Epoch 35/100\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7371 - custom_f1: 0.5733 - weighted_custom_f1: 0.5780 - val_loss: 0.9965 - val_custom_f1: 0.4998 - val_weighted_custom_f1: 0.5095\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.6752 - custom_f1: 0.5928 - weighted_custom_f1: 0.5969Epoch 35/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6640 - custom_f1: 0.6004 - weighted_custom_f1: 0.6047 - val_loss: 0.9839 - val_custom_f1: 0.5337 - val_weighted_custom_f1: 0.5425\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.6466 - custom_f1: 0.5872 - weighted_custom_f1: 0.5894Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7020 - custom_f1: 0.5978 - weighted_custom_f1: 0.6012 - val_loss: 0.9413 - val_custom_f1: 0.4704 - val_weighted_custom_f1: 0.4823\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.6820 - custom_f1: 0.6024 - weighted_custom_f1: 0.6070Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7240 - custom_f1: 0.5793 - weighted_custom_f1: 0.5841 - val_loss: 0.9431 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5253\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6729 - custom_f1: 0.5981 - weighted_custom_f1: 0.6030 - val_loss: 1.0102 - val_custom_f1: 0.5014 - val_weighted_custom_f1: 0.5124\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6759 - custom_f1: 0.5925 - weighted_custom_f1: 0.5969 - val_loss: 0.9611 - val_custom_f1: 0.4973 - val_weighted_custom_f1: 0.5098\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7197 - custom_f1: 0.5795 - weighted_custom_f1: 0.5828 - val_loss: 0.9192 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5272\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.6859 - custom_f1: 0.5986 - weighted_custom_f1: 0.6038Epoch 35/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6867 - custom_f1: 0.5936 - weighted_custom_f1: 0.5984 - val_loss: 0.9822 - val_custom_f1: 0.4941 - val_weighted_custom_f1: 0.4951\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.6933 - custom_f1: 0.5925 - weighted_custom_f1: 0.5963Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7420 - custom_f1: 0.5729 - weighted_custom_f1: 0.5790 - val_loss: 0.9012 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5271\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.7330 - custom_f1: 0.5804 - weighted_custom_f1: 0.5851Epoch 36/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8996 - custom_f1: 0.5120 - weighted_custom_f1: 0.5176 - val_loss: 1.1096 - val_custom_f1: 0.4473 - val_weighted_custom_f1: 0.4589\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7071 - custom_f1: 0.5894 - weighted_custom_f1: 0.5939 - val_loss: 1.0305 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5259\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.7364 - custom_f1: 0.5837 - weighted_custom_f1: 0.5887Epoch 36/100\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6828 - custom_f1: 0.5899 - weighted_custom_f1: 0.5942 - val_loss: 1.1697 - val_custom_f1: 0.5458 - val_weighted_custom_f1: 0.5354\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.6560 - custom_f1: 0.6072 - weighted_custom_f1: 0.6113Epoch 35/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6906 - custom_f1: 0.5922 - weighted_custom_f1: 0.5956 - val_loss: 0.9355 - val_custom_f1: 0.4886 - val_weighted_custom_f1: 0.5115\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6811 - custom_f1: 0.5947 - weighted_custom_f1: 0.6011 - val_loss: 0.9492 - val_custom_f1: 0.5115 - val_weighted_custom_f1: 0.5211\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6472 - custom_f1: 0.6146 - weighted_custom_f1: 0.6187 - val_loss: 1.0607 - val_custom_f1: 0.5359 - val_weighted_custom_f1: 0.5320\n",
            "  9/105 [=>............................] - ETA: 0s - loss: 0.6762 - custom_f1: 0.6087 - weighted_custom_f1: 0.6199Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7327 - custom_f1: 0.5782 - weighted_custom_f1: 0.5841 - val_loss: 0.9536 - val_custom_f1: 0.4891 - val_weighted_custom_f1: 0.4999\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7335 - custom_f1: 0.5766 - weighted_custom_f1: 0.5817 - val_loss: 0.9226 - val_custom_f1: 0.4916 - val_weighted_custom_f1: 0.5022\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6547 - custom_f1: 0.6091 - weighted_custom_f1: 0.6141 - val_loss: 1.0165 - val_custom_f1: 0.4995 - val_weighted_custom_f1: 0.5214\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.7118 - custom_f1: 0.5884 - weighted_custom_f1: 0.5937Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7307 - custom_f1: 0.5818 - weighted_custom_f1: 0.5869 - val_loss: 0.9745 - val_custom_f1: 0.5278 - val_weighted_custom_f1: 0.5364\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7109 - custom_f1: 0.5872 - weighted_custom_f1: 0.5928 - val_loss: 0.9230 - val_custom_f1: 0.5212 - val_weighted_custom_f1: 0.5444\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6690 - custom_f1: 0.6005 - weighted_custom_f1: 0.6053 - val_loss: 1.0307 - val_custom_f1: 0.4540 - val_weighted_custom_f1: 0.4662\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.6789 - custom_f1: 0.5989 - weighted_custom_f1: 0.6012Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7003 - custom_f1: 0.5930 - weighted_custom_f1: 0.5998 - val_loss: 0.9520 - val_custom_f1: 0.4989 - val_weighted_custom_f1: 0.5111\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5844 - custom_f1: 0.4127 - weighted_custom_f1: 0.4127Epoch 36/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6680 - custom_f1: 0.5995 - weighted_custom_f1: 0.6050 - val_loss: 1.0080 - val_custom_f1: 0.4960 - val_weighted_custom_f1: 0.4953\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.6329 - custom_f1: 0.6283 - weighted_custom_f1: 0.6321Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7339 - custom_f1: 0.5751 - weighted_custom_f1: 0.5814 - val_loss: 0.9386 - val_custom_f1: 0.4900 - val_weighted_custom_f1: 0.5022\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.6512 - custom_f1: 0.6011 - weighted_custom_f1: 0.6051Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7222 - custom_f1: 0.5836 - weighted_custom_f1: 0.5884 - val_loss: 0.9041 - val_custom_f1: 0.4741 - val_weighted_custom_f1: 0.4874\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.6908 - custom_f1: 0.5985 - weighted_custom_f1: 0.6028Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6761 - custom_f1: 0.5993 - weighted_custom_f1: 0.6036 - val_loss: 1.0640 - val_custom_f1: 0.5348 - val_weighted_custom_f1: 0.5305\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.7087 - custom_f1: 0.5997 - weighted_custom_f1: 0.6044Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8954 - custom_f1: 0.5077 - weighted_custom_f1: 0.5129 - val_loss: 1.1422 - val_custom_f1: 0.4540 - val_weighted_custom_f1: 0.4640\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6880 - custom_f1: 0.5946 - weighted_custom_f1: 0.5982 - val_loss: 1.0428 - val_custom_f1: 0.4844 - val_weighted_custom_f1: 0.4939\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0009 - custom_f1: 0.4595 - weighted_custom_f1: 0.4595Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6750 - custom_f1: 0.5966 - weighted_custom_f1: 0.6023 - val_loss: 0.9773 - val_custom_f1: 0.5037 - val_weighted_custom_f1: 0.5251\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6581 - custom_f1: 0.6040 - weighted_custom_f1: 0.6071 - val_loss: 0.9691 - val_custom_f1: 0.4740 - val_weighted_custom_f1: 0.4833\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.6606 - custom_f1: 0.6077 - weighted_custom_f1: 0.6122Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6248 - custom_f1: 0.6224 - weighted_custom_f1: 0.6277 - val_loss: 1.1696 - val_custom_f1: 0.5237 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6996 - custom_f1: 0.5926 - weighted_custom_f1: 0.5973 - val_loss: 0.9637 - val_custom_f1: 0.4543 - val_weighted_custom_f1: 0.4662\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5960 - custom_f1: 0.6316 - weighted_custom_f1: 0.6316Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7094 - custom_f1: 0.5888 - weighted_custom_f1: 0.5938 - val_loss: 0.9473 - val_custom_f1: 0.4903 - val_weighted_custom_f1: 0.5022\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6432 - custom_f1: 0.6092 - weighted_custom_f1: 0.6129 - val_loss: 1.0338 - val_custom_f1: 0.4964 - val_weighted_custom_f1: 0.5079\n",
            "Epoch 37/100\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7097 - custom_f1: 0.5804 - weighted_custom_f1: 0.5860 - val_loss: 0.9795 - val_custom_f1: 0.5199 - val_weighted_custom_f1: 0.5278\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6832 - custom_f1: 0.5988 - weighted_custom_f1: 0.6027 - val_loss: 0.8957 - val_custom_f1: 0.4972 - val_weighted_custom_f1: 0.5096\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6674 - custom_f1: 0.6064 - weighted_custom_f1: 0.6107 - val_loss: 1.0021 - val_custom_f1: 0.4578 - val_weighted_custom_f1: 0.4687\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.6640 - custom_f1: 0.6059 - weighted_custom_f1: 0.6097Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6634 - custom_f1: 0.6046 - weighted_custom_f1: 0.6092 - val_loss: 1.0227 - val_custom_f1: 0.5031 - val_weighted_custom_f1: 0.5138\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6721 - custom_f1: 0.6025 - weighted_custom_f1: 0.6080 - val_loss: 1.0874 - val_custom_f1: 0.5410 - val_weighted_custom_f1: 0.5393\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.6771 - custom_f1: 0.5923 - weighted_custom_f1: 0.5972Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7009 - custom_f1: 0.5888 - weighted_custom_f1: 0.5921 - val_loss: 0.9352 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.5010\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.6994 - custom_f1: 0.6033 - weighted_custom_f1: 0.6073Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7225 - custom_f1: 0.5846 - weighted_custom_f1: 0.5903 - val_loss: 0.8869 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5165\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.6667 - custom_f1: 0.6088 - weighted_custom_f1: 0.6133Epoch 38/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6812 - custom_f1: 0.5908 - weighted_custom_f1: 0.5950 - val_loss: 1.0550 - val_custom_f1: 0.5272 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9007 - custom_f1: 0.5047 - weighted_custom_f1: 0.5089 - val_loss: 1.0984 - val_custom_f1: 0.5097 - val_weighted_custom_f1: 0.5203\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6644 - custom_f1: 0.6027 - weighted_custom_f1: 0.6081 - val_loss: 1.0291 - val_custom_f1: 0.5151 - val_weighted_custom_f1: 0.5364\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8098 - custom_f1: 0.5000 - weighted_custom_f1: 0.5000Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6865 - custom_f1: 0.5955 - weighted_custom_f1: 0.6008 - val_loss: 1.0720 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.7153 - custom_f1: 0.5958 - weighted_custom_f1: 0.6004 - val_loss: 0.9486 - val_custom_f1: 0.4876 - val_weighted_custom_f1: 0.4997\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6397 - custom_f1: 0.5574 - weighted_custom_f1: 0.5574Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7137 - custom_f1: 0.5846 - weighted_custom_f1: 0.5900 - val_loss: 1.1267 - val_custom_f1: 0.4840 - val_weighted_custom_f1: 0.5049\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 0.6880 - custom_f1: 0.6019 - weighted_custom_f1: 0.6056Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6322 - custom_f1: 0.6240 - weighted_custom_f1: 0.6285 - val_loss: 1.2672 - val_custom_f1: 0.5071 - val_weighted_custom_f1: 0.5079\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6397 - custom_f1: 0.6082 - weighted_custom_f1: 0.6135 - val_loss: 1.1153 - val_custom_f1: 0.5140 - val_weighted_custom_f1: 0.5357\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.7127 - custom_f1: 0.5906 - weighted_custom_f1: 0.5942Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7225 - custom_f1: 0.5806 - weighted_custom_f1: 0.5844 - val_loss: 0.9591 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5409\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7001 - custom_f1: 0.5864 - weighted_custom_f1: 0.5911 - val_loss: 0.9759 - val_custom_f1: 0.4933 - val_weighted_custom_f1: 0.5071\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6881 - custom_f1: 0.5940 - weighted_custom_f1: 0.5988 - val_loss: 0.9238 - val_custom_f1: 0.5268 - val_weighted_custom_f1: 0.5361\n",
            "Epoch 39/100\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6648 - custom_f1: 0.6066 - weighted_custom_f1: 0.6106 - val_loss: 0.9980 - val_custom_f1: 0.5188 - val_weighted_custom_f1: 0.5197\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6866 - custom_f1: 0.6080 - weighted_custom_f1: 0.6126Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6770 - custom_f1: 0.5998 - weighted_custom_f1: 0.6043 - val_loss: 0.9868 - val_custom_f1: 0.5032 - val_weighted_custom_f1: 0.5141\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6574 - custom_f1: 0.6083 - weighted_custom_f1: 0.6123 - val_loss: 1.0296 - val_custom_f1: 0.5109 - val_weighted_custom_f1: 0.5191\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.6348 - custom_f1: 0.6200 - weighted_custom_f1: 0.6253Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7292 - custom_f1: 0.5785 - weighted_custom_f1: 0.5823 - val_loss: 0.9698 - val_custom_f1: 0.4945 - val_weighted_custom_f1: 0.5026\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7008 - custom_f1: 0.5882 - weighted_custom_f1: 0.5938 - val_loss: 0.9266 - val_custom_f1: 0.4859 - val_weighted_custom_f1: 0.4961\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.6813 - custom_f1: 0.5983 - weighted_custom_f1: 0.6027Epoch 38/100\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8955 - custom_f1: 0.5011 - weighted_custom_f1: 0.5060 - val_loss: 1.1160 - val_custom_f1: 0.4725 - val_weighted_custom_f1: 0.4852\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6497 - custom_f1: 0.6085 - weighted_custom_f1: 0.6154 - val_loss: 1.0618 - val_custom_f1: 0.5077 - val_weighted_custom_f1: 0.5104\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.6457 - custom_f1: 0.6213 - weighted_custom_f1: 0.6252Epoch 39/100\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6798 - custom_f1: 0.5981 - weighted_custom_f1: 0.6034 - val_loss: 1.0928 - val_custom_f1: 0.5158 - val_weighted_custom_f1: 0.5127\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6641 - custom_f1: 0.6033 - weighted_custom_f1: 0.6075 - val_loss: 0.9720 - val_custom_f1: 0.4775 - val_weighted_custom_f1: 0.4996\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6725 - custom_f1: 0.5969 - weighted_custom_f1: 0.6028 - val_loss: 1.1745 - val_custom_f1: 0.4889 - val_weighted_custom_f1: 0.5092\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5996 - custom_f1: 0.6316 - weighted_custom_f1: 0.6316Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6795 - custom_f1: 0.6033 - weighted_custom_f1: 0.6087 - val_loss: 0.9921 - val_custom_f1: 0.5213 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6351 - custom_f1: 0.6193 - weighted_custom_f1: 0.6229 - val_loss: 1.1742 - val_custom_f1: 0.5318 - val_weighted_custom_f1: 0.5321\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.7032 - custom_f1: 0.5916 - weighted_custom_f1: 0.5952Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6296 - custom_f1: 0.6198 - weighted_custom_f1: 0.6258 - val_loss: 1.0868 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5356\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7349 - custom_f1: 0.5803 - weighted_custom_f1: 0.5850 - val_loss: 1.0125 - val_custom_f1: 0.4628 - val_weighted_custom_f1: 0.4726\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.6788 - custom_f1: 0.6073 - weighted_custom_f1: 0.6110Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6957 - custom_f1: 0.5932 - weighted_custom_f1: 0.5975 - val_loss: 0.9646 - val_custom_f1: 0.5290 - val_weighted_custom_f1: 0.5371\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.6947 - custom_f1: 0.5891 - weighted_custom_f1: 0.5948Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6753 - custom_f1: 0.6046 - weighted_custom_f1: 0.6110 - val_loss: 0.9102 - val_custom_f1: 0.5104 - val_weighted_custom_f1: 0.5322\n",
            " 53/105 [==============>...............] - ETA: 0s - loss: 0.6553 - custom_f1: 0.6148 - weighted_custom_f1: 0.6206Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6595 - custom_f1: 0.6082 - weighted_custom_f1: 0.6141 - val_loss: 1.0248 - val_custom_f1: 0.5221 - val_weighted_custom_f1: 0.5237\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.6579 - custom_f1: 0.6118 - weighted_custom_f1: 0.6162Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6485 - custom_f1: 0.6059 - weighted_custom_f1: 0.6110 - val_loss: 0.9827 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5294\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.8973 - custom_f1: 0.4987 - weighted_custom_f1: 0.5041Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6747 - custom_f1: 0.5987 - weighted_custom_f1: 0.6037 - val_loss: 1.0724 - val_custom_f1: 0.4652 - val_weighted_custom_f1: 0.4769\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6970 - custom_f1: 0.5862 - weighted_custom_f1: 0.5931 - val_loss: 0.9832 - val_custom_f1: 0.5118 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6958 - custom_f1: 0.5903 - weighted_custom_f1: 0.5934 - val_loss: 0.9081 - val_custom_f1: 0.5267 - val_weighted_custom_f1: 0.5349\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6482 - custom_f1: 0.6164 - weighted_custom_f1: 0.6197 - val_loss: 1.0155 - val_custom_f1: 0.4975 - val_weighted_custom_f1: 0.5053\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.6485 - custom_f1: 0.6170 - weighted_custom_f1: 0.6213Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9024 - custom_f1: 0.5013 - weighted_custom_f1: 0.5065 - val_loss: 1.0768 - val_custom_f1: 0.4565 - val_weighted_custom_f1: 0.4680\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6345 - custom_f1: 0.6099 - weighted_custom_f1: 0.6141Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6634 - custom_f1: 0.6103 - weighted_custom_f1: 0.6140 - val_loss: 1.0619 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5047\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.6615 - custom_f1: 0.6157 - weighted_custom_f1: 0.6208Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6624 - custom_f1: 0.6015 - weighted_custom_f1: 0.6055 - val_loss: 1.1874 - val_custom_f1: 0.5433 - val_weighted_custom_f1: 0.5361\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6588 - custom_f1: 0.6051 - weighted_custom_f1: 0.6084 - val_loss: 0.9574 - val_custom_f1: 0.4872 - val_weighted_custom_f1: 0.5098\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.6547 - custom_f1: 0.6139 - weighted_custom_f1: 0.6190Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6729 - custom_f1: 0.6080 - weighted_custom_f1: 0.6120 - val_loss: 0.9488 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.5131\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6316 - custom_f1: 0.6199 - weighted_custom_f1: 0.6245 - val_loss: 1.1203 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5338\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6205 - custom_f1: 0.6272 - weighted_custom_f1: 0.6328 - val_loss: 1.2997 - val_custom_f1: 0.5428 - val_weighted_custom_f1: 0.5441\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.6332 - custom_f1: 0.6069 - weighted_custom_f1: 0.6115Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7061 - custom_f1: 0.5872 - weighted_custom_f1: 0.5923 - val_loss: 0.9511 - val_custom_f1: 0.5198 - val_weighted_custom_f1: 0.5310\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6956 - custom_f1: 0.5944 - weighted_custom_f1: 0.5987 - val_loss: 0.9789 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5299\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6673 - custom_f1: 0.6052 - weighted_custom_f1: 0.6087 - val_loss: 0.9305 - val_custom_f1: 0.5084 - val_weighted_custom_f1: 0.5316\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6459 - custom_f1: 0.6057 - weighted_custom_f1: 0.6092 - val_loss: 1.0423 - val_custom_f1: 0.5506 - val_weighted_custom_f1: 0.5574\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6535 - custom_f1: 0.6120 - weighted_custom_f1: 0.6168 - val_loss: 1.0135 - val_custom_f1: 0.4734 - val_weighted_custom_f1: 0.4727\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.6580 - custom_f1: 0.5992 - weighted_custom_f1: 0.6032Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6636 - custom_f1: 0.6086 - weighted_custom_f1: 0.6137 - val_loss: 1.0235 - val_custom_f1: 0.5099 - val_weighted_custom_f1: 0.5201\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6947 - custom_f1: 0.5942 - weighted_custom_f1: 0.5976 - val_loss: 0.9549 - val_custom_f1: 0.4880 - val_weighted_custom_f1: 0.4980\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.6531 - custom_f1: 0.6097 - weighted_custom_f1: 0.6144Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7036 - custom_f1: 0.5903 - weighted_custom_f1: 0.5957 - val_loss: 0.9120 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5290\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6562 - custom_f1: 0.5961 - weighted_custom_f1: 0.6004 - val_loss: 0.9930 - val_custom_f1: 0.4880 - val_weighted_custom_f1: 0.4975\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6625 - custom_f1: 0.6018 - weighted_custom_f1: 0.6059 - val_loss: 1.0222 - val_custom_f1: 0.4847 - val_weighted_custom_f1: 0.4946\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8979 - custom_f1: 0.5048 - weighted_custom_f1: 0.5092 - val_loss: 1.1186 - val_custom_f1: 0.4706 - val_weighted_custom_f1: 0.4827\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6268 - custom_f1: 0.5797 - weighted_custom_f1: 0.5797Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6828 - custom_f1: 0.5980 - weighted_custom_f1: 0.6041 - val_loss: 1.1762 - val_custom_f1: 0.5378 - val_weighted_custom_f1: 0.5341\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6563 - custom_f1: 0.6128 - weighted_custom_f1: 0.6168 - val_loss: 1.0211 - val_custom_f1: 0.5233 - val_weighted_custom_f1: 0.5456\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6182 - custom_f1: 0.6188 - weighted_custom_f1: 0.6227 - val_loss: 1.0178 - val_custom_f1: 0.4803 - val_weighted_custom_f1: 0.4917\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.6547 - custom_f1: 0.6002 - weighted_custom_f1: 0.6052Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6851 - custom_f1: 0.5970 - weighted_custom_f1: 0.6017 - val_loss: 0.9966 - val_custom_f1: 0.5075 - val_weighted_custom_f1: 0.5152\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.6518 - custom_f1: 0.6050 - weighted_custom_f1: 0.6097Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6200 - custom_f1: 0.6268 - weighted_custom_f1: 0.6306 - val_loss: 1.0810 - val_custom_f1: 0.4907 - val_weighted_custom_f1: 0.4875\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6852 - custom_f1: 0.5997 - weighted_custom_f1: 0.6032 - val_loss: 0.9835 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5197\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.6498 - custom_f1: 0.6192 - weighted_custom_f1: 0.6242Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6992 - custom_f1: 0.5925 - weighted_custom_f1: 0.5967 - val_loss: 0.9744 - val_custom_f1: 0.5141 - val_weighted_custom_f1: 0.5241\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.6858 - custom_f1: 0.5926 - weighted_custom_f1: 0.5967Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6684 - custom_f1: 0.6052 - weighted_custom_f1: 0.6101 - val_loss: 0.9209 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5142\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.6291 - custom_f1: 0.6138 - weighted_custom_f1: 0.6173Epoch 41/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6489 - custom_f1: 0.6124 - weighted_custom_f1: 0.6180 - val_loss: 1.0190 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5143\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6769 - custom_f1: 0.5982 - weighted_custom_f1: 0.6028 - val_loss: 0.9881 - val_custom_f1: 0.5267 - val_weighted_custom_f1: 0.5355\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6936 - custom_f1: 0.5848 - weighted_custom_f1: 0.5896 - val_loss: 0.9622 - val_custom_f1: 0.4801 - val_weighted_custom_f1: 0.4928\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6503 - custom_f1: 0.6070 - weighted_custom_f1: 0.6109 - val_loss: 1.1199 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5313\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.6601 - custom_f1: 0.5995 - weighted_custom_f1: 0.6042Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6926 - custom_f1: 0.5944 - weighted_custom_f1: 0.5978 - val_loss: 0.9925 - val_custom_f1: 0.5510 - val_weighted_custom_f1: 0.5587\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6595 - custom_f1: 0.6024 - weighted_custom_f1: 0.6069 - val_loss: 1.0057 - val_custom_f1: 0.5190 - val_weighted_custom_f1: 0.5242\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9092 - custom_f1: 0.5028 - weighted_custom_f1: 0.5068 - val_loss: 0.9989 - val_custom_f1: 0.5028 - val_weighted_custom_f1: 0.5125\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6380 - custom_f1: 0.6078 - weighted_custom_f1: 0.6110 - val_loss: 1.0565 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 42/100\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6438 - custom_f1: 0.6093 - weighted_custom_f1: 0.6135 - val_loss: 0.9696 - val_custom_f1: 0.4902 - val_weighted_custom_f1: 0.5119\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.6922 - custom_f1: 0.5942 - weighted_custom_f1: 0.5988Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6269 - custom_f1: 0.6302 - weighted_custom_f1: 0.6340 - val_loss: 1.0836 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5344\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6869 - custom_f1: 0.5941 - weighted_custom_f1: 0.5978 - val_loss: 1.1111 - val_custom_f1: 0.5011 - val_weighted_custom_f1: 0.4962\n",
            " 60/105 [================>.............] - ETA: 0s - loss: 0.6638 - custom_f1: 0.6053 - weighted_custom_f1: 0.6087Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6723 - custom_f1: 0.5993 - weighted_custom_f1: 0.6022 - val_loss: 0.9934 - val_custom_f1: 0.5359 - val_weighted_custom_f1: 0.5439\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.6246 - custom_f1: 0.6220 - weighted_custom_f1: 0.6246Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6181 - custom_f1: 0.6289 - weighted_custom_f1: 0.6342 - val_loss: 1.1773 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5441\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.6705 - custom_f1: 0.6278 - weighted_custom_f1: 0.6305Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6736 - custom_f1: 0.6063 - weighted_custom_f1: 0.6102 - val_loss: 0.9596 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5117\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6833 - custom_f1: 0.6000 - weighted_custom_f1: 0.6027 - val_loss: 0.9808 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5393\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.6306 - custom_f1: 0.6198 - weighted_custom_f1: 0.6224Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6668 - custom_f1: 0.6091 - weighted_custom_f1: 0.6121 - val_loss: 0.9406 - val_custom_f1: 0.5285 - val_weighted_custom_f1: 0.5376\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6356 - custom_f1: 0.6189 - weighted_custom_f1: 0.6216 - val_loss: 1.1506 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5297\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.6539 - custom_f1: 0.6215 - weighted_custom_f1: 0.6256Epoch 42/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6409 - custom_f1: 0.6181 - weighted_custom_f1: 0.6220 - val_loss: 1.0458 - val_custom_f1: 0.4952 - val_weighted_custom_f1: 0.4960\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.5920 - custom_f1: 0.6356 - weighted_custom_f1: 0.6393Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6378 - custom_f1: 0.6120 - weighted_custom_f1: 0.6150 - val_loss: 1.0417 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5409\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6735 - custom_f1: 0.5977 - weighted_custom_f1: 0.6003 - val_loss: 0.9737 - val_custom_f1: 0.4869 - val_weighted_custom_f1: 0.4986\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.6137 - custom_f1: 0.6409 - weighted_custom_f1: 0.6455Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6797 - custom_f1: 0.5977 - weighted_custom_f1: 0.6028 - val_loss: 0.9413 - val_custom_f1: 0.4816 - val_weighted_custom_f1: 0.4939\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6361 - custom_f1: 0.6122 - weighted_custom_f1: 0.6162 - val_loss: 1.1617 - val_custom_f1: 0.5088 - val_weighted_custom_f1: 0.5316\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6227 - custom_f1: 0.6197 - weighted_custom_f1: 0.6239 - val_loss: 1.0890 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5250\n",
            "Epoch 43/100\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.6731 - custom_f1: 0.5928 - weighted_custom_f1: 0.5961Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8915 - custom_f1: 0.5027 - weighted_custom_f1: 0.5063 - val_loss: 1.0778 - val_custom_f1: 0.4646 - val_weighted_custom_f1: 0.4759\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6562 - custom_f1: 0.6090 - weighted_custom_f1: 0.6154 - val_loss: 1.0087 - val_custom_f1: 0.4555 - val_weighted_custom_f1: 0.4674\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5941 - custom_f1: 0.6324 - weighted_custom_f1: 0.6367 - val_loss: 1.0569 - val_custom_f1: 0.5148 - val_weighted_custom_f1: 0.5255\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6388 - custom_f1: 0.6114 - weighted_custom_f1: 0.6151Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6549 - custom_f1: 0.6060 - weighted_custom_f1: 0.6111 - val_loss: 1.1815 - val_custom_f1: 0.5326 - val_weighted_custom_f1: 0.5288\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.6195 - custom_f1: 0.6170 - weighted_custom_f1: 0.6222Epoch 42/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6676 - custom_f1: 0.6029 - weighted_custom_f1: 0.6070 - val_loss: 0.9366 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5302\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.8790 - custom_f1: 0.5089 - weighted_custom_f1: 0.5140Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6080 - custom_f1: 0.6356 - weighted_custom_f1: 0.6407 - val_loss: 1.1303 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5211\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6796 - custom_f1: 0.5984 - weighted_custom_f1: 0.6054 - val_loss: 0.9903 - val_custom_f1: 0.5165 - val_weighted_custom_f1: 0.5258\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.6333 - custom_f1: 0.6333 - weighted_custom_f1: 0.6367Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6775 - custom_f1: 0.5941 - weighted_custom_f1: 0.5981 - val_loss: 0.9901 - val_custom_f1: 0.4927 - val_weighted_custom_f1: 0.5031\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.6252 - custom_f1: 0.6022 - weighted_custom_f1: 0.6076Epoch 43/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6468 - custom_f1: 0.6116 - weighted_custom_f1: 0.6163 - val_loss: 0.9412 - val_custom_f1: 0.5197 - val_weighted_custom_f1: 0.5290\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.6430 - custom_f1: 0.6033 - weighted_custom_f1: 0.6060Epoch 43/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6317 - custom_f1: 0.6198 - weighted_custom_f1: 0.6231 - val_loss: 1.0239 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6561 - custom_f1: 0.6038 - weighted_custom_f1: 0.6089 - val_loss: 0.9865 - val_custom_f1: 0.5126 - val_weighted_custom_f1: 0.5245\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6280 - custom_f1: 0.6193 - weighted_custom_f1: 0.6235 - val_loss: 0.9970 - val_custom_f1: 0.5143 - val_weighted_custom_f1: 0.5263\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.7175 - custom_f1: 0.5745 - weighted_custom_f1: 0.5800Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6346 - custom_f1: 0.6203 - weighted_custom_f1: 0.6239 - val_loss: 1.0680 - val_custom_f1: 0.4793 - val_weighted_custom_f1: 0.4917\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.5791 - custom_f1: 0.6447 - weighted_custom_f1: 0.6490Epoch 43/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6818 - custom_f1: 0.5960 - weighted_custom_f1: 0.6027 - val_loss: 0.9165 - val_custom_f1: 0.5102 - val_weighted_custom_f1: 0.5209\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6254 - custom_f1: 0.6212 - weighted_custom_f1: 0.6265 - val_loss: 1.0648 - val_custom_f1: 0.4782 - val_weighted_custom_f1: 0.4878\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.6766 - custom_f1: 0.5899 - weighted_custom_f1: 0.5945Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6701 - custom_f1: 0.6054 - weighted_custom_f1: 0.6112 - val_loss: 1.0649 - val_custom_f1: 0.4554 - val_weighted_custom_f1: 0.4682\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8912 - custom_f1: 0.5083 - weighted_custom_f1: 0.5149 - val_loss: 0.9958 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5183\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5283 - custom_f1: 0.5424 - weighted_custom_f1: 0.5424Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6385 - custom_f1: 0.6197 - weighted_custom_f1: 0.6240 - val_loss: 0.9948 - val_custom_f1: 0.5035 - val_weighted_custom_f1: 0.5261\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6394 - custom_f1: 0.6174 - weighted_custom_f1: 0.6248 - val_loss: 0.9524 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5144\n",
            "Epoch 45/100\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6069 - custom_f1: 0.6277 - weighted_custom_f1: 0.6336 - val_loss: 1.0671 - val_custom_f1: 0.4876 - val_weighted_custom_f1: 0.4978\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6487 - custom_f1: 0.6125 - weighted_custom_f1: 0.6164 - val_loss: 1.1764 - val_custom_f1: 0.5184 - val_weighted_custom_f1: 0.5118\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5822 - custom_f1: 0.6461 - weighted_custom_f1: 0.6490 - val_loss: 1.1758 - val_custom_f1: 0.5331 - val_weighted_custom_f1: 0.5322\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6890 - custom_f1: 0.6043 - weighted_custom_f1: 0.6089 - val_loss: 0.9745 - val_custom_f1: 0.4979 - val_weighted_custom_f1: 0.5106\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6943 - custom_f1: 0.5893 - weighted_custom_f1: 0.5965 - val_loss: 0.9653 - val_custom_f1: 0.5075 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6498 - custom_f1: 0.6101 - weighted_custom_f1: 0.6161 - val_loss: 0.9186 - val_custom_f1: 0.4854 - val_weighted_custom_f1: 0.4976\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6281 - custom_f1: 0.6246 - weighted_custom_f1: 0.6275 - val_loss: 1.0933 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5268\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.6475 - custom_f1: 0.6179 - weighted_custom_f1: 0.6210Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6691 - custom_f1: 0.6004 - weighted_custom_f1: 0.6062 - val_loss: 0.9713 - val_custom_f1: 0.4866 - val_weighted_custom_f1: 0.4970\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.6348 - custom_f1: 0.6426 - weighted_custom_f1: 0.6463Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6187 - custom_f1: 0.6235 - weighted_custom_f1: 0.6306 - val_loss: 1.0130 - val_custom_f1: 0.5167 - val_weighted_custom_f1: 0.5254\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6876 - custom_f1: 0.6042 - weighted_custom_f1: 0.6082 - val_loss: 0.9228 - val_custom_f1: 0.5248 - val_weighted_custom_f1: 0.5333\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.5798 - custom_f1: 0.6691 - weighted_custom_f1: 0.6708Epoch 45/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6811 - custom_f1: 0.6004 - weighted_custom_f1: 0.6040 - val_loss: 1.0686 - val_custom_f1: 0.4796 - val_weighted_custom_f1: 0.5010\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6468 - custom_f1: 0.6151 - weighted_custom_f1: 0.6198 - val_loss: 1.1029 - val_custom_f1: 0.5193 - val_weighted_custom_f1: 0.5233\n",
            " 69/105 [==================>...........] - ETA: 0s - loss: 0.6544 - custom_f1: 0.6186 - weighted_custom_f1: 0.6247Epoch 45/100\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.6300 - custom_f1: 0.6107 - weighted_custom_f1: 0.6178 - val_loss: 1.0922 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5090\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9072 - custom_f1: 0.5105 - weighted_custom_f1: 0.5148 - val_loss: 1.0897 - val_custom_f1: 0.4847 - val_weighted_custom_f1: 0.4972\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6250 - custom_f1: 0.6260 - weighted_custom_f1: 0.6316 - val_loss: 1.0071 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5285\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.6782 - custom_f1: 0.5990 - weighted_custom_f1: 0.6050Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6063 - custom_f1: 0.6269 - weighted_custom_f1: 0.6308 - val_loss: 1.0776 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5138\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6365 - custom_f1: 0.6154 - weighted_custom_f1: 0.6192 - val_loss: 1.2012 - val_custom_f1: 0.5291 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6598 - custom_f1: 0.6168 - weighted_custom_f1: 0.6213 - val_loss: 0.9891 - val_custom_f1: 0.4859 - val_weighted_custom_f1: 0.4968\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6676 - custom_f1: 0.6012 - weighted_custom_f1: 0.6068 - val_loss: 0.9843 - val_custom_f1: 0.5117 - val_weighted_custom_f1: 0.5201\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.6143 - custom_f1: 0.6277 - weighted_custom_f1: 0.6323Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5832 - custom_f1: 0.6441 - weighted_custom_f1: 0.6468 - val_loss: 1.2625 - val_custom_f1: 0.5382 - val_weighted_custom_f1: 0.5368\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.6674 - custom_f1: 0.6042 - weighted_custom_f1: 0.6092Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6796 - custom_f1: 0.6030 - weighted_custom_f1: 0.6074 - val_loss: 0.9947 - val_custom_f1: 0.5088 - val_weighted_custom_f1: 0.5201\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6560 - custom_f1: 0.6127 - weighted_custom_f1: 0.6176 - val_loss: 0.9680 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5349\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6281 - custom_f1: 0.6256 - weighted_custom_f1: 0.6308 - val_loss: 1.0223 - val_custom_f1: 0.4812 - val_weighted_custom_f1: 0.4818\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6785 - custom_f1: 0.6001 - weighted_custom_f1: 0.6049 - val_loss: 0.9943 - val_custom_f1: 0.4934 - val_weighted_custom_f1: 0.5058\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6141 - custom_f1: 0.6290 - weighted_custom_f1: 0.6324 - val_loss: 1.0310 - val_custom_f1: 0.5025 - val_weighted_custom_f1: 0.5134\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6766 - custom_f1: 0.5988 - weighted_custom_f1: 0.6040 - val_loss: 0.9195 - val_custom_f1: 0.5099 - val_weighted_custom_f1: 0.5202\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6240 - custom_f1: 0.6201 - weighted_custom_f1: 0.6242 - val_loss: 1.0987 - val_custom_f1: 0.4958 - val_weighted_custom_f1: 0.5052\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.6882 - custom_f1: 0.5998 - weighted_custom_f1: 0.6040Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6183 - custom_f1: 0.6249 - weighted_custom_f1: 0.6306 - val_loss: 1.0593 - val_custom_f1: 0.4900 - val_weighted_custom_f1: 0.4939\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.6300 - custom_f1: 0.6259 - weighted_custom_f1: 0.6316Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6496 - custom_f1: 0.6075 - weighted_custom_f1: 0.6135 - val_loss: 1.1389 - val_custom_f1: 0.4867 - val_weighted_custom_f1: 0.5096\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9037 - custom_f1: 0.5079 - weighted_custom_f1: 0.5132 - val_loss: 1.0905 - val_custom_f1: 0.5329 - val_weighted_custom_f1: 0.5420\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.5801 - custom_f1: 0.6451 - weighted_custom_f1: 0.6479Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6145 - custom_f1: 0.6301 - weighted_custom_f1: 0.6356 - val_loss: 1.0583 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5342\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6233 - custom_f1: 0.6217 - weighted_custom_f1: 0.6261 - val_loss: 0.9880 - val_custom_f1: 0.5052 - val_weighted_custom_f1: 0.5277\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.6441 - custom_f1: 0.6112 - weighted_custom_f1: 0.6159Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6344 - custom_f1: 0.6152 - weighted_custom_f1: 0.6183 - val_loss: 1.2432 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5319\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6879 - custom_f1: 0.5981 - weighted_custom_f1: 0.6034 - val_loss: 0.9489 - val_custom_f1: 0.5486 - val_weighted_custom_f1: 0.5472\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6629 - custom_f1: 0.6110 - weighted_custom_f1: 0.6156 - val_loss: 1.1761 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5265\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6876 - custom_f1: 0.5965 - weighted_custom_f1: 0.6024 - val_loss: 1.0459 - val_custom_f1: 0.4868 - val_weighted_custom_f1: 0.4968\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8216 - custom_f1: 0.7458 - weighted_custom_f1: 0.7458Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5847 - custom_f1: 0.6481 - weighted_custom_f1: 0.6528 - val_loss: 1.1760 - val_custom_f1: 0.4754 - val_weighted_custom_f1: 0.4712\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6507 - custom_f1: 0.6122 - weighted_custom_f1: 0.6169 - val_loss: 0.9299 - val_custom_f1: 0.5047 - val_weighted_custom_f1: 0.5156\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6201 - custom_f1: 0.6272 - weighted_custom_f1: 0.6322 - val_loss: 1.0495 - val_custom_f1: 0.5053 - val_weighted_custom_f1: 0.5063\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6910 - custom_f1: 0.5945 - weighted_custom_f1: 0.5994 - val_loss: 0.9995 - val_custom_f1: 0.4848 - val_weighted_custom_f1: 0.4947\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.6754 - custom_f1: 0.6103 - weighted_custom_f1: 0.6143Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6409 - custom_f1: 0.6166 - weighted_custom_f1: 0.6220 - val_loss: 1.0057 - val_custom_f1: 0.5056 - val_weighted_custom_f1: 0.5140\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6667 - custom_f1: 0.6053 - weighted_custom_f1: 0.6088 - val_loss: 0.9478 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5359\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.6473 - custom_f1: 0.6153 - weighted_custom_f1: 0.6216Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6183 - custom_f1: 0.6246 - weighted_custom_f1: 0.6303 - val_loss: 1.0828 - val_custom_f1: 0.4955 - val_weighted_custom_f1: 0.5071\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5942 - custom_f1: 0.6366 - weighted_custom_f1: 0.6405 - val_loss: 1.1697 - val_custom_f1: 0.5248 - val_weighted_custom_f1: 0.5293\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.5920 - custom_f1: 0.6265 - weighted_custom_f1: 0.6313Epoch 47/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9174 - custom_f1: 0.5054 - weighted_custom_f1: 0.5098 - val_loss: 1.1010 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5386\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6372 - custom_f1: 0.6148 - weighted_custom_f1: 0.6191 - val_loss: 1.0989 - val_custom_f1: 0.4827 - val_weighted_custom_f1: 0.5054\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5986 - custom_f1: 0.6398 - weighted_custom_f1: 0.6436 - val_loss: 1.0787 - val_custom_f1: 0.5153 - val_weighted_custom_f1: 0.5383\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.6197 - custom_f1: 0.6265 - weighted_custom_f1: 0.6306Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6352 - custom_f1: 0.6248 - weighted_custom_f1: 0.6274 - val_loss: 1.0072 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5291\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6390 - custom_f1: 0.6257 - weighted_custom_f1: 0.6291 - val_loss: 1.0233 - val_custom_f1: 0.5167 - val_weighted_custom_f1: 0.5241\n",
            "Epoch 48/100\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6455 - custom_f1: 0.6141 - weighted_custom_f1: 0.6191 - val_loss: 1.2102 - val_custom_f1: 0.4763 - val_weighted_custom_f1: 0.4744\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6630 - custom_f1: 0.6103 - weighted_custom_f1: 0.6154 - val_loss: 1.1296 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5378\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.6563 - custom_f1: 0.6054 - weighted_custom_f1: 0.6099Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6735 - custom_f1: 0.6086 - weighted_custom_f1: 0.6129 - val_loss: 0.9956 - val_custom_f1: 0.5019 - val_weighted_custom_f1: 0.5087\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5854 - custom_f1: 0.6408 - weighted_custom_f1: 0.6454 - val_loss: 1.2317 - val_custom_f1: 0.5294 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6297 - custom_f1: 0.6217 - weighted_custom_f1: 0.6251 - val_loss: 1.0120 - val_custom_f1: 0.5212 - val_weighted_custom_f1: 0.5443\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6222 - custom_f1: 0.6266 - weighted_custom_f1: 0.6312 - val_loss: 1.0581 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5147\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6864 - custom_f1: 0.5938 - weighted_custom_f1: 0.5965 - val_loss: 1.0675 - val_custom_f1: 0.4932 - val_weighted_custom_f1: 0.5154\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6581 - custom_f1: 0.6078 - weighted_custom_f1: 0.6123 - val_loss: 0.9598 - val_custom_f1: 0.5219 - val_weighted_custom_f1: 0.5434\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6156 - custom_f1: 0.6275 - weighted_custom_f1: 0.6317 - val_loss: 1.1178 - val_custom_f1: 0.5018 - val_weighted_custom_f1: 0.5097\n",
            "Epoch 48/100\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.6962 - custom_f1: 0.5940 - weighted_custom_f1: 0.5971Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6165 - custom_f1: 0.6307 - weighted_custom_f1: 0.6346 - val_loss: 1.4494 - val_custom_f1: 0.4901 - val_weighted_custom_f1: 0.5104\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.6620 - custom_f1: 0.6116 - weighted_custom_f1: 0.6167Epoch 47/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6372 - custom_f1: 0.6192 - weighted_custom_f1: 0.6218 - val_loss: 1.1136 - val_custom_f1: 0.4773 - val_weighted_custom_f1: 0.4993\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6057 - custom_f1: 0.6295 - weighted_custom_f1: 0.6341 - val_loss: 1.1178 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5255\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.6337 - custom_f1: 0.6140 - weighted_custom_f1: 0.6180Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9026 - custom_f1: 0.5089 - weighted_custom_f1: 0.5127 - val_loss: 1.0751 - val_custom_f1: 0.5139 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6339 - custom_f1: 0.6123 - weighted_custom_f1: 0.6169 - val_loss: 1.1464 - val_custom_f1: 0.5324 - val_weighted_custom_f1: 0.5282\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5927 - custom_f1: 0.6420 - weighted_custom_f1: 0.6446 - val_loss: 1.1428 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5526\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6232 - custom_f1: 0.6290 - weighted_custom_f1: 0.6327 - val_loss: 1.0088 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5435\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6999 - custom_f1: 0.5921 - weighted_custom_f1: 0.5969 - val_loss: 0.9918 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5160\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.5805 - custom_f1: 0.6188 - weighted_custom_f1: 0.6233Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6345 - custom_f1: 0.6193 - weighted_custom_f1: 0.6240 - val_loss: 0.9763 - val_custom_f1: 0.5355 - val_weighted_custom_f1: 0.5399\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6605 - custom_f1: 0.6079 - weighted_custom_f1: 0.6127 - val_loss: 1.0437 - val_custom_f1: 0.5116 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5708 - custom_f1: 0.6509 - weighted_custom_f1: 0.6562 - val_loss: 1.3117 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5175\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6373 - custom_f1: 0.6173 - weighted_custom_f1: 0.6217 - val_loss: 0.9279 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6148 - custom_f1: 0.6231 - weighted_custom_f1: 0.6270 - val_loss: 1.1067 - val_custom_f1: 0.5368 - val_weighted_custom_f1: 0.5376\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6592 - custom_f1: 0.6022 - weighted_custom_f1: 0.6068 - val_loss: 1.0767 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5382\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.8908 - custom_f1: 0.5122 - weighted_custom_f1: 0.5169Epoch 49/100\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6558 - custom_f1: 0.6114 - weighted_custom_f1: 0.6155 - val_loss: 0.9434 - val_custom_f1: 0.5331 - val_weighted_custom_f1: 0.5420\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6157 - custom_f1: 0.6239 - weighted_custom_f1: 0.6286 - val_loss: 1.0414 - val_custom_f1: 0.5394 - val_weighted_custom_f1: 0.5482\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6450 - custom_f1: 0.6179 - weighted_custom_f1: 0.6222 - val_loss: 1.0937 - val_custom_f1: 0.4923 - val_weighted_custom_f1: 0.5043\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6225 - custom_f1: 0.6226 - weighted_custom_f1: 0.6273 - val_loss: 1.3703 - val_custom_f1: 0.5447 - val_weighted_custom_f1: 0.5498\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6463 - custom_f1: 0.6099 - weighted_custom_f1: 0.6147 - val_loss: 1.1016 - val_custom_f1: 0.4903 - val_weighted_custom_f1: 0.5120\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6229 - custom_f1: 0.6272 - weighted_custom_f1: 0.6315Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8917 - custom_f1: 0.5102 - weighted_custom_f1: 0.5152 - val_loss: 1.0731 - val_custom_f1: 0.4495 - val_weighted_custom_f1: 0.4609\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6167 - custom_f1: 0.6290 - weighted_custom_f1: 0.6340 - val_loss: 0.9738 - val_custom_f1: 0.4875 - val_weighted_custom_f1: 0.5095\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6032 - custom_f1: 0.6344 - weighted_custom_f1: 0.6390 - val_loss: 1.0690 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5326\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6475 - custom_f1: 0.6158 - weighted_custom_f1: 0.6209 - val_loss: 1.3234 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5099\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6766 - custom_f1: 0.5995 - weighted_custom_f1: 0.6038 - val_loss: 1.0484 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5384\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.6344 - custom_f1: 0.6196 - weighted_custom_f1: 0.6251Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6614 - custom_f1: 0.6048 - weighted_custom_f1: 0.6110 - val_loss: 1.1626 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5226\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5824 - custom_f1: 0.6433 - weighted_custom_f1: 0.6466 - val_loss: 1.3979 - val_custom_f1: 0.5454 - val_weighted_custom_f1: 0.5461\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.6094 - custom_f1: 0.6421 - weighted_custom_f1: 0.6451Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6487 - custom_f1: 0.6165 - weighted_custom_f1: 0.6222 - val_loss: 1.0396 - val_custom_f1: 0.5526 - val_weighted_custom_f1: 0.5576\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6432 - custom_f1: 0.6172 - weighted_custom_f1: 0.6216 - val_loss: 1.1179 - val_custom_f1: 0.5195 - val_weighted_custom_f1: 0.5407\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6134 - custom_f1: 0.6287 - weighted_custom_f1: 0.6334 - val_loss: 1.0697 - val_custom_f1: 0.5222 - val_weighted_custom_f1: 0.5244\n",
            "  8/105 [=>............................] - ETA: 0s - loss: 0.5590 - custom_f1: 0.6309 - weighted_custom_f1: 0.6335Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6499 - custom_f1: 0.6113 - weighted_custom_f1: 0.6143 - val_loss: 1.0667 - val_custom_f1: 0.5601 - val_weighted_custom_f1: 0.5665\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6510 - custom_f1: 0.6074 - weighted_custom_f1: 0.6137 - val_loss: 0.9347 - val_custom_f1: 0.5002 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6065 - custom_f1: 0.6279 - weighted_custom_f1: 0.6319 - val_loss: 1.0430 - val_custom_f1: 0.5384 - val_weighted_custom_f1: 0.5476\n",
            "  7/105 [=>............................] - ETA: 0s - loss: 0.6644 - custom_f1: 0.5578 - weighted_custom_f1: 0.5603Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6422 - custom_f1: 0.6160 - weighted_custom_f1: 0.6218 - val_loss: 1.3383 - val_custom_f1: 0.5322 - val_weighted_custom_f1: 0.5370\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6003 - custom_f1: 0.6292 - weighted_custom_f1: 0.6335 - val_loss: 1.2131 - val_custom_f1: 0.5375 - val_weighted_custom_f1: 0.5432\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.5640 - custom_f1: 0.6532 - weighted_custom_f1: 0.6569Epoch 50/100\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6402 - custom_f1: 0.6100 - weighted_custom_f1: 0.6138 - val_loss: 1.1332 - val_custom_f1: 0.4980 - val_weighted_custom_f1: 0.5195\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9058 - custom_f1: 0.5050 - weighted_custom_f1: 0.5116 - val_loss: 1.0875 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5415\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6154 - custom_f1: 0.6295 - weighted_custom_f1: 0.6342 - val_loss: 0.9627 - val_custom_f1: 0.4729 - val_weighted_custom_f1: 0.4945\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5788 - custom_f1: 0.6415 - weighted_custom_f1: 0.6466 - val_loss: 1.1148 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5259\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6185 - custom_f1: 0.6234 - weighted_custom_f1: 0.6274 - val_loss: 1.4667 - val_custom_f1: 0.5308 - val_weighted_custom_f1: 0.5271\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.9167 - custom_f1: 0.4877 - weighted_custom_f1: 0.4910Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6911 - custom_f1: 0.5880 - weighted_custom_f1: 0.5945 - val_loss: 1.2699 - val_custom_f1: 0.5208 - val_weighted_custom_f1: 0.5259\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6464 - custom_f1: 0.6116 - weighted_custom_f1: 0.6179 - val_loss: 1.0145 - val_custom_f1: 0.5637 - val_weighted_custom_f1: 0.5633\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.5965 - custom_f1: 0.6387 - weighted_custom_f1: 0.6419Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6423 - custom_f1: 0.6230 - weighted_custom_f1: 0.6265 - val_loss: 1.0154 - val_custom_f1: 0.4695 - val_weighted_custom_f1: 0.4822\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.5734 - custom_f1: 0.6424 - weighted_custom_f1: 0.6448Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5742 - custom_f1: 0.6448 - weighted_custom_f1: 0.6489 - val_loss: 1.2861 - val_custom_f1: 0.5259 - val_weighted_custom_f1: 0.5269\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6383 - custom_f1: 0.6244 - weighted_custom_f1: 0.6313 - val_loss: 0.9382 - val_custom_f1: 0.5136 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 50/100\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.6027 - custom_f1: 0.6362 - weighted_custom_f1: 0.6396Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6385 - custom_f1: 0.6104 - weighted_custom_f1: 0.6167 - val_loss: 1.0828 - val_custom_f1: 0.5437 - val_weighted_custom_f1: 0.5500\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6041 - custom_f1: 0.6389 - weighted_custom_f1: 0.6424 - val_loss: 1.0889 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5097\n",
            "Epoch 50/100\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.7135 - custom_f1: 0.6080 - weighted_custom_f1: 0.6124Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5905 - custom_f1: 0.6353 - weighted_custom_f1: 0.6419 - val_loss: 1.1403 - val_custom_f1: 0.5361 - val_weighted_custom_f1: 0.5453\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6455 - custom_f1: 0.6162 - weighted_custom_f1: 0.6204 - val_loss: 0.9104 - val_custom_f1: 0.5037 - val_weighted_custom_f1: 0.5144\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5239 - custom_f1: 0.6102 - weighted_custom_f1: 0.6102Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6074 - custom_f1: 0.6336 - weighted_custom_f1: 0.6369 - val_loss: 1.0581 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5047\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.6099 - custom_f1: 0.6345 - weighted_custom_f1: 0.6402Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6166 - custom_f1: 0.6245 - weighted_custom_f1: 0.6308 - val_loss: 1.4163 - val_custom_f1: 0.5250 - val_weighted_custom_f1: 0.5299\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.6421 - custom_f1: 0.6253 - weighted_custom_f1: 0.6292Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6996 - custom_f1: 0.6024 - weighted_custom_f1: 0.6073 - val_loss: 1.0141 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.4939\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8841 - custom_f1: 0.5107 - weighted_custom_f1: 0.5151 - val_loss: 1.1013 - val_custom_f1: 0.4500 - val_weighted_custom_f1: 0.4611\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6069 - custom_f1: 0.6358 - weighted_custom_f1: 0.6411 - val_loss: 1.0030 - val_custom_f1: 0.4976 - val_weighted_custom_f1: 0.5196\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.6185 - custom_f1: 0.6313 - weighted_custom_f1: 0.6339Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5726 - custom_f1: 0.6427 - weighted_custom_f1: 0.6475 - val_loss: 1.0559 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5226\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6197 - custom_f1: 0.6209 - weighted_custom_f1: 0.6252 - val_loss: 1.2662 - val_custom_f1: 0.5312 - val_weighted_custom_f1: 0.5264\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.6302 - custom_f1: 0.6238 - weighted_custom_f1: 0.6279Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6523 - custom_f1: 0.6174 - weighted_custom_f1: 0.6209 - val_loss: 1.0051 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4967\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6359 - custom_f1: 0.6249 - weighted_custom_f1: 0.6294 - val_loss: 1.1162 - val_custom_f1: 0.5071 - val_weighted_custom_f1: 0.5296\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.5662 - custom_f1: 0.6417 - weighted_custom_f1: 0.6432Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6228 - custom_f1: 0.6294 - weighted_custom_f1: 0.6340 - val_loss: 0.9845 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4978\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6158 - custom_f1: 0.6285 - weighted_custom_f1: 0.6315 - val_loss: 0.9304 - val_custom_f1: 0.5090 - val_weighted_custom_f1: 0.5174\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.8980 - custom_f1: 0.4967 - weighted_custom_f1: 0.5002Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6404 - custom_f1: 0.6257 - weighted_custom_f1: 0.6291 - val_loss: 0.9938 - val_custom_f1: 0.4852 - val_weighted_custom_f1: 0.4969\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.5902 - custom_f1: 0.6531 - weighted_custom_f1: 0.6560Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6062 - custom_f1: 0.6346 - weighted_custom_f1: 0.6384 - val_loss: 1.0798 - val_custom_f1: 0.5407 - val_weighted_custom_f1: 0.5425\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5590 - custom_f1: 0.6536 - weighted_custom_f1: 0.6587 - val_loss: 1.3454 - val_custom_f1: 0.5217 - val_weighted_custom_f1: 0.5200\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6389 - custom_f1: 0.6171 - weighted_custom_f1: 0.6206 - val_loss: 1.0298 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5481\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5762 - custom_f1: 0.6428 - weighted_custom_f1: 0.6452Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5882 - custom_f1: 0.6382 - weighted_custom_f1: 0.6425 - val_loss: 1.0269 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5232\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5883 - custom_f1: 0.6366 - weighted_custom_f1: 0.6409 - val_loss: 1.0721 - val_custom_f1: 0.5276 - val_weighted_custom_f1: 0.5326\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.6286 - custom_f1: 0.6277 - weighted_custom_f1: 0.6352Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5795 - custom_f1: 0.6456 - weighted_custom_f1: 0.6490 - val_loss: 1.1275 - val_custom_f1: 0.4775 - val_weighted_custom_f1: 0.4884\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6433 - custom_f1: 0.6131 - weighted_custom_f1: 0.6174 - val_loss: 1.0547 - val_custom_f1: 0.4807 - val_weighted_custom_f1: 0.5029\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8920 - custom_f1: 0.5052 - weighted_custom_f1: 0.5096 - val_loss: 1.0653 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5200\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5960 - custom_f1: 0.6370 - weighted_custom_f1: 0.6404 - val_loss: 0.9724 - val_custom_f1: 0.4853 - val_weighted_custom_f1: 0.5078\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5699 - custom_f1: 0.6484 - weighted_custom_f1: 0.6527 - val_loss: 1.1153 - val_custom_f1: 0.5063 - val_weighted_custom_f1: 0.5143\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6639 - custom_f1: 0.6084 - weighted_custom_f1: 0.6125 - val_loss: 1.1910 - val_custom_f1: 0.5234 - val_weighted_custom_f1: 0.5328\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6160 - custom_f1: 0.6321 - weighted_custom_f1: 0.6356 - val_loss: 1.3730 - val_custom_f1: 0.5330 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 52/100\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6375 - custom_f1: 0.6248 - weighted_custom_f1: 0.6300 - val_loss: 1.0227 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5205\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6276 - custom_f1: 0.6186 - weighted_custom_f1: 0.6238 - val_loss: 1.0896 - val_custom_f1: 0.5599 - val_weighted_custom_f1: 0.5656\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6344 - custom_f1: 0.6126 - weighted_custom_f1: 0.6175 - val_loss: 1.0191 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5860 - custom_f1: 0.6458 - weighted_custom_f1: 0.6497 - val_loss: 1.1294 - val_custom_f1: 0.5228 - val_weighted_custom_f1: 0.5246\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6109 - custom_f1: 0.6271 - weighted_custom_f1: 0.6312 - val_loss: 0.9815 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5471\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.6607 - custom_f1: 0.6181 - weighted_custom_f1: 0.6248Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5703 - custom_f1: 0.6499 - weighted_custom_f1: 0.6532 - val_loss: 1.2887 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5237\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6397 - custom_f1: 0.6209 - weighted_custom_f1: 0.6265 - val_loss: 0.9356 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5319\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6013 - custom_f1: 0.6322 - weighted_custom_f1: 0.6368 - val_loss: 1.2229 - val_custom_f1: 0.5334 - val_weighted_custom_f1: 0.5556\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5813 - custom_f1: 0.6410 - weighted_custom_f1: 0.6455 - val_loss: 1.1305 - val_custom_f1: 0.5001 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5973 - custom_f1: 0.6321 - weighted_custom_f1: 0.6355 - val_loss: 1.3756 - val_custom_f1: 0.5045 - val_weighted_custom_f1: 0.5258\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.6562 - custom_f1: 0.6141 - weighted_custom_f1: 0.6197Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6292 - custom_f1: 0.6201 - weighted_custom_f1: 0.6238 - val_loss: 1.1527 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5017\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5558 - custom_f1: 0.6510 - weighted_custom_f1: 0.6545 - val_loss: 1.1227 - val_custom_f1: 0.5275 - val_weighted_custom_f1: 0.5402\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9043 - custom_f1: 0.5086 - weighted_custom_f1: 0.5136 - val_loss: 1.1227 - val_custom_f1: 0.4667 - val_weighted_custom_f1: 0.4784\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6011 - custom_f1: 0.6418 - weighted_custom_f1: 0.6466 - val_loss: 1.0042 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5249\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6234 - custom_f1: 0.6239 - weighted_custom_f1: 0.6277 - val_loss: 1.2705 - val_custom_f1: 0.5298 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6562 - custom_f1: 0.6141 - weighted_custom_f1: 0.6197 - val_loss: 1.0371 - val_custom_f1: 0.4953 - val_weighted_custom_f1: 0.5052\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.5276 - custom_f1: 0.6662 - weighted_custom_f1: 0.6699Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6426 - custom_f1: 0.6176 - weighted_custom_f1: 0.6238 - val_loss: 0.9886 - val_custom_f1: 0.5054 - val_weighted_custom_f1: 0.5168\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.5763 - custom_f1: 0.6505 - weighted_custom_f1: 0.6520Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6351 - custom_f1: 0.6170 - weighted_custom_f1: 0.6244 - val_loss: 1.0200 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.5129\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6085 - custom_f1: 0.6367 - weighted_custom_f1: 0.6413 - val_loss: 0.9294 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5089\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.6276 - custom_f1: 0.6213 - weighted_custom_f1: 0.6283Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5994 - custom_f1: 0.6306 - weighted_custom_f1: 0.6355 - val_loss: 1.0813 - val_custom_f1: 0.4913 - val_weighted_custom_f1: 0.4937\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6301 - custom_f1: 0.6204 - weighted_custom_f1: 0.6245 - val_loss: 1.0268 - val_custom_f1: 0.4864 - val_weighted_custom_f1: 0.4948\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5253 - custom_f1: 0.6682 - weighted_custom_f1: 0.6715 - val_loss: 1.3149 - val_custom_f1: 0.5376 - val_weighted_custom_f1: 0.5369\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6465 - custom_f1: 0.6108 - weighted_custom_f1: 0.6172 - val_loss: 0.9299 - val_custom_f1: 0.5177 - val_weighted_custom_f1: 0.5280\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.5086 - custom_f1: 0.6837 - weighted_custom_f1: 0.6853Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6012 - custom_f1: 0.6393 - weighted_custom_f1: 0.6445 - val_loss: 1.1060 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5244\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5725 - custom_f1: 0.6514 - weighted_custom_f1: 0.6567 - val_loss: 1.1739 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5210\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6264 - custom_f1: 0.6244 - weighted_custom_f1: 0.6295 - val_loss: 1.1996 - val_custom_f1: 0.4675 - val_weighted_custom_f1: 0.4873\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6008 - custom_f1: 0.6385 - weighted_custom_f1: 0.6431 - val_loss: 1.2098 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5282\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6112 - custom_f1: 0.6349 - weighted_custom_f1: 0.6349Epoch 53/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9077 - custom_f1: 0.5011 - weighted_custom_f1: 0.5071 - val_loss: 1.3197 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5202\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.5790 - custom_f1: 0.6543 - weighted_custom_f1: 0.6594Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5558 - custom_f1: 0.6603 - weighted_custom_f1: 0.6653 - val_loss: 1.2448 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5192\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5983 - custom_f1: 0.6421 - weighted_custom_f1: 0.6449 - val_loss: 1.0098 - val_custom_f1: 0.4565 - val_weighted_custom_f1: 0.4786\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.5908 - custom_f1: 0.6334 - weighted_custom_f1: 0.6357Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6161 - custom_f1: 0.6235 - weighted_custom_f1: 0.6262 - val_loss: 1.1881 - val_custom_f1: 0.5145 - val_weighted_custom_f1: 0.5139\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6510 - custom_f1: 0.6059 - weighted_custom_f1: 0.6130 - val_loss: 1.1231 - val_custom_f1: 0.5287 - val_weighted_custom_f1: 0.5395\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6470 - custom_f1: 0.6193 - weighted_custom_f1: 0.6255 - val_loss: 1.0314 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6212 - custom_f1: 0.6273 - weighted_custom_f1: 0.6318 - val_loss: 1.0369 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4986\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6578 - custom_f1: 0.6774 - weighted_custom_f1: 0.6774Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6260 - custom_f1: 0.6225 - weighted_custom_f1: 0.6274 - val_loss: 1.1072 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5531\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5891 - custom_f1: 0.6370 - weighted_custom_f1: 0.6428 - val_loss: 1.1458 - val_custom_f1: 0.5274 - val_weighted_custom_f1: 0.5268\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6098 - custom_f1: 0.6312 - weighted_custom_f1: 0.6362 - val_loss: 0.9321 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5269\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.5456 - custom_f1: 0.6598 - weighted_custom_f1: 0.6632Epoch 55/100\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5578 - custom_f1: 0.6529 - weighted_custom_f1: 0.6577 - val_loss: 1.3602 - val_custom_f1: 0.5047 - val_weighted_custom_f1: 0.5025\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6265 - custom_f1: 0.6262 - weighted_custom_f1: 0.6296 - val_loss: 0.9795 - val_custom_f1: 0.4883 - val_weighted_custom_f1: 0.4978\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5832 - custom_f1: 0.6372 - weighted_custom_f1: 0.6433 - val_loss: 1.0904 - val_custom_f1: 0.5433 - val_weighted_custom_f1: 0.5531\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5649 - custom_f1: 0.6500 - weighted_custom_f1: 0.6535 - val_loss: 1.1077 - val_custom_f1: 0.4834 - val_weighted_custom_f1: 0.5054\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6194 - custom_f1: 0.6231 - weighted_custom_f1: 0.6278Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5986 - custom_f1: 0.6384 - weighted_custom_f1: 0.6412 - val_loss: 1.0776 - val_custom_f1: 0.4644 - val_weighted_custom_f1: 0.4758\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.5951 - custom_f1: 0.6400 - weighted_custom_f1: 0.6431Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5841 - custom_f1: 0.6358 - weighted_custom_f1: 0.6436 - val_loss: 1.2880 - val_custom_f1: 0.5225 - val_weighted_custom_f1: 0.5339\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6599 - custom_f1: 0.5429 - weighted_custom_f1: 0.5429Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8869 - custom_f1: 0.5111 - weighted_custom_f1: 0.5162 - val_loss: 1.2842 - val_custom_f1: 0.4497 - val_weighted_custom_f1: 0.4610\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7139 - custom_f1: 0.5333 - weighted_custom_f1: 0.5333Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5557 - custom_f1: 0.6586 - weighted_custom_f1: 0.6624 - val_loss: 1.1405 - val_custom_f1: 0.4681 - val_weighted_custom_f1: 0.4771\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.5722 - custom_f1: 0.6447 - weighted_custom_f1: 0.6503Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5961 - custom_f1: 0.6353 - weighted_custom_f1: 0.6394 - val_loss: 1.0283 - val_custom_f1: 0.4847 - val_weighted_custom_f1: 0.5066\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6195 - custom_f1: 0.6226 - weighted_custom_f1: 0.6276 - val_loss: 1.1448 - val_custom_f1: 0.5055 - val_weighted_custom_f1: 0.5010\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6316 - custom_f1: 0.6229 - weighted_custom_f1: 0.6281 - val_loss: 1.1171 - val_custom_f1: 0.4659 - val_weighted_custom_f1: 0.4772\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5365 - custom_f1: 0.4906 - weighted_custom_f1: 0.4906Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5905 - custom_f1: 0.6359 - weighted_custom_f1: 0.6402 - val_loss: 1.0260 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5182\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6205 - custom_f1: 0.6300 - weighted_custom_f1: 0.6317 - val_loss: 1.0393 - val_custom_f1: 0.4967 - val_weighted_custom_f1: 0.5179\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5775 - custom_f1: 0.6457 - weighted_custom_f1: 0.6510 - val_loss: 1.0748 - val_custom_f1: 0.5260 - val_weighted_custom_f1: 0.5286\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.5627 - custom_f1: 0.6560 - weighted_custom_f1: 0.6607Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6215 - custom_f1: 0.6225 - weighted_custom_f1: 0.6267 - val_loss: 1.0283 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5087\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6036 - custom_f1: 0.6351 - weighted_custom_f1: 0.6382 - val_loss: 0.9513 - val_custom_f1: 0.5098 - val_weighted_custom_f1: 0.5187\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.5582 - custom_f1: 0.6590 - weighted_custom_f1: 0.6630Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5582 - custom_f1: 0.6538 - weighted_custom_f1: 0.6585 - val_loss: 1.4341 - val_custom_f1: 0.5465 - val_weighted_custom_f1: 0.5454\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6358 - custom_f1: 0.6180 - weighted_custom_f1: 0.6195 - val_loss: 1.0138 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5388\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.6158 - custom_f1: 0.6268 - weighted_custom_f1: 0.6304Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5580 - custom_f1: 0.6561 - weighted_custom_f1: 0.6602 - val_loss: 1.1291 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5299\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.5455 - custom_f1: 0.6780 - weighted_custom_f1: 0.6834Epoch 55/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5852 - custom_f1: 0.6434 - weighted_custom_f1: 0.6462 - val_loss: 1.3241 - val_custom_f1: 0.5515 - val_weighted_custom_f1: 0.5571\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.6278 - custom_f1: 0.6258 - weighted_custom_f1: 0.6296Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6166 - custom_f1: 0.6266 - weighted_custom_f1: 0.6298 - val_loss: 1.0842 - val_custom_f1: 0.5077 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8935 - custom_f1: 0.5108 - weighted_custom_f1: 0.5135 - val_loss: 1.2728 - val_custom_f1: 0.4591 - val_weighted_custom_f1: 0.4666\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5660 - custom_f1: 0.6530 - weighted_custom_f1: 0.6573 - val_loss: 1.1727 - val_custom_f1: 0.5007 - val_weighted_custom_f1: 0.5109\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5994 - custom_f1: 0.6397 - weighted_custom_f1: 0.6442 - val_loss: 1.0164 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5271\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5540 - custom_f1: 0.6597 - weighted_custom_f1: 0.6631 - val_loss: 1.2015 - val_custom_f1: 0.5136 - val_weighted_custom_f1: 0.5350\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.6254 - custom_f1: 0.6287 - weighted_custom_f1: 0.6320Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6247 - custom_f1: 0.6204 - weighted_custom_f1: 0.6248 - val_loss: 1.4294 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5378\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.5503 - custom_f1: 0.6413 - weighted_custom_f1: 0.6459Epoch 55/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6219 - custom_f1: 0.6291 - weighted_custom_f1: 0.6328 - val_loss: 1.0477 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5198\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6326 - custom_f1: 0.6178 - weighted_custom_f1: 0.6208 - val_loss: 1.1032 - val_custom_f1: 0.5144 - val_weighted_custom_f1: 0.5254\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.5602 - custom_f1: 0.6594 - weighted_custom_f1: 0.6625Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6047 - custom_f1: 0.6351 - weighted_custom_f1: 0.6378 - val_loss: 1.0563 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6177 - custom_f1: 0.6292 - weighted_custom_f1: 0.6323 - val_loss: 1.0468 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5378\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.6011 - custom_f1: 0.6328 - weighted_custom_f1: 0.6378Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5727 - custom_f1: 0.6515 - weighted_custom_f1: 0.6551 - val_loss: 1.1407 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5272\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6018 - custom_f1: 0.6381 - weighted_custom_f1: 0.6408 - val_loss: 1.0805 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5274\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 0.5481 - custom_f1: 0.6558 - weighted_custom_f1: 0.6601Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5362 - custom_f1: 0.6615 - weighted_custom_f1: 0.6673 - val_loss: 1.3099 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5108\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6393 - custom_f1: 0.6168 - weighted_custom_f1: 0.6204 - val_loss: 0.9824 - val_custom_f1: 0.5145 - val_weighted_custom_f1: 0.5366\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5696 - custom_f1: 0.6586 - weighted_custom_f1: 0.6602 - val_loss: 1.1382 - val_custom_f1: 0.5506 - val_weighted_custom_f1: 0.5568\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5869 - custom_f1: 0.6464 - weighted_custom_f1: 0.6509 - val_loss: 1.2212 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6421 - custom_f1: 0.6207 - weighted_custom_f1: 0.6250 - val_loss: 1.1644 - val_custom_f1: 0.4920 - val_weighted_custom_f1: 0.5133\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.5730 - custom_f1: 0.6424 - weighted_custom_f1: 0.6459Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8986 - custom_f1: 0.5063 - weighted_custom_f1: 0.5099 - val_loss: 1.1919 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5723 - custom_f1: 0.6489 - weighted_custom_f1: 0.6518 - val_loss: 1.2916 - val_custom_f1: 0.5011 - val_weighted_custom_f1: 0.5087\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5584 - custom_f1: 0.6573 - weighted_custom_f1: 0.6610 - val_loss: 1.1410 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5230\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5748 - custom_f1: 0.6499 - weighted_custom_f1: 0.6532 - val_loss: 1.0157 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5353\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6249 - custom_f1: 0.6278 - weighted_custom_f1: 0.6316 - val_loss: 1.0517 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5366\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6146 - custom_f1: 0.6234 - weighted_custom_f1: 0.6285 - val_loss: 1.2436 - val_custom_f1: 0.5035 - val_weighted_custom_f1: 0.4991\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5386 - custom_f1: 0.6534 - weighted_custom_f1: 0.6568Epoch 56/100\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6033 - custom_f1: 0.6316 - weighted_custom_f1: 0.6353 - val_loss: 1.0640 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5277\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6104 - custom_f1: 0.6318 - weighted_custom_f1: 0.6364 - val_loss: 1.0978 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5276\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.6154 - custom_f1: 0.6340 - weighted_custom_f1: 0.6384Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6225 - custom_f1: 0.6223 - weighted_custom_f1: 0.6275 - val_loss: 1.1458 - val_custom_f1: 0.4925 - val_weighted_custom_f1: 0.5002\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5680 - custom_f1: 0.6545 - weighted_custom_f1: 0.6579 - val_loss: 1.0773 - val_custom_f1: 0.5238 - val_weighted_custom_f1: 0.5227\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6077 - custom_f1: 0.6370 - weighted_custom_f1: 0.6414 - val_loss: 0.9603 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5181\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.5705 - custom_f1: 0.6567 - weighted_custom_f1: 0.6604Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5410 - custom_f1: 0.6687 - weighted_custom_f1: 0.6716 - val_loss: 1.3651 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5380\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6144 - custom_f1: 0.6338 - weighted_custom_f1: 0.6362 - val_loss: 1.0250 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5403\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.6011 - custom_f1: 0.6427 - weighted_custom_f1: 0.6458Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5711 - custom_f1: 0.6472 - weighted_custom_f1: 0.6510 - val_loss: 1.1768 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5423\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5588 - custom_f1: 0.6550 - weighted_custom_f1: 0.6583 - val_loss: 1.1986 - val_custom_f1: 0.5353 - val_weighted_custom_f1: 0.5401\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6181 - custom_f1: 0.6281 - weighted_custom_f1: 0.6318 - val_loss: 1.2133 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5279\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.5872 - custom_f1: 0.6291 - weighted_custom_f1: 0.6352Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9178 - custom_f1: 0.5051 - weighted_custom_f1: 0.5091 - val_loss: 1.2145 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5302\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.6218 - custom_f1: 0.6245 - weighted_custom_f1: 0.6293Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5669 - custom_f1: 0.6497 - weighted_custom_f1: 0.6536 - val_loss: 1.2602 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5537 - custom_f1: 0.6590 - weighted_custom_f1: 0.6621 - val_loss: 1.2037 - val_custom_f1: 0.5199 - val_weighted_custom_f1: 0.5427\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5656 - custom_f1: 0.6519 - weighted_custom_f1: 0.6547 - val_loss: 1.0049 - val_custom_f1: 0.4804 - val_weighted_custom_f1: 0.5026\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5895 - custom_f1: 0.6380 - weighted_custom_f1: 0.6422 - val_loss: 1.2914 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5278\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5950 - custom_f1: 0.6227 - weighted_custom_f1: 0.6302Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6218 - custom_f1: 0.6245 - weighted_custom_f1: 0.6293 - val_loss: 1.1570 - val_custom_f1: 0.5164 - val_weighted_custom_f1: 0.5242\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6249 - custom_f1: 0.6256 - weighted_custom_f1: 0.6305 - val_loss: 1.1159 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5288\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6029 - custom_f1: 0.6365 - weighted_custom_f1: 0.6404Epoch 59/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6225 - custom_f1: 0.6305 - weighted_custom_f1: 0.6336 - val_loss: 1.0896 - val_custom_f1: 0.5466 - val_weighted_custom_f1: 0.5524\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6603 - custom_f1: 0.6094 - weighted_custom_f1: 0.6133 - val_loss: 1.0356 - val_custom_f1: 0.5128 - val_weighted_custom_f1: 0.5336\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5861 - custom_f1: 0.6437 - weighted_custom_f1: 0.6477 - val_loss: 0.9934 - val_custom_f1: 0.5193 - val_weighted_custom_f1: 0.5423\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5637 - custom_f1: 0.6544 - weighted_custom_f1: 0.6590 - val_loss: 1.0575 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5258\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6124 - custom_f1: 0.6287 - weighted_custom_f1: 0.6327 - val_loss: 0.9715 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5427\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8945 - custom_f1: 0.5118 - weighted_custom_f1: 0.5161Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5050 - custom_f1: 0.6857 - weighted_custom_f1: 0.6885 - val_loss: 1.3480 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5141\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5509 - custom_f1: 0.6604 - weighted_custom_f1: 0.6627 - val_loss: 1.1508 - val_custom_f1: 0.5434 - val_weighted_custom_f1: 0.5500\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5608 - custom_f1: 0.6549 - weighted_custom_f1: 0.6588 - val_loss: 1.1885 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5249\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5985 - custom_f1: 0.6329 - weighted_custom_f1: 0.6356 - val_loss: 1.1742 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.5103\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8943 - custom_f1: 0.5100 - weighted_custom_f1: 0.5154 - val_loss: 1.2370 - val_custom_f1: 0.5020 - val_weighted_custom_f1: 0.5125\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.6256 - custom_f1: 0.6325 - weighted_custom_f1: 0.6368Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5619 - custom_f1: 0.6548 - weighted_custom_f1: 0.6592 - val_loss: 1.4184 - val_custom_f1: 0.5030 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5627 - custom_f1: 0.6533 - weighted_custom_f1: 0.6581 - val_loss: 1.0215 - val_custom_f1: 0.5015 - val_weighted_custom_f1: 0.5239\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7360 - custom_f1: 0.7059 - weighted_custom_f1: 0.7059Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5226 - custom_f1: 0.6699 - weighted_custom_f1: 0.6726 - val_loss: 1.1697 - val_custom_f1: 0.5065 - val_weighted_custom_f1: 0.5291\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.5902 - custom_f1: 0.6386 - weighted_custom_f1: 0.6430Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5829 - custom_f1: 0.6450 - weighted_custom_f1: 0.6475 - val_loss: 1.2863 - val_custom_f1: 0.5489 - val_weighted_custom_f1: 0.5444\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.5333 - custom_f1: 0.6648 - weighted_custom_f1: 0.6696Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6293 - custom_f1: 0.6222 - weighted_custom_f1: 0.6273 - val_loss: 1.0863 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5142\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6102 - custom_f1: 0.6364 - weighted_custom_f1: 0.6392 - val_loss: 1.0835 - val_custom_f1: 0.5014 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6212 - custom_f1: 0.6344 - weighted_custom_f1: 0.6382 - val_loss: 1.0302 - val_custom_f1: 0.5274 - val_weighted_custom_f1: 0.5347\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.6040 - custom_f1: 0.6400 - weighted_custom_f1: 0.6421Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6373 - custom_f1: 0.6207 - weighted_custom_f1: 0.6239 - val_loss: 1.0154 - val_custom_f1: 0.5381 - val_weighted_custom_f1: 0.5467\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5618 - custom_f1: 0.6548 - weighted_custom_f1: 0.6575 - val_loss: 1.1235 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5105\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5815 - custom_f1: 0.6405 - weighted_custom_f1: 0.6445 - val_loss: 0.9575 - val_custom_f1: 0.5324 - val_weighted_custom_f1: 0.5420\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.8931 - custom_f1: 0.5133 - weighted_custom_f1: 0.5166Epoch 59/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5166 - custom_f1: 0.6752 - weighted_custom_f1: 0.6789 - val_loss: 1.3300 - val_custom_f1: 0.5254 - val_weighted_custom_f1: 0.5259\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.5845 - custom_f1: 0.6311 - weighted_custom_f1: 0.6361Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6135 - custom_f1: 0.6327 - weighted_custom_f1: 0.6376 - val_loss: 1.0965 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5439\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5645 - custom_f1: 0.6497 - weighted_custom_f1: 0.6534 - val_loss: 1.0871 - val_custom_f1: 0.5277 - val_weighted_custom_f1: 0.5344\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5877 - custom_f1: 0.6377 - weighted_custom_f1: 0.6421 - val_loss: 1.1334 - val_custom_f1: 0.4986 - val_weighted_custom_f1: 0.5206\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5434 - custom_f1: 0.6612 - weighted_custom_f1: 0.6660 - val_loss: 1.2491 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5355\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.5962 - custom_f1: 0.6417 - weighted_custom_f1: 0.6454Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8936 - custom_f1: 0.5116 - weighted_custom_f1: 0.5155 - val_loss: 1.2025 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5221\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5233 - custom_f1: 0.6648 - weighted_custom_f1: 0.6693 - val_loss: 1.2617 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5236\n",
            "  7/105 [=>............................] - ETA: 1s - loss: 0.5704 - custom_f1: 0.6712 - weighted_custom_f1: 0.6759Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5788 - custom_f1: 0.6452 - weighted_custom_f1: 0.6499 - val_loss: 1.3393 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5414\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5686 - custom_f1: 0.6455 - weighted_custom_f1: 0.6507 - val_loss: 1.1738 - val_custom_f1: 0.5222 - val_weighted_custom_f1: 0.5435\n",
            "Epoch 61/100\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5895 - custom_f1: 0.6361 - weighted_custom_f1: 0.6410 - val_loss: 1.1895 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5185\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6245 - custom_f1: 0.6232 - weighted_custom_f1: 0.6276 - val_loss: 1.0426 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5203\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6102 - custom_f1: 0.6349 - weighted_custom_f1: 0.6407 - val_loss: 1.0533 - val_custom_f1: 0.4660 - val_weighted_custom_f1: 0.4790\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.5573 - custom_f1: 0.6542 - weighted_custom_f1: 0.6599Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6013 - custom_f1: 0.6385 - weighted_custom_f1: 0.6423 - val_loss: 1.1479 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5538\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6314 - custom_f1: 0.6248 - weighted_custom_f1: 0.6296 - val_loss: 1.0573 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5677 - custom_f1: 0.6514 - weighted_custom_f1: 0.6564 - val_loss: 1.0972 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5113\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.8941 - custom_f1: 0.5123 - weighted_custom_f1: 0.5174Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5927 - custom_f1: 0.6381 - weighted_custom_f1: 0.6434 - val_loss: 1.0123 - val_custom_f1: 0.5192 - val_weighted_custom_f1: 0.5421\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.5438 - custom_f1: 0.6712 - weighted_custom_f1: 0.6748Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6123 - custom_f1: 0.6289 - weighted_custom_f1: 0.6352 - val_loss: 0.9615 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5266\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.5233 - custom_f1: 0.6729 - weighted_custom_f1: 0.6768Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5171 - custom_f1: 0.6727 - weighted_custom_f1: 0.6765 - val_loss: 1.4917 - val_custom_f1: 0.5263 - val_weighted_custom_f1: 0.5259\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5608 - custom_f1: 0.6512 - weighted_custom_f1: 0.6553 - val_loss: 1.2795 - val_custom_f1: 0.5378 - val_weighted_custom_f1: 0.5611\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.6162 - custom_f1: 0.6162 - weighted_custom_f1: 0.6199Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5943 - custom_f1: 0.6370 - weighted_custom_f1: 0.6413 - val_loss: 1.3155 - val_custom_f1: 0.5038 - val_weighted_custom_f1: 0.5245\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.6300 - custom_f1: 0.6252 - weighted_custom_f1: 0.6294Epoch 61/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5607 - custom_f1: 0.6515 - weighted_custom_f1: 0.6568 - val_loss: 1.2373 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5205\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.5963 - custom_f1: 0.6319 - weighted_custom_f1: 0.6366Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9035 - custom_f1: 0.5053 - weighted_custom_f1: 0.5113 - val_loss: 1.3024 - val_custom_f1: 0.4704 - val_weighted_custom_f1: 0.4814\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.6321 - custom_f1: 0.6243 - weighted_custom_f1: 0.6286Epoch 61/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5631 - custom_f1: 0.6529 - weighted_custom_f1: 0.6575 - val_loss: 1.0080 - val_custom_f1: 0.5041 - val_weighted_custom_f1: 0.5268\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5289 - custom_f1: 0.6665 - weighted_custom_f1: 0.6709 - val_loss: 1.3553 - val_custom_f1: 0.5093 - val_weighted_custom_f1: 0.5326\n",
            " 10/105 [=>............................] - ETA: 0s - loss: 0.9045 - custom_f1: 0.4953 - weighted_custom_f1: 0.4984Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5445 - custom_f1: 0.6640 - weighted_custom_f1: 0.6676 - val_loss: 1.2203 - val_custom_f1: 0.5223 - val_weighted_custom_f1: 0.5309\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5833 - custom_f1: 0.6377 - weighted_custom_f1: 0.6408 - val_loss: 1.3048 - val_custom_f1: 0.5383 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6234 - custom_f1: 0.6240 - weighted_custom_f1: 0.6306 - val_loss: 1.1303 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5233\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 0.5001 - custom_f1: 0.6874 - weighted_custom_f1: 0.6918Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6335 - custom_f1: 0.6252 - weighted_custom_f1: 0.6295 - val_loss: 1.0343 - val_custom_f1: 0.4920 - val_weighted_custom_f1: 0.5035\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5608 - custom_f1: 0.6556 - weighted_custom_f1: 0.6588 - val_loss: 1.2058 - val_custom_f1: 0.5389 - val_weighted_custom_f1: 0.5362\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7148 - custom_f1: 0.6345 - weighted_custom_f1: 0.6411 - val_loss: 1.0864 - val_custom_f1: 0.5444 - val_weighted_custom_f1: 0.5433\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6285 - custom_f1: 0.6204 - weighted_custom_f1: 0.6250 - val_loss: 1.0670 - val_custom_f1: 0.5345 - val_weighted_custom_f1: 0.5442\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5855 - custom_f1: 0.6429 - weighted_custom_f1: 0.6470 - val_loss: 0.9582 - val_custom_f1: 0.5287 - val_weighted_custom_f1: 0.5383\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6002 - custom_f1: 0.6354 - weighted_custom_f1: 0.6395 - val_loss: 0.9851 - val_custom_f1: 0.5199 - val_weighted_custom_f1: 0.5414\n",
            " 12/105 [==>...........................] - ETA: 0s - loss: 0.5618 - custom_f1: 0.6653 - weighted_custom_f1: 0.6702Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5095 - custom_f1: 0.6850 - weighted_custom_f1: 0.6890 - val_loss: 1.3893 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5132\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5678 - custom_f1: 0.6516 - weighted_custom_f1: 0.6579 - val_loss: 1.2096 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5228\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5503 - custom_f1: 0.6577 - weighted_custom_f1: 0.6615 - val_loss: 1.2587 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5909 - custom_f1: 0.6397 - weighted_custom_f1: 0.6426 - val_loss: 1.2439 - val_custom_f1: 0.5027 - val_weighted_custom_f1: 0.5239\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5146 - custom_f1: 0.6765 - weighted_custom_f1: 0.6802 - val_loss: 1.1809 - val_custom_f1: 0.5051 - val_weighted_custom_f1: 0.5274\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5705 - custom_f1: 0.6513 - weighted_custom_f1: 0.6579 - val_loss: 1.2565 - val_custom_f1: 0.4717 - val_weighted_custom_f1: 0.4842\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.5818 - custom_f1: 0.6458 - weighted_custom_f1: 0.6501Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9044 - custom_f1: 0.5084 - weighted_custom_f1: 0.5126 - val_loss: 1.2235 - val_custom_f1: 0.5040 - val_weighted_custom_f1: 0.5144\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.5617 - custom_f1: 0.6530 - weighted_custom_f1: 0.6575Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5592 - custom_f1: 0.6598 - weighted_custom_f1: 0.6638 - val_loss: 1.0224 - val_custom_f1: 0.5009 - val_weighted_custom_f1: 0.5235\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.8522 - custom_f1: 0.5017 - weighted_custom_f1: 0.5098Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6522 - custom_f1: 0.6205 - weighted_custom_f1: 0.6247 - val_loss: 1.0760 - val_custom_f1: 0.4836 - val_weighted_custom_f1: 0.4961\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5339 - custom_f1: 0.6771 - weighted_custom_f1: 0.6854Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5883 - custom_f1: 0.6355 - weighted_custom_f1: 0.6395 - val_loss: 1.3292 - val_custom_f1: 0.5236 - val_weighted_custom_f1: 0.5174\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5922 - custom_f1: 0.6465 - weighted_custom_f1: 0.6511 - val_loss: 1.0625 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5056\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5997 - custom_f1: 0.6351 - weighted_custom_f1: 0.6399 - val_loss: 1.1003 - val_custom_f1: 0.5559 - val_weighted_custom_f1: 0.5609\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6382 - custom_f1: 0.4762 - weighted_custom_f1: 0.4762Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5516 - custom_f1: 0.6619 - weighted_custom_f1: 0.6651 - val_loss: 1.0976 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5120\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6236 - custom_f1: 0.6269 - weighted_custom_f1: 0.6311 - val_loss: 1.0107 - val_custom_f1: 0.5225 - val_weighted_custom_f1: 0.5344\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.9129 - custom_f1: 0.5099 - weighted_custom_f1: 0.5142Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5784 - custom_f1: 0.6461 - weighted_custom_f1: 0.6506 - val_loss: 0.9535 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5304\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5948 - custom_f1: 0.6392 - weighted_custom_f1: 0.6432 - val_loss: 0.9618 - val_custom_f1: 0.5139 - val_weighted_custom_f1: 0.5236\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.5250 - custom_f1: 0.6819 - weighted_custom_f1: 0.6852Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5041 - custom_f1: 0.6838 - weighted_custom_f1: 0.6867 - val_loss: 1.5633 - val_custom_f1: 0.5447 - val_weighted_custom_f1: 0.5404\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6303 - custom_f1: 0.4561 - weighted_custom_f1: 0.4561Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5408 - custom_f1: 0.6626 - weighted_custom_f1: 0.6662 - val_loss: 1.2654 - val_custom_f1: 0.4747 - val_weighted_custom_f1: 0.4817\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6066 - custom_f1: 0.6307 - weighted_custom_f1: 0.6344 - val_loss: 1.1458 - val_custom_f1: 0.4743 - val_weighted_custom_f1: 0.4953\n",
            "Epoch 63/100\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5543 - custom_f1: 0.6551 - weighted_custom_f1: 0.6599 - val_loss: 1.1358 - val_custom_f1: 0.5410 - val_weighted_custom_f1: 0.5473\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.5729 - custom_f1: 0.6508 - weighted_custom_f1: 0.6554Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9178 - custom_f1: 0.5085 - weighted_custom_f1: 0.5126 - val_loss: 1.2593 - val_custom_f1: 0.4535 - val_weighted_custom_f1: 0.4652\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.6009 - custom_f1: 0.6395 - weighted_custom_f1: 0.6457Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5241 - custom_f1: 0.6813 - weighted_custom_f1: 0.6847 - val_loss: 1.2930 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5430\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5728 - custom_f1: 0.6518 - weighted_custom_f1: 0.6559 - val_loss: 1.0547 - val_custom_f1: 0.4881 - val_weighted_custom_f1: 0.4999\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5963 - custom_f1: 0.6388 - weighted_custom_f1: 0.6430 - val_loss: 1.2657 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5030\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.5088 - custom_f1: 0.6709 - weighted_custom_f1: 0.6749Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6199 - custom_f1: 0.6257 - weighted_custom_f1: 0.6301 - val_loss: 1.0881 - val_custom_f1: 0.4782 - val_weighted_custom_f1: 0.4899\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.5544 - custom_f1: 0.6532 - weighted_custom_f1: 0.6585Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5961 - custom_f1: 0.6423 - weighted_custom_f1: 0.6465 - val_loss: 1.4778 - val_custom_f1: 0.5554 - val_weighted_custom_f1: 0.5450\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.5578 - custom_f1: 0.6720 - weighted_custom_f1: 0.6752Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5991 - custom_f1: 0.6363 - weighted_custom_f1: 0.6400 - val_loss: 1.1966 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5294\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.5312 - custom_f1: 0.6554 - weighted_custom_f1: 0.6604Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5726 - custom_f1: 0.6526 - weighted_custom_f1: 0.6562 - val_loss: 1.0285 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5339\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5443 - custom_f1: 0.6621 - weighted_custom_f1: 0.6640 - val_loss: 1.2286 - val_custom_f1: 0.5234 - val_weighted_custom_f1: 0.5198\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.5994 - custom_f1: 0.6283 - weighted_custom_f1: 0.6332Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6147 - custom_f1: 0.6336 - weighted_custom_f1: 0.6375 - val_loss: 1.0691 - val_custom_f1: 0.4781 - val_weighted_custom_f1: 0.4852\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4970 - custom_f1: 0.7273 - weighted_custom_f1: 0.7273Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5739 - custom_f1: 0.6462 - weighted_custom_f1: 0.6511 - val_loss: 0.9762 - val_custom_f1: 0.4820 - val_weighted_custom_f1: 0.4903\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6667 - custom_f1: 0.4675 - weighted_custom_f1: 0.4675Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5122 - custom_f1: 0.6803 - weighted_custom_f1: 0.6839 - val_loss: 1.4854 - val_custom_f1: 0.5288 - val_weighted_custom_f1: 0.5245\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5909 - custom_f1: 0.6398 - weighted_custom_f1: 0.6454 - val_loss: 1.1018 - val_custom_f1: 0.5221 - val_weighted_custom_f1: 0.5431\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.6096 - custom_f1: 0.6302 - weighted_custom_f1: 0.6344Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6050 - custom_f1: 0.6328 - weighted_custom_f1: 0.6380 - val_loss: 1.1567 - val_custom_f1: 0.4783 - val_weighted_custom_f1: 0.5003\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5284 - custom_f1: 0.6651 - weighted_custom_f1: 0.6694 - val_loss: 1.1301 - val_custom_f1: 0.4975 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 64/100\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.4597 - custom_f1: 0.7130 - weighted_custom_f1: 0.7177Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5472 - custom_f1: 0.6628 - weighted_custom_f1: 0.6671 - val_loss: 1.3451 - val_custom_f1: 0.5105 - val_weighted_custom_f1: 0.5152\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5937 - custom_f1: 0.6667 - weighted_custom_f1: 0.6667Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9084 - custom_f1: 0.5072 - weighted_custom_f1: 0.5115 - val_loss: 1.3548 - val_custom_f1: 0.4998 - val_weighted_custom_f1: 0.5107\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5223 - custom_f1: 0.6688 - weighted_custom_f1: 0.6726 - val_loss: 1.2268 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5357\n",
            "Epoch 64/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7226 - custom_f1: 0.5172 - weighted_custom_f1: 0.5172Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5387 - custom_f1: 0.6595 - weighted_custom_f1: 0.6635 - val_loss: 1.2325 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.5125\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.5936 - custom_f1: 0.6469 - weighted_custom_f1: 0.6509Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5567 - custom_f1: 0.6597 - weighted_custom_f1: 0.6633 - val_loss: 1.0559 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5290\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.5632 - custom_f1: 0.6519 - weighted_custom_f1: 0.6549Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6081 - custom_f1: 0.6341 - weighted_custom_f1: 0.6379 - val_loss: 1.2651 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5413\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.5601 - custom_f1: 0.6524 - weighted_custom_f1: 0.6556Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5592 - custom_f1: 0.6489 - weighted_custom_f1: 0.6512 - val_loss: 1.3376 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5128\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.5364 - custom_f1: 0.6672 - weighted_custom_f1: 0.6706Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5922 - custom_f1: 0.6474 - weighted_custom_f1: 0.6512 - val_loss: 1.1845 - val_custom_f1: 0.4942 - val_weighted_custom_f1: 0.5148\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5918 - custom_f1: 0.6408 - weighted_custom_f1: 0.6462 - val_loss: 1.3290 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5294\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 0.5335 - custom_f1: 0.6715 - weighted_custom_f1: 0.6760Epoch 64/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5526 - custom_f1: 0.6629 - weighted_custom_f1: 0.6677 - val_loss: 1.2171 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5402\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5863 - custom_f1: 0.6426 - weighted_custom_f1: 0.6463 - val_loss: 1.1120 - val_custom_f1: 0.5386 - val_weighted_custom_f1: 0.5478\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5763 - custom_f1: 0.6493 - weighted_custom_f1: 0.6532 - val_loss: 1.0779 - val_custom_f1: 0.5337 - val_weighted_custom_f1: 0.5439\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4820 - custom_f1: 0.6929 - weighted_custom_f1: 0.6950 - val_loss: 1.5655 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5070\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5721 - custom_f1: 0.6449 - weighted_custom_f1: 0.6491 - val_loss: 1.1863 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5967 - custom_f1: 0.6414 - weighted_custom_f1: 0.6458 - val_loss: 1.0368 - val_custom_f1: 0.5216 - val_weighted_custom_f1: 0.5439\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.5885 - custom_f1: 0.6461 - weighted_custom_f1: 0.6505Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5375 - custom_f1: 0.6630 - weighted_custom_f1: 0.6684 - val_loss: 1.2150 - val_custom_f1: 0.5532 - val_weighted_custom_f1: 0.5600\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5320 - custom_f1: 0.6709 - weighted_custom_f1: 0.6754 - val_loss: 1.3056 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5225\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4615 - custom_f1: 0.6897 - weighted_custom_f1: 0.6897Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9060 - custom_f1: 0.5112 - weighted_custom_f1: 0.5156 - val_loss: 1.2779 - val_custom_f1: 0.5009 - val_weighted_custom_f1: 0.5115\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5222 - custom_f1: 0.6708 - weighted_custom_f1: 0.6757 - val_loss: 1.2805 - val_custom_f1: 0.5168 - val_weighted_custom_f1: 0.5391\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7926 - custom_f1: 0.5625 - weighted_custom_f1: 0.5625Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5468 - custom_f1: 0.6571 - weighted_custom_f1: 0.6620 - val_loss: 1.0904 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5345\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5400 - custom_f1: 0.6660 - weighted_custom_f1: 0.6699 - val_loss: 1.3965 - val_custom_f1: 0.5303 - val_weighted_custom_f1: 0.5347\n",
            "Epoch 66/100\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5923 - custom_f1: 0.6368 - weighted_custom_f1: 0.6417 - val_loss: 1.1734 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5306\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 0.5291 - custom_f1: 0.6687 - weighted_custom_f1: 0.6734Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5508 - custom_f1: 0.6621 - weighted_custom_f1: 0.6644 - val_loss: 1.4580 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5176\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.5436 - custom_f1: 0.6804 - weighted_custom_f1: 0.6836Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5811 - custom_f1: 0.6449 - weighted_custom_f1: 0.6493 - val_loss: 1.1738 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5288\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5983 - custom_f1: 0.6408 - weighted_custom_f1: 0.6463 - val_loss: 1.2838 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5297\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5839 - custom_f1: 0.6364 - weighted_custom_f1: 0.6364Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5880 - custom_f1: 0.6412 - weighted_custom_f1: 0.6464 - val_loss: 1.1560 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5351\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.6071 - custom_f1: 0.6585 - weighted_custom_f1: 0.6637Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5574 - custom_f1: 0.6590 - weighted_custom_f1: 0.6647 - val_loss: 1.1096 - val_custom_f1: 0.5015 - val_weighted_custom_f1: 0.5024\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5669 - custom_f1: 0.6532 - weighted_custom_f1: 0.6571 - val_loss: 0.9954 - val_custom_f1: 0.5246 - val_weighted_custom_f1: 0.5481\n",
            " 12/105 [==>...........................] - ETA: 0s - loss: 0.5431 - custom_f1: 0.6563 - weighted_custom_f1: 0.6578Epoch 65/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5851 - custom_f1: 0.6416 - weighted_custom_f1: 0.6482 - val_loss: 1.0042 - val_custom_f1: 0.5190 - val_weighted_custom_f1: 0.5408\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.5229 - custom_f1: 0.6842 - weighted_custom_f1: 0.6854Epoch 66/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5263 - custom_f1: 0.6690 - weighted_custom_f1: 0.6729 - val_loss: 1.3044 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5461\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5709 - custom_f1: 0.6442 - weighted_custom_f1: 0.6497 - val_loss: 1.3022 - val_custom_f1: 0.5091 - val_weighted_custom_f1: 0.5304\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.5805 - custom_f1: 0.6488 - weighted_custom_f1: 0.6543Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4915 - custom_f1: 0.6889 - weighted_custom_f1: 0.6932 - val_loss: 1.5747 - val_custom_f1: 0.5647 - val_weighted_custom_f1: 0.5553\n",
            "Epoch 65/100\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.5677 - custom_f1: 0.6575 - weighted_custom_f1: 0.6610Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5186 - custom_f1: 0.6742 - weighted_custom_f1: 0.6798 - val_loss: 1.2989 - val_custom_f1: 0.5272 - val_weighted_custom_f1: 0.5362\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.5430 - custom_f1: 0.6900 - weighted_custom_f1: 0.6923Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9375 - custom_f1: 0.4900 - weighted_custom_f1: 0.4953 - val_loss: 1.3232 - val_custom_f1: 0.5123 - val_weighted_custom_f1: 0.5087\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4875 - custom_f1: 0.6864 - weighted_custom_f1: 0.6921 - val_loss: 1.2973 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5443\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.5613 - custom_f1: 0.6644 - weighted_custom_f1: 0.6679Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5416 - custom_f1: 0.6671 - weighted_custom_f1: 0.6718 - val_loss: 1.4314 - val_custom_f1: 0.5344 - val_weighted_custom_f1: 0.5455\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5714 - custom_f1: 0.6551 - weighted_custom_f1: 0.6599 - val_loss: 1.0384 - val_custom_f1: 0.4792 - val_weighted_custom_f1: 0.5016\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.5083 - custom_f1: 0.6820 - weighted_custom_f1: 0.6866Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6066 - custom_f1: 0.6293 - weighted_custom_f1: 0.6340 - val_loss: 1.1805 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5574\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.5854 - custom_f1: 0.6467 - weighted_custom_f1: 0.6506Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5777 - custom_f1: 0.6447 - weighted_custom_f1: 0.6522 - val_loss: 1.1103 - val_custom_f1: 0.5572 - val_weighted_custom_f1: 0.5555\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5935 - custom_f1: 0.6453 - weighted_custom_f1: 0.6501 - val_loss: 1.0893 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5211\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5590 - custom_f1: 0.6509 - weighted_custom_f1: 0.6555 - val_loss: 1.5011 - val_custom_f1: 0.5414 - val_weighted_custom_f1: 0.5305\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.5541 - custom_f1: 0.6748 - weighted_custom_f1: 0.6783Epoch 65/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5389 - custom_f1: 0.6684 - weighted_custom_f1: 0.6727 - val_loss: 1.1163 - val_custom_f1: 0.5016 - val_weighted_custom_f1: 0.5009\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5841 - custom_f1: 0.6403 - weighted_custom_f1: 0.6461 - val_loss: 1.1953 - val_custom_f1: 0.5044 - val_weighted_custom_f1: 0.5258\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.5986 - custom_f1: 0.6626 - weighted_custom_f1: 0.6661Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5615 - custom_f1: 0.6546 - weighted_custom_f1: 0.6611 - val_loss: 0.9659 - val_custom_f1: 0.5237 - val_weighted_custom_f1: 0.5329\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5849 - custom_f1: 0.6478 - weighted_custom_f1: 0.6517 - val_loss: 0.9899 - val_custom_f1: 0.5027 - val_weighted_custom_f1: 0.5235\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.9130 - custom_f1: 0.5094 - weighted_custom_f1: 0.5148Epoch 67/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5987 - custom_f1: 0.6459 - weighted_custom_f1: 0.6502 - val_loss: 1.2888 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5325\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.5507 - custom_f1: 0.6865 - weighted_custom_f1: 0.6884Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5320 - custom_f1: 0.6726 - weighted_custom_f1: 0.6780 - val_loss: 1.4270 - val_custom_f1: 0.5192 - val_weighted_custom_f1: 0.5193\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5115 - custom_f1: 0.6711 - weighted_custom_f1: 0.6782 - val_loss: 1.3033 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5417\n",
            "Epoch 66/100\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5169 - custom_f1: 0.6785 - weighted_custom_f1: 0.6829 - val_loss: 1.2753 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5233\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4152 - custom_f1: 0.6667 - weighted_custom_f1: 0.6667Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9158 - custom_f1: 0.5063 - weighted_custom_f1: 0.5131 - val_loss: 1.2738 - val_custom_f1: 0.5032 - val_weighted_custom_f1: 0.5132\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.4816 - custom_f1: 0.7151 - weighted_custom_f1: 0.7188Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5178 - custom_f1: 0.6776 - weighted_custom_f1: 0.6819 - val_loss: 1.1909 - val_custom_f1: 0.4895 - val_weighted_custom_f1: 0.5108\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5220 - custom_f1: 0.6693 - weighted_custom_f1: 0.6741 - val_loss: 1.4075 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5505\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.5659 - custom_f1: 0.6469 - weighted_custom_f1: 0.6511Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5563 - custom_f1: 0.6603 - weighted_custom_f1: 0.6662 - val_loss: 1.0690 - val_custom_f1: 0.5049 - val_weighted_custom_f1: 0.5276\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.8531 - custom_f1: 0.5422 - weighted_custom_f1: 0.5455Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5972 - custom_f1: 0.6428 - weighted_custom_f1: 0.6483 - val_loss: 1.1384 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5123\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5285 - custom_f1: 0.6659 - weighted_custom_f1: 0.6704Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5956 - custom_f1: 0.6431 - weighted_custom_f1: 0.6475 - val_loss: 1.0612 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5116\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5803 - custom_f1: 0.6403 - weighted_custom_f1: 0.6473 - val_loss: 1.3676 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4815\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5765 - custom_f1: 0.6515 - weighted_custom_f1: 0.6565 - val_loss: 1.0823 - val_custom_f1: 0.4990 - val_weighted_custom_f1: 0.5108\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.5112 - custom_f1: 0.6920 - weighted_custom_f1: 0.6956Epoch 68/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5680 - custom_f1: 0.6504 - weighted_custom_f1: 0.6553 - val_loss: 0.9883 - val_custom_f1: 0.4971 - val_weighted_custom_f1: 0.5073\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.5222 - custom_f1: 0.6865 - weighted_custom_f1: 0.6908Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6121 - custom_f1: 0.6325 - weighted_custom_f1: 0.6370 - val_loss: 1.0405 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5238\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6370 - custom_f1: 0.6000 - weighted_custom_f1: 0.6000Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5361 - custom_f1: 0.6684 - weighted_custom_f1: 0.6734 - val_loss: 1.2016 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5339\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5949 - custom_f1: 0.6367 - weighted_custom_f1: 0.6427 - val_loss: 1.2361 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5149\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.5666 - custom_f1: 0.6464 - weighted_custom_f1: 0.6503Epoch 68/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5749 - custom_f1: 0.6467 - weighted_custom_f1: 0.6516 - val_loss: 0.9946 - val_custom_f1: 0.5181 - val_weighted_custom_f1: 0.5396\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.5420 - custom_f1: 0.6679 - weighted_custom_f1: 0.6727Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4728 - custom_f1: 0.7038 - weighted_custom_f1: 0.7071 - val_loss: 1.5382 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5381 - custom_f1: 0.6664 - weighted_custom_f1: 0.6709 - val_loss: 1.2136 - val_custom_f1: 0.5349 - val_weighted_custom_f1: 0.5359\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5105 - custom_f1: 0.6804 - weighted_custom_f1: 0.6876 - val_loss: 1.2712 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 67/100\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.5557 - custom_f1: 0.6474 - weighted_custom_f1: 0.6547Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5035 - custom_f1: 0.6795 - weighted_custom_f1: 0.6860 - val_loss: 1.2736 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5230\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.5678 - custom_f1: 0.6501 - weighted_custom_f1: 0.6537Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9033 - custom_f1: 0.5131 - weighted_custom_f1: 0.5184 - val_loss: 1.2526 - val_custom_f1: 0.4804 - val_weighted_custom_f1: 0.4910\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.5403 - custom_f1: 0.6711 - weighted_custom_f1: 0.6754Epoch 68/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5319 - custom_f1: 0.6692 - weighted_custom_f1: 0.6738 - val_loss: 1.1374 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5324\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.4656 - custom_f1: 0.6945 - weighted_custom_f1: 0.6994Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5411 - custom_f1: 0.6671 - weighted_custom_f1: 0.6721 - val_loss: 1.3207 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5289\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.5516 - custom_f1: 0.6588 - weighted_custom_f1: 0.6636Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5835 - custom_f1: 0.6366 - weighted_custom_f1: 0.6418 - val_loss: 1.2546 - val_custom_f1: 0.5255 - val_weighted_custom_f1: 0.5364\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5829 - custom_f1: 0.6499 - weighted_custom_f1: 0.6532 - val_loss: 1.2199 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5203\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5571 - custom_f1: 0.6597 - weighted_custom_f1: 0.6643 - val_loss: 1.2340 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5267\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5638 - custom_f1: 0.6516 - weighted_custom_f1: 0.6554 - val_loss: 1.4387 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5038\n",
            "Epoch 68/100\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.8945 - custom_f1: 0.5163 - weighted_custom_f1: 0.5196Epoch 67/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5310 - custom_f1: 0.6750 - weighted_custom_f1: 0.6786 - val_loss: 1.3894 - val_custom_f1: 0.5366 - val_weighted_custom_f1: 0.5305\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.5851 - custom_f1: 0.6647 - weighted_custom_f1: 0.6668Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5528 - custom_f1: 0.6582 - weighted_custom_f1: 0.6648 - val_loss: 0.9702 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5189\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5865 - custom_f1: 0.6387 - weighted_custom_f1: 0.6450 - val_loss: 1.0202 - val_custom_f1: 0.5023 - val_weighted_custom_f1: 0.5128\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5733 - custom_f1: 0.6443 - weighted_custom_f1: 0.6504 - val_loss: 1.1681 - val_custom_f1: 0.4842 - val_weighted_custom_f1: 0.5054\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.5749 - custom_f1: 0.6543 - weighted_custom_f1: 0.6621Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5711 - custom_f1: 0.6496 - weighted_custom_f1: 0.6526 - val_loss: 1.0483 - val_custom_f1: 0.5216 - val_weighted_custom_f1: 0.5437\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5451 - custom_f1: 0.6715 - weighted_custom_f1: 0.6748 - val_loss: 1.2533 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5274\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4938 - custom_f1: 0.6816 - weighted_custom_f1: 0.6866 - val_loss: 1.2655 - val_custom_f1: 0.5054 - val_weighted_custom_f1: 0.5285\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6237 - custom_f1: 0.6824 - weighted_custom_f1: 0.6824Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4775 - custom_f1: 0.6946 - weighted_custom_f1: 0.7007 - val_loss: 1.6526 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5212\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8974 - custom_f1: 0.5113 - weighted_custom_f1: 0.5153 - val_loss: 1.2441 - val_custom_f1: 0.5024 - val_weighted_custom_f1: 0.5131\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4815 - custom_f1: 0.6909 - weighted_custom_f1: 0.6964 - val_loss: 1.2075 - val_custom_f1: 0.5172 - val_weighted_custom_f1: 0.5402\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5717 - custom_f1: 0.6535 - weighted_custom_f1: 0.6577Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5376 - custom_f1: 0.6681 - weighted_custom_f1: 0.6726 - val_loss: 1.0901 - val_custom_f1: 0.5133 - val_weighted_custom_f1: 0.5359\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.5454 - custom_f1: 0.6700 - weighted_custom_f1: 0.6753Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5204 - custom_f1: 0.6763 - weighted_custom_f1: 0.6805 - val_loss: 1.2911 - val_custom_f1: 0.5195 - val_weighted_custom_f1: 0.5308\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.9069 - custom_f1: 0.5195 - weighted_custom_f1: 0.5240Epoch 68/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5726 - custom_f1: 0.6531 - weighted_custom_f1: 0.6575 - val_loss: 1.1054 - val_custom_f1: 0.4601 - val_weighted_custom_f1: 0.4723\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.8994 - custom_f1: 0.5150 - weighted_custom_f1: 0.5195Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6048 - custom_f1: 0.6389 - weighted_custom_f1: 0.6430 - val_loss: 1.4002 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5140\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5697 - custom_f1: 0.6515 - weighted_custom_f1: 0.6559 - val_loss: 1.5760 - val_custom_f1: 0.5375 - val_weighted_custom_f1: 0.5324\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5518 - custom_f1: 0.6561 - weighted_custom_f1: 0.6609 - val_loss: 1.0763 - val_custom_f1: 0.5311 - val_weighted_custom_f1: 0.5356\n",
            "Epoch 69/100\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.5257 - custom_f1: 0.6765 - weighted_custom_f1: 0.6782Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5473 - custom_f1: 0.6645 - weighted_custom_f1: 0.6702 - val_loss: 1.1394 - val_custom_f1: 0.5203 - val_weighted_custom_f1: 0.5227\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.4949 - custom_f1: 0.6938 - weighted_custom_f1: 0.6974Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5987 - custom_f1: 0.6395 - weighted_custom_f1: 0.6433 - val_loss: 1.0138 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5067\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.6272 - custom_f1: 0.6374 - weighted_custom_f1: 0.6409Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5539 - custom_f1: 0.6574 - weighted_custom_f1: 0.6621 - val_loss: 0.9805 - val_custom_f1: 0.5081 - val_weighted_custom_f1: 0.5171\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5776 - custom_f1: 0.6441 - weighted_custom_f1: 0.6491 - val_loss: 1.3035 - val_custom_f1: 0.5030 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5655 - custom_f1: 0.6562 - weighted_custom_f1: 0.6609 - val_loss: 0.9971 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5299\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.5842 - custom_f1: 0.6688 - weighted_custom_f1: 0.6726Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5071 - custom_f1: 0.6789 - weighted_custom_f1: 0.6821 - val_loss: 1.3767 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5364\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5040 - custom_f1: 0.6793 - weighted_custom_f1: 0.6830 - val_loss: 1.1699 - val_custom_f1: 0.5411 - val_weighted_custom_f1: 0.5478\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4793 - custom_f1: 0.6931 - weighted_custom_f1: 0.6961 - val_loss: 1.8801 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 69/100\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8948 - custom_f1: 0.5113 - weighted_custom_f1: 0.5170 - val_loss: 1.2953 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5258\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4919 - custom_f1: 0.6923 - weighted_custom_f1: 0.6967 - val_loss: 1.2311 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5399\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0514 - custom_f1: 0.6506 - weighted_custom_f1: 0.6506Epoch 70/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5276 - custom_f1: 0.6719 - weighted_custom_f1: 0.6761 - val_loss: 1.0311 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5326\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 0.5874 - custom_f1: 0.6471 - weighted_custom_f1: 0.6509Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5158 - custom_f1: 0.6795 - weighted_custom_f1: 0.6832 - val_loss: 1.4521 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5378\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.5848 - custom_f1: 0.6484 - weighted_custom_f1: 0.6527Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6076 - custom_f1: 0.6357 - weighted_custom_f1: 0.6407 - val_loss: 1.2409 - val_custom_f1: 0.4879 - val_weighted_custom_f1: 0.4987\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5766 - custom_f1: 0.6514 - weighted_custom_f1: 0.6573 - val_loss: 1.0783 - val_custom_f1: 0.4696 - val_weighted_custom_f1: 0.4805\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6057 - custom_f1: 0.6462 - weighted_custom_f1: 0.6496 - val_loss: 1.5954 - val_custom_f1: 0.5407 - val_weighted_custom_f1: 0.5301\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5423 - custom_f1: 0.6618 - weighted_custom_f1: 0.6667 - val_loss: 1.2463 - val_custom_f1: 0.5336 - val_weighted_custom_f1: 0.5410\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6016 - custom_f1: 0.6408 - weighted_custom_f1: 0.6448 - val_loss: 1.0807 - val_custom_f1: 0.5314 - val_weighted_custom_f1: 0.5402\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.4933 - custom_f1: 0.6958 - weighted_custom_f1: 0.6993Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5153 - custom_f1: 0.6763 - weighted_custom_f1: 0.6800 - val_loss: 1.2545 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5299\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.5046 - custom_f1: 0.6843 - weighted_custom_f1: 0.6893Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5489 - custom_f1: 0.6636 - weighted_custom_f1: 0.6671 - val_loss: 1.0004 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5338\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5839 - custom_f1: 0.6483 - weighted_custom_f1: 0.6516 - val_loss: 1.2692 - val_custom_f1: 0.4896 - val_weighted_custom_f1: 0.5101\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5405 - custom_f1: 0.7077 - weighted_custom_f1: 0.7077Epoch 71/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5629 - custom_f1: 0.6610 - weighted_custom_f1: 0.6633 - val_loss: 0.9976 - val_custom_f1: 0.4892 - val_weighted_custom_f1: 0.5113\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5103 - custom_f1: 0.6817 - weighted_custom_f1: 0.6847 - val_loss: 1.2452 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5110\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4738 - custom_f1: 0.6988 - weighted_custom_f1: 0.7046 - val_loss: 1.5864 - val_custom_f1: 0.5271 - val_weighted_custom_f1: 0.5255\n",
            "Epoch 71/100\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4897 - custom_f1: 0.6896 - weighted_custom_f1: 0.6938 - val_loss: 1.3744 - val_custom_f1: 0.5475 - val_weighted_custom_f1: 0.5473\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.5582 - custom_f1: 0.6610 - weighted_custom_f1: 0.6628Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9086 - custom_f1: 0.5077 - weighted_custom_f1: 0.5134 - val_loss: 1.2571 - val_custom_f1: 0.5241 - val_weighted_custom_f1: 0.5333\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.5785 - custom_f1: 0.6471 - weighted_custom_f1: 0.6516Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4972 - custom_f1: 0.6880 - weighted_custom_f1: 0.6919 - val_loss: 1.2581 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5411\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5252 - custom_f1: 0.6760 - weighted_custom_f1: 0.6796 - val_loss: 1.1050 - val_custom_f1: 0.5155 - val_weighted_custom_f1: 0.5383\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5286 - custom_f1: 0.6732 - weighted_custom_f1: 0.6777 - val_loss: 1.2845 - val_custom_f1: 0.5142 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5806 - custom_f1: 0.6384 - weighted_custom_f1: 0.6453 - val_loss: 1.2383 - val_custom_f1: 0.4680 - val_weighted_custom_f1: 0.4793\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.4985 - custom_f1: 0.6910 - weighted_custom_f1: 0.6933Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5805 - custom_f1: 0.6466 - weighted_custom_f1: 0.6514 - val_loss: 1.1210 - val_custom_f1: 0.5052 - val_weighted_custom_f1: 0.5162\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5627 - custom_f1: 0.6603 - weighted_custom_f1: 0.6627 - val_loss: 1.0902 - val_custom_f1: 0.4999 - val_weighted_custom_f1: 0.5101\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5165 - custom_f1: 0.6821 - weighted_custom_f1: 0.6867 - val_loss: 1.2792 - val_custom_f1: 0.5401 - val_weighted_custom_f1: 0.5374\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5745 - custom_f1: 0.6436 - weighted_custom_f1: 0.6500 - val_loss: 1.4221 - val_custom_f1: 0.5306 - val_weighted_custom_f1: 0.5250\n",
            "Epoch 72/100\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5406 - custom_f1: 0.6694 - weighted_custom_f1: 0.6721 - val_loss: 0.9879 - val_custom_f1: 0.5228 - val_weighted_custom_f1: 0.5321\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.5163 - custom_f1: 0.6810 - weighted_custom_f1: 0.6842Epoch 71/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5847 - custom_f1: 0.6466 - weighted_custom_f1: 0.6500 - val_loss: 1.0602 - val_custom_f1: 0.5278 - val_weighted_custom_f1: 0.5508\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5663 - custom_f1: 0.6509 - weighted_custom_f1: 0.6558 - val_loss: 1.2874 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5278\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5906 - custom_f1: 0.6447 - weighted_custom_f1: 0.6493 - val_loss: 1.0423 - val_custom_f1: 0.5195 - val_weighted_custom_f1: 0.5408\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.5841 - custom_f1: 0.6423 - weighted_custom_f1: 0.6457Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5058 - custom_f1: 0.6840 - weighted_custom_f1: 0.6868 - val_loss: 1.2264 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5294\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5060 - custom_f1: 0.6853 - weighted_custom_f1: 0.6880 - val_loss: 1.4597 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5277\n",
            "Epoch 71/100\n",
            " 69/105 [==================>...........] - ETA: 0s - loss: 0.6001 - custom_f1: 0.6519 - weighted_custom_f1: 0.6557Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4708 - custom_f1: 0.6996 - weighted_custom_f1: 0.7031 - val_loss: 1.9255 - val_custom_f1: 0.5354 - val_weighted_custom_f1: 0.5306\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9030 - custom_f1: 0.5112 - weighted_custom_f1: 0.5164 - val_loss: 1.2448 - val_custom_f1: 0.4733 - val_weighted_custom_f1: 0.4844\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4673 - custom_f1: 0.7004 - weighted_custom_f1: 0.7042 - val_loss: 1.4217 - val_custom_f1: 0.5245 - val_weighted_custom_f1: 0.5462\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5219 - custom_f1: 0.6754 - weighted_custom_f1: 0.6798 - val_loss: 1.0689 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5230\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.9242 - custom_f1: 0.5060 - weighted_custom_f1: 0.5125Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5379 - custom_f1: 0.6726 - weighted_custom_f1: 0.6780 - val_loss: 1.2655 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5264\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.5486 - custom_f1: 0.6519 - weighted_custom_f1: 0.6592Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5889 - custom_f1: 0.6418 - weighted_custom_f1: 0.6466 - val_loss: 1.2725 - val_custom_f1: 0.5047 - val_weighted_custom_f1: 0.5158\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5714 - custom_f1: 0.6493 - weighted_custom_f1: 0.6551 - val_loss: 1.1731 - val_custom_f1: 0.5102 - val_weighted_custom_f1: 0.5316\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5608 - custom_f1: 0.6569 - weighted_custom_f1: 0.6614 - val_loss: 1.4130 - val_custom_f1: 0.5146 - val_weighted_custom_f1: 0.5084\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.5148 - custom_f1: 0.6775 - weighted_custom_f1: 0.6805Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5956 - custom_f1: 0.6461 - weighted_custom_f1: 0.6506 - val_loss: 1.1580 - val_custom_f1: 0.5194 - val_weighted_custom_f1: 0.5404\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5162 - custom_f1: 0.6819 - weighted_custom_f1: 0.6867 - val_loss: 1.1610 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5485 - custom_f1: 0.6625 - weighted_custom_f1: 0.6675 - val_loss: 1.3162 - val_custom_f1: 0.4917 - val_weighted_custom_f1: 0.5133\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.5672 - custom_f1: 0.6698 - weighted_custom_f1: 0.6770Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5812 - custom_f1: 0.6474 - weighted_custom_f1: 0.6507 - val_loss: 1.1087 - val_custom_f1: 0.5387 - val_weighted_custom_f1: 0.5437\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5489 - custom_f1: 0.6613 - weighted_custom_f1: 0.6651 - val_loss: 1.0258 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5372\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.4562 - custom_f1: 0.7114 - weighted_custom_f1: 0.7155Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5630 - custom_f1: 0.6471 - weighted_custom_f1: 0.6515 - val_loss: 1.0090 - val_custom_f1: 0.4958 - val_weighted_custom_f1: 0.5180\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5140 - custom_f1: 0.6765 - weighted_custom_f1: 0.6815 - val_loss: 1.2552 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5112\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5156 - custom_f1: 0.6774 - weighted_custom_f1: 0.6816 - val_loss: 1.2679 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5400\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4662 - custom_f1: 0.7009 - weighted_custom_f1: 0.7054 - val_loss: 1.8358 - val_custom_f1: 0.5321 - val_weighted_custom_f1: 0.5320\n",
            "Epoch 73/100\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.5776 - custom_f1: 0.6519 - weighted_custom_f1: 0.6558Epoch 72/100\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8969 - custom_f1: 0.4982 - weighted_custom_f1: 0.5038 - val_loss: 1.3316 - val_custom_f1: 0.4915 - val_weighted_custom_f1: 0.5034\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5225 - custom_f1: 0.6715 - weighted_custom_f1: 0.6764 - val_loss: 1.1195 - val_custom_f1: 0.5116 - val_weighted_custom_f1: 0.5338\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4569 - custom_f1: 0.7072 - weighted_custom_f1: 0.7117 - val_loss: 1.3264 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5228\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.4852 - custom_f1: 0.6886 - weighted_custom_f1: 0.6937Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5382 - custom_f1: 0.6713 - weighted_custom_f1: 0.6746 - val_loss: 1.3184 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5474 - custom_f1: 0.6620 - weighted_custom_f1: 0.6655 - val_loss: 1.6738 - val_custom_f1: 0.5448 - val_weighted_custom_f1: 0.5361\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.4990 - custom_f1: 0.6861 - weighted_custom_f1: 0.6904Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5721 - custom_f1: 0.6496 - weighted_custom_f1: 0.6555 - val_loss: 1.3090 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5196\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5721 - custom_f1: 0.6531 - weighted_custom_f1: 0.6578 - val_loss: 1.1300 - val_custom_f1: 0.4957 - val_weighted_custom_f1: 0.5072\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5623 - custom_f1: 0.6509 - weighted_custom_f1: 0.6558 - val_loss: 1.2058 - val_custom_f1: 0.5505 - val_weighted_custom_f1: 0.5550\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.4652 - custom_f1: 0.6986 - weighted_custom_f1: 0.7048Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5152 - custom_f1: 0.6841 - weighted_custom_f1: 0.6887 - val_loss: 1.1801 - val_custom_f1: 0.5190 - val_weighted_custom_f1: 0.5176\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5564 - custom_f1: 0.6539 - weighted_custom_f1: 0.6596 - val_loss: 1.3473 - val_custom_f1: 0.4955 - val_weighted_custom_f1: 0.5172\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.5615 - custom_f1: 0.6554 - weighted_custom_f1: 0.6599Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5528 - custom_f1: 0.6559 - weighted_custom_f1: 0.6613 - val_loss: 1.1202 - val_custom_f1: 0.5241 - val_weighted_custom_f1: 0.5356\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5352 - custom_f1: 0.6705 - weighted_custom_f1: 0.6755 - val_loss: 0.9985 - val_custom_f1: 0.5167 - val_weighted_custom_f1: 0.5286\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5592 - custom_f1: 0.6595 - weighted_custom_f1: 0.6660 - val_loss: 1.0121 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5294\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.5227 - custom_f1: 0.6776 - weighted_custom_f1: 0.6815Epoch 74/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5165 - custom_f1: 0.6811 - weighted_custom_f1: 0.6877 - val_loss: 1.2968 - val_custom_f1: 0.5176 - val_weighted_custom_f1: 0.5229\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.5244 - custom_f1: 0.6756 - weighted_custom_f1: 0.6790Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4571 - custom_f1: 0.7051 - weighted_custom_f1: 0.7101 - val_loss: 1.6498 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5294\n",
            "  9/105 [=>............................] - ETA: 0s - loss: 0.5982 - custom_f1: 0.7004 - weighted_custom_f1: 0.7048Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4857 - custom_f1: 0.6860 - weighted_custom_f1: 0.6910 - val_loss: 1.3581 - val_custom_f1: 0.5179 - val_weighted_custom_f1: 0.5416\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4395 - custom_f1: 0.6557 - weighted_custom_f1: 0.6557Epoch 73/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4822 - custom_f1: 0.6917 - weighted_custom_f1: 0.6966 - val_loss: 1.2485 - val_custom_f1: 0.5055 - val_weighted_custom_f1: 0.5277\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9059 - custom_f1: 0.5087 - weighted_custom_f1: 0.5124 - val_loss: 1.4330 - val_custom_f1: 0.5247 - val_weighted_custom_f1: 0.5283\n",
            "  9/105 [=>............................] - ETA: 0s - loss: 0.4398 - custom_f1: 0.7050 - weighted_custom_f1: 0.7084Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5256 - custom_f1: 0.6750 - weighted_custom_f1: 0.6793 - val_loss: 1.1433 - val_custom_f1: 0.5074 - val_weighted_custom_f1: 0.5306\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5445 - custom_f1: 0.6716 - weighted_custom_f1: 0.6774 - val_loss: 1.4687 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5370\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5773 - custom_f1: 0.6463 - weighted_custom_f1: 0.6502Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5864 - custom_f1: 0.6515 - weighted_custom_f1: 0.6560 - val_loss: 1.2766 - val_custom_f1: 0.4965 - val_weighted_custom_f1: 0.5071\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5723 - custom_f1: 0.6558 - weighted_custom_f1: 0.6610 - val_loss: 1.1569 - val_custom_f1: 0.5214 - val_weighted_custom_f1: 0.5258\n",
            "Epoch 74/100\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5547 - custom_f1: 0.6590 - weighted_custom_f1: 0.6640 - val_loss: 1.1956 - val_custom_f1: 0.5015 - val_weighted_custom_f1: 0.5239\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6092 - custom_f1: 0.6216 - weighted_custom_f1: 0.6216Epoch 75/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5282 - custom_f1: 0.6648 - weighted_custom_f1: 0.6695 - val_loss: 1.4558 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5088 - custom_f1: 0.6839 - weighted_custom_f1: 0.6871 - val_loss: 1.2614 - val_custom_f1: 0.5351 - val_weighted_custom_f1: 0.5324\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.5485 - custom_f1: 0.6586 - weighted_custom_f1: 0.6626Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5494 - custom_f1: 0.6671 - weighted_custom_f1: 0.6705 - val_loss: 1.3215 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5148\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5591 - custom_f1: 0.6575 - weighted_custom_f1: 0.6638 - val_loss: 1.1306 - val_custom_f1: 0.5267 - val_weighted_custom_f1: 0.5347\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.5560 - custom_f1: 0.6617 - weighted_custom_f1: 0.6656Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5338 - custom_f1: 0.6619 - weighted_custom_f1: 0.6684 - val_loss: 1.0547 - val_custom_f1: 0.5190 - val_weighted_custom_f1: 0.5287\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5737 - custom_f1: 0.6491 - weighted_custom_f1: 0.6541 - val_loss: 1.0446 - val_custom_f1: 0.5165 - val_weighted_custom_f1: 0.5387\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5887 - custom_f1: 0.6478 - weighted_custom_f1: 0.6545Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4999 - custom_f1: 0.6886 - weighted_custom_f1: 0.6931 - val_loss: 1.4463 - val_custom_f1: 0.5238 - val_weighted_custom_f1: 0.5277\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.5896 - custom_f1: 0.6408 - weighted_custom_f1: 0.6444Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5211 - custom_f1: 0.6753 - weighted_custom_f1: 0.6811 - val_loss: 1.2690 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9012 - custom_f1: 0.5133 - weighted_custom_f1: 0.5172 - val_loss: 1.2467 - val_custom_f1: 0.5007 - val_weighted_custom_f1: 0.5117\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4637 - custom_f1: 0.7097 - weighted_custom_f1: 0.7133 - val_loss: 1.5884 - val_custom_f1: 0.5219 - val_weighted_custom_f1: 0.5186\n",
            "Epoch 75/100\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.5139 - custom_f1: 0.6779 - weighted_custom_f1: 0.6818Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4852 - custom_f1: 0.6951 - weighted_custom_f1: 0.6982 - val_loss: 1.3199 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5388\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5210 - custom_f1: 0.6767 - weighted_custom_f1: 0.6805 - val_loss: 1.0759 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5349\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5131 - custom_f1: 0.6758 - weighted_custom_f1: 0.6804 - val_loss: 1.2871 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5115\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.5412 - custom_f1: 0.6645 - weighted_custom_f1: 0.6689Epoch 74/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5964 - custom_f1: 0.6433 - weighted_custom_f1: 0.6468 - val_loss: 1.2273 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5291\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5700 - custom_f1: 0.6579 - weighted_custom_f1: 0.6579Epoch 75/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5885 - custom_f1: 0.6476 - weighted_custom_f1: 0.6517 - val_loss: 1.2348 - val_custom_f1: 0.5487 - val_weighted_custom_f1: 0.5474\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5598 - custom_f1: 0.6614 - weighted_custom_f1: 0.6640 - val_loss: 1.1325 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5021\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.5041 - custom_f1: 0.6843 - weighted_custom_f1: 0.6880Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5191 - custom_f1: 0.6734 - weighted_custom_f1: 0.6781 - val_loss: 1.5694 - val_custom_f1: 0.5308 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4958 - custom_f1: 0.6841 - weighted_custom_f1: 0.6881 - val_loss: 1.2340 - val_custom_f1: 0.5312 - val_weighted_custom_f1: 0.5316\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5701 - custom_f1: 0.6503 - weighted_custom_f1: 0.6542 - val_loss: 1.2087 - val_custom_f1: 0.5616 - val_weighted_custom_f1: 0.5681\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5533 - custom_f1: 0.6596 - weighted_custom_f1: 0.6648 - val_loss: 1.3284 - val_custom_f1: 0.4829 - val_weighted_custom_f1: 0.5036\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.5078 - custom_f1: 0.6837 - weighted_custom_f1: 0.6876Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5384 - custom_f1: 0.6672 - weighted_custom_f1: 0.6713 - val_loss: 1.1461 - val_custom_f1: 0.5219 - val_weighted_custom_f1: 0.5439\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.5047 - custom_f1: 0.6866 - weighted_custom_f1: 0.6901Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5434 - custom_f1: 0.6649 - weighted_custom_f1: 0.6688 - val_loss: 1.0347 - val_custom_f1: 0.4901 - val_weighted_custom_f1: 0.5110\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5078 - custom_f1: 0.6837 - weighted_custom_f1: 0.6876 - val_loss: 1.2622 - val_custom_f1: 0.5104 - val_weighted_custom_f1: 0.5189\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8938 - custom_f1: 0.5095 - weighted_custom_f1: 0.5122 - val_loss: 1.2893 - val_custom_f1: 0.5040 - val_weighted_custom_f1: 0.5132\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.5117 - custom_f1: 0.6791 - weighted_custom_f1: 0.6846Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4836 - custom_f1: 0.6907 - weighted_custom_f1: 0.6936 - val_loss: 1.4171 - val_custom_f1: 0.5526 - val_weighted_custom_f1: 0.5584\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4483 - custom_f1: 0.7090 - weighted_custom_f1: 0.7123 - val_loss: 1.7396 - val_custom_f1: 0.5415 - val_weighted_custom_f1: 0.5369\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.5025 - custom_f1: 0.6892 - weighted_custom_f1: 0.6937Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4637 - custom_f1: 0.7092 - weighted_custom_f1: 0.7138 - val_loss: 1.2876 - val_custom_f1: 0.5385 - val_weighted_custom_f1: 0.5613\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3368 - custom_f1: 0.8136 - weighted_custom_f1: 0.8136Epoch 76/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5181 - custom_f1: 0.6774 - weighted_custom_f1: 0.6800 - val_loss: 1.0771 - val_custom_f1: 0.5025 - val_weighted_custom_f1: 0.5254\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.4221 - custom_f1: 0.7165 - weighted_custom_f1: 0.7192Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5054 - custom_f1: 0.6853 - weighted_custom_f1: 0.6891 - val_loss: 1.4405 - val_custom_f1: 0.5262 - val_weighted_custom_f1: 0.5371\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5977 - custom_f1: 0.6394 - weighted_custom_f1: 0.6425 - val_loss: 1.2394 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.5040\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5357 - custom_f1: 0.6697 - weighted_custom_f1: 0.6732 - val_loss: 1.2006 - val_custom_f1: 0.5196 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5638 - custom_f1: 0.6531 - weighted_custom_f1: 0.6576 - val_loss: 1.6412 - val_custom_f1: 0.5471 - val_weighted_custom_f1: 0.5403\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.8910 - custom_f1: 0.5142 - weighted_custom_f1: 0.5173Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5041 - custom_f1: 0.6860 - weighted_custom_f1: 0.6915 - val_loss: 1.1771 - val_custom_f1: 0.4799 - val_weighted_custom_f1: 0.4804\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5464 - custom_f1: 0.6663 - weighted_custom_f1: 0.6697 - val_loss: 1.1998 - val_custom_f1: 0.4963 - val_weighted_custom_f1: 0.5173\n",
            "Epoch 77/100\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5423 - custom_f1: 0.6601 - weighted_custom_f1: 0.6625 - val_loss: 1.3996 - val_custom_f1: 0.4886 - val_weighted_custom_f1: 0.5089\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5789 - custom_f1: 0.6494 - weighted_custom_f1: 0.6533 - val_loss: 1.0949 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5318\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5293 - custom_f1: 0.6769 - weighted_custom_f1: 0.6810 - val_loss: 1.0293 - val_custom_f1: 0.5032 - val_weighted_custom_f1: 0.5116\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.5450 - custom_f1: 0.6846 - weighted_custom_f1: 0.6874Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5483 - custom_f1: 0.6618 - weighted_custom_f1: 0.6640 - val_loss: 1.0023 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5392\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.4952 - custom_f1: 0.6929 - weighted_custom_f1: 0.6977Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4918 - custom_f1: 0.6964 - weighted_custom_f1: 0.6986 - val_loss: 1.2995 - val_custom_f1: 0.5025 - val_weighted_custom_f1: 0.5072\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.5390 - custom_f1: 0.6706 - weighted_custom_f1: 0.6729Epoch 77/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8874 - custom_f1: 0.5090 - weighted_custom_f1: 0.5133 - val_loss: 1.2750 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5208\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.5761 - custom_f1: 0.6558 - weighted_custom_f1: 0.6596Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5013 - custom_f1: 0.6816 - weighted_custom_f1: 0.6858 - val_loss: 1.2609 - val_custom_f1: 0.5086 - val_weighted_custom_f1: 0.5195\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4393 - custom_f1: 0.7150 - weighted_custom_f1: 0.7191 - val_loss: 1.8769 - val_custom_f1: 0.5458 - val_weighted_custom_f1: 0.5404\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4533 - custom_f1: 0.7123 - weighted_custom_f1: 0.7151 - val_loss: 1.3920 - val_custom_f1: 0.5053 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5083 - custom_f1: 0.6812 - weighted_custom_f1: 0.6861 - val_loss: 1.1021 - val_custom_f1: 0.4710 - val_weighted_custom_f1: 0.4928\n",
            " 96/105 [==========================>...] - ETA: 0s - loss: 0.4924 - custom_f1: 0.6886 - weighted_custom_f1: 0.6922Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5462 - custom_f1: 0.6636 - weighted_custom_f1: 0.6687 - val_loss: 1.3557 - val_custom_f1: 0.5132 - val_weighted_custom_f1: 0.5230\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4975 - custom_f1: 0.6871 - weighted_custom_f1: 0.6906 - val_loss: 1.3837 - val_custom_f1: 0.5049 - val_weighted_custom_f1: 0.5148\n",
            "Epoch 77/100\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5384 - custom_f1: 0.6666 - weighted_custom_f1: 0.6698 - val_loss: 1.2286 - val_custom_f1: 0.5189 - val_weighted_custom_f1: 0.5396\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3954 - custom_f1: 0.7843 - weighted_custom_f1: 0.7843Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5639 - custom_f1: 0.6544 - weighted_custom_f1: 0.6592 - val_loss: 1.6659 - val_custom_f1: 0.5271 - val_weighted_custom_f1: 0.5219\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.4977 - custom_f1: 0.6842 - weighted_custom_f1: 0.6896Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5476 - custom_f1: 0.6626 - weighted_custom_f1: 0.6679 - val_loss: 1.3435 - val_custom_f1: 0.4779 - val_weighted_custom_f1: 0.4987\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5097 - custom_f1: 0.6804 - weighted_custom_f1: 0.6841 - val_loss: 1.4346 - val_custom_f1: 0.5345 - val_weighted_custom_f1: 0.5318\n",
            "Epoch 78/100\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.5844 - custom_f1: 0.6546 - weighted_custom_f1: 0.6604Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5590 - custom_f1: 0.6615 - weighted_custom_f1: 0.6689 - val_loss: 1.1162 - val_custom_f1: 0.4803 - val_weighted_custom_f1: 0.4912\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5817 - custom_f1: 0.6190 - weighted_custom_f1: 0.6190Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5641 - custom_f1: 0.6555 - weighted_custom_f1: 0.6578 - val_loss: 1.2315 - val_custom_f1: 0.5197 - val_weighted_custom_f1: 0.5304\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5422 - custom_f1: 0.6694 - weighted_custom_f1: 0.6717 - val_loss: 1.0204 - val_custom_f1: 0.5283 - val_weighted_custom_f1: 0.5379\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5572 - custom_f1: 0.6564 - weighted_custom_f1: 0.6638 - val_loss: 1.0278 - val_custom_f1: 0.4802 - val_weighted_custom_f1: 0.5012\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4988 - custom_f1: 0.6896 - weighted_custom_f1: 0.6950 - val_loss: 1.2572 - val_custom_f1: 0.4893 - val_weighted_custom_f1: 0.4946\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9087 - custom_f1: 0.5059 - weighted_custom_f1: 0.5121 - val_loss: 1.3494 - val_custom_f1: 0.4637 - val_weighted_custom_f1: 0.4751\n",
            "Epoch 78/100\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.4834 - custom_f1: 0.6976 - weighted_custom_f1: 0.7013Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4559 - custom_f1: 0.7095 - weighted_custom_f1: 0.7153 - val_loss: 1.7059 - val_custom_f1: 0.5282 - val_weighted_custom_f1: 0.5267\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4812 - custom_f1: 0.6968 - weighted_custom_f1: 0.6988 - val_loss: 1.3271 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5346\n",
            "Epoch 77/100\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.9096 - custom_f1: 0.5111 - weighted_custom_f1: 0.5152Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4636 - custom_f1: 0.7043 - weighted_custom_f1: 0.7080 - val_loss: 1.4044 - val_custom_f1: 0.4643 - val_weighted_custom_f1: 0.4857\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.5337 - custom_f1: 0.6554 - weighted_custom_f1: 0.6605Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5084 - custom_f1: 0.6797 - weighted_custom_f1: 0.6836 - val_loss: 1.1503 - val_custom_f1: 0.5165 - val_weighted_custom_f1: 0.5398\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.4972 - custom_f1: 0.6911 - weighted_custom_f1: 0.6939Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5356 - custom_f1: 0.6681 - weighted_custom_f1: 0.6754 - val_loss: 1.2159 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5307\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5789 - custom_f1: 0.6516 - weighted_custom_f1: 0.6587 - val_loss: 1.3082 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4959\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4852 - custom_f1: 0.6947 - weighted_custom_f1: 0.6983 - val_loss: 1.5357 - val_custom_f1: 0.5230 - val_weighted_custom_f1: 0.5317\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5317 - custom_f1: 0.6702 - weighted_custom_f1: 0.6750 - val_loss: 1.5346 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5239\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.4476 - custom_f1: 0.7137 - weighted_custom_f1: 0.7173Epoch 79/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5443 - custom_f1: 0.6673 - weighted_custom_f1: 0.6720 - val_loss: 1.1528 - val_custom_f1: 0.4918 - val_weighted_custom_f1: 0.5049\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4274 - custom_f1: 0.7200 - weighted_custom_f1: 0.7200Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5285 - custom_f1: 0.6596 - weighted_custom_f1: 0.6654 - val_loss: 1.5801 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5119\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5693 - custom_f1: 0.6558 - weighted_custom_f1: 0.6617 - val_loss: 1.1873 - val_custom_f1: 0.4664 - val_weighted_custom_f1: 0.4803\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4955 - custom_f1: 0.6945 - weighted_custom_f1: 0.6958 - val_loss: 1.4021 - val_custom_f1: 0.5488 - val_weighted_custom_f1: 0.5462\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.4936 - custom_f1: 0.7025 - weighted_custom_f1: 0.7079Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5290 - custom_f1: 0.6736 - weighted_custom_f1: 0.6798 - val_loss: 1.0240 - val_custom_f1: 0.4890 - val_weighted_custom_f1: 0.4972\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.5677 - custom_f1: 0.6654 - weighted_custom_f1: 0.6696Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5500 - custom_f1: 0.6653 - weighted_custom_f1: 0.6695 - val_loss: 1.0347 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5384\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9042 - custom_f1: 0.5152 - weighted_custom_f1: 0.5202 - val_loss: 1.2560 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5022\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4842 - custom_f1: 0.6949 - weighted_custom_f1: 0.6980 - val_loss: 1.3752 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5229\n",
            "Epoch 79/100\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4467 - custom_f1: 0.7072 - weighted_custom_f1: 0.7111 - val_loss: 1.4854 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5414\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.5400 - custom_f1: 0.6799 - weighted_custom_f1: 0.6831Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4921 - custom_f1: 0.6879 - weighted_custom_f1: 0.6948 - val_loss: 1.3555 - val_custom_f1: 0.4983 - val_weighted_custom_f1: 0.5090\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.2954 - custom_f1: 0.8163 - weighted_custom_f1: 0.8163Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4721 - custom_f1: 0.7056 - weighted_custom_f1: 0.7090 - val_loss: 1.9283 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5380\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.5717 - custom_f1: 0.6524 - weighted_custom_f1: 0.6570Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5071 - custom_f1: 0.6849 - weighted_custom_f1: 0.6910 - val_loss: 1.1304 - val_custom_f1: 0.4920 - val_weighted_custom_f1: 0.5139\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.5108 - custom_f1: 0.6932 - weighted_custom_f1: 0.6961Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5826 - custom_f1: 0.6482 - weighted_custom_f1: 0.6528 - val_loss: 1.2655 - val_custom_f1: 0.4912 - val_weighted_custom_f1: 0.5005\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5599 - custom_f1: 0.6581 - weighted_custom_f1: 0.6625 - val_loss: 1.2664 - val_custom_f1: 0.4970 - val_weighted_custom_f1: 0.5044\n",
            "Epoch 79/100\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4876 - custom_f1: 0.6906 - weighted_custom_f1: 0.6977 - val_loss: 1.3611 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5205\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.4341 - custom_f1: 0.7219 - weighted_custom_f1: 0.7253Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5471 - custom_f1: 0.6694 - weighted_custom_f1: 0.6734 - val_loss: 1.1642 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5182\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5145 - custom_f1: 0.6745 - weighted_custom_f1: 0.6822 - val_loss: 1.3609 - val_custom_f1: 0.4953 - val_weighted_custom_f1: 0.5158\n",
            "Epoch 80/100\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5329 - custom_f1: 0.6645 - weighted_custom_f1: 0.6681 - val_loss: 1.6144 - val_custom_f1: 0.5488 - val_weighted_custom_f1: 0.5414\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5077 - custom_f1: 0.6852 - weighted_custom_f1: 0.6894 - val_loss: 1.2361 - val_custom_f1: 0.5271 - val_weighted_custom_f1: 0.5274\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5595 - custom_f1: 0.6581 - weighted_custom_f1: 0.6625 - val_loss: 1.2100 - val_custom_f1: 0.5372 - val_weighted_custom_f1: 0.5454\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.5627 - custom_f1: 0.6508 - weighted_custom_f1: 0.6570Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5136 - custom_f1: 0.6828 - weighted_custom_f1: 0.6868 - val_loss: 1.0138 - val_custom_f1: 0.5031 - val_weighted_custom_f1: 0.5250\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4744 - custom_f1: 0.6973 - weighted_custom_f1: 0.7033 - val_loss: 1.3526 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5266\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8873 - custom_f1: 0.5095 - weighted_custom_f1: 0.5142 - val_loss: 1.3321 - val_custom_f1: 0.5258 - val_weighted_custom_f1: 0.5352\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5372 - custom_f1: 0.6657 - weighted_custom_f1: 0.6701 - val_loss: 1.1054 - val_custom_f1: 0.5131 - val_weighted_custom_f1: 0.5347\n",
            "Epoch 80/100\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.4894 - custom_f1: 0.7002 - weighted_custom_f1: 0.7043Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4815 - custom_f1: 0.6944 - weighted_custom_f1: 0.6981 - val_loss: 1.3972 - val_custom_f1: 0.5113 - val_weighted_custom_f1: 0.5345\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4488 - custom_f1: 0.7079 - weighted_custom_f1: 0.7151 - val_loss: 1.4691 - val_custom_f1: 0.5033 - val_weighted_custom_f1: 0.5256\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4566 - custom_f1: 0.7098 - weighted_custom_f1: 0.7118 - val_loss: 1.9959 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5411\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5066 - custom_f1: 0.6889 - weighted_custom_f1: 0.6927 - val_loss: 1.0986 - val_custom_f1: 0.4819 - val_weighted_custom_f1: 0.5041\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.8798 - custom_f1: 0.5029 - weighted_custom_f1: 0.5068Epoch 81/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5517 - custom_f1: 0.6532 - weighted_custom_f1: 0.6588 - val_loss: 1.3029 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5218\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 0.5140 - custom_f1: 0.6782 - weighted_custom_f1: 0.6828Epoch 80/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5314 - custom_f1: 0.6716 - weighted_custom_f1: 0.6759 - val_loss: 1.3035 - val_custom_f1: 0.5376 - val_weighted_custom_f1: 0.5418\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5443 - custom_f1: 0.6556 - weighted_custom_f1: 0.6591 - val_loss: 1.3255 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.4937\n",
            " 60/105 [================>.............] - ETA: 0s - loss: 0.4845 - custom_f1: 0.7053 - weighted_custom_f1: 0.7099Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4862 - custom_f1: 0.6945 - weighted_custom_f1: 0.6983 - val_loss: 1.3643 - val_custom_f1: 0.5228 - val_weighted_custom_f1: 0.5341\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5385 - custom_f1: 0.6687 - weighted_custom_f1: 0.6731 - val_loss: 1.2797 - val_custom_f1: 0.5081 - val_weighted_custom_f1: 0.5157\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5245 - custom_f1: 0.6720 - weighted_custom_f1: 0.6743 - val_loss: 1.8264 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5239\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4934 - custom_f1: 0.6879 - weighted_custom_f1: 0.6921 - val_loss: 1.2029 - val_custom_f1: 0.4940 - val_weighted_custom_f1: 0.4953\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5451 - custom_f1: 0.6673 - weighted_custom_f1: 0.6732 - val_loss: 1.2608 - val_custom_f1: 0.5204 - val_weighted_custom_f1: 0.5429\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5137 - custom_f1: 0.6780 - weighted_custom_f1: 0.6840 - val_loss: 1.0363 - val_custom_f1: 0.5073 - val_weighted_custom_f1: 0.5307\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4691 - custom_f1: 0.7051 - weighted_custom_f1: 0.7077 - val_loss: 1.4453 - val_custom_f1: 0.5290 - val_weighted_custom_f1: 0.5355\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.5069 - custom_f1: 0.6808 - weighted_custom_f1: 0.6851Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8926 - custom_f1: 0.5113 - weighted_custom_f1: 0.5151 - val_loss: 1.3208 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5234\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.5211 - custom_f1: 0.6914 - weighted_custom_f1: 0.6952Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5389 - custom_f1: 0.6698 - weighted_custom_f1: 0.6735 - val_loss: 1.0499 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5304\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4501 - custom_f1: 0.7155 - weighted_custom_f1: 0.7192 - val_loss: 1.4116 - val_custom_f1: 0.4932 - val_weighted_custom_f1: 0.5159\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.5282 - custom_f1: 0.6699 - weighted_custom_f1: 0.6755Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4716 - custom_f1: 0.6954 - weighted_custom_f1: 0.7002 - val_loss: 1.4207 - val_custom_f1: 0.5293 - val_weighted_custom_f1: 0.5298\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.9226 - custom_f1: 0.5042 - weighted_custom_f1: 0.5080Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4872 - custom_f1: 0.7039 - weighted_custom_f1: 0.7083 - val_loss: 1.8434 - val_custom_f1: 0.5494 - val_weighted_custom_f1: 0.5456\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5089 - custom_f1: 0.6837 - weighted_custom_f1: 0.6867 - val_loss: 1.1136 - val_custom_f1: 0.5128 - val_weighted_custom_f1: 0.5357\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.5445 - custom_f1: 0.6644 - weighted_custom_f1: 0.6663Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5453 - custom_f1: 0.6663 - weighted_custom_f1: 0.6706 - val_loss: 1.4275 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5260\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5344 - custom_f1: 0.6710 - weighted_custom_f1: 0.6741 - val_loss: 1.1757 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5394\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.5184 - custom_f1: 0.6818 - weighted_custom_f1: 0.6841Epoch 81/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5378 - custom_f1: 0.6743 - weighted_custom_f1: 0.6783 - val_loss: 1.1725 - val_custom_f1: 0.4961 - val_weighted_custom_f1: 0.5061\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5615 - custom_f1: 0.6642 - weighted_custom_f1: 0.6676 - val_loss: 1.3045 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5269\n",
            "Epoch 82/100\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4730 - custom_f1: 0.6936 - weighted_custom_f1: 0.6975 - val_loss: 1.5233 - val_custom_f1: 0.5212 - val_weighted_custom_f1: 0.5287\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5369 - custom_f1: 0.6686 - weighted_custom_f1: 0.6730 - val_loss: 1.5867 - val_custom_f1: 0.5402 - val_weighted_custom_f1: 0.5341\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4845 - custom_f1: 0.6988 - weighted_custom_f1: 0.7040 - val_loss: 1.2940 - val_custom_f1: 0.5373 - val_weighted_custom_f1: 0.5347\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5218 - custom_f1: 0.7869 - weighted_custom_f1: 0.7869Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5490 - custom_f1: 0.6624 - weighted_custom_f1: 0.6649 - val_loss: 1.1895 - val_custom_f1: 0.5450 - val_weighted_custom_f1: 0.5508\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.4610 - custom_f1: 0.7072 - weighted_custom_f1: 0.7111Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5181 - custom_f1: 0.6804 - weighted_custom_f1: 0.6832 - val_loss: 1.0888 - val_custom_f1: 0.5099 - val_weighted_custom_f1: 0.5329\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5332 - custom_f1: 0.6656 - weighted_custom_f1: 0.6700 - val_loss: 1.0675 - val_custom_f1: 0.4877 - val_weighted_custom_f1: 0.5094\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4907 - custom_f1: 0.6923 - weighted_custom_f1: 0.6973 - val_loss: 1.2959 - val_custom_f1: 0.5172 - val_weighted_custom_f1: 0.5231\n",
            "Epoch 82/100\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8892 - custom_f1: 0.5099 - weighted_custom_f1: 0.5139 - val_loss: 1.3179 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5192\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4612 - custom_f1: 0.7077 - weighted_custom_f1: 0.7107 - val_loss: 1.4785 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5289\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4609 - custom_f1: 0.7093 - weighted_custom_f1: 0.7121 - val_loss: 1.3514 - val_custom_f1: 0.5242 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5033 - custom_f1: 0.6874 - weighted_custom_f1: 0.6912 - val_loss: 1.1049 - val_custom_f1: 0.5109 - val_weighted_custom_f1: 0.5338\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.5080 - custom_f1: 0.6775 - weighted_custom_f1: 0.6823Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4370 - custom_f1: 0.7193 - weighted_custom_f1: 0.7232 - val_loss: 1.6967 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5035\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.9044 - custom_f1: 0.5210 - weighted_custom_f1: 0.5239Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5483 - custom_f1: 0.6625 - weighted_custom_f1: 0.6671 - val_loss: 1.1914 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5211\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5515 - custom_f1: 0.6642 - weighted_custom_f1: 0.6691 - val_loss: 1.4102 - val_custom_f1: 0.4956 - val_weighted_custom_f1: 0.5051\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5631 - custom_f1: 0.6570 - weighted_custom_f1: 0.6604 - val_loss: 1.2882 - val_custom_f1: 0.4887 - val_weighted_custom_f1: 0.5098\n",
            "Epoch 82/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4457 - custom_f1: 0.6316 - weighted_custom_f1: 0.6316Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4845 - custom_f1: 0.6935 - weighted_custom_f1: 0.6979 - val_loss: 1.5629 - val_custom_f1: 0.5213 - val_weighted_custom_f1: 0.5296\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.5131 - custom_f1: 0.6472 - weighted_custom_f1: 0.6481Epoch 81/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5401 - custom_f1: 0.6671 - weighted_custom_f1: 0.6733 - val_loss: 1.1672 - val_custom_f1: 0.4943 - val_weighted_custom_f1: 0.5062\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.4670 - custom_f1: 0.7067 - weighted_custom_f1: 0.7099Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5128 - custom_f1: 0.6745 - weighted_custom_f1: 0.6788 - val_loss: 1.6231 - val_custom_f1: 0.5057 - val_weighted_custom_f1: 0.4981\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.4214 - custom_f1: 0.7255 - weighted_custom_f1: 0.7300Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5621 - custom_f1: 0.6566 - weighted_custom_f1: 0.6623 - val_loss: 1.1656 - val_custom_f1: 0.4933 - val_weighted_custom_f1: 0.5009\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.4862 - custom_f1: 0.6860 - weighted_custom_f1: 0.6934Epoch 82/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4808 - custom_f1: 0.6992 - weighted_custom_f1: 0.7047 - val_loss: 1.3615 - val_custom_f1: 0.5434 - val_weighted_custom_f1: 0.5413\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.5291 - custom_f1: 0.6683 - weighted_custom_f1: 0.6728Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5096 - custom_f1: 0.6819 - weighted_custom_f1: 0.6868 - val_loss: 1.0427 - val_custom_f1: 0.5013 - val_weighted_custom_f1: 0.5097\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4721 - custom_f1: 0.7021 - weighted_custom_f1: 0.7060 - val_loss: 1.4251 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5205\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9213 - custom_f1: 0.5116 - weighted_custom_f1: 0.5154 - val_loss: 1.3511 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5381\n",
            "Epoch 83/100\n",
            " 11/105 [==>...........................] - ETA: 0s - loss: 0.4439 - custom_f1: 0.6787 - weighted_custom_f1: 0.6828Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5288 - custom_f1: 0.6697 - weighted_custom_f1: 0.6750 - val_loss: 1.0722 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5394\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4406 - custom_f1: 0.7153 - weighted_custom_f1: 0.7188 - val_loss: 1.4356 - val_custom_f1: 0.5019 - val_weighted_custom_f1: 0.5241\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4761 - custom_f1: 0.6960 - weighted_custom_f1: 0.7004 - val_loss: 1.2919 - val_custom_f1: 0.4893 - val_weighted_custom_f1: 0.4979\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5163 - custom_f1: 0.6840 - weighted_custom_f1: 0.6883 - val_loss: 1.1313 - val_custom_f1: 0.5049 - val_weighted_custom_f1: 0.5277\n",
            "Epoch 82/100\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4305 - custom_f1: 0.7192 - weighted_custom_f1: 0.7241 - val_loss: 1.9234 - val_custom_f1: 0.5443 - val_weighted_custom_f1: 0.5408\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5767 - custom_f1: 0.6571 - weighted_custom_f1: 0.6628 - val_loss: 1.3264 - val_custom_f1: 0.4837 - val_weighted_custom_f1: 0.4951\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5284 - custom_f1: 0.6708 - weighted_custom_f1: 0.6766 - val_loss: 1.1584 - val_custom_f1: 0.5307 - val_weighted_custom_f1: 0.5294\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6759 - custom_f1: 0.5882 - weighted_custom_f1: 0.5882Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5341 - custom_f1: 0.6607 - weighted_custom_f1: 0.6652 - val_loss: 1.5138 - val_custom_f1: 0.5096 - val_weighted_custom_f1: 0.5306\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4666 - custom_f1: 0.7060 - weighted_custom_f1: 0.7098 - val_loss: 1.4090 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5271\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5308 - custom_f1: 0.6806 - weighted_custom_f1: 0.6842 - val_loss: 1.1557 - val_custom_f1: 0.4814 - val_weighted_custom_f1: 0.4937\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.5340 - custom_f1: 0.6421 - weighted_custom_f1: 0.6494Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5363 - custom_f1: 0.6687 - weighted_custom_f1: 0.6738 - val_loss: 1.5600 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5261\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5494 - custom_f1: 0.6620 - weighted_custom_f1: 0.6669 - val_loss: 1.2456 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5214\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.5239 - custom_f1: 0.6464 - weighted_custom_f1: 0.6512Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4771 - custom_f1: 0.6994 - weighted_custom_f1: 0.7044 - val_loss: 1.2412 - val_custom_f1: 0.5098 - val_weighted_custom_f1: 0.5107\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5092 - custom_f1: 0.6782 - weighted_custom_f1: 0.6823 - val_loss: 1.0591 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5251\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.4972 - custom_f1: 0.6756 - weighted_custom_f1: 0.6795Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5307 - custom_f1: 0.6741 - weighted_custom_f1: 0.6774 - val_loss: 1.0772 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5212\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.5533 - custom_f1: 0.6616 - weighted_custom_f1: 0.6659Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4782 - custom_f1: 0.6982 - weighted_custom_f1: 0.7012 - val_loss: 1.5673 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8828 - custom_f1: 0.5124 - weighted_custom_f1: 0.5172 - val_loss: 1.3275 - val_custom_f1: 0.4481 - val_weighted_custom_f1: 0.4592\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.5234 - custom_f1: 0.6807 - weighted_custom_f1: 0.6836Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4191 - custom_f1: 0.7229 - weighted_custom_f1: 0.7275 - val_loss: 1.5174 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5345\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5043 - custom_f1: 0.6864 - weighted_custom_f1: 0.6893 - val_loss: 1.1466 - val_custom_f1: 0.4933 - val_weighted_custom_f1: 0.5150\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4201 - custom_f1: 0.7283 - weighted_custom_f1: 0.7329 - val_loss: 2.0631 - val_custom_f1: 0.5227 - val_weighted_custom_f1: 0.5244\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4500 - custom_f1: 0.7096 - weighted_custom_f1: 0.7139 - val_loss: 1.4562 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5301\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5148 - custom_f1: 0.6816 - weighted_custom_f1: 0.6844 - val_loss: 1.4103 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5172\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5469 - custom_f1: 0.6655 - weighted_custom_f1: 0.6695 - val_loss: 1.3168 - val_custom_f1: 0.4999 - val_weighted_custom_f1: 0.5079\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5508 - custom_f1: 0.6641 - weighted_custom_f1: 0.6677 - val_loss: 1.1806 - val_custom_f1: 0.5333 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4650 - custom_f1: 0.6981 - weighted_custom_f1: 0.7043 - val_loss: 1.3817 - val_custom_f1: 0.4943 - val_weighted_custom_f1: 0.5022\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.4694 - custom_f1: 0.6960 - weighted_custom_f1: 0.7003Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5388 - custom_f1: 0.6681 - weighted_custom_f1: 0.6707 - val_loss: 1.2987 - val_custom_f1: 0.4971 - val_weighted_custom_f1: 0.5072\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.8864 - custom_f1: 0.5110 - weighted_custom_f1: 0.5150Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5218 - custom_f1: 0.6732 - weighted_custom_f1: 0.6788 - val_loss: 1.9054 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5113\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4833 - custom_f1: 0.6958 - weighted_custom_f1: 0.7001 - val_loss: 1.3107 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5212\n",
            "Epoch 83/100\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5563 - custom_f1: 0.6610 - weighted_custom_f1: 0.6645 - val_loss: 1.3039 - val_custom_f1: 0.5670 - val_weighted_custom_f1: 0.5740\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5272 - custom_f1: 0.6779 - weighted_custom_f1: 0.6818 - val_loss: 1.0989 - val_custom_f1: 0.5057 - val_weighted_custom_f1: 0.5288\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.5187 - custom_f1: 0.6681 - weighted_custom_f1: 0.6729Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5272 - custom_f1: 0.6693 - weighted_custom_f1: 0.6739 - val_loss: 1.0682 - val_custom_f1: 0.5086 - val_weighted_custom_f1: 0.5305\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4719 - custom_f1: 0.6993 - weighted_custom_f1: 0.7027 - val_loss: 1.4176 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5211\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8899 - custom_f1: 0.5142 - weighted_custom_f1: 0.5181 - val_loss: 1.3811 - val_custom_f1: 0.4256 - val_weighted_custom_f1: 0.4356\n",
            "Epoch 85/100\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4199 - custom_f1: 0.7286 - weighted_custom_f1: 0.7318 - val_loss: 1.5575 - val_custom_f1: 0.5107 - val_weighted_custom_f1: 0.5338\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4947 - custom_f1: 0.6914 - weighted_custom_f1: 0.6972 - val_loss: 1.1189 - val_custom_f1: 0.5078 - val_weighted_custom_f1: 0.5309\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4634 - custom_f1: 0.7058 - weighted_custom_f1: 0.7094 - val_loss: 1.3319 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5220\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.4730 - custom_f1: 0.7037 - weighted_custom_f1: 0.7061Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4187 - custom_f1: 0.7289 - weighted_custom_f1: 0.7339 - val_loss: 1.8249 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5147\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5403 - custom_f1: 0.6689 - weighted_custom_f1: 0.6714 - val_loss: 1.4011 - val_custom_f1: 0.4909 - val_weighted_custom_f1: 0.5027\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5543 - custom_f1: 0.6617 - weighted_custom_f1: 0.6686 - val_loss: 1.3418 - val_custom_f1: 0.4832 - val_weighted_custom_f1: 0.5045\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5389 - custom_f1: 0.6683 - weighted_custom_f1: 0.6735 - val_loss: 1.1435 - val_custom_f1: 0.5400 - val_weighted_custom_f1: 0.5446\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5407 - custom_f1: 0.6723 - weighted_custom_f1: 0.6766 - val_loss: 1.2063 - val_custom_f1: 0.5093 - val_weighted_custom_f1: 0.5174\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4756 - custom_f1: 0.7000 - weighted_custom_f1: 0.7034 - val_loss: 1.4107 - val_custom_f1: 0.5285 - val_weighted_custom_f1: 0.5368\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4685 - custom_f1: 0.7021 - weighted_custom_f1: 0.7046 - val_loss: 1.2711 - val_custom_f1: 0.5297 - val_weighted_custom_f1: 0.5289\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5440 - custom_f1: 0.6667 - weighted_custom_f1: 0.6704 - val_loss: 1.2073 - val_custom_f1: 0.5164 - val_weighted_custom_f1: 0.5284\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.4994 - custom_f1: 0.6864 - weighted_custom_f1: 0.6902Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5143 - custom_f1: 0.6697 - weighted_custom_f1: 0.6756 - val_loss: 1.8407 - val_custom_f1: 0.4948 - val_weighted_custom_f1: 0.4904\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5039 - custom_f1: 0.6888 - weighted_custom_f1: 0.6934 - val_loss: 1.0751 - val_custom_f1: 0.5173 - val_weighted_custom_f1: 0.5260\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4963 - custom_f1: 0.6890 - weighted_custom_f1: 0.6925 - val_loss: 1.4251 - val_custom_f1: 0.4969 - val_weighted_custom_f1: 0.5014\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5175 - custom_f1: 0.6761 - weighted_custom_f1: 0.6804 - val_loss: 1.0787 - val_custom_f1: 0.5030 - val_weighted_custom_f1: 0.5253\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8937 - custom_f1: 0.5080 - weighted_custom_f1: 0.5126 - val_loss: 1.3164 - val_custom_f1: 0.5109 - val_weighted_custom_f1: 0.5215\n",
            "Epoch 86/100\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4259 - custom_f1: 0.7202 - weighted_custom_f1: 0.7249 - val_loss: 1.5652 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5421\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4872 - custom_f1: 0.6907 - weighted_custom_f1: 0.6942 - val_loss: 1.1455 - val_custom_f1: 0.4866 - val_weighted_custom_f1: 0.5093\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4850 - custom_f1: 0.6966 - weighted_custom_f1: 0.7015 - val_loss: 1.4314 - val_custom_f1: 0.5297 - val_weighted_custom_f1: 0.5385\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4259 - custom_f1: 0.7253 - weighted_custom_f1: 0.7302 - val_loss: 1.9639 - val_custom_f1: 0.5413 - val_weighted_custom_f1: 0.5378\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5398 - custom_f1: 0.6682 - weighted_custom_f1: 0.6711 - val_loss: 1.4747 - val_custom_f1: 0.5338 - val_weighted_custom_f1: 0.5418\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5299 - custom_f1: 0.6655 - weighted_custom_f1: 0.6693 - val_loss: 1.3337 - val_custom_f1: 0.4761 - val_weighted_custom_f1: 0.4979\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5225 - custom_f1: 0.6790 - weighted_custom_f1: 0.6820 - val_loss: 1.3380 - val_custom_f1: 0.5276 - val_weighted_custom_f1: 0.5495\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.4460 - custom_f1: 0.7101 - weighted_custom_f1: 0.7134Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4650 - custom_f1: 0.7015 - weighted_custom_f1: 0.7040 - val_loss: 1.6680 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5403\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5326 - custom_f1: 0.6729 - weighted_custom_f1: 0.6763 - val_loss: 1.2037 - val_custom_f1: 0.4766 - val_weighted_custom_f1: 0.4886\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4797 - custom_f1: 0.7170 - weighted_custom_f1: 0.7170Epoch 87/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4693 - custom_f1: 0.7071 - weighted_custom_f1: 0.7109 - val_loss: 1.3933 - val_custom_f1: 0.5484 - val_weighted_custom_f1: 0.5433\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5314 - custom_f1: 0.6658 - weighted_custom_f1: 0.6705 - val_loss: 1.8688 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5322\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5560 - custom_f1: 0.6630 - weighted_custom_f1: 0.6673 - val_loss: 1.2290 - val_custom_f1: 0.5250 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5232 - custom_f1: 0.6771 - weighted_custom_f1: 0.6814 - val_loss: 1.0897 - val_custom_f1: 0.5083 - val_weighted_custom_f1: 0.5319\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.4429 - custom_f1: 0.7282 - weighted_custom_f1: 0.7312Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5209 - custom_f1: 0.6750 - weighted_custom_f1: 0.6791 - val_loss: 1.0519 - val_custom_f1: 0.4981 - val_weighted_custom_f1: 0.5197\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8898 - custom_f1: 0.5098 - weighted_custom_f1: 0.5136 - val_loss: 1.3923 - val_custom_f1: 0.5138 - val_weighted_custom_f1: 0.5255\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4702 - custom_f1: 0.7047 - weighted_custom_f1: 0.7086 - val_loss: 1.4548 - val_custom_f1: 0.5204 - val_weighted_custom_f1: 0.5292\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.4707 - custom_f1: 0.6912 - weighted_custom_f1: 0.6988Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4348 - custom_f1: 0.7232 - weighted_custom_f1: 0.7255 - val_loss: 1.5743 - val_custom_f1: 0.5161 - val_weighted_custom_f1: 0.5387\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5172 - custom_f1: 0.6795 - weighted_custom_f1: 0.6848Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4800 - custom_f1: 0.6937 - weighted_custom_f1: 0.6999 - val_loss: 1.1527 - val_custom_f1: 0.5073 - val_weighted_custom_f1: 0.5300\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.5228 - custom_f1: 0.6756 - weighted_custom_f1: 0.6788Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4713 - custom_f1: 0.6998 - weighted_custom_f1: 0.7030 - val_loss: 1.4974 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5437\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.5146 - custom_f1: 0.6828 - weighted_custom_f1: 0.6880Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3934 - custom_f1: 0.7435 - weighted_custom_f1: 0.7446 - val_loss: 1.9997 - val_custom_f1: 0.5400 - val_weighted_custom_f1: 0.5327\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.4559 - custom_f1: 0.7159 - weighted_custom_f1: 0.7190Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5315 - custom_f1: 0.6779 - weighted_custom_f1: 0.6814 - val_loss: 1.3205 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5153\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.4457 - custom_f1: 0.7174 - weighted_custom_f1: 0.7207Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5434 - custom_f1: 0.6663 - weighted_custom_f1: 0.6724 - val_loss: 1.2899 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5659 - custom_f1: 0.6610 - weighted_custom_f1: 0.6644 - val_loss: 1.1854 - val_custom_f1: 0.5560 - val_weighted_custom_f1: 0.5614\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5182 - custom_f1: 0.6796 - weighted_custom_f1: 0.6850 - val_loss: 1.1903 - val_custom_f1: 0.4976 - val_weighted_custom_f1: 0.5092\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4735 - custom_f1: 0.7011 - weighted_custom_f1: 0.7052 - val_loss: 1.4679 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5334\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.4850 - custom_f1: 0.6950 - weighted_custom_f1: 0.6980Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5747 - custom_f1: 0.6533 - weighted_custom_f1: 0.6579 - val_loss: 1.2026 - val_custom_f1: 0.5233 - val_weighted_custom_f1: 0.5291\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4639 - custom_f1: 0.7044 - weighted_custom_f1: 0.7097 - val_loss: 1.3276 - val_custom_f1: 0.5328 - val_weighted_custom_f1: 0.5301\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5173 - custom_f1: 0.6786 - weighted_custom_f1: 0.6808 - val_loss: 1.7918 - val_custom_f1: 0.5407 - val_weighted_custom_f1: 0.5314\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5007 - custom_f1: 0.6895 - weighted_custom_f1: 0.6932 - val_loss: 1.0881 - val_custom_f1: 0.5261 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8959 - custom_f1: 0.5061 - weighted_custom_f1: 0.5104 - val_loss: 1.3387 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5268\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.4753 - custom_f1: 0.6990 - weighted_custom_f1: 0.7030Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4566 - custom_f1: 0.7086 - weighted_custom_f1: 0.7132 - val_loss: 1.4315 - val_custom_f1: 0.5250 - val_weighted_custom_f1: 0.5307\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5125 - custom_f1: 0.6796 - weighted_custom_f1: 0.6848 - val_loss: 1.0592 - val_custom_f1: 0.5023 - val_weighted_custom_f1: 0.5243\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.4726 - custom_f1: 0.7010 - weighted_custom_f1: 0.7044Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4375 - custom_f1: 0.7189 - weighted_custom_f1: 0.7244 - val_loss: 1.5205 - val_custom_f1: 0.5056 - val_weighted_custom_f1: 0.5280\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.4693 - custom_f1: 0.7020 - weighted_custom_f1: 0.7070Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4951 - custom_f1: 0.6884 - weighted_custom_f1: 0.6922 - val_loss: 1.2003 - val_custom_f1: 0.5035 - val_weighted_custom_f1: 0.5254\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.4855 - custom_f1: 0.7019 - weighted_custom_f1: 0.7056Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5069 - custom_f1: 0.6943 - weighted_custom_f1: 0.6984 - val_loss: 1.3983 - val_custom_f1: 0.5184 - val_weighted_custom_f1: 0.5267\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4134 - custom_f1: 0.7307 - weighted_custom_f1: 0.7352 - val_loss: 2.1816 - val_custom_f1: 0.5482 - val_weighted_custom_f1: 0.5414\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5396 - custom_f1: 0.6714 - weighted_custom_f1: 0.6749 - val_loss: 1.3397 - val_custom_f1: 0.4940 - val_weighted_custom_f1: 0.5165\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5366 - custom_f1: 0.6684 - weighted_custom_f1: 0.6729 - val_loss: 1.3558 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5260\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5033 - custom_f1: 0.6802 - weighted_custom_f1: 0.6848 - val_loss: 1.2024 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5534\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.4065 - custom_f1: 0.7347 - weighted_custom_f1: 0.7381Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5226 - custom_f1: 0.6814 - weighted_custom_f1: 0.6862 - val_loss: 1.2335 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.5125\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4778 - custom_f1: 0.6986 - weighted_custom_f1: 0.7032 - val_loss: 1.2745 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5272\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4782 - custom_f1: 0.6993 - weighted_custom_f1: 0.7027 - val_loss: 1.4211 - val_custom_f1: 0.5033 - val_weighted_custom_f1: 0.5122\n",
            "Epoch 89/100\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5353 - custom_f1: 0.6602 - weighted_custom_f1: 0.6655 - val_loss: 1.2332 - val_custom_f1: 0.5375 - val_weighted_custom_f1: 0.5462\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5034 - custom_f1: 0.6817 - weighted_custom_f1: 0.6863 - val_loss: 1.9277 - val_custom_f1: 0.5372 - val_weighted_custom_f1: 0.5316\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4883 - custom_f1: 0.6911 - weighted_custom_f1: 0.6959 - val_loss: 1.0750 - val_custom_f1: 0.5201 - val_weighted_custom_f1: 0.5444\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8896 - custom_f1: 0.5048 - weighted_custom_f1: 0.5101 - val_loss: 1.2836 - val_custom_f1: 0.4640 - val_weighted_custom_f1: 0.4743\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4569 - custom_f1: 0.7087 - weighted_custom_f1: 0.7131 - val_loss: 1.4351 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5180\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.4998 - custom_f1: 0.6799 - weighted_custom_f1: 0.6850Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5072 - custom_f1: 0.6818 - weighted_custom_f1: 0.6854 - val_loss: 1.1302 - val_custom_f1: 0.5205 - val_weighted_custom_f1: 0.5416\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4760 - custom_f1: 0.7004 - weighted_custom_f1: 0.7035 - val_loss: 1.1756 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5206\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.8476 - custom_f1: 0.5075 - weighted_custom_f1: 0.5118Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4196 - custom_f1: 0.7241 - weighted_custom_f1: 0.7276 - val_loss: 1.6296 - val_custom_f1: 0.5058 - val_weighted_custom_f1: 0.5279\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4743 - custom_f1: 0.7138 - weighted_custom_f1: 0.7168 - val_loss: 1.3775 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5371\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4246 - custom_f1: 0.7293 - weighted_custom_f1: 0.7345 - val_loss: 1.9294 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5279\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5219 - custom_f1: 0.6751 - weighted_custom_f1: 0.6780 - val_loss: 1.3891 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5287\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5208 - custom_f1: 0.6721 - weighted_custom_f1: 0.6773 - val_loss: 1.3487 - val_custom_f1: 0.5294 - val_weighted_custom_f1: 0.5408\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5174 - custom_f1: 0.6760 - weighted_custom_f1: 0.6801 - val_loss: 1.3562 - val_custom_f1: 0.5297 - val_weighted_custom_f1: 0.5514\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.4138 - custom_f1: 0.7279 - weighted_custom_f1: 0.7309Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5149 - custom_f1: 0.6826 - weighted_custom_f1: 0.6879 - val_loss: 1.2363 - val_custom_f1: 0.4804 - val_weighted_custom_f1: 0.4915\n",
            " 53/105 [==============>...............] - ETA: 0s - loss: 0.4219 - custom_f1: 0.7245 - weighted_custom_f1: 0.7272Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4616 - custom_f1: 0.7039 - weighted_custom_f1: 0.7076 - val_loss: 1.2808 - val_custom_f1: 0.5173 - val_weighted_custom_f1: 0.5193\n",
            " 96/105 [==========================>...] - ETA: 0s - loss: 0.5088 - custom_f1: 0.6811 - weighted_custom_f1: 0.6858Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4518 - custom_f1: 0.7064 - weighted_custom_f1: 0.7104 - val_loss: 1.4150 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5381\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5078 - custom_f1: 0.6804 - weighted_custom_f1: 0.6840 - val_loss: 1.3343 - val_custom_f1: 0.5482 - val_weighted_custom_f1: 0.5716\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5090 - custom_f1: 0.6793 - weighted_custom_f1: 0.6852 - val_loss: 1.7489 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4867 - custom_f1: 0.6939 - weighted_custom_f1: 0.6972 - val_loss: 1.2059 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5392\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8865 - custom_f1: 0.5083 - weighted_custom_f1: 0.5140 - val_loss: 1.3210 - val_custom_f1: 0.4635 - val_weighted_custom_f1: 0.4743\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4358 - custom_f1: 0.7198 - weighted_custom_f1: 0.7234 - val_loss: 1.4288 - val_custom_f1: 0.5239 - val_weighted_custom_f1: 0.5286\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5105 - custom_f1: 0.6844 - weighted_custom_f1: 0.6889 - val_loss: 1.1140 - val_custom_f1: 0.4829 - val_weighted_custom_f1: 0.5045\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.4794 - custom_f1: 0.7077 - weighted_custom_f1: 0.7125Epoch 90/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4817 - custom_f1: 0.6978 - weighted_custom_f1: 0.7029 - val_loss: 1.3639 - val_custom_f1: 0.5115 - val_weighted_custom_f1: 0.5336\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.3803 - custom_f1: 0.7652 - weighted_custom_f1: 0.7701Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4253 - custom_f1: 0.7221 - weighted_custom_f1: 0.7252 - val_loss: 1.5504 - val_custom_f1: 0.4946 - val_weighted_custom_f1: 0.5176\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.4760 - custom_f1: 0.7046 - weighted_custom_f1: 0.7086Epoch 90/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4351 - custom_f1: 0.7243 - weighted_custom_f1: 0.7289 - val_loss: 1.8111 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5120\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4963 - custom_f1: 0.6833 - weighted_custom_f1: 0.6879 - val_loss: 1.5138 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5138\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4421 - custom_f1: 0.7164 - weighted_custom_f1: 0.7191 - val_loss: 1.6009 - val_custom_f1: 0.5211 - val_weighted_custom_f1: 0.5419\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5433 - custom_f1: 0.6612 - weighted_custom_f1: 0.6665Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5337 - custom_f1: 0.6709 - weighted_custom_f1: 0.6749 - val_loss: 1.4246 - val_custom_f1: 0.4930 - val_weighted_custom_f1: 0.5004\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5252 - custom_f1: 0.6775 - weighted_custom_f1: 0.6820 - val_loss: 1.3289 - val_custom_f1: 0.5150 - val_weighted_custom_f1: 0.5184\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.5367 - custom_f1: 0.6756 - weighted_custom_f1: 0.6804Epoch 90/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5151 - custom_f1: 0.6754 - weighted_custom_f1: 0.6804 - val_loss: 1.2948 - val_custom_f1: 0.4965 - val_weighted_custom_f1: 0.5056\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4361 - custom_f1: 0.7168 - weighted_custom_f1: 0.7215 - val_loss: 1.5800 - val_custom_f1: 0.5233 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4711 - custom_f1: 0.7036 - weighted_custom_f1: 0.7081 - val_loss: 1.4523 - val_custom_f1: 0.5367 - val_weighted_custom_f1: 0.5316\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3925 - custom_f1: 0.7742 - weighted_custom_f1: 0.7742Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5367 - custom_f1: 0.6756 - weighted_custom_f1: 0.6804 - val_loss: 1.1419 - val_custom_f1: 0.5224 - val_weighted_custom_f1: 0.5332\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5384 - custom_f1: 0.6653 - weighted_custom_f1: 0.6703 - val_loss: 1.6720 - val_custom_f1: 0.5151 - val_weighted_custom_f1: 0.5137\n",
            "Epoch 90/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4310 - custom_f1: 0.7636 - weighted_custom_f1: 0.7636Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8824 - custom_f1: 0.5138 - weighted_custom_f1: 0.5195 - val_loss: 1.2861 - val_custom_f1: 0.5257 - val_weighted_custom_f1: 0.5327\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4955 - custom_f1: 0.6888 - weighted_custom_f1: 0.6934 - val_loss: 1.1077 - val_custom_f1: 0.5023 - val_weighted_custom_f1: 0.5109\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.3830 - custom_f1: 0.7503 - weighted_custom_f1: 0.7543Epoch 90/100\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5105 - custom_f1: 0.6894 - weighted_custom_f1: 0.6948Epoch 91/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4229 - custom_f1: 0.7304 - weighted_custom_f1: 0.7359 - val_loss: 1.5124 - val_custom_f1: 0.5148 - val_weighted_custom_f1: 0.5229\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.5685 - custom_f1: 0.6495 - weighted_custom_f1: 0.6532Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5132 - custom_f1: 0.6763 - weighted_custom_f1: 0.6822 - val_loss: 1.0830 - val_custom_f1: 0.4901 - val_weighted_custom_f1: 0.5112\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.5237 - custom_f1: 0.6747 - weighted_custom_f1: 0.6803Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4687 - custom_f1: 0.7051 - weighted_custom_f1: 0.7092 - val_loss: 1.2715 - val_custom_f1: 0.5055 - val_weighted_custom_f1: 0.5275\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.3960 - custom_f1: 0.7594 - weighted_custom_f1: 0.7622Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4140 - custom_f1: 0.7297 - weighted_custom_f1: 0.7354 - val_loss: 1.8568 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5272\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.4763 - custom_f1: 0.7008 - weighted_custom_f1: 0.7034Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3877 - custom_f1: 0.7442 - weighted_custom_f1: 0.7478 - val_loss: 2.0921 - val_custom_f1: 0.5315 - val_weighted_custom_f1: 0.5241\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.4844 - custom_f1: 0.6909 - weighted_custom_f1: 0.6956Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4980 - custom_f1: 0.6814 - weighted_custom_f1: 0.6851 - val_loss: 1.5642 - val_custom_f1: 0.5074 - val_weighted_custom_f1: 0.5285\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.4817 - custom_f1: 0.6949 - weighted_custom_f1: 0.6987Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5425 - custom_f1: 0.6620 - weighted_custom_f1: 0.6667 - val_loss: 1.4919 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5179\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4468 - custom_f1: 0.7144 - weighted_custom_f1: 0.7196 - val_loss: 1.4575 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5160\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5485 - custom_f1: 0.6613 - weighted_custom_f1: 0.6663 - val_loss: 1.2213 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5319\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.3932 - custom_f1: 0.7477 - weighted_custom_f1: 0.7496Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5122 - custom_f1: 0.6824 - weighted_custom_f1: 0.6868 - val_loss: 1.2436 - val_custom_f1: 0.5007 - val_weighted_custom_f1: 0.5107\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.5050 - custom_f1: 0.6899 - weighted_custom_f1: 0.6926Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5253 - custom_f1: 0.6745 - weighted_custom_f1: 0.6792 - val_loss: 1.2326 - val_custom_f1: 0.5461 - val_weighted_custom_f1: 0.5519\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.5019 - custom_f1: 0.6912 - weighted_custom_f1: 0.6942Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4643 - custom_f1: 0.7030 - weighted_custom_f1: 0.7086 - val_loss: 1.3027 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5232\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4611 - custom_f1: 0.7099 - weighted_custom_f1: 0.7152 - val_loss: 1.5593 - val_custom_f1: 0.5142 - val_weighted_custom_f1: 0.5191\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.5323 - custom_f1: 0.6777 - weighted_custom_f1: 0.6824Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4900 - custom_f1: 0.6795 - weighted_custom_f1: 0.6831 - val_loss: 1.8198 - val_custom_f1: 0.5205 - val_weighted_custom_f1: 0.5137\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8877 - custom_f1: 0.5097 - weighted_custom_f1: 0.5150 - val_loss: 1.3095 - val_custom_f1: 0.4720 - val_weighted_custom_f1: 0.4834\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4885 - custom_f1: 0.6945 - weighted_custom_f1: 0.6991 - val_loss: 1.1220 - val_custom_f1: 0.5223 - val_weighted_custom_f1: 0.5457\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4347 - custom_f1: 0.7199 - weighted_custom_f1: 0.7237 - val_loss: 1.4909 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5370\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.4504 - custom_f1: 0.7131 - weighted_custom_f1: 0.7163Epoch 92/100\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4961 - custom_f1: 0.6918 - weighted_custom_f1: 0.6952 - val_loss: 1.0883 - val_custom_f1: 0.4939 - val_weighted_custom_f1: 0.5150\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4702 - custom_f1: 0.7012 - weighted_custom_f1: 0.7058 - val_loss: 1.1685 - val_custom_f1: 0.5091 - val_weighted_custom_f1: 0.5319\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.5296 - custom_f1: 0.6765 - weighted_custom_f1: 0.6803Epoch 93/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4289 - custom_f1: 0.7272 - weighted_custom_f1: 0.7301 - val_loss: 1.5650 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.5175\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.4650 - custom_f1: 0.7126 - weighted_custom_f1: 0.7162Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5212 - custom_f1: 0.6738 - weighted_custom_f1: 0.6783 - val_loss: 1.4645 - val_custom_f1: 0.4857 - val_weighted_custom_f1: 0.5065\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4220 - custom_f1: 0.7309 - weighted_custom_f1: 0.7343 - val_loss: 2.2446 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5132\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4355 - custom_f1: 0.7185 - weighted_custom_f1: 0.7234 - val_loss: 1.5243 - val_custom_f1: 0.5477 - val_weighted_custom_f1: 0.5533\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4395 - custom_f1: 0.6154 - weighted_custom_f1: 0.6154Epoch 91/100\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5296 - custom_f1: 0.6709 - weighted_custom_f1: 0.6751 - val_loss: 1.3665 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5205\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.4963 - custom_f1: 0.6890 - weighted_custom_f1: 0.6920Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5121 - custom_f1: 0.6856 - weighted_custom_f1: 0.6893 - val_loss: 1.2110 - val_custom_f1: 0.5441 - val_weighted_custom_f1: 0.5486\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5070 - custom_f1: 0.6862 - weighted_custom_f1: 0.6904 - val_loss: 1.4015 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5111\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5199 - custom_f1: 0.6800 - weighted_custom_f1: 0.6831 - val_loss: 1.2795 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5356\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.4958 - custom_f1: 0.6871 - weighted_custom_f1: 0.6914Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4628 - custom_f1: 0.7090 - weighted_custom_f1: 0.7121 - val_loss: 1.4660 - val_custom_f1: 0.5353 - val_weighted_custom_f1: 0.5299\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4446 - custom_f1: 0.7104 - weighted_custom_f1: 0.7153 - val_loss: 1.5249 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5221\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.4950 - custom_f1: 0.6971 - weighted_custom_f1: 0.7023Epoch 93/100\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4938 - custom_f1: 0.6888 - weighted_custom_f1: 0.6919 - val_loss: 1.7297 - val_custom_f1: 0.5329 - val_weighted_custom_f1: 0.5269\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.5098 - custom_f1: 0.6921 - weighted_custom_f1: 0.6980Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4779 - custom_f1: 0.7029 - weighted_custom_f1: 0.7063 - val_loss: 1.0767 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5266\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8933 - custom_f1: 0.5114 - weighted_custom_f1: 0.5171 - val_loss: 1.3328 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5112\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4644 - custom_f1: 0.7082 - weighted_custom_f1: 0.7121 - val_loss: 1.6263 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5357\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4958 - custom_f1: 0.6874 - weighted_custom_f1: 0.6912 - val_loss: 1.1977 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5391\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4121 - custom_f1: 0.7295 - weighted_custom_f1: 0.7349 - val_loss: 1.4825 - val_custom_f1: 0.4910 - val_weighted_custom_f1: 0.5139\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4971 - custom_f1: 0.6961 - weighted_custom_f1: 0.7003 - val_loss: 1.2392 - val_custom_f1: 0.5175 - val_weighted_custom_f1: 0.5404\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.4473 - custom_f1: 0.7135 - weighted_custom_f1: 0.7173Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4079 - custom_f1: 0.7376 - weighted_custom_f1: 0.7424 - val_loss: 1.9299 - val_custom_f1: 0.5343 - val_weighted_custom_f1: 0.5293\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5090 - custom_f1: 0.6794 - weighted_custom_f1: 0.6830 - val_loss: 1.3616 - val_custom_f1: 0.4912 - val_weighted_custom_f1: 0.5129\n",
            "Epoch 92/100\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4310 - custom_f1: 0.7223 - weighted_custom_f1: 0.7250 - val_loss: 1.5343 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5248\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5843 - custom_f1: 0.6557 - weighted_custom_f1: 0.6557Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5139 - custom_f1: 0.6781 - weighted_custom_f1: 0.6836 - val_loss: 1.5408 - val_custom_f1: 0.5238 - val_weighted_custom_f1: 0.5354\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.4465 - custom_f1: 0.7129 - weighted_custom_f1: 0.7184Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5007 - custom_f1: 0.6876 - weighted_custom_f1: 0.6911 - val_loss: 1.3259 - val_custom_f1: 0.5422 - val_weighted_custom_f1: 0.5646\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5051 - custom_f1: 0.6843 - weighted_custom_f1: 0.6895 - val_loss: 1.2478 - val_custom_f1: 0.4865 - val_weighted_custom_f1: 0.4962\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5272 - custom_f1: 0.6725 - weighted_custom_f1: 0.6767 - val_loss: 1.3857 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5319\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4459 - custom_f1: 0.7196 - weighted_custom_f1: 0.7238 - val_loss: 1.4897 - val_custom_f1: 0.5326 - val_weighted_custom_f1: 0.5316\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4422 - custom_f1: 0.7106 - weighted_custom_f1: 0.7149 - val_loss: 1.5835 - val_custom_f1: 0.5173 - val_weighted_custom_f1: 0.5257\n",
            "Epoch 94/100\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.4247 - custom_f1: 0.7385 - weighted_custom_f1: 0.7406Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5001 - custom_f1: 0.6770 - weighted_custom_f1: 0.6829 - val_loss: 1.7861 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9186 - custom_f1: 0.5082 - weighted_custom_f1: 0.5132 - val_loss: 1.2989 - val_custom_f1: 0.5128 - val_weighted_custom_f1: 0.5217\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.4277 - custom_f1: 0.7259 - weighted_custom_f1: 0.7298Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4853 - custom_f1: 0.6889 - weighted_custom_f1: 0.6921 - val_loss: 1.1508 - val_custom_f1: 0.5236 - val_weighted_custom_f1: 0.5468\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.5701 - custom_f1: 0.6540 - weighted_custom_f1: 0.6594Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4443 - custom_f1: 0.7143 - weighted_custom_f1: 0.7186 - val_loss: 1.4509 - val_custom_f1: 0.5242 - val_weighted_custom_f1: 0.5289\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.8532 - custom_f1: 0.5322 - weighted_custom_f1: 0.5355Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5038 - custom_f1: 0.6896 - weighted_custom_f1: 0.6934 - val_loss: 1.1408 - val_custom_f1: 0.4954 - val_weighted_custom_f1: 0.5179\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4007 - custom_f1: 0.7797 - weighted_custom_f1: 0.7797Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4276 - custom_f1: 0.7264 - weighted_custom_f1: 0.7303 - val_loss: 1.5720 - val_custom_f1: 0.5169 - val_weighted_custom_f1: 0.5392\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4705 - custom_f1: 0.7018 - weighted_custom_f1: 0.7051 - val_loss: 1.2122 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5358\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4333 - custom_f1: 0.7295 - weighted_custom_f1: 0.7310 - val_loss: 2.1604 - val_custom_f1: 0.5075 - val_weighted_custom_f1: 0.5038\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4092 - custom_f1: 0.7348 - weighted_custom_f1: 0.7378 - val_loss: 1.4803 - val_custom_f1: 0.5266 - val_weighted_custom_f1: 0.5493\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5111 - custom_f1: 0.6808 - weighted_custom_f1: 0.6852 - val_loss: 1.5410 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5395\n",
            "Epoch 93/100\n",
            "Epoch 93/100\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5668 - custom_f1: 0.6576 - weighted_custom_f1: 0.6629 - val_loss: 1.4302 - val_custom_f1: 0.4856 - val_weighted_custom_f1: 0.4972\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5068 - custom_f1: 0.6873 - weighted_custom_f1: 0.6910 - val_loss: 1.2224 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5292\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.3713 - custom_f1: 0.7505 - weighted_custom_f1: 0.7542Epoch 94/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5057 - custom_f1: 0.6872 - weighted_custom_f1: 0.6902 - val_loss: 1.2509 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5117\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5138 - custom_f1: 0.6803 - weighted_custom_f1: 0.6853 - val_loss: 1.2935 - val_custom_f1: 0.5417 - val_weighted_custom_f1: 0.5465\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4514 - custom_f1: 0.7169 - weighted_custom_f1: 0.7200 - val_loss: 1.3568 - val_custom_f1: 0.5410 - val_weighted_custom_f1: 0.5396\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8996 - custom_f1: 0.5160 - weighted_custom_f1: 0.5210 - val_loss: 1.3277 - val_custom_f1: 0.4856 - val_weighted_custom_f1: 0.4980\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4319 - custom_f1: 0.7205 - weighted_custom_f1: 0.7259 - val_loss: 1.5935 - val_custom_f1: 0.5469 - val_weighted_custom_f1: 0.5559\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4863 - custom_f1: 0.7000 - weighted_custom_f1: 0.7027 - val_loss: 1.9889 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 93/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4265 - custom_f1: 0.7937 - weighted_custom_f1: 0.7937Epoch 93/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4989 - custom_f1: 0.6931 - weighted_custom_f1: 0.6976 - val_loss: 1.0988 - val_custom_f1: 0.5144 - val_weighted_custom_f1: 0.5230\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.5019 - custom_f1: 0.6834 - weighted_custom_f1: 0.6875Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4382 - custom_f1: 0.7286 - weighted_custom_f1: 0.7305 - val_loss: 1.4865 - val_custom_f1: 0.5066 - val_weighted_custom_f1: 0.5109\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5083 - custom_f1: 0.6833 - weighted_custom_f1: 0.6860 - val_loss: 1.1110 - val_custom_f1: 0.5109 - val_weighted_custom_f1: 0.5332\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.4762 - custom_f1: 0.6975 - weighted_custom_f1: 0.6996Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4695 - custom_f1: 0.7021 - weighted_custom_f1: 0.7057 - val_loss: 1.1944 - val_custom_f1: 0.4896 - val_weighted_custom_f1: 0.5118\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4009 - custom_f1: 0.7369 - weighted_custom_f1: 0.7415 - val_loss: 1.6303 - val_custom_f1: 0.5056 - val_weighted_custom_f1: 0.5294\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.5019 - custom_f1: 0.6940 - weighted_custom_f1: 0.6988Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4287 - custom_f1: 0.7213 - weighted_custom_f1: 0.7261 - val_loss: 1.4781 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5392\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.4877 - custom_f1: 0.6856 - weighted_custom_f1: 0.6893Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4027 - custom_f1: 0.7378 - weighted_custom_f1: 0.7417 - val_loss: 2.3824 - val_custom_f1: 0.5057 - val_weighted_custom_f1: 0.5012\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5732 - custom_f1: 0.6641 - weighted_custom_f1: 0.6685 - val_loss: 1.5082 - val_custom_f1: 0.4825 - val_weighted_custom_f1: 0.4927\n",
            "Epoch 94/100\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5029 - custom_f1: 0.6880 - weighted_custom_f1: 0.6907 - val_loss: 1.4153 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5447\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.4005 - custom_f1: 0.7130 - weighted_custom_f1: 0.7150Epoch 95/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5285 - custom_f1: 0.6706 - weighted_custom_f1: 0.6746 - val_loss: 1.4367 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5285\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5047 - custom_f1: 0.6890 - weighted_custom_f1: 0.6936 - val_loss: 1.2423 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.4874\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.4606 - custom_f1: 0.7085 - weighted_custom_f1: 0.7117Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5144 - custom_f1: 0.6838 - weighted_custom_f1: 0.6858 - val_loss: 1.1877 - val_custom_f1: 0.5215 - val_weighted_custom_f1: 0.5316\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4558 - custom_f1: 0.7100 - weighted_custom_f1: 0.7137 - val_loss: 1.6250 - val_custom_f1: 0.5214 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4508 - custom_f1: 0.7113 - weighted_custom_f1: 0.7156 - val_loss: 1.3867 - val_custom_f1: 0.5349 - val_weighted_custom_f1: 0.5332\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.4491 - custom_f1: 0.7117 - weighted_custom_f1: 0.7157Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4911 - custom_f1: 0.6911 - weighted_custom_f1: 0.6943 - val_loss: 2.0349 - val_custom_f1: 0.5126 - val_weighted_custom_f1: 0.5012\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.5083 - custom_f1: 0.6828 - weighted_custom_f1: 0.6863Epoch 94/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8962 - custom_f1: 0.5108 - weighted_custom_f1: 0.5154 - val_loss: 1.3232 - val_custom_f1: 0.4960 - val_weighted_custom_f1: 0.5048\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4792 - custom_f1: 0.6996 - weighted_custom_f1: 0.7024 - val_loss: 1.1252 - val_custom_f1: 0.5179 - val_weighted_custom_f1: 0.5420\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4623 - custom_f1: 0.7094 - weighted_custom_f1: 0.7125 - val_loss: 1.4377 - val_custom_f1: 0.4994 - val_weighted_custom_f1: 0.5069\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4940 - custom_f1: 0.6876 - weighted_custom_f1: 0.6911 - val_loss: 1.1505 - val_custom_f1: 0.4714 - val_weighted_custom_f1: 0.4926\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4785 - custom_f1: 0.7186 - weighted_custom_f1: 0.7226 - val_loss: 1.5306 - val_custom_f1: 0.4911 - val_weighted_custom_f1: 0.5140\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4590 - custom_f1: 0.7081 - weighted_custom_f1: 0.7117 - val_loss: 1.3806 - val_custom_f1: 0.5138 - val_weighted_custom_f1: 0.5348\n",
            "Epoch 97/100\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5988 - custom_f1: 0.6577 - weighted_custom_f1: 0.6611 - val_loss: 1.3843 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5142\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4355 - custom_f1: 0.7196 - weighted_custom_f1: 0.7225 - val_loss: 1.5734 - val_custom_f1: 0.5417 - val_weighted_custom_f1: 0.5482\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3770 - custom_f1: 0.7561 - weighted_custom_f1: 0.7599 - val_loss: 2.0761 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5279\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5117 - custom_f1: 0.6798 - weighted_custom_f1: 0.6840 - val_loss: 1.5488 - val_custom_f1: 0.4841 - val_weighted_custom_f1: 0.4946\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.5087 - custom_f1: 0.6827 - weighted_custom_f1: 0.6863Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5396 - custom_f1: 0.6766 - weighted_custom_f1: 0.6801 - val_loss: 1.3059 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5063\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4985 - custom_f1: 0.6924 - weighted_custom_f1: 0.6973 - val_loss: 1.2517 - val_custom_f1: 0.4797 - val_weighted_custom_f1: 0.4905\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5245 - custom_f1: 0.6815 - weighted_custom_f1: 0.6854 - val_loss: 1.3516 - val_custom_f1: 0.4881 - val_weighted_custom_f1: 0.4951\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.4097 - custom_f1: 0.7226 - weighted_custom_f1: 0.7259Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4411 - custom_f1: 0.7135 - weighted_custom_f1: 0.7175 - val_loss: 1.5340 - val_custom_f1: 0.5254 - val_weighted_custom_f1: 0.5360\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.5042 - custom_f1: 0.6624 - weighted_custom_f1: 0.6676Epoch 95/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8854 - custom_f1: 0.5087 - weighted_custom_f1: 0.5139 - val_loss: 1.3917 - val_custom_f1: 0.4824 - val_weighted_custom_f1: 0.4929\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.4448 - custom_f1: 0.7146 - weighted_custom_f1: 0.7168Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4450 - custom_f1: 0.7163 - weighted_custom_f1: 0.7191 - val_loss: 1.4056 - val_custom_f1: 0.5329 - val_weighted_custom_f1: 0.5325\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0248 - custom_f1: 0.5075 - weighted_custom_f1: 0.5075Epoch 97/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4762 - custom_f1: 0.6982 - weighted_custom_f1: 0.7027 - val_loss: 1.1354 - val_custom_f1: 0.4901 - val_weighted_custom_f1: 0.5004\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4938 - custom_f1: 0.6887 - weighted_custom_f1: 0.6930 - val_loss: 1.1175 - val_custom_f1: 0.5083 - val_weighted_custom_f1: 0.5305\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5080 - custom_f1: 0.6826 - weighted_custom_f1: 0.6864 - val_loss: 1.7036 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5155\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4247 - custom_f1: 0.7268 - weighted_custom_f1: 0.7301 - val_loss: 1.6217 - val_custom_f1: 0.5408 - val_weighted_custom_f1: 0.5452\n",
            "Epoch 95/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.2812 - custom_f1: 0.7442 - weighted_custom_f1: 0.7442Epoch 97/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4868 - custom_f1: 0.6968 - weighted_custom_f1: 0.7007 - val_loss: 1.2385 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5390\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.5159 - custom_f1: 0.6813 - weighted_custom_f1: 0.6861Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4110 - custom_f1: 0.7373 - weighted_custom_f1: 0.7407 - val_loss: 1.7905 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5307\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5971 - custom_f1: 0.6544 - weighted_custom_f1: 0.6586 - val_loss: 1.4139 - val_custom_f1: 0.4949 - val_weighted_custom_f1: 0.5171\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4443 - custom_f1: 0.7135 - weighted_custom_f1: 0.7166 - val_loss: 1.5582 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5027\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3998 - custom_f1: 0.7347 - weighted_custom_f1: 0.7398 - val_loss: 2.1038 - val_custom_f1: 0.5425 - val_weighted_custom_f1: 0.5366\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.4441 - custom_f1: 0.7191 - weighted_custom_f1: 0.7225Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5166 - custom_f1: 0.6833 - weighted_custom_f1: 0.6880 - val_loss: 1.3828 - val_custom_f1: 0.4959 - val_weighted_custom_f1: 0.5058\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.4302 - custom_f1: 0.7213 - weighted_custom_f1: 0.7245Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5062 - custom_f1: 0.6822 - weighted_custom_f1: 0.6869 - val_loss: 1.4442 - val_custom_f1: 0.5322 - val_weighted_custom_f1: 0.5541\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.4698 - custom_f1: 0.7039 - weighted_custom_f1: 0.7072Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4925 - custom_f1: 0.6888 - weighted_custom_f1: 0.6935 - val_loss: 1.3718 - val_custom_f1: 0.4934 - val_weighted_custom_f1: 0.5138\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.5029 - custom_f1: 0.6882 - weighted_custom_f1: 0.6938Epoch 98/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6145 - custom_f1: 0.6520 - weighted_custom_f1: 0.6567 - val_loss: 1.2825 - val_custom_f1: 0.5184 - val_weighted_custom_f1: 0.5262\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4453 - custom_f1: 0.7146 - weighted_custom_f1: 0.7185 - val_loss: 1.6531 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5270\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4449 - custom_f1: 0.7157 - weighted_custom_f1: 0.7197 - val_loss: 1.3376 - val_custom_f1: 0.5383 - val_weighted_custom_f1: 0.5353\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5187 - custom_f1: 0.6706 - weighted_custom_f1: 0.6743 - val_loss: 1.7997 - val_custom_f1: 0.5213 - val_weighted_custom_f1: 0.5113\n",
            "Epoch 98/100\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4745 - custom_f1: 0.7033 - weighted_custom_f1: 0.7064 - val_loss: 1.0869 - val_custom_f1: 0.4890 - val_weighted_custom_f1: 0.5117\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4867 - custom_f1: 0.6942 - weighted_custom_f1: 0.6986 - val_loss: 1.1374 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5241\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4313 - custom_f1: 0.7221 - weighted_custom_f1: 0.7257 - val_loss: 1.4710 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5360\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8954 - custom_f1: 0.5130 - weighted_custom_f1: 0.5170 - val_loss: 1.3794 - val_custom_f1: 0.5201 - val_weighted_custom_f1: 0.5295\n",
            "Epoch 98/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3378 - custom_f1: 0.6000 - weighted_custom_f1: 0.6000Epoch 98/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3974 - custom_f1: 0.7411 - weighted_custom_f1: 0.7448 - val_loss: 1.5888 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5158\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4616 - custom_f1: 0.7116 - weighted_custom_f1: 0.7136 - val_loss: 1.2123 - val_custom_f1: 0.5117 - val_weighted_custom_f1: 0.5345\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.4396 - custom_f1: 0.7194 - weighted_custom_f1: 0.7245Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5271 - custom_f1: 0.6703 - weighted_custom_f1: 0.6731 - val_loss: 1.5116 - val_custom_f1: 0.4965 - val_weighted_custom_f1: 0.5173\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.4873 - custom_f1: 0.6968 - weighted_custom_f1: 0.7008Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3865 - custom_f1: 0.7492 - weighted_custom_f1: 0.7515 - val_loss: 2.3379 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5188\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4287 - custom_f1: 0.7279 - weighted_custom_f1: 0.7314 - val_loss: 1.6284 - val_custom_f1: 0.5034 - val_weighted_custom_f1: 0.5259\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5187 - custom_f1: 0.6831 - weighted_custom_f1: 0.6864 - val_loss: 1.2568 - val_custom_f1: 0.5134 - val_weighted_custom_f1: 0.5171\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.4904 - custom_f1: 0.6952 - weighted_custom_f1: 0.6993Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5180 - custom_f1: 0.6788 - weighted_custom_f1: 0.6822 - val_loss: 1.5842 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5223\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.3739 - custom_f1: 0.7511 - weighted_custom_f1: 0.7528Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4988 - custom_f1: 0.6887 - weighted_custom_f1: 0.6949 - val_loss: 1.3526 - val_custom_f1: 0.4991 - val_weighted_custom_f1: 0.5193\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.3552 - custom_f1: 0.7654 - weighted_custom_f1: 0.7686Epoch 99/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4166 - custom_f1: 0.7310 - weighted_custom_f1: 0.7353 - val_loss: 1.5881 - val_custom_f1: 0.5217 - val_weighted_custom_f1: 0.5326\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5568 - custom_f1: 0.6615 - weighted_custom_f1: 0.6663 - val_loss: 1.2225 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5262\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.4509 - custom_f1: 0.7075 - weighted_custom_f1: 0.7114Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4445 - custom_f1: 0.7166 - weighted_custom_f1: 0.7204 - val_loss: 1.4418 - val_custom_f1: 0.5301 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9005 - custom_f1: 0.5023 - weighted_custom_f1: 0.5093 - val_loss: 1.4953 - val_custom_f1: 0.5264 - val_weighted_custom_f1: 0.5332\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4929 - custom_f1: 0.6949 - weighted_custom_f1: 0.6993 - val_loss: 1.1544 - val_custom_f1: 0.5094 - val_weighted_custom_f1: 0.5328\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4877 - custom_f1: 0.6950 - weighted_custom_f1: 0.7000 - val_loss: 1.1950 - val_custom_f1: 0.4999 - val_weighted_custom_f1: 0.5211\n",
            "Epoch 98/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8443 - custom_f1: 0.6122 - weighted_custom_f1: 0.6122Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4812 - custom_f1: 0.6924 - weighted_custom_f1: 0.6956 - val_loss: 2.1855 - val_custom_f1: 0.5288 - val_weighted_custom_f1: 0.5175\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4009 - custom_f1: 0.7417 - weighted_custom_f1: 0.7442 - val_loss: 1.5971 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5228\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4505 - custom_f1: 0.7100 - weighted_custom_f1: 0.7134 - val_loss: 1.1816 - val_custom_f1: 0.4969 - val_weighted_custom_f1: 0.5190\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.4090 - custom_f1: 0.7296 - weighted_custom_f1: 0.7330 - val_loss: 1.4540 - val_custom_f1: 0.5288 - val_weighted_custom_f1: 0.5340\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4161 - custom_f1: 0.7294 - weighted_custom_f1: 0.7330 - val_loss: 1.5854 - val_custom_f1: 0.5272 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5020 - custom_f1: 0.6798 - weighted_custom_f1: 0.6832 - val_loss: 1.4184 - val_custom_f1: 0.4971 - val_weighted_custom_f1: 0.5195\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.8886 - custom_f1: 0.5124 - weighted_custom_f1: 0.5171Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4799 - custom_f1: 0.6963 - weighted_custom_f1: 0.7012 - val_loss: 1.4522 - val_custom_f1: 0.5451 - val_weighted_custom_f1: 0.5446\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3712 - custom_f1: 0.7611 - weighted_custom_f1: 0.7646 - val_loss: 2.1418 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5288\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5089 - custom_f1: 0.6833 - weighted_custom_f1: 0.6901 - val_loss: 1.6112 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5447\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.4732 - custom_f1: 0.6954 - weighted_custom_f1: 0.6990Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4974 - custom_f1: 0.6944 - weighted_custom_f1: 0.6990 - val_loss: 1.3335 - val_custom_f1: 0.4830 - val_weighted_custom_f1: 0.4943\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4222 - custom_f1: 0.7244 - weighted_custom_f1: 0.7281 - val_loss: 1.6905 - val_custom_f1: 0.5356 - val_weighted_custom_f1: 0.5444\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8938 - custom_f1: 0.5104 - weighted_custom_f1: 0.5160 - val_loss: 1.3141 - val_custom_f1: 0.4941 - val_weighted_custom_f1: 0.5055\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.4948 - custom_f1: 0.6883 - weighted_custom_f1: 0.6909Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5003 - custom_f1: 0.6836 - weighted_custom_f1: 0.6859 - val_loss: 1.3198 - val_custom_f1: 0.5230 - val_weighted_custom_f1: 0.5309\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4436 - custom_f1: 0.7161 - weighted_custom_f1: 0.7195 - val_loss: 1.4320 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5318\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4606 - custom_f1: 0.7138 - weighted_custom_f1: 0.7173 - val_loss: 1.1323 - val_custom_f1: 0.5131 - val_weighted_custom_f1: 0.5364\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5050 - custom_f1: 0.7547 - weighted_custom_f1: 0.7547Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4758 - custom_f1: 0.6997 - weighted_custom_f1: 0.7040 - val_loss: 1.1602 - val_custom_f1: 0.4971 - val_weighted_custom_f1: 0.5189\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4732 - custom_f1: 0.6954 - weighted_custom_f1: 0.6990 - val_loss: 1.9463 - val_custom_f1: 0.5293 - val_weighted_custom_f1: 0.5220\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.4913 - custom_f1: 0.7037 - weighted_custom_f1: 0.7077Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3907 - custom_f1: 0.7431 - weighted_custom_f1: 0.7465 - val_loss: 1.6032 - val_custom_f1: 0.4966 - val_weighted_custom_f1: 0.5184\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.5030 - custom_f1: 0.6918 - weighted_custom_f1: 0.6962Epoch 100/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3996 - custom_f1: 0.7429 - weighted_custom_f1: 0.7462 - val_loss: 1.4728 - val_custom_f1: 0.5201 - val_weighted_custom_f1: 0.5261\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.3734 - custom_f1: 0.7504 - weighted_custom_f1: 0.7533Epoch 100/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4525 - custom_f1: 0.7146 - weighted_custom_f1: 0.7179 - val_loss: 1.3763 - val_custom_f1: 0.5107 - val_weighted_custom_f1: 0.5324\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4999 - custom_f1: 0.6838 - weighted_custom_f1: 0.6885 - val_loss: 1.7226 - val_custom_f1: 0.4968 - val_weighted_custom_f1: 0.5180\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4751 - custom_f1: 0.6984 - weighted_custom_f1: 0.7031 - val_loss: 1.3826 - val_custom_f1: 0.5412 - val_weighted_custom_f1: 0.5462\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4167 - custom_f1: 0.7283 - weighted_custom_f1: 0.7332 - val_loss: 1.5965 - val_custom_f1: 0.5270 - val_weighted_custom_f1: 0.5260\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3721 - custom_f1: 0.7550 - weighted_custom_f1: 0.7579 - val_loss: 2.1903 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5165\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4017 - custom_f1: 0.6667 - weighted_custom_f1: 0.6667Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4906 - custom_f1: 0.6870 - weighted_custom_f1: 0.6916 - val_loss: 1.6095 - val_custom_f1: 0.5093 - val_weighted_custom_f1: 0.5203\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4921 - custom_f1: 0.6909 - weighted_custom_f1: 0.6961 - val_loss: 1.2556 - val_custom_f1: 0.4852 - val_weighted_custom_f1: 0.4960\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5089 - custom_f1: 0.6788 - weighted_custom_f1: 0.6836 - val_loss: 1.2512 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5281\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4602 - custom_f1: 0.7044 - weighted_custom_f1: 0.7114 - val_loss: 1.8983 - val_custom_f1: 0.5376 - val_weighted_custom_f1: 0.5367\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4393 - custom_f1: 0.7197 - weighted_custom_f1: 0.7239 - val_loss: 1.4935 - val_custom_f1: 0.5226 - val_weighted_custom_f1: 0.5212\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4819 - custom_f1: 0.6885 - weighted_custom_f1: 0.6928 - val_loss: 2.0669 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5072\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9049 - custom_f1: 0.5079 - weighted_custom_f1: 0.5135 - val_loss: 1.3466 - val_custom_f1: 0.4831 - val_weighted_custom_f1: 0.4937\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4641 - custom_f1: 0.7037 - weighted_custom_f1: 0.7073 - val_loss: 1.1194 - val_custom_f1: 0.5261 - val_weighted_custom_f1: 0.5354\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.4362 - custom_f1: 0.7274 - weighted_custom_f1: 0.7339Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4852 - custom_f1: 0.6969 - weighted_custom_f1: 0.7006 - val_loss: 1.2196 - val_custom_f1: 0.5198 - val_weighted_custom_f1: 0.5408\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4118 - custom_f1: 0.7308 - weighted_custom_f1: 0.7337 - val_loss: 1.7730 - val_custom_f1: 0.5294 - val_weighted_custom_f1: 0.5358\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3966 - custom_f1: 0.7381 - weighted_custom_f1: 0.7421 - val_loss: 1.7662 - val_custom_f1: 0.5116 - val_weighted_custom_f1: 0.5338\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.4623 - custom_f1: 0.7194 - weighted_custom_f1: 0.7222\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.4993 - custom_f1: 0.6884 - weighted_custom_f1: 0.6935 - val_loss: 1.4541 - val_custom_f1: 0.5630 - val_weighted_custom_f1: 0.5633\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.4183 - custom_f1: 0.7320 - weighted_custom_f1: 0.7351 - val_loss: 1.4889 - val_custom_f1: 0.5370 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.4054 - custom_f1: 0.7368 - weighted_custom_f1: 0.7407 - val_loss: 2.0951 - val_custom_f1: 0.5371 - val_weighted_custom_f1: 0.5298\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.5122 - custom_f1: 0.6812 - weighted_custom_f1: 0.6858 - val_loss: 1.5195 - val_custom_f1: 0.5065 - val_weighted_custom_f1: 0.5183\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.5053 - custom_f1: 0.6836 - weighted_custom_f1: 0.6860 - val_loss: 1.3475 - val_custom_f1: 0.5423 - val_weighted_custom_f1: 0.5505\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.4268 - custom_f1: 0.7257 - weighted_custom_f1: 0.7304 - val_loss: 1.7163 - val_custom_f1: 0.5266 - val_weighted_custom_f1: 0.5352\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.4975 - custom_f1: 0.6853 - weighted_custom_f1: 0.6896 - val_loss: 1.8098 - val_custom_f1: 0.4937 - val_weighted_custom_f1: 0.4870\n",
            "Epoch 100/100\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.6230 - custom_f1: 0.6176 - weighted_custom_f1: 0.61\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.4724 - custom_f1: 0.7069 - weighted_custom_f1: 0.7101 - val_loss: 1.3254 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5380\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.3950 - custom_f1: 0.7334 - weighted_custom_f1: 0.7359\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.4255 - custom_f1: 0.7306 - weighted_custom_f1: 0.73\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.4652 - custom_f1: 0.7009 - weighted_custom_f1: 0.7050\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.4203 - custom_f1: 0.7253 - weighted_custom_f1: 0.73\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.4324 - custom_f1: 0.7258 - weighted_custom_f1: 0.7302 - val_loss: 1.7088 - val_custom_f1: 0.5413 - val_weighted_custom_f1: 0.5466\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.4204 - custom_f1: 0.7311 - weighted_custom_f1: 0.7338 - val_loss: 2.4641 - val_custom_f1: 0.5227 - val_weighted_custom_f1: 0.5190\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.4821 - custom_f1: 0.6906 - weighted_custom_f1: 0.69\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.4245 - custom_f1: 0.7209 - weighted_custom_f1: 0.7256 - val_loss: 1.7247 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5302\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.4832 - custom_f1: 0.6910 - weighted_custom_f1: 0.6942 - val_loss: 2.1873 - val_custom_f1: 0.5278 - val_weighted_custom_f1: 0.5240\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 1ms/step\n",
            "131/131 [==============================] - 0s 1ms/step\n",
            "131/131 [==============================] - 0s 1ms/step\n",
            "131/131 [==============================] - 0s 1ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 2.8989 - custom_f1: 0.3457 - weighted_custom_f1: 0.3482 - val_loss: 1.0846 - val_custom_f1: 0.4284 - val_weighted_custom_f1: 0.4367\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 2s 11ms/step - loss: 2.7077 - custom_f1: 0.3499 - weighted_custom_f1: 0.3531 - val_loss: 1.0580 - val_custom_f1: 0.4020 - val_weighted_custom_f1: 0.4119\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 2.8070 - custom_f1: 0.3643 - weighted_custom_f1: 0.3687 - val_loss: 1.1386 - val_custom_f1: 0.3695 - val_weighted_custom_f1: 0.3810\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0547 - custom_f1: 0.4311 - weighted_custom_f1: 0.4363Epoch 2/100\n",
            "105/105 [==============================] - 2s 12ms/step - loss: 5.2392 - custom_f1: 0.1278 - weighted_custom_f1: 0.1282 - val_loss: 1.4255 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 13ms/step - loss: 2.4107 - custom_f1: 0.3641 - weighted_custom_f1: 0.3678 - val_loss: 1.0448 - val_custom_f1: 0.4499 - val_weighted_custom_f1: 0.4486\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.2113 - custom_f1: 0.2345 - weighted_custom_f1: 0.2345Epoch 2/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 4.3508 - custom_f1: 0.3595 - weighted_custom_f1: 0.3637 - val_loss: 1.2412 - val_custom_f1: 0.4164 - val_weighted_custom_f1: 0.4261\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 1.2457 - custom_f1: 0.3972 - weighted_custom_f1: 0.4018Epoch 2/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 1.0547 - custom_f1: 0.4321 - weighted_custom_f1: 0.4368 - val_loss: 1.1153 - val_custom_f1: 0.3851 - val_weighted_custom_f1: 0.3966\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.9955 - custom_f1: 0.4454 - weighted_custom_f1: 0.4533Epoch 3/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 4.5905 - custom_f1: 0.2778 - weighted_custom_f1: 0.2808 - val_loss: 1.0617 - val_custom_f1: 0.4196 - val_weighted_custom_f1: 0.4291\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 13ms/step - loss: 4.7548 - custom_f1: 0.3358 - weighted_custom_f1: 0.3411 - val_loss: 1.0602 - val_custom_f1: 0.3994 - val_weighted_custom_f1: 0.4090\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0314 - custom_f1: 0.4478 - weighted_custom_f1: 0.4505 - val_loss: 1.0252 - val_custom_f1: 0.4332 - val_weighted_custom_f1: 0.4420\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 3.3629 - custom_f1: 0.3968 - weighted_custom_f1: 0.3996 - val_loss: 1.0404 - val_custom_f1: 0.4450 - val_weighted_custom_f1: 0.4440\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 1.2766 - custom_f1: 0.3637 - weighted_custom_f1: 0.3677 - val_loss: 1.0825 - val_custom_f1: 0.4207 - val_weighted_custom_f1: 0.4259\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0203 - custom_f1: 0.4388 - weighted_custom_f1: 0.4435 - val_loss: 1.0223 - val_custom_f1: 0.4153 - val_weighted_custom_f1: 0.4260\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 3s 12ms/step - loss: 1.2599 - custom_f1: 0.3688 - weighted_custom_f1: 0.3724 - val_loss: 1.0711 - val_custom_f1: 0.4093 - val_weighted_custom_f1: 0.4197\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.9874 - custom_f1: 0.4549 - weighted_custom_f1: 0.4600Epoch 2/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0158 - custom_f1: 0.4614 - weighted_custom_f1: 0.4674 - val_loss: 1.0089 - val_custom_f1: 0.4680 - val_weighted_custom_f1: 0.4675\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.9743 - custom_f1: 0.4681 - weighted_custom_f1: 0.4718Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.2671 - custom_f1: 0.2850 - weighted_custom_f1: 0.2890 - val_loss: 1.4225 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.1074 - custom_f1: 0.4253 - weighted_custom_f1: 0.4305 - val_loss: 1.0640 - val_custom_f1: 0.4106 - val_weighted_custom_f1: 0.4220\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 1.0605 - custom_f1: 0.4477 - weighted_custom_f1: 0.4534Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0457 - custom_f1: 0.4428 - weighted_custom_f1: 0.4459 - val_loss: 1.0683 - val_custom_f1: 0.4145 - val_weighted_custom_f1: 0.4228\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0112 - custom_f1: 0.4500 - weighted_custom_f1: 0.4542 - val_loss: 1.0327 - val_custom_f1: 0.4396 - val_weighted_custom_f1: 0.4514\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 1.2591 - custom_f1: 0.2812 - weighted_custom_f1: 0.2856Epoch 4/100\n",
            "105/105 [==============================] - 3s 13ms/step - loss: 1.2471 - custom_f1: 0.3709 - weighted_custom_f1: 0.3752 - val_loss: 1.0990 - val_custom_f1: 0.3840 - val_weighted_custom_f1: 0.3942\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0468 - custom_f1: 0.4454 - weighted_custom_f1: 0.4505 - val_loss: 0.9993 - val_custom_f1: 0.4499 - val_weighted_custom_f1: 0.4582\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9932 - custom_f1: 0.4578 - weighted_custom_f1: 0.4620 - val_loss: 0.9939 - val_custom_f1: 0.4518 - val_weighted_custom_f1: 0.4619\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 1.0944 - custom_f1: 0.4214 - weighted_custom_f1: 0.4270Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0890 - custom_f1: 0.4487 - weighted_custom_f1: 0.4539 - val_loss: 1.0189 - val_custom_f1: 0.4140 - val_weighted_custom_f1: 0.4127\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 3s 14ms/step - loss: 1.2484 - custom_f1: 0.3700 - weighted_custom_f1: 0.3745 - val_loss: 1.1180 - val_custom_f1: 0.3705 - val_weighted_custom_f1: 0.3809\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 3s 14ms/step - loss: 1.2552 - custom_f1: 0.3808 - weighted_custom_f1: 0.3846 - val_loss: 1.0982 - val_custom_f1: 0.4041 - val_weighted_custom_f1: 0.4014\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0743 - custom_f1: 0.4198 - weighted_custom_f1: 0.4247 - val_loss: 1.0396 - val_custom_f1: 0.4075 - val_weighted_custom_f1: 0.4173\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 1.0963 - custom_f1: 0.4382 - weighted_custom_f1: 0.4431Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0004 - custom_f1: 0.4607 - weighted_custom_f1: 0.4650 - val_loss: 1.0046 - val_custom_f1: 0.4346 - val_weighted_custom_f1: 0.4461\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 1.0960 - custom_f1: 0.4217 - weighted_custom_f1: 0.4270Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0685 - custom_f1: 0.4275 - weighted_custom_f1: 0.4321 - val_loss: 1.0948 - val_custom_f1: 0.3792 - val_weighted_custom_f1: 0.3896\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2627 - custom_f1: 0.2849 - weighted_custom_f1: 0.2886 - val_loss: 1.4220 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.9874 - custom_f1: 0.4638 - weighted_custom_f1: 0.4687Epoch 3/100\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.9662 - custom_f1: 0.4532 - weighted_custom_f1: 0.4605Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9726 - custom_f1: 0.4780 - weighted_custom_f1: 0.4836 - val_loss: 1.0103 - val_custom_f1: 0.4864 - val_weighted_custom_f1: 0.4843\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.9927 - custom_f1: 0.4647 - weighted_custom_f1: 0.4691Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9828 - custom_f1: 0.4621 - weighted_custom_f1: 0.4654 - val_loss: 1.0179 - val_custom_f1: 0.4843 - val_weighted_custom_f1: 0.4941\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 1.0659 - custom_f1: 0.4079 - weighted_custom_f1: 0.4129Epoch 4/100\n",
            "105/105 [==============================] - 3s 15ms/step - loss: 1.2276 - custom_f1: 0.3983 - weighted_custom_f1: 0.4027 - val_loss: 1.2014 - val_custom_f1: 0.3540 - val_weighted_custom_f1: 0.3646\n",
            "105/105 [==============================] - 3s 14ms/step - loss: 1.2723 - custom_f1: 0.3897 - weighted_custom_f1: 0.3925 - val_loss: 1.0572 - val_custom_f1: 0.4037 - val_weighted_custom_f1: 0.4134\n",
            "Epoch 2/100\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0470 - custom_f1: 0.4568 - weighted_custom_f1: 0.4615 - val_loss: 1.0619 - val_custom_f1: 0.4194 - val_weighted_custom_f1: 0.4291\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9976 - custom_f1: 0.4588 - weighted_custom_f1: 0.4640 - val_loss: 1.1052 - val_custom_f1: 0.4887 - val_weighted_custom_f1: 0.4924\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 1.0988 - custom_f1: 0.4725 - weighted_custom_f1: 0.4780Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0524 - custom_f1: 0.4256 - weighted_custom_f1: 0.4290 - val_loss: 1.0572 - val_custom_f1: 0.4033 - val_weighted_custom_f1: 0.4132\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 1.0256 - custom_f1: 0.4372 - weighted_custom_f1: 0.4441Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9812 - custom_f1: 0.4642 - weighted_custom_f1: 0.4703 - val_loss: 0.9716 - val_custom_f1: 0.4449 - val_weighted_custom_f1: 0.4572\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.9992 - custom_f1: 0.4746 - weighted_custom_f1: 0.4783Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9935 - custom_f1: 0.4655 - weighted_custom_f1: 0.4699 - val_loss: 1.0378 - val_custom_f1: 0.4131 - val_weighted_custom_f1: 0.4225\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.9712 - custom_f1: 0.4648 - weighted_custom_f1: 0.4695Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0897 - custom_f1: 0.4743 - weighted_custom_f1: 0.4794 - val_loss: 0.9986 - val_custom_f1: 0.4869 - val_weighted_custom_f1: 0.4847\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 1.0294 - custom_f1: 0.4401 - weighted_custom_f1: 0.4434Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0459 - custom_f1: 0.4280 - weighted_custom_f1: 0.4329 - val_loss: 1.0767 - val_custom_f1: 0.3933 - val_weighted_custom_f1: 0.4028\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0268 - custom_f1: 0.4413 - weighted_custom_f1: 0.4470 - val_loss: 1.0586 - val_custom_f1: 0.4525 - val_weighted_custom_f1: 0.4509\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 1.0463 - custom_f1: 0.4565 - weighted_custom_f1: 0.4618Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9721 - custom_f1: 0.4666 - weighted_custom_f1: 0.4710 - val_loss: 0.9944 - val_custom_f1: 0.4395 - val_weighted_custom_f1: 0.4470\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0227 - custom_f1: 0.4417 - weighted_custom_f1: 0.4448 - val_loss: 1.0150 - val_custom_f1: 0.4461 - val_weighted_custom_f1: 0.4568\n",
            "Epoch 5/100\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9683 - custom_f1: 0.4720 - weighted_custom_f1: 0.4792 - val_loss: 1.0100 - val_custom_f1: 0.4980 - val_weighted_custom_f1: 0.5060\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0383 - custom_f1: 0.4369 - weighted_custom_f1: 0.4409 - val_loss: 1.0381 - val_custom_f1: 0.4016 - val_weighted_custom_f1: 0.4134\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9487 - custom_f1: 0.4842 - weighted_custom_f1: 0.4871 - val_loss: 0.9413 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.4919\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.9736 - custom_f1: 0.4728 - weighted_custom_f1: 0.4760Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.2618 - custom_f1: 0.2834 - weighted_custom_f1: 0.2888 - val_loss: 1.4221 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.1425 - custom_f1: 0.4183 - weighted_custom_f1: 0.4228 - val_loss: 1.1996 - val_custom_f1: 0.3578 - val_weighted_custom_f1: 0.3694\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.9758 - custom_f1: 0.4544 - weighted_custom_f1: 0.4601Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.1568 - custom_f1: 0.4186 - weighted_custom_f1: 0.4223 - val_loss: 1.3656 - val_custom_f1: 0.3337 - val_weighted_custom_f1: 0.3445\n",
            "Epoch 3/100\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 1.0331 - custom_f1: 0.4374 - weighted_custom_f1: 0.4423Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0636 - custom_f1: 0.4551 - weighted_custom_f1: 0.4613 - val_loss: 1.0525 - val_custom_f1: 0.4192 - val_weighted_custom_f1: 0.4281\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0340 - custom_f1: 0.4588 - weighted_custom_f1: 0.4640 - val_loss: 1.0413 - val_custom_f1: 0.4239 - val_weighted_custom_f1: 0.4356\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0169 - custom_f1: 0.4550 - weighted_custom_f1: 0.4589 - val_loss: 1.0788 - val_custom_f1: 0.3990 - val_weighted_custom_f1: 0.4101\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.9360 - custom_f1: 0.4869 - weighted_custom_f1: 0.4900Epoch 6/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0205 - custom_f1: 0.4444 - weighted_custom_f1: 0.4493 - val_loss: 1.0534 - val_custom_f1: 0.3955 - val_weighted_custom_f1: 0.4076\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.9373 - custom_f1: 0.4827 - weighted_custom_f1: 0.4852Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9866 - custom_f1: 0.4708 - weighted_custom_f1: 0.4752 - val_loss: 0.9892 - val_custom_f1: 0.4467 - val_weighted_custom_f1: 0.4551\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 1.0460 - custom_f1: 0.4422 - weighted_custom_f1: 0.4438Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9625 - custom_f1: 0.4811 - weighted_custom_f1: 0.4847 - val_loss: 0.9612 - val_custom_f1: 0.4724 - val_weighted_custom_f1: 0.4721\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.9831 - custom_f1: 0.4760 - weighted_custom_f1: 0.4798Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0341 - custom_f1: 0.4407 - weighted_custom_f1: 0.4446 - val_loss: 1.0232 - val_custom_f1: 0.4462 - val_weighted_custom_f1: 0.4530\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0015 - custom_f1: 0.4475 - weighted_custom_f1: 0.4550 - val_loss: 1.0410 - val_custom_f1: 0.4683 - val_weighted_custom_f1: 0.4756\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9972 - custom_f1: 0.4542 - weighted_custom_f1: 0.4599 - val_loss: 1.0396 - val_custom_f1: 0.4568 - val_weighted_custom_f1: 0.4563\n",
            "Epoch 4/100\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.9644 - custom_f1: 0.4775 - weighted_custom_f1: 0.4817Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9688 - custom_f1: 0.4652 - weighted_custom_f1: 0.4710 - val_loss: 1.0405 - val_custom_f1: 0.4056 - val_weighted_custom_f1: 0.4173\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0167 - custom_f1: 0.4460 - weighted_custom_f1: 0.4513 - val_loss: 1.0724 - val_custom_f1: 0.4798 - val_weighted_custom_f1: 0.4793\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9663 - custom_f1: 0.4745 - weighted_custom_f1: 0.4787 - val_loss: 1.0228 - val_custom_f1: 0.4426 - val_weighted_custom_f1: 0.4535\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2626 - custom_f1: 0.2844 - weighted_custom_f1: 0.2894 - val_loss: 1.4231 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9290 - custom_f1: 0.4920 - weighted_custom_f1: 0.4981 - val_loss: 0.9472 - val_custom_f1: 0.4973 - val_weighted_custom_f1: 0.4957\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.3527 - custom_f1: 0.3268 - weighted_custom_f1: 0.3268Epoch 6/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0244 - custom_f1: 0.4510 - weighted_custom_f1: 0.4554 - val_loss: 0.9987 - val_custom_f1: 0.4804 - val_weighted_custom_f1: 0.4866\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0140 - custom_f1: 0.4526 - weighted_custom_f1: 0.4557 - val_loss: 0.9951 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.4819\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.9920 - custom_f1: 0.4573 - weighted_custom_f1: 0.4625Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0818 - custom_f1: 0.4441 - weighted_custom_f1: 0.4482 - val_loss: 1.0973 - val_custom_f1: 0.4233 - val_weighted_custom_f1: 0.4341\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.9459 - custom_f1: 0.4935 - weighted_custom_f1: 0.4963Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0163 - custom_f1: 0.4689 - weighted_custom_f1: 0.4732 - val_loss: 1.0554 - val_custom_f1: 0.4641 - val_weighted_custom_f1: 0.4711\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9674 - custom_f1: 0.4731 - weighted_custom_f1: 0.4766 - val_loss: 1.0135 - val_custom_f1: 0.4743 - val_weighted_custom_f1: 0.4816\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.9568 - custom_f1: 0.4759 - weighted_custom_f1: 0.4812Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0460 - custom_f1: 0.4732 - weighted_custom_f1: 0.4787 - val_loss: 1.0799 - val_custom_f1: 0.4027 - val_weighted_custom_f1: 0.4129\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0003 - custom_f1: 0.4506 - weighted_custom_f1: 0.4566 - val_loss: 1.0104 - val_custom_f1: 0.4650 - val_weighted_custom_f1: 0.4737\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7917 - custom_f1: 0.5417 - weighted_custom_f1: 0.5417Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9488 - custom_f1: 0.4885 - weighted_custom_f1: 0.4947 - val_loss: 0.9684 - val_custom_f1: 0.4772 - val_weighted_custom_f1: 0.4772\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.9593 - custom_f1: 0.4752 - weighted_custom_f1: 0.4810Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9953 - custom_f1: 0.4576 - weighted_custom_f1: 0.4614 - val_loss: 1.0133 - val_custom_f1: 0.4596 - val_weighted_custom_f1: 0.4660\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9916 - custom_f1: 0.4608 - weighted_custom_f1: 0.4646 - val_loss: 0.9983 - val_custom_f1: 0.4639 - val_weighted_custom_f1: 0.4706\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.9856 - custom_f1: 0.4709 - weighted_custom_f1: 0.4752Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9748 - custom_f1: 0.4686 - weighted_custom_f1: 0.4729 - val_loss: 1.0336 - val_custom_f1: 0.4642 - val_weighted_custom_f1: 0.4623\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9552 - custom_f1: 0.4819 - weighted_custom_f1: 0.4868 - val_loss: 0.9657 - val_custom_f1: 0.4561 - val_weighted_custom_f1: 0.4660\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0262 - custom_f1: 0.4515 - weighted_custom_f1: 0.4563 - val_loss: 1.0299 - val_custom_f1: 0.4641 - val_weighted_custom_f1: 0.4715\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2630 - custom_f1: 0.2846 - weighted_custom_f1: 0.2885 - val_loss: 1.4235 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9279 - custom_f1: 0.4891 - weighted_custom_f1: 0.4946 - val_loss: 0.9333 - val_custom_f1: 0.4764 - val_weighted_custom_f1: 0.4755\n",
            "Epoch 7/100\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.9422 - custom_f1: 0.4775 - weighted_custom_f1: 0.4819Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9552 - custom_f1: 0.4788 - weighted_custom_f1: 0.4835 - val_loss: 1.0330 - val_custom_f1: 0.4688 - val_weighted_custom_f1: 0.4785\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9974 - custom_f1: 0.4613 - weighted_custom_f1: 0.4687 - val_loss: 0.9838 - val_custom_f1: 0.4790 - val_weighted_custom_f1: 0.4866\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.9565 - custom_f1: 0.4638 - weighted_custom_f1: 0.4714Epoch 5/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9888 - custom_f1: 0.4671 - weighted_custom_f1: 0.4733 - val_loss: 1.0623 - val_custom_f1: 0.4909 - val_weighted_custom_f1: 0.4919\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9757 - custom_f1: 0.4740 - weighted_custom_f1: 0.4781 - val_loss: 1.0290 - val_custom_f1: 0.4904 - val_weighted_custom_f1: 0.4983\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.9722 - custom_f1: 0.4737 - weighted_custom_f1: 0.4795Epoch 8/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0311 - custom_f1: 0.4663 - weighted_custom_f1: 0.4704 - val_loss: 1.1796 - val_custom_f1: 0.4659 - val_weighted_custom_f1: 0.4470\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9628 - custom_f1: 0.4852 - weighted_custom_f1: 0.4890 - val_loss: 0.9708 - val_custom_f1: 0.4834 - val_weighted_custom_f1: 0.4941\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9923 - custom_f1: 0.4594 - weighted_custom_f1: 0.4645 - val_loss: 0.9914 - val_custom_f1: 0.4393 - val_weighted_custom_f1: 0.4504\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9769 - custom_f1: 0.4749 - weighted_custom_f1: 0.4790 - val_loss: 1.0172 - val_custom_f1: 0.4638 - val_weighted_custom_f1: 0.4715\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.9599 - custom_f1: 0.4834 - weighted_custom_f1: 0.4863Epoch 8/100\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.9891 - custom_f1: 0.4646 - weighted_custom_f1: 0.4696Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9567 - custom_f1: 0.4892 - weighted_custom_f1: 0.4946 - val_loss: 0.9484 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.4780\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.9653 - custom_f1: 0.4903 - weighted_custom_f1: 0.4938Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9700 - custom_f1: 0.4700 - weighted_custom_f1: 0.4752 - val_loss: 1.0259 - val_custom_f1: 0.4632 - val_weighted_custom_f1: 0.4704\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.9784 - custom_f1: 0.4795 - weighted_custom_f1: 0.4856Epoch 7/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9913 - custom_f1: 0.4609 - weighted_custom_f1: 0.4666 - val_loss: 1.0444 - val_custom_f1: 0.3944 - val_weighted_custom_f1: 0.4067\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.9479 - custom_f1: 0.5031 - weighted_custom_f1: 0.5048Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9708 - custom_f1: 0.4869 - weighted_custom_f1: 0.4901 - val_loss: 1.0203 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5137\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9578 - custom_f1: 0.4751 - weighted_custom_f1: 0.4811 - val_loss: 1.0373 - val_custom_f1: 0.4650 - val_weighted_custom_f1: 0.4634\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.9764 - custom_f1: 0.4775 - weighted_custom_f1: 0.4814Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9880 - custom_f1: 0.4577 - weighted_custom_f1: 0.4618 - val_loss: 1.0631 - val_custom_f1: 0.4693 - val_weighted_custom_f1: 0.4735\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9018 - custom_f1: 0.4974 - weighted_custom_f1: 0.5033 - val_loss: 1.0222 - val_custom_f1: 0.4979 - val_weighted_custom_f1: 0.4967\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.9419 - custom_f1: 0.4820 - weighted_custom_f1: 0.4857Epoch 8/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.2625 - custom_f1: 0.2840 - weighted_custom_f1: 0.2887 - val_loss: 1.4241 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9440 - custom_f1: 0.4884 - weighted_custom_f1: 0.4920 - val_loss: 1.0395 - val_custom_f1: 0.4887 - val_weighted_custom_f1: 0.4970\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9415 - custom_f1: 0.4838 - weighted_custom_f1: 0.4874Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9680 - custom_f1: 0.4761 - weighted_custom_f1: 0.4815 - val_loss: 0.9641 - val_custom_f1: 0.4483 - val_weighted_custom_f1: 0.4591\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9611 - custom_f1: 0.4811 - weighted_custom_f1: 0.4846 - val_loss: 1.0155 - val_custom_f1: 0.4903 - val_weighted_custom_f1: 0.5000\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9725 - custom_f1: 0.4762 - weighted_custom_f1: 0.4820 - val_loss: 1.0076 - val_custom_f1: 0.4123 - val_weighted_custom_f1: 0.4235\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.9348 - custom_f1: 0.4878 - weighted_custom_f1: 0.4920Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0438 - custom_f1: 0.4669 - weighted_custom_f1: 0.4718 - val_loss: 1.0399 - val_custom_f1: 0.4600 - val_weighted_custom_f1: 0.4664\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 1.0057 - custom_f1: 0.4953 - weighted_custom_f1: 0.4991Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9411 - custom_f1: 0.4827 - weighted_custom_f1: 0.4870 - val_loss: 0.9588 - val_custom_f1: 0.4908 - val_weighted_custom_f1: 0.5010\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.9304 - custom_f1: 0.4883 - weighted_custom_f1: 0.4935Epoch 9/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9714 - custom_f1: 0.4920 - weighted_custom_f1: 0.4952 - val_loss: 1.0718 - val_custom_f1: 0.4870 - val_weighted_custom_f1: 0.4892\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 1.2685 - custom_f1: 0.2872 - weighted_custom_f1: 0.2910Epoch 8/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9731 - custom_f1: 0.4732 - weighted_custom_f1: 0.4774 - val_loss: 1.0086 - val_custom_f1: 0.4703 - val_weighted_custom_f1: 0.4800\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9431 - custom_f1: 0.4917 - weighted_custom_f1: 0.4973 - val_loss: 0.9919 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5118\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.9329 - custom_f1: 0.4928 - weighted_custom_f1: 0.4970Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9571 - custom_f1: 0.4698 - weighted_custom_f1: 0.4749 - val_loss: 1.0122 - val_custom_f1: 0.4649 - val_weighted_custom_f1: 0.4714\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9740 - custom_f1: 0.4676 - weighted_custom_f1: 0.4720 - val_loss: 0.9884 - val_custom_f1: 0.4556 - val_weighted_custom_f1: 0.4651\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.9658 - custom_f1: 0.4839 - weighted_custom_f1: 0.4888Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9718 - custom_f1: 0.4887 - weighted_custom_f1: 0.4948 - val_loss: 1.0323 - val_custom_f1: 0.5040 - val_weighted_custom_f1: 0.5059\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9848 - custom_f1: 0.4646 - weighted_custom_f1: 0.4703 - val_loss: 0.9922 - val_custom_f1: 0.4412 - val_weighted_custom_f1: 0.4505\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9466 - custom_f1: 0.4770 - weighted_custom_f1: 0.4827 - val_loss: 0.9964 - val_custom_f1: 0.4619 - val_weighted_custom_f1: 0.4616\n",
            "Epoch 8/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7896 - custom_f1: 0.5366 - weighted_custom_f1: 0.5366Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9131 - custom_f1: 0.4952 - weighted_custom_f1: 0.5002 - val_loss: 0.9380 - val_custom_f1: 0.4869 - val_weighted_custom_f1: 0.4861\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2628 - custom_f1: 0.2844 - weighted_custom_f1: 0.2880 - val_loss: 1.4228 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.9465 - custom_f1: 0.4881 - weighted_custom_f1: 0.4920Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9340 - custom_f1: 0.4903 - weighted_custom_f1: 0.4950 - val_loss: 1.0512 - val_custom_f1: 0.4937 - val_weighted_custom_f1: 0.5042\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.9560 - custom_f1: 0.4741 - weighted_custom_f1: 0.4766Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9520 - custom_f1: 0.4832 - weighted_custom_f1: 0.4885 - val_loss: 0.9877 - val_custom_f1: 0.4727 - val_weighted_custom_f1: 0.4828\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9472 - custom_f1: 0.4732 - weighted_custom_f1: 0.4775 - val_loss: 0.9891 - val_custom_f1: 0.4789 - val_weighted_custom_f1: 0.4869\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.9442 - custom_f1: 0.4963 - weighted_custom_f1: 0.4963Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9621 - custom_f1: 0.4853 - weighted_custom_f1: 0.4895 - val_loss: 1.0610 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.4793\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0132 - custom_f1: 0.4697 - weighted_custom_f1: 0.4747 - val_loss: 1.0655 - val_custom_f1: 0.4843 - val_weighted_custom_f1: 0.4921\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.9651 - custom_f1: 0.4773 - weighted_custom_f1: 0.4800Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9308 - custom_f1: 0.4934 - weighted_custom_f1: 0.4971 - val_loss: 0.9422 - val_custom_f1: 0.4705 - val_weighted_custom_f1: 0.4807\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9376 - custom_f1: 0.4989 - weighted_custom_f1: 0.5048 - val_loss: 1.1281 - val_custom_f1: 0.4613 - val_weighted_custom_f1: 0.4607\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9522 - custom_f1: 0.4714 - weighted_custom_f1: 0.4775 - val_loss: 0.9793 - val_custom_f1: 0.4692 - val_weighted_custom_f1: 0.4794\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9418 - custom_f1: 0.4890 - weighted_custom_f1: 0.4938 - val_loss: 0.9757 - val_custom_f1: 0.4808 - val_weighted_custom_f1: 0.4811\n",
            "Epoch 8/100\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 1.2547 - custom_f1: 0.2536 - weighted_custom_f1: 0.2572Epoch 9/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9584 - custom_f1: 0.4706 - weighted_custom_f1: 0.4752 - val_loss: 0.9849 - val_custom_f1: 0.4752 - val_weighted_custom_f1: 0.4867\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9454 - custom_f1: 0.4827 - weighted_custom_f1: 0.4876 - val_loss: 0.9662 - val_custom_f1: 0.4626 - val_weighted_custom_f1: 0.4737\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.9175 - custom_f1: 0.4956 - weighted_custom_f1: 0.4995Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9603 - custom_f1: 0.4754 - weighted_custom_f1: 0.4795 - val_loss: 0.9831 - val_custom_f1: 0.4570 - val_weighted_custom_f1: 0.4667\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9358 - custom_f1: 0.4844 - weighted_custom_f1: 0.4909 - val_loss: 1.0095 - val_custom_f1: 0.4686 - val_weighted_custom_f1: 0.4665\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9277 - custom_f1: 0.4964 - weighted_custom_f1: 0.5000 - val_loss: 0.9527 - val_custom_f1: 0.4837 - val_weighted_custom_f1: 0.4955\n",
            "  5/105 [>.............................] - ETA: 1s - loss: 0.9317 - custom_f1: 0.5554 - weighted_custom_f1: 0.5598Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9012 - custom_f1: 0.5112 - weighted_custom_f1: 0.5163 - val_loss: 0.9645 - val_custom_f1: 0.5102 - val_weighted_custom_f1: 0.5101\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2622 - custom_f1: 0.2658 - weighted_custom_f1: 0.2691 - val_loss: 1.4223 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.9445 - custom_f1: 0.4905 - weighted_custom_f1: 0.4933Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9462 - custom_f1: 0.4881 - weighted_custom_f1: 0.4936 - val_loss: 1.0164 - val_custom_f1: 0.4821 - val_weighted_custom_f1: 0.4922\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.9047 - custom_f1: 0.4829 - weighted_custom_f1: 0.4886Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9175 - custom_f1: 0.4956 - weighted_custom_f1: 0.4995 - val_loss: 1.0090 - val_custom_f1: 0.4838 - val_weighted_custom_f1: 0.4920\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 1.2736 - custom_f1: 0.2877 - weighted_custom_f1: 0.2942Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9770 - custom_f1: 0.4708 - weighted_custom_f1: 0.4758 - val_loss: 1.0534 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5025\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9247 - custom_f1: 0.4927 - weighted_custom_f1: 0.4973 - val_loss: 0.9585 - val_custom_f1: 0.4844 - val_weighted_custom_f1: 0.4932\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.8944 - custom_f1: 0.5115 - weighted_custom_f1: 0.5179Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0529 - custom_f1: 0.4693 - weighted_custom_f1: 0.4731 - val_loss: 1.0463 - val_custom_f1: 0.4383 - val_weighted_custom_f1: 0.4465\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9359 - custom_f1: 0.4885 - weighted_custom_f1: 0.4919 - val_loss: 0.9681 - val_custom_f1: 0.4781 - val_weighted_custom_f1: 0.4872\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9384 - custom_f1: 0.4961 - weighted_custom_f1: 0.4999 - val_loss: 0.9640 - val_custom_f1: 0.4816 - val_weighted_custom_f1: 0.4902\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.9358 - custom_f1: 0.4856 - weighted_custom_f1: 0.4896Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9560 - custom_f1: 0.4983 - weighted_custom_f1: 0.5034 - val_loss: 0.9453 - val_custom_f1: 0.4898 - val_weighted_custom_f1: 0.4902\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9371 - custom_f1: 0.4826 - weighted_custom_f1: 0.4877 - val_loss: 0.9606 - val_custom_f1: 0.4545 - val_weighted_custom_f1: 0.4651\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.9357 - custom_f1: 0.5014 - weighted_custom_f1: 0.5053Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9225 - custom_f1: 0.4894 - weighted_custom_f1: 0.4945 - val_loss: 0.9598 - val_custom_f1: 0.4680 - val_weighted_custom_f1: 0.4784\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.9347 - custom_f1: 0.4899 - weighted_custom_f1: 0.4940Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9530 - custom_f1: 0.4774 - weighted_custom_f1: 0.4816 - val_loss: 0.9582 - val_custom_f1: 0.4546 - val_weighted_custom_f1: 0.4663\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9420 - custom_f1: 0.4821 - weighted_custom_f1: 0.4875 - val_loss: 0.9794 - val_custom_f1: 0.4524 - val_weighted_custom_f1: 0.4614\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9255 - custom_f1: 0.4908 - weighted_custom_f1: 0.4951 - val_loss: 1.0422 - val_custom_f1: 0.4123 - val_weighted_custom_f1: 0.4109\n",
            "Epoch 9/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9451 - custom_f1: 0.5833 - weighted_custom_f1: 0.5833Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9223 - custom_f1: 0.4907 - weighted_custom_f1: 0.4954 - val_loss: 0.9357 - val_custom_f1: 0.4889 - val_weighted_custom_f1: 0.4996\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8777 - custom_f1: 0.5078 - weighted_custom_f1: 0.5148 - val_loss: 0.9245 - val_custom_f1: 0.5263 - val_weighted_custom_f1: 0.5258\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.9423 - custom_f1: 0.4867 - weighted_custom_f1: 0.4917Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2633 - custom_f1: 0.2840 - weighted_custom_f1: 0.2888 - val_loss: 1.4220 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9755 - custom_f1: 0.4795 - weighted_custom_f1: 0.4854 - val_loss: 1.0997 - val_custom_f1: 0.5141 - val_weighted_custom_f1: 0.5207\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.9318 - custom_f1: 0.4836 - weighted_custom_f1: 0.4880Epoch 11/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9010 - custom_f1: 0.5002 - weighted_custom_f1: 0.5046 - val_loss: 1.0484 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5155\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9060 - custom_f1: 0.5005 - weighted_custom_f1: 0.5054 - val_loss: 0.9309 - val_custom_f1: 0.4904 - val_weighted_custom_f1: 0.5015\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.9352 - custom_f1: 0.4792 - weighted_custom_f1: 0.4851Epoch 9/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9496 - custom_f1: 0.4838 - weighted_custom_f1: 0.4870 - val_loss: 1.0808 - val_custom_f1: 0.4254 - val_weighted_custom_f1: 0.4351\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0153 - custom_f1: 0.4711 - weighted_custom_f1: 0.4755 - val_loss: 1.0734 - val_custom_f1: 0.4823 - val_weighted_custom_f1: 0.4836\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.9474 - custom_f1: 0.4833 - weighted_custom_f1: 0.4882Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9343 - custom_f1: 0.4912 - weighted_custom_f1: 0.4951 - val_loss: 0.9552 - val_custom_f1: 0.4802 - val_weighted_custom_f1: 0.4898\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9344 - custom_f1: 0.4895 - weighted_custom_f1: 0.4944 - val_loss: 1.0729 - val_custom_f1: 0.4166 - val_weighted_custom_f1: 0.4261\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9320 - custom_f1: 0.4899 - weighted_custom_f1: 0.4959 - val_loss: 0.9662 - val_custom_f1: 0.5134 - val_weighted_custom_f1: 0.5107\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9338 - custom_f1: 0.4893 - weighted_custom_f1: 0.4936 - val_loss: 0.9552 - val_custom_f1: 0.4602 - val_weighted_custom_f1: 0.4708\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9255 - custom_f1: 0.4890 - weighted_custom_f1: 0.4949 - val_loss: 0.9726 - val_custom_f1: 0.4308 - val_weighted_custom_f1: 0.4418\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 1.0257 - custom_f1: 0.4674 - weighted_custom_f1: 0.4730Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9435 - custom_f1: 0.4742 - weighted_custom_f1: 0.4796 - val_loss: 0.9562 - val_custom_f1: 0.4751 - val_weighted_custom_f1: 0.4848\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9477 - custom_f1: 0.4876 - weighted_custom_f1: 0.4915 - val_loss: 0.9601 - val_custom_f1: 0.4444 - val_weighted_custom_f1: 0.4549\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.9369 - custom_f1: 0.4938 - weighted_custom_f1: 0.4973Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9455 - custom_f1: 0.4958 - weighted_custom_f1: 0.5001 - val_loss: 0.9312 - val_custom_f1: 0.4624 - val_weighted_custom_f1: 0.4723\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.9499 - custom_f1: 0.4890 - weighted_custom_f1: 0.4948Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9063 - custom_f1: 0.4944 - weighted_custom_f1: 0.4998 - val_loss: 0.9741 - val_custom_f1: 0.4798 - val_weighted_custom_f1: 0.4789\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8798 - custom_f1: 0.5138 - weighted_custom_f1: 0.5195 - val_loss: 0.9282 - val_custom_f1: 0.5184 - val_weighted_custom_f1: 0.5176\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.9592 - custom_f1: 0.4876 - weighted_custom_f1: 0.4926Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2629 - custom_f1: 0.2852 - weighted_custom_f1: 0.2880 - val_loss: 1.4238 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.9450 - custom_f1: 0.4913 - weighted_custom_f1: 0.4953Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9428 - custom_f1: 0.4919 - weighted_custom_f1: 0.4944 - val_loss: 1.0924 - val_custom_f1: 0.4267 - val_weighted_custom_f1: 0.4384\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8754 - custom_f1: 0.5121 - weighted_custom_f1: 0.5171 - val_loss: 0.9410 - val_custom_f1: 0.4951 - val_weighted_custom_f1: 0.5061\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9587 - custom_f1: 0.4813 - weighted_custom_f1: 0.4870 - val_loss: 1.0284 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5162\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.9022 - custom_f1: 0.5062 - weighted_custom_f1: 0.5118Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8939 - custom_f1: 0.5027 - weighted_custom_f1: 0.5060 - val_loss: 0.9103 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5245\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1714 - custom_f1: 0.5075 - weighted_custom_f1: 0.5075Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0212 - custom_f1: 0.4685 - weighted_custom_f1: 0.4735 - val_loss: 1.0998 - val_custom_f1: 0.4012 - val_weighted_custom_f1: 0.4117\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9640 - custom_f1: 0.4855 - weighted_custom_f1: 0.4903 - val_loss: 0.9631 - val_custom_f1: 0.4748 - val_weighted_custom_f1: 0.4852\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.9453 - custom_f1: 0.4922 - weighted_custom_f1: 0.4959Epoch 12/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9286 - custom_f1: 0.4917 - weighted_custom_f1: 0.4978 - val_loss: 0.9359 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5197\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.9084 - custom_f1: 0.5023 - weighted_custom_f1: 0.5051Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9510 - custom_f1: 0.4985 - weighted_custom_f1: 0.5029 - val_loss: 0.9566 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9142 - custom_f1: 0.4951 - weighted_custom_f1: 0.4990 - val_loss: 0.9737 - val_custom_f1: 0.4589 - val_weighted_custom_f1: 0.4696\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9090 - custom_f1: 0.5047 - weighted_custom_f1: 0.5068 - val_loss: 0.9585 - val_custom_f1: 0.4454 - val_weighted_custom_f1: 0.4564\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.9341 - custom_f1: 0.4943 - weighted_custom_f1: 0.4989Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9240 - custom_f1: 0.4957 - weighted_custom_f1: 0.4992 - val_loss: 0.9458 - val_custom_f1: 0.4572 - val_weighted_custom_f1: 0.4692\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9172 - custom_f1: 0.4878 - weighted_custom_f1: 0.4923 - val_loss: 0.9760 - val_custom_f1: 0.4773 - val_weighted_custom_f1: 0.4881\n",
            "Epoch 12/100\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.9686 - custom_f1: 0.4844 - weighted_custom_f1: 0.4873Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9076 - custom_f1: 0.4954 - weighted_custom_f1: 0.5017 - val_loss: 0.9401 - val_custom_f1: 0.4626 - val_weighted_custom_f1: 0.4729\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.9313 - custom_f1: 0.5013 - weighted_custom_f1: 0.5049Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8924 - custom_f1: 0.5043 - weighted_custom_f1: 0.5104 - val_loss: 0.9734 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4871\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.8773 - custom_f1: 0.4964 - weighted_custom_f1: 0.5000Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2628 - custom_f1: 0.2838 - weighted_custom_f1: 0.2886 - val_loss: 1.4224 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.8946 - custom_f1: 0.5019 - weighted_custom_f1: 0.5087Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8754 - custom_f1: 0.5118 - weighted_custom_f1: 0.5175 - val_loss: 0.9658 - val_custom_f1: 0.4955 - val_weighted_custom_f1: 0.4967\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.9208 - custom_f1: 0.5004 - weighted_custom_f1: 0.5037Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9338 - custom_f1: 0.4948 - weighted_custom_f1: 0.4996 - val_loss: 1.0504 - val_custom_f1: 0.4708 - val_weighted_custom_f1: 0.4817\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.8907 - custom_f1: 0.5054 - weighted_custom_f1: 0.5080Epoch 13/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9039 - custom_f1: 0.5114 - weighted_custom_f1: 0.5168 - val_loss: 0.9720 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5387\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.9053 - custom_f1: 0.4982 - weighted_custom_f1: 0.5044Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9578 - custom_f1: 0.4829 - weighted_custom_f1: 0.4860 - val_loss: 0.9867 - val_custom_f1: 0.4658 - val_weighted_custom_f1: 0.4771\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8897 - custom_f1: 0.5089 - weighted_custom_f1: 0.5130 - val_loss: 0.9465 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5280\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.9299 - custom_f1: 0.4821 - weighted_custom_f1: 0.4863Epoch 11/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0065 - custom_f1: 0.4751 - weighted_custom_f1: 0.4814 - val_loss: 1.0707 - val_custom_f1: 0.4606 - val_weighted_custom_f1: 0.4689\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.9792 - custom_f1: 0.4642 - weighted_custom_f1: 0.4685Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9217 - custom_f1: 0.5010 - weighted_custom_f1: 0.5082 - val_loss: 0.9538 - val_custom_f1: 0.4849 - val_weighted_custom_f1: 0.4960\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9167 - custom_f1: 0.5009 - weighted_custom_f1: 0.5043 - val_loss: 0.9174 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5045\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.8483 - custom_f1: 0.5247 - weighted_custom_f1: 0.5278Epoch 13/100\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.9108 - custom_f1: 0.4955 - weighted_custom_f1: 0.4990Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9399 - custom_f1: 0.4977 - weighted_custom_f1: 0.5023 - val_loss: 1.0162 - val_custom_f1: 0.4623 - val_weighted_custom_f1: 0.4650\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.8782 - custom_f1: 0.5050 - weighted_custom_f1: 0.5102Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9076 - custom_f1: 0.4964 - weighted_custom_f1: 0.5018 - val_loss: 0.9414 - val_custom_f1: 0.4788 - val_weighted_custom_f1: 0.4898\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8941 - custom_f1: 0.5018 - weighted_custom_f1: 0.5069 - val_loss: 0.9542 - val_custom_f1: 0.4937 - val_weighted_custom_f1: 0.5037\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9288 - custom_f1: 0.4910 - weighted_custom_f1: 0.4955 - val_loss: 0.9638 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5137\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9018 - custom_f1: 0.5060 - weighted_custom_f1: 0.5110 - val_loss: 0.9659 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5068\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9003 - custom_f1: 0.4994 - weighted_custom_f1: 0.5026 - val_loss: 0.9362 - val_custom_f1: 0.4695 - val_weighted_custom_f1: 0.4812\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8823 - custom_f1: 0.5052 - weighted_custom_f1: 0.5108 - val_loss: 1.0207 - val_custom_f1: 0.4215 - val_weighted_custom_f1: 0.4209\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8848 - custom_f1: 0.5147 - weighted_custom_f1: 0.5188 - val_loss: 0.9125 - val_custom_f1: 0.5044 - val_weighted_custom_f1: 0.5032\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2629 - custom_f1: 0.2849 - weighted_custom_f1: 0.2878 - val_loss: 1.4254 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 39/105 [==========>...................] - ETA: 0s - loss: 0.9134 - custom_f1: 0.5037 - weighted_custom_f1: 0.5064Epoch 14/100\n",
            "Epoch 12/100\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9311 - custom_f1: 0.4948 - weighted_custom_f1: 0.4982 - val_loss: 1.0950 - val_custom_f1: 0.4805 - val_weighted_custom_f1: 0.4861\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.9462 - custom_f1: 0.4768 - weighted_custom_f1: 0.4833Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8555 - custom_f1: 0.5253 - weighted_custom_f1: 0.5288 - val_loss: 0.9476 - val_custom_f1: 0.4500 - val_weighted_custom_f1: 0.4610\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9551 - custom_f1: 0.4855 - weighted_custom_f1: 0.4899 - val_loss: 0.9962 - val_custom_f1: 0.4926 - val_weighted_custom_f1: 0.5029\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8068 - custom_f1: 0.5122 - weighted_custom_f1: 0.5122Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8626 - custom_f1: 0.5268 - weighted_custom_f1: 0.5305 - val_loss: 1.0255 - val_custom_f1: 0.4171 - val_weighted_custom_f1: 0.4274\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.9090 - custom_f1: 0.4852 - weighted_custom_f1: 0.4883Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0289 - custom_f1: 0.4725 - weighted_custom_f1: 0.4754 - val_loss: 1.0802 - val_custom_f1: 0.4700 - val_weighted_custom_f1: 0.4746\n",
            " 55/105 [==============>...............] - ETA: 0s - loss: 0.8871 - custom_f1: 0.5016 - weighted_custom_f1: 0.5071Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9140 - custom_f1: 0.5064 - weighted_custom_f1: 0.5102 - val_loss: 0.9622 - val_custom_f1: 0.4695 - val_weighted_custom_f1: 0.4812\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.9181 - custom_f1: 0.4845 - weighted_custom_f1: 0.4883Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9061 - custom_f1: 0.5033 - weighted_custom_f1: 0.5083 - val_loss: 0.9116 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5087\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 1.2580 - custom_f1: 0.2819 - weighted_custom_f1: 0.2864Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9385 - custom_f1: 0.5002 - weighted_custom_f1: 0.5049 - val_loss: 0.9574 - val_custom_f1: 0.5135 - val_weighted_custom_f1: 0.5152\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.8971 - custom_f1: 0.5028 - weighted_custom_f1: 0.5089Epoch 14/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8849 - custom_f1: 0.5100 - weighted_custom_f1: 0.5135 - val_loss: 0.9371 - val_custom_f1: 0.4871 - val_weighted_custom_f1: 0.4973\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 1.0207 - custom_f1: 0.4624 - weighted_custom_f1: 0.4680Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8993 - custom_f1: 0.5024 - weighted_custom_f1: 0.5088 - val_loss: 0.9437 - val_custom_f1: 0.4905 - val_weighted_custom_f1: 0.5026\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8932 - custom_f1: 0.5004 - weighted_custom_f1: 0.5036 - val_loss: 0.9285 - val_custom_f1: 0.4703 - val_weighted_custom_f1: 0.4828\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.8760 - custom_f1: 0.5092 - weighted_custom_f1: 0.5137Epoch 14/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8651 - custom_f1: 0.5219 - weighted_custom_f1: 0.5257 - val_loss: 0.9222 - val_custom_f1: 0.5323 - val_weighted_custom_f1: 0.5285\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8583 - custom_f1: 0.5154 - weighted_custom_f1: 0.5205 - val_loss: 0.9652 - val_custom_f1: 0.4744 - val_weighted_custom_f1: 0.4737\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0066 - custom_f1: 0.6866 - weighted_custom_f1: 0.6866Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8971 - custom_f1: 0.5028 - weighted_custom_f1: 0.5089 - val_loss: 0.9774 - val_custom_f1: 0.4822 - val_weighted_custom_f1: 0.4914\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2630 - custom_f1: 0.2845 - weighted_custom_f1: 0.2889 - val_loss: 1.4225 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 13/100\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9057 - custom_f1: 0.4962 - weighted_custom_f1: 0.5009 - val_loss: 0.9634 - val_custom_f1: 0.4968 - val_weighted_custom_f1: 0.5036\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.8482 - custom_f1: 0.4957 - weighted_custom_f1: 0.5049Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9229 - custom_f1: 0.4944 - weighted_custom_f1: 0.4991 - val_loss: 1.1088 - val_custom_f1: 0.5081 - val_weighted_custom_f1: 0.5151\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.8684 - custom_f1: 0.5117 - weighted_custom_f1: 0.5180Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8427 - custom_f1: 0.5274 - weighted_custom_f1: 0.5330 - val_loss: 0.9284 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.5033\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9419 - custom_f1: 0.4882 - weighted_custom_f1: 0.4928 - val_loss: 1.0230 - val_custom_f1: 0.5091 - val_weighted_custom_f1: 0.5178\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.8886 - custom_f1: 0.5110 - weighted_custom_f1: 0.5147Epoch 13/100\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8533 - custom_f1: 0.5188 - weighted_custom_f1: 0.5246 - val_loss: 0.9843 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5210\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0104 - custom_f1: 0.4735 - weighted_custom_f1: 0.4776 - val_loss: 1.0303 - val_custom_f1: 0.4659 - val_weighted_custom_f1: 0.4745\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9381 - custom_f1: 0.4891 - weighted_custom_f1: 0.4939 - val_loss: 1.0003 - val_custom_f1: 0.4490 - val_weighted_custom_f1: 0.4599\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9389 - custom_f1: 0.4918 - weighted_custom_f1: 0.4918Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8960 - custom_f1: 0.5100 - weighted_custom_f1: 0.5139 - val_loss: 0.9220 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5325\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.8734 - custom_f1: 0.5360 - weighted_custom_f1: 0.5381Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9319 - custom_f1: 0.4954 - weighted_custom_f1: 0.5004 - val_loss: 0.9610 - val_custom_f1: 0.5098 - val_weighted_custom_f1: 0.5074\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.9288 - custom_f1: 0.5061 - weighted_custom_f1: 0.5123Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8774 - custom_f1: 0.5095 - weighted_custom_f1: 0.5145 - val_loss: 1.0221 - val_custom_f1: 0.5114 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8759 - custom_f1: 0.5142 - weighted_custom_f1: 0.5178 - val_loss: 0.9456 - val_custom_f1: 0.4686 - val_weighted_custom_f1: 0.4806\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.9551 - custom_f1: 0.5138 - weighted_custom_f1: 0.5175Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8921 - custom_f1: 0.5036 - weighted_custom_f1: 0.5076 - val_loss: 0.9892 - val_custom_f1: 0.5014 - val_weighted_custom_f1: 0.5081\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.8459 - custom_f1: 0.5229 - weighted_custom_f1: 0.5267Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8615 - custom_f1: 0.5179 - weighted_custom_f1: 0.5238 - val_loss: 0.9714 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.4952\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8542 - custom_f1: 0.5250 - weighted_custom_f1: 0.5302 - val_loss: 1.0043 - val_custom_f1: 0.4702 - val_weighted_custom_f1: 0.4667\n",
            "Epoch 14/100\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8701 - custom_f1: 0.5148 - weighted_custom_f1: 0.5188 - val_loss: 0.9525 - val_custom_f1: 0.4510 - val_weighted_custom_f1: 0.4631\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9006 - custom_f1: 0.5003 - weighted_custom_f1: 0.5057 - val_loss: 0.9894 - val_custom_f1: 0.5223 - val_weighted_custom_f1: 0.5303\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.9430 - custom_f1: 0.5058 - weighted_custom_f1: 0.5112Epoch 16/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.2618 - custom_f1: 0.2842 - weighted_custom_f1: 0.2884 - val_loss: 1.4226 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9120 - custom_f1: 0.5065 - weighted_custom_f1: 0.5114Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9307 - custom_f1: 0.4910 - weighted_custom_f1: 0.4958 - val_loss: 1.0645 - val_custom_f1: 0.4961 - val_weighted_custom_f1: 0.5075\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.9343 - custom_f1: 0.5019 - weighted_custom_f1: 0.5071Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9649 - custom_f1: 0.4877 - weighted_custom_f1: 0.4929 - val_loss: 0.9957 - val_custom_f1: 0.5062 - val_weighted_custom_f1: 0.5166\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8494 - custom_f1: 0.5265 - weighted_custom_f1: 0.5302 - val_loss: 0.9915 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5158\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.8505 - custom_f1: 0.5177 - weighted_custom_f1: 0.5217Epoch 17/100\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8401 - custom_f1: 0.5321 - weighted_custom_f1: 0.5352 - val_loss: 0.9237 - val_custom_f1: 0.4883 - val_weighted_custom_f1: 0.5014\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0141 - custom_f1: 0.4728 - weighted_custom_f1: 0.4767 - val_loss: 1.0311 - val_custom_f1: 0.4470 - val_weighted_custom_f1: 0.4568\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.8238 - custom_f1: 0.5245 - weighted_custom_f1: 0.5298Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9126 - custom_f1: 0.4996 - weighted_custom_f1: 0.5051 - val_loss: 0.9574 - val_custom_f1: 0.5164 - val_weighted_custom_f1: 0.5281\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0165 - custom_f1: 0.4615 - weighted_custom_f1: 0.4615Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9113 - custom_f1: 0.5069 - weighted_custom_f1: 0.5116 - val_loss: 0.9181 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5148\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.8462 - custom_f1: 0.5125 - weighted_custom_f1: 0.5192Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9347 - custom_f1: 0.5002 - weighted_custom_f1: 0.5053 - val_loss: 0.9496 - val_custom_f1: 0.4867 - val_weighted_custom_f1: 0.4875\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8812 - custom_f1: 0.5111 - weighted_custom_f1: 0.5154 - val_loss: 0.9247 - val_custom_f1: 0.4690 - val_weighted_custom_f1: 0.4809\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.8223 - custom_f1: 0.5317 - weighted_custom_f1: 0.5363Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8674 - custom_f1: 0.5167 - weighted_custom_f1: 0.5214 - val_loss: 0.9573 - val_custom_f1: 0.5031 - val_weighted_custom_f1: 0.5141\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8656 - custom_f1: 0.5152 - weighted_custom_f1: 0.5198 - val_loss: 0.9340 - val_custom_f1: 0.4838 - val_weighted_custom_f1: 0.4951\n",
            "Epoch 15/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9571 - custom_f1: 0.4348 - weighted_custom_f1: 0.4348Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8399 - custom_f1: 0.5275 - weighted_custom_f1: 0.5326 - val_loss: 1.0266 - val_custom_f1: 0.5290 - val_weighted_custom_f1: 0.5243\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 1.0071 - custom_f1: 0.4736 - weighted_custom_f1: 0.4789Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8629 - custom_f1: 0.5103 - weighted_custom_f1: 0.5161 - val_loss: 0.9350 - val_custom_f1: 0.5004 - val_weighted_custom_f1: 0.5114\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9113 - custom_f1: 0.4995 - weighted_custom_f1: 0.5032 - val_loss: 0.9669 - val_custom_f1: 0.5057 - val_weighted_custom_f1: 0.5153\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8654 - custom_f1: 0.5200 - weighted_custom_f1: 0.5236 - val_loss: 0.9394 - val_custom_f1: 0.4722 - val_weighted_custom_f1: 0.4731\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 1.0200 - custom_f1: 0.4713 - weighted_custom_f1: 0.4759Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2629 - custom_f1: 0.2838 - weighted_custom_f1: 0.2885 - val_loss: 1.4224 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9400 - custom_f1: 0.4944 - weighted_custom_f1: 0.4981 - val_loss: 1.1348 - val_custom_f1: 0.4501 - val_weighted_custom_f1: 0.4618\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9448 - custom_f1: 0.4930 - weighted_custom_f1: 0.4964 - val_loss: 0.9829 - val_custom_f1: 0.4892 - val_weighted_custom_f1: 0.4969\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8983 - custom_f1: 0.4304 - weighted_custom_f1: 0.4304Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8294 - custom_f1: 0.5320 - weighted_custom_f1: 0.5368 - val_loss: 1.1849 - val_custom_f1: 0.5071 - val_weighted_custom_f1: 0.5151\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0733 - custom_f1: 0.4516 - weighted_custom_f1: 0.4516Epoch 15/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8277 - custom_f1: 0.5325 - weighted_custom_f1: 0.5363 - val_loss: 0.8981 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5214\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.8585 - custom_f1: 0.5207 - weighted_custom_f1: 0.5263Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9330 - custom_f1: 0.4994 - weighted_custom_f1: 0.5030 - val_loss: 1.0999 - val_custom_f1: 0.4280 - val_weighted_custom_f1: 0.4330\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.8722 - custom_f1: 0.5202 - weighted_custom_f1: 0.5249Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0161 - custom_f1: 0.4728 - weighted_custom_f1: 0.4774 - val_loss: 1.0712 - val_custom_f1: 0.4554 - val_weighted_custom_f1: 0.4651\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8977 - custom_f1: 0.5155 - weighted_custom_f1: 0.5201 - val_loss: 0.9017 - val_custom_f1: 0.4795 - val_weighted_custom_f1: 0.4905\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9305 - custom_f1: 0.4983 - weighted_custom_f1: 0.5017 - val_loss: 0.9875 - val_custom_f1: 0.4780 - val_weighted_custom_f1: 0.4825\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.9910 - custom_f1: 0.4722 - weighted_custom_f1: 0.4785Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8698 - custom_f1: 0.5194 - weighted_custom_f1: 0.5239 - val_loss: 0.9395 - val_custom_f1: 0.4750 - val_weighted_custom_f1: 0.4863\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 1.0049 - custom_f1: 0.4768 - weighted_custom_f1: 0.4837Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8717 - custom_f1: 0.5158 - weighted_custom_f1: 0.5203 - val_loss: 0.9278 - val_custom_f1: 0.4651 - val_weighted_custom_f1: 0.4777\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8848 - custom_f1: 0.5075 - weighted_custom_f1: 0.5127 - val_loss: 0.9250 - val_custom_f1: 0.4762 - val_weighted_custom_f1: 0.4875\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8547 - custom_f1: 0.5179 - weighted_custom_f1: 0.5235 - val_loss: 0.9547 - val_custom_f1: 0.5307 - val_weighted_custom_f1: 0.5298\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.8619 - custom_f1: 0.5254 - weighted_custom_f1: 0.5288Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8443 - custom_f1: 0.5227 - weighted_custom_f1: 0.5280 - val_loss: 0.9767 - val_custom_f1: 0.5201 - val_weighted_custom_f1: 0.5182\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9267 - custom_f1: 0.4973 - weighted_custom_f1: 0.5014 - val_loss: 0.9428 - val_custom_f1: 0.5051 - val_weighted_custom_f1: 0.5139\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.2620 - custom_f1: 0.2847 - weighted_custom_f1: 0.2882 - val_loss: 1.4226 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.8339 - custom_f1: 0.5414 - weighted_custom_f1: 0.5452Epoch 18/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8571 - custom_f1: 0.5149 - weighted_custom_f1: 0.5210 - val_loss: 0.9439 - val_custom_f1: 0.4550 - val_weighted_custom_f1: 0.4668\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9500 - custom_f1: 0.4918 - weighted_custom_f1: 0.4946 - val_loss: 1.1620 - val_custom_f1: 0.5038 - val_weighted_custom_f1: 0.5114\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.8427 - custom_f1: 0.5261 - weighted_custom_f1: 0.5306Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8013 - custom_f1: 0.5445 - weighted_custom_f1: 0.5486 - val_loss: 0.9716 - val_custom_f1: 0.5429 - val_weighted_custom_f1: 0.5469\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9399 - custom_f1: 0.4939 - weighted_custom_f1: 0.4988 - val_loss: 0.9994 - val_custom_f1: 0.5051 - val_weighted_custom_f1: 0.5148\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.8865 - custom_f1: 0.5071 - weighted_custom_f1: 0.5130Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7141 - custom_f1: 0.5731 - weighted_custom_f1: 0.5799 - val_loss: 0.9460 - val_custom_f1: 0.5094 - val_weighted_custom_f1: 0.5216\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6605 - custom_f1: 0.6035 - weighted_custom_f1: 0.6084Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6769 - custom_f1: 0.5982 - weighted_custom_f1: 0.6028 - val_loss: 0.9881 - val_custom_f1: 0.5267 - val_weighted_custom_f1: 0.5355\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7380 - custom_f1: 0.5794 - weighted_custom_f1: 0.5863 - val_loss: 0.9601 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5177\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6636 - custom_f1: 0.6086 - weighted_custom_f1: 0.6137 - val_loss: 1.0235 - val_custom_f1: 0.5099 - val_weighted_custom_f1: 0.5201\n",
            "Epoch 41/100\n",
            "Epoch 34/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6243 - custom_f1: 0.7458 - weighted_custom_f1: 0.7458Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6248 - custom_f1: 0.6224 - weighted_custom_f1: 0.6277 - val_loss: 1.1696 - val_custom_f1: 0.5237 - val_weighted_custom_f1: 0.5240\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5685 - custom_f1: 0.5714 - weighted_custom_f1: 0.5714Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6482 - custom_f1: 0.6164 - weighted_custom_f1: 0.6197 - val_loss: 1.0155 - val_custom_f1: 0.4975 - val_weighted_custom_f1: 0.5053\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5960 - custom_f1: 0.6316 - weighted_custom_f1: 0.6316Epoch 40/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6397 - custom_f1: 0.6082 - weighted_custom_f1: 0.6135 - val_loss: 1.1153 - val_custom_f1: 0.5140 - val_weighted_custom_f1: 0.5357\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6588 - custom_f1: 0.6051 - weighted_custom_f1: 0.6084 - val_loss: 0.9574 - val_custom_f1: 0.4872 - val_weighted_custom_f1: 0.5098\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7371 - custom_f1: 0.5733 - weighted_custom_f1: 0.5780 - val_loss: 0.9965 - val_custom_f1: 0.4998 - val_weighted_custom_f1: 0.5095\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0629 - custom_f1: 0.4392 - weighted_custom_f1: 0.4438 - val_loss: 1.0312 - val_custom_f1: 0.4183 - val_weighted_custom_f1: 0.4283\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6852 - custom_f1: 0.5997 - weighted_custom_f1: 0.6032 - val_loss: 0.9835 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5197\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6926 - custom_f1: 0.5944 - weighted_custom_f1: 0.5978 - val_loss: 0.9925 - val_custom_f1: 0.5510 - val_weighted_custom_f1: 0.5587\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.7021 - custom_f1: 0.5797 - weighted_custom_f1: 0.5833Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6684 - custom_f1: 0.6052 - weighted_custom_f1: 0.6101 - val_loss: 0.9209 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5142\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.6427 - custom_f1: 0.6081 - weighted_custom_f1: 0.6123Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9445 - custom_f1: 0.5008 - weighted_custom_f1: 0.5050 - val_loss: 0.9856 - val_custom_f1: 0.4967 - val_weighted_custom_f1: 0.4973\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9898 - custom_f1: 0.4805 - weighted_custom_f1: 0.4863 - val_loss: 1.4979 - val_custom_f1: 0.3794 - val_weighted_custom_f1: 0.3574\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6489 - custom_f1: 0.6124 - weighted_custom_f1: 0.6180 - val_loss: 1.0190 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5143\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7197 - custom_f1: 0.5795 - weighted_custom_f1: 0.5828 - val_loss: 0.9192 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5272\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 1.0762 - custom_f1: 0.4865 - weighted_custom_f1: 0.4887Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7113 - custom_f1: 0.5805 - weighted_custom_f1: 0.5852 - val_loss: 1.0960 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4953\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6378 - custom_f1: 0.6120 - weighted_custom_f1: 0.6150 - val_loss: 1.0417 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5409\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6503 - custom_f1: 0.6070 - weighted_custom_f1: 0.6109 - val_loss: 1.1199 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5313\n",
            "Epoch 42/100\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6562 - custom_f1: 0.5961 - weighted_custom_f1: 0.6004 - val_loss: 0.9930 - val_custom_f1: 0.4880 - val_weighted_custom_f1: 0.4975\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6296 - custom_f1: 0.6198 - weighted_custom_f1: 0.6258 - val_loss: 1.0868 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5356\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.7671 - custom_f1: 0.5834 - weighted_custom_f1: 0.5863Epoch 39/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6322 - custom_f1: 0.6240 - weighted_custom_f1: 0.6285 - val_loss: 1.2672 - val_custom_f1: 0.5071 - val_weighted_custom_f1: 0.5079\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6563 - custom_f1: 0.6128 - weighted_custom_f1: 0.6168 - val_loss: 1.0211 - val_custom_f1: 0.5233 - val_weighted_custom_f1: 0.5456\n",
            " 55/105 [==============>...............] - ETA: 0s - loss: 0.6427 - custom_f1: 0.6255 - weighted_custom_f1: 0.6292Epoch 42/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7335 - custom_f1: 0.5766 - weighted_custom_f1: 0.5817 - val_loss: 0.9226 - val_custom_f1: 0.4916 - val_weighted_custom_f1: 0.5022\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0197 - custom_f1: 0.4457 - weighted_custom_f1: 0.4504 - val_loss: 0.9923 - val_custom_f1: 0.4682 - val_weighted_custom_f1: 0.4764\n",
            "Epoch 36/100\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6736 - custom_f1: 0.6063 - weighted_custom_f1: 0.6102 - val_loss: 0.9596 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5117\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6797 - custom_f1: 0.5977 - weighted_custom_f1: 0.6028 - val_loss: 0.9413 - val_custom_f1: 0.4816 - val_weighted_custom_f1: 0.4939\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6668 - custom_f1: 0.6091 - weighted_custom_f1: 0.6121 - val_loss: 0.9406 - val_custom_f1: 0.5285 - val_weighted_custom_f1: 0.5376\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.6448 - custom_f1: 0.6120 - weighted_custom_f1: 0.6166Epoch 42/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9530 - custom_f1: 0.4989 - weighted_custom_f1: 0.5029 - val_loss: 0.9578 - val_custom_f1: 0.4725 - val_weighted_custom_f1: 0.4721\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.6359 - custom_f1: 0.6153 - weighted_custom_f1: 0.6198Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0110 - custom_f1: 0.4817 - weighted_custom_f1: 0.4838 - val_loss: 1.2382 - val_custom_f1: 0.4927 - val_weighted_custom_f1: 0.4984\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.6251 - custom_f1: 0.6154 - weighted_custom_f1: 0.6198Epoch 45/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6409 - custom_f1: 0.6181 - weighted_custom_f1: 0.6220 - val_loss: 1.0458 - val_custom_f1: 0.4952 - val_weighted_custom_f1: 0.4960\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6356 - custom_f1: 0.6189 - weighted_custom_f1: 0.6216 - val_loss: 1.1506 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5297\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7327 - custom_f1: 0.5782 - weighted_custom_f1: 0.5841 - val_loss: 0.9536 - val_custom_f1: 0.4891 - val_weighted_custom_f1: 0.4999\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7565 - custom_f1: 0.6575 - weighted_custom_f1: 0.6575Epoch 36/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7339 - custom_f1: 0.5751 - weighted_custom_f1: 0.5814 - val_loss: 0.9386 - val_custom_f1: 0.4900 - val_weighted_custom_f1: 0.5022\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.6465 - custom_f1: 0.6115 - weighted_custom_f1: 0.6156Epoch 36/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6280 - custom_f1: 0.6193 - weighted_custom_f1: 0.6235 - val_loss: 0.9970 - val_custom_f1: 0.5143 - val_weighted_custom_f1: 0.5263\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.6838 - custom_f1: 0.5988 - weighted_custom_f1: 0.6021Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6380 - custom_f1: 0.6078 - weighted_custom_f1: 0.6110 - val_loss: 1.0565 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5248\n",
            " 69/105 [==================>...........] - ETA: 0s - loss: 0.9527 - custom_f1: 0.4966 - weighted_custom_f1: 0.4989Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6351 - custom_f1: 0.6193 - weighted_custom_f1: 0.6229 - val_loss: 1.1742 - val_custom_f1: 0.5318 - val_weighted_custom_f1: 0.5321\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6316 - custom_f1: 0.6199 - weighted_custom_f1: 0.6245 - val_loss: 1.1203 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5338\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.6460 - custom_f1: 0.6134 - weighted_custom_f1: 0.6175Epoch 40/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6438 - custom_f1: 0.6093 - weighted_custom_f1: 0.6135 - val_loss: 0.9696 - val_custom_f1: 0.4902 - val_weighted_custom_f1: 0.5119\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.5679 - custom_f1: 0.6587 - weighted_custom_f1: 0.6612Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9678 - custom_f1: 0.4709 - weighted_custom_f1: 0.4748 - val_loss: 0.9837 - val_custom_f1: 0.4783 - val_weighted_custom_f1: 0.4858\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7094 - custom_f1: 0.5888 - weighted_custom_f1: 0.5938 - val_loss: 0.9473 - val_custom_f1: 0.4903 - val_weighted_custom_f1: 0.5022\n",
            "Epoch 5/100\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6796 - custom_f1: 0.5984 - weighted_custom_f1: 0.6054 - val_loss: 0.9903 - val_custom_f1: 0.5165 - val_weighted_custom_f1: 0.5258\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.6236 - custom_f1: 0.6194 - weighted_custom_f1: 0.6212Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6468 - custom_f1: 0.6116 - weighted_custom_f1: 0.6163 - val_loss: 0.9412 - val_custom_f1: 0.5197 - val_weighted_custom_f1: 0.5290\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.6217 - custom_f1: 0.6264 - weighted_custom_f1: 0.6300Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6818 - custom_f1: 0.5960 - weighted_custom_f1: 0.6027 - val_loss: 0.9165 - val_custom_f1: 0.5102 - val_weighted_custom_f1: 0.5209\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.6647 - custom_f1: 0.6113 - weighted_custom_f1: 0.6136Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9602 - custom_f1: 0.5017 - weighted_custom_f1: 0.5030 - val_loss: 0.9838 - val_custom_f1: 0.4565 - val_weighted_custom_f1: 0.4576\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9858 - custom_f1: 0.4845 - weighted_custom_f1: 0.4906 - val_loss: 1.2289 - val_custom_f1: 0.4613 - val_weighted_custom_f1: 0.4691\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6317 - custom_f1: 0.6198 - weighted_custom_f1: 0.6231 - val_loss: 1.0239 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7009 - custom_f1: 0.5888 - weighted_custom_f1: 0.5921 - val_loss: 0.9352 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.5010\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.5793 - custom_f1: 0.6412 - weighted_custom_f1: 0.6436Epoch 37/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6346 - custom_f1: 0.6203 - weighted_custom_f1: 0.6239 - val_loss: 1.0680 - val_custom_f1: 0.4793 - val_weighted_custom_f1: 0.4917\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6187 - custom_f1: 0.6235 - weighted_custom_f1: 0.6306 - val_loss: 1.0130 - val_custom_f1: 0.5167 - val_weighted_custom_f1: 0.5254\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6996 - custom_f1: 0.5926 - weighted_custom_f1: 0.5973 - val_loss: 0.9637 - val_custom_f1: 0.4543 - val_weighted_custom_f1: 0.4662\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6227 - custom_f1: 0.6197 - weighted_custom_f1: 0.6239 - val_loss: 1.0890 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5250\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8377 - custom_f1: 0.5060 - weighted_custom_f1: 0.5060Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6205 - custom_f1: 0.6272 - weighted_custom_f1: 0.6328 - val_loss: 1.2997 - val_custom_f1: 0.5428 - val_weighted_custom_f1: 0.5441\n",
            " 12/105 [==>...........................] - ETA: 0s - loss: 0.6527 - custom_f1: 0.6086 - weighted_custom_f1: 0.6122Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6182 - custom_f1: 0.6188 - weighted_custom_f1: 0.6227 - val_loss: 1.0178 - val_custom_f1: 0.4803 - val_weighted_custom_f1: 0.4917\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6890 - custom_f1: 0.6043 - weighted_custom_f1: 0.6089 - val_loss: 0.9745 - val_custom_f1: 0.4979 - val_weighted_custom_f1: 0.5106\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6562 - custom_f1: 0.6090 - weighted_custom_f1: 0.6154 - val_loss: 1.0087 - val_custom_f1: 0.4555 - val_weighted_custom_f1: 0.4674\n",
            "Epoch 45/100\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9621 - custom_f1: 0.4726 - weighted_custom_f1: 0.4795 - val_loss: 1.0227 - val_custom_f1: 0.4078 - val_weighted_custom_f1: 0.4203\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7225 - custom_f1: 0.5806 - weighted_custom_f1: 0.5844 - val_loss: 0.9591 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5409\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6498 - custom_f1: 0.6101 - weighted_custom_f1: 0.6161 - val_loss: 0.9186 - val_custom_f1: 0.4854 - val_weighted_custom_f1: 0.4976\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6876 - custom_f1: 0.6042 - weighted_custom_f1: 0.6082 - val_loss: 0.9228 - val_custom_f1: 0.5248 - val_weighted_custom_f1: 0.5333\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.6335 - custom_f1: 0.6175 - weighted_custom_f1: 0.6215Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9725 - custom_f1: 0.5009 - weighted_custom_f1: 0.5058 - val_loss: 1.0288 - val_custom_f1: 0.4528 - val_weighted_custom_f1: 0.4528\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9648 - custom_f1: 0.4872 - weighted_custom_f1: 0.4915 - val_loss: 1.2380 - val_custom_f1: 0.4737 - val_weighted_custom_f1: 0.4784\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6281 - custom_f1: 0.6246 - weighted_custom_f1: 0.6275 - val_loss: 1.0933 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5268\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.6389 - custom_f1: 0.6197 - weighted_custom_f1: 0.6239Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6300 - custom_f1: 0.6107 - weighted_custom_f1: 0.6178 - val_loss: 1.0922 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5090\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6141 - custom_f1: 0.6290 - weighted_custom_f1: 0.6324 - val_loss: 1.0310 - val_custom_f1: 0.5025 - val_weighted_custom_f1: 0.5134\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7153 - custom_f1: 0.5958 - weighted_custom_f1: 0.6004 - val_loss: 0.9486 - val_custom_f1: 0.4876 - val_weighted_custom_f1: 0.4997\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6269 - custom_f1: 0.6302 - weighted_custom_f1: 0.6340 - val_loss: 1.0836 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5344\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.9882 - custom_f1: 0.5064 - weighted_custom_f1: 0.5106Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6200 - custom_f1: 0.6268 - weighted_custom_f1: 0.6306 - val_loss: 1.0810 - val_custom_f1: 0.4907 - val_weighted_custom_f1: 0.4875\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7292 - custom_f1: 0.5785 - weighted_custom_f1: 0.5823 - val_loss: 0.9698 - val_custom_f1: 0.4945 - val_weighted_custom_f1: 0.5026\n",
            "Epoch 38/100\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.6690 - custom_f1: 0.6037 - weighted_custom_f1: 0.6086Epoch 41/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6254 - custom_f1: 0.6212 - weighted_custom_f1: 0.6265 - val_loss: 1.0648 - val_custom_f1: 0.4782 - val_weighted_custom_f1: 0.4878\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6676 - custom_f1: 0.6012 - weighted_custom_f1: 0.6068 - val_loss: 0.9843 - val_custom_f1: 0.5117 - val_weighted_custom_f1: 0.5201\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6385 - custom_f1: 0.6197 - weighted_custom_f1: 0.6240 - val_loss: 0.9948 - val_custom_f1: 0.5035 - val_weighted_custom_f1: 0.5261\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9377 - custom_f1: 0.4904 - weighted_custom_f1: 0.4948 - val_loss: 0.9513 - val_custom_f1: 0.4839 - val_weighted_custom_f1: 0.4944\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.7127 - custom_f1: 0.6195 - weighted_custom_f1: 0.6246Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7349 - custom_f1: 0.5803 - weighted_custom_f1: 0.5850 - val_loss: 1.0125 - val_custom_f1: 0.4628 - val_weighted_custom_f1: 0.4726\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.8844 - custom_f1: 0.5133 - weighted_custom_f1: 0.5143Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6560 - custom_f1: 0.6127 - weighted_custom_f1: 0.6176 - val_loss: 0.9680 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5349\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.6857 - custom_f1: 0.5929 - weighted_custom_f1: 0.5972Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6766 - custom_f1: 0.5988 - weighted_custom_f1: 0.6040 - val_loss: 0.9195 - val_custom_f1: 0.5099 - val_weighted_custom_f1: 0.5202\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.6122 - custom_f1: 0.6011 - weighted_custom_f1: 0.6058Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9850 - custom_f1: 0.4968 - weighted_custom_f1: 0.5020 - val_loss: 1.0140 - val_custom_f1: 0.4784 - val_weighted_custom_f1: 0.4792\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.5933 - custom_f1: 0.6351 - weighted_custom_f1: 0.6385Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9701 - custom_f1: 0.4872 - weighted_custom_f1: 0.4906 - val_loss: 1.3147 - val_custom_f1: 0.4234 - val_weighted_custom_f1: 0.4330\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6281 - custom_f1: 0.6256 - weighted_custom_f1: 0.6308 - val_loss: 1.0223 - val_custom_f1: 0.4812 - val_weighted_custom_f1: 0.4818\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6409 - custom_f1: 0.6166 - weighted_custom_f1: 0.6220 - val_loss: 1.0057 - val_custom_f1: 0.5056 - val_weighted_custom_f1: 0.5140\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6970 - custom_f1: 0.5862 - weighted_custom_f1: 0.5931 - val_loss: 0.9832 - val_custom_f1: 0.5118 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 46/100\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.6642 - custom_f1: 0.6249 - weighted_custom_f1: 0.6312Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6795 - custom_f1: 0.6033 - weighted_custom_f1: 0.6087 - val_loss: 0.9921 - val_custom_f1: 0.5213 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6240 - custom_f1: 0.6201 - weighted_custom_f1: 0.6242 - val_loss: 1.0987 - val_custom_f1: 0.4958 - val_weighted_custom_f1: 0.5052\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6468 - custom_f1: 0.6151 - weighted_custom_f1: 0.6198 - val_loss: 1.1029 - val_custom_f1: 0.5193 - val_weighted_custom_f1: 0.5233\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.9465 - custom_f1: 0.5074 - weighted_custom_f1: 0.5108Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5941 - custom_f1: 0.6324 - weighted_custom_f1: 0.6367 - val_loss: 1.0569 - val_custom_f1: 0.5148 - val_weighted_custom_f1: 0.5255\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.6941 - custom_f1: 0.5839 - weighted_custom_f1: 0.5884Epoch 43/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6181 - custom_f1: 0.6289 - weighted_custom_f1: 0.6342 - val_loss: 1.1773 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5441\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4965 - custom_f1: 0.6786 - weighted_custom_f1: 0.6786Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6629 - custom_f1: 0.6110 - weighted_custom_f1: 0.6156 - val_loss: 1.1761 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5265\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6250 - custom_f1: 0.6260 - weighted_custom_f1: 0.6316 - val_loss: 1.0071 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5285\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.9658 - custom_f1: 0.4978 - weighted_custom_f1: 0.5014Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9210 - custom_f1: 0.5005 - weighted_custom_f1: 0.5041 - val_loss: 1.0270 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7061 - custom_f1: 0.5872 - weighted_custom_f1: 0.5923 - val_loss: 0.9511 - val_custom_f1: 0.5198 - val_weighted_custom_f1: 0.5310\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.6406 - custom_f1: 0.6163 - weighted_custom_f1: 0.6199Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6507 - custom_f1: 0.6122 - weighted_custom_f1: 0.6169 - val_loss: 0.9299 - val_custom_f1: 0.5047 - val_weighted_custom_f1: 0.5156\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.8937 - custom_f1: 0.5097 - weighted_custom_f1: 0.5123Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6667 - custom_f1: 0.6053 - weighted_custom_f1: 0.6088 - val_loss: 0.9478 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5359\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9719 - custom_f1: 0.4984 - weighted_custom_f1: 0.5026 - val_loss: 1.0541 - val_custom_f1: 0.4482 - val_weighted_custom_f1: 0.4487\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.6765 - custom_f1: 0.5984 - weighted_custom_f1: 0.6021Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9903 - custom_f1: 0.4852 - weighted_custom_f1: 0.4881 - val_loss: 1.2628 - val_custom_f1: 0.4370 - val_weighted_custom_f1: 0.4467\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6201 - custom_f1: 0.6272 - weighted_custom_f1: 0.6322 - val_loss: 1.0495 - val_custom_f1: 0.5053 - val_weighted_custom_f1: 0.5063\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.9848 - custom_f1: 0.5170 - weighted_custom_f1: 0.5201Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6156 - custom_f1: 0.6275 - weighted_custom_f1: 0.6317 - val_loss: 1.1178 - val_custom_f1: 0.5018 - val_weighted_custom_f1: 0.5097\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.9542 - custom_f1: 0.5078 - weighted_custom_f1: 0.5122Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6729 - custom_f1: 0.6080 - weighted_custom_f1: 0.6120 - val_loss: 0.9488 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.5131\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6947 - custom_f1: 0.5942 - weighted_custom_f1: 0.5976 - val_loss: 0.9549 - val_custom_f1: 0.4880 - val_weighted_custom_f1: 0.4980\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6183 - custom_f1: 0.6246 - weighted_custom_f1: 0.6303 - val_loss: 1.0828 - val_custom_f1: 0.4955 - val_weighted_custom_f1: 0.5071\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6080 - custom_f1: 0.6356 - weighted_custom_f1: 0.6407 - val_loss: 1.1303 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5211\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6069 - custom_f1: 0.6277 - weighted_custom_f1: 0.6336 - val_loss: 1.0671 - val_custom_f1: 0.4876 - val_weighted_custom_f1: 0.4978\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6183 - custom_f1: 0.6249 - weighted_custom_f1: 0.6306 - val_loss: 1.0593 - val_custom_f1: 0.4900 - val_weighted_custom_f1: 0.4939\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6735 - custom_f1: 0.6086 - weighted_custom_f1: 0.6129 - val_loss: 0.9956 - val_custom_f1: 0.5019 - val_weighted_custom_f1: 0.5087\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.6566 - custom_f1: 0.6096 - weighted_custom_f1: 0.6138Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8862 - custom_f1: 0.5020 - weighted_custom_f1: 0.5077 - val_loss: 1.0898 - val_custom_f1: 0.4889 - val_weighted_custom_f1: 0.4908\n",
            " 76/105 [====================>.........] - ETA: 0s - loss: 0.9744 - custom_f1: 0.4876 - weighted_custom_f1: 0.4908Epoch 9/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6233 - custom_f1: 0.6217 - weighted_custom_f1: 0.6261 - val_loss: 0.9880 - val_custom_f1: 0.5052 - val_weighted_custom_f1: 0.5277\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.5821 - custom_f1: 0.6534 - weighted_custom_f1: 0.6559Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6992 - custom_f1: 0.5925 - weighted_custom_f1: 0.5967 - val_loss: 0.9744 - val_custom_f1: 0.5141 - val_weighted_custom_f1: 0.5241\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.9760 - custom_f1: 0.5043 - weighted_custom_f1: 0.5085Epoch 41/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6297 - custom_f1: 0.6217 - weighted_custom_f1: 0.6251 - val_loss: 1.0120 - val_custom_f1: 0.5212 - val_weighted_custom_f1: 0.5443\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6581 - custom_f1: 0.6078 - weighted_custom_f1: 0.6123 - val_loss: 0.9598 - val_custom_f1: 0.5219 - val_weighted_custom_f1: 0.5434\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9694 - custom_f1: 0.5032 - weighted_custom_f1: 0.5074 - val_loss: 0.9759 - val_custom_f1: 0.4973 - val_weighted_custom_f1: 0.4976\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9677 - custom_f1: 0.4839 - weighted_custom_f1: 0.4875 - val_loss: 1.2389 - val_custom_f1: 0.4810 - val_weighted_custom_f1: 0.4859\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.8748 - custom_f1: 0.5185 - weighted_custom_f1: 0.5202Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6222 - custom_f1: 0.6266 - weighted_custom_f1: 0.6312 - val_loss: 1.0581 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5147\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.5765 - custom_f1: 0.6457 - weighted_custom_f1: 0.6494Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6157 - custom_f1: 0.6239 - weighted_custom_f1: 0.6286 - val_loss: 1.0414 - val_custom_f1: 0.5394 - val_weighted_custom_f1: 0.5482\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6851 - custom_f1: 0.5970 - weighted_custom_f1: 0.6017 - val_loss: 0.9966 - val_custom_f1: 0.5075 - val_weighted_custom_f1: 0.5152\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6936 - custom_f1: 0.5848 - weighted_custom_f1: 0.5896 - val_loss: 0.9622 - val_custom_f1: 0.4801 - val_weighted_custom_f1: 0.4928\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.6304 - custom_f1: 0.6164 - weighted_custom_f1: 0.6211Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6165 - custom_f1: 0.6307 - weighted_custom_f1: 0.6346 - val_loss: 1.4494 - val_custom_f1: 0.4901 - val_weighted_custom_f1: 0.5104\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5942 - custom_f1: 0.6366 - weighted_custom_f1: 0.6405 - val_loss: 1.1697 - val_custom_f1: 0.5248 - val_weighted_custom_f1: 0.5293\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6605 - custom_f1: 0.6079 - weighted_custom_f1: 0.6127 - val_loss: 1.0437 - val_custom_f1: 0.5116 - val_weighted_custom_f1: 0.5222\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.6358 - custom_f1: 0.6182 - weighted_custom_f1: 0.6227Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6063 - custom_f1: 0.6269 - weighted_custom_f1: 0.6308 - val_loss: 1.0776 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5138\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8834 - custom_f1: 0.6944 - weighted_custom_f1: 0.6944Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8676 - custom_f1: 0.5167 - weighted_custom_f1: 0.5195 - val_loss: 0.9376 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5225\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5822 - custom_f1: 0.6461 - weighted_custom_f1: 0.6490 - val_loss: 1.1758 - val_custom_f1: 0.5331 - val_weighted_custom_f1: 0.5322\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.6957 - custom_f1: 0.6014 - weighted_custom_f1: 0.6054Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6833 - custom_f1: 0.6000 - weighted_custom_f1: 0.6027 - val_loss: 0.9808 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5393\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.6827 - custom_f1: 0.6008 - weighted_custom_f1: 0.6051Epoch 42/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6352 - custom_f1: 0.6248 - weighted_custom_f1: 0.6274 - val_loss: 1.0072 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5291\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.8333 - custom_f1: 0.4861 - weighted_custom_f1: 0.4913Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6373 - custom_f1: 0.6173 - weighted_custom_f1: 0.6217 - val_loss: 0.9279 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6558 - custom_f1: 0.6114 - weighted_custom_f1: 0.6155 - val_loss: 0.9434 - val_custom_f1: 0.5331 - val_weighted_custom_f1: 0.5420\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.5997 - custom_f1: 0.6311 - weighted_custom_f1: 0.6352Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9600 - custom_f1: 0.5020 - weighted_custom_f1: 0.5028 - val_loss: 1.1309 - val_custom_f1: 0.4819 - val_weighted_custom_f1: 0.4760\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.6046 - custom_f1: 0.6377 - weighted_custom_f1: 0.6434Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9874 - custom_f1: 0.4807 - weighted_custom_f1: 0.4857 - val_loss: 1.2440 - val_custom_f1: 0.4870 - val_weighted_custom_f1: 0.4943\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6148 - custom_f1: 0.6231 - weighted_custom_f1: 0.6270 - val_loss: 1.1067 - val_custom_f1: 0.5368 - val_weighted_custom_f1: 0.5376\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6065 - custom_f1: 0.6279 - weighted_custom_f1: 0.6319 - val_loss: 1.0430 - val_custom_f1: 0.5384 - val_weighted_custom_f1: 0.5476\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6723 - custom_f1: 0.5993 - weighted_custom_f1: 0.6022 - val_loss: 0.9934 - val_custom_f1: 0.5359 - val_weighted_custom_f1: 0.5439\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6735 - custom_f1: 0.5977 - weighted_custom_f1: 0.6003 - val_loss: 0.9737 - val_custom_f1: 0.4869 - val_weighted_custom_f1: 0.4986\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.6341 - custom_f1: 0.6215 - weighted_custom_f1: 0.6256Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6614 - custom_f1: 0.6048 - weighted_custom_f1: 0.6110 - val_loss: 1.1626 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5226\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6450 - custom_f1: 0.6179 - weighted_custom_f1: 0.6222 - val_loss: 1.0937 - val_custom_f1: 0.4923 - val_weighted_custom_f1: 0.5043\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.6078 - custom_f1: 0.6369 - weighted_custom_f1: 0.6404Epoch 50/100\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6057 - custom_f1: 0.6295 - weighted_custom_f1: 0.6341 - val_loss: 1.1178 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5255\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6145 - custom_f1: 0.6301 - weighted_custom_f1: 0.6356 - val_loss: 1.0583 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5342\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8725 - custom_f1: 0.5117 - weighted_custom_f1: 0.5159 - val_loss: 0.9564 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5400\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.6077 - custom_f1: 0.6295 - weighted_custom_f1: 0.6332Epoch 11/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5832 - custom_f1: 0.6441 - weighted_custom_f1: 0.6468 - val_loss: 1.2625 - val_custom_f1: 0.5382 - val_weighted_custom_f1: 0.5368\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6775 - custom_f1: 0.5941 - weighted_custom_f1: 0.5981 - val_loss: 0.9901 - val_custom_f1: 0.4927 - val_weighted_custom_f1: 0.5031\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6232 - custom_f1: 0.6290 - weighted_custom_f1: 0.6327 - val_loss: 1.0088 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5435\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6432 - custom_f1: 0.6172 - weighted_custom_f1: 0.6216 - val_loss: 1.1179 - val_custom_f1: 0.5195 - val_weighted_custom_f1: 0.5407\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.6607 - custom_f1: 0.6055 - weighted_custom_f1: 0.6096Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6510 - custom_f1: 0.6074 - weighted_custom_f1: 0.6137 - val_loss: 0.9347 - val_custom_f1: 0.5002 - val_weighted_custom_f1: 0.5214\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.5836 - custom_f1: 0.6311 - weighted_custom_f1: 0.6351Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9856 - custom_f1: 0.4908 - weighted_custom_f1: 0.4936 - val_loss: 0.9763 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5095\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.7141 - custom_f1: 0.5733 - weighted_custom_f1: 0.5786Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0001 - custom_f1: 0.4868 - weighted_custom_f1: 0.4907 - val_loss: 1.2628 - val_custom_f1: 0.4366 - val_weighted_custom_f1: 0.4465\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.8253 - custom_f1: 0.5203 - weighted_custom_f1: 0.5260Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6134 - custom_f1: 0.6287 - weighted_custom_f1: 0.6334 - val_loss: 1.0697 - val_custom_f1: 0.5222 - val_weighted_custom_f1: 0.5244\n",
            " 76/105 [====================>.........] - ETA: 0s - loss: 0.5783 - custom_f1: 0.6427 - weighted_custom_f1: 0.6468Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5905 - custom_f1: 0.6353 - weighted_custom_f1: 0.6419 - val_loss: 1.1403 - val_custom_f1: 0.5361 - val_weighted_custom_f1: 0.5453\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6676 - custom_f1: 0.6029 - weighted_custom_f1: 0.6070 - val_loss: 0.9366 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5302\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.9913 - custom_f1: 0.4793 - weighted_custom_f1: 0.4830Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6561 - custom_f1: 0.6038 - weighted_custom_f1: 0.6089 - val_loss: 0.9865 - val_custom_f1: 0.5126 - val_weighted_custom_f1: 0.5245\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6423 - custom_f1: 0.6230 - weighted_custom_f1: 0.6265 - val_loss: 1.0154 - val_custom_f1: 0.4695 - val_weighted_custom_f1: 0.4822\n",
            "Epoch 43/100\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6225 - custom_f1: 0.6226 - weighted_custom_f1: 0.6273 - val_loss: 1.3703 - val_custom_f1: 0.5447 - val_weighted_custom_f1: 0.5498\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5986 - custom_f1: 0.6398 - weighted_custom_f1: 0.6436 - val_loss: 1.0787 - val_custom_f1: 0.5153 - val_weighted_custom_f1: 0.5383\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.9759 - custom_f1: 0.4819 - weighted_custom_f1: 0.4854Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8460 - custom_f1: 0.5227 - weighted_custom_f1: 0.5274 - val_loss: 0.9295 - val_custom_f1: 0.4853 - val_weighted_custom_f1: 0.4954\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5721 - custom_f1: 0.6364 - weighted_custom_f1: 0.6364Epoch 12/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5847 - custom_f1: 0.6481 - weighted_custom_f1: 0.6528 - val_loss: 1.1760 - val_custom_f1: 0.4754 - val_weighted_custom_f1: 0.4712\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.5731 - custom_f1: 0.6466 - weighted_custom_f1: 0.6502Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6943 - custom_f1: 0.5893 - weighted_custom_f1: 0.5965 - val_loss: 0.9653 - val_custom_f1: 0.5075 - val_weighted_custom_f1: 0.5193\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.6619 - custom_f1: 0.5797 - weighted_custom_f1: 0.5858Epoch 44/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.6003 - custom_f1: 0.6292 - weighted_custom_f1: 0.6335 - val_loss: 1.2131 - val_custom_f1: 0.5375 - val_weighted_custom_f1: 0.5432\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6167 - custom_f1: 0.6290 - weighted_custom_f1: 0.6340 - val_loss: 0.9738 - val_custom_f1: 0.4875 - val_weighted_custom_f1: 0.5095\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6383 - custom_f1: 0.6244 - weighted_custom_f1: 0.6313 - val_loss: 0.9382 - val_custom_f1: 0.5136 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6455 - custom_f1: 0.6162 - weighted_custom_f1: 0.6204 - val_loss: 0.9104 - val_custom_f1: 0.5037 - val_weighted_custom_f1: 0.5144\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9729 - custom_f1: 0.4892 - weighted_custom_f1: 0.4930 - val_loss: 1.2514 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.4945\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9658 - custom_f1: 0.4889 - weighted_custom_f1: 0.4937 - val_loss: 1.0945 - val_custom_f1: 0.4642 - val_weighted_custom_f1: 0.4637\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6528 - custom_f1: 0.6085 - weighted_custom_f1: 0.6124Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6041 - custom_f1: 0.6389 - weighted_custom_f1: 0.6424 - val_loss: 1.0889 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5097\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.5661 - custom_f1: 0.6480 - weighted_custom_f1: 0.6508Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5882 - custom_f1: 0.6382 - weighted_custom_f1: 0.6425 - val_loss: 1.0269 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5232\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.9683 - custom_f1: 0.4997 - weighted_custom_f1: 0.5032Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6691 - custom_f1: 0.6004 - weighted_custom_f1: 0.6062 - val_loss: 0.9713 - val_custom_f1: 0.4866 - val_weighted_custom_f1: 0.4970\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6394 - custom_f1: 0.6174 - weighted_custom_f1: 0.6248 - val_loss: 0.9524 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5144\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4681 - custom_f1: 0.5000 - weighted_custom_f1: 0.5000Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6422 - custom_f1: 0.6160 - weighted_custom_f1: 0.6218 - val_loss: 1.3383 - val_custom_f1: 0.5322 - val_weighted_custom_f1: 0.5370\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6359 - custom_f1: 0.6249 - weighted_custom_f1: 0.6294 - val_loss: 1.1162 - val_custom_f1: 0.5071 - val_weighted_custom_f1: 0.5296\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.5977 - custom_f1: 0.6383 - weighted_custom_f1: 0.6419Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6166 - custom_f1: 0.6245 - weighted_custom_f1: 0.6308 - val_loss: 1.4163 - val_custom_f1: 0.5250 - val_weighted_custom_f1: 0.5299\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8444 - custom_f1: 0.5290 - weighted_custom_f1: 0.5349 - val_loss: 0.9542 - val_custom_f1: 0.4642 - val_weighted_custom_f1: 0.4775\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.6706 - custom_f1: 0.6449 - weighted_custom_f1: 0.6496Epoch 50/100\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5854 - custom_f1: 0.6408 - weighted_custom_f1: 0.6454 - val_loss: 1.2317 - val_custom_f1: 0.5294 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5927 - custom_f1: 0.6420 - weighted_custom_f1: 0.6446 - val_loss: 1.1428 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5526\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 1.0008 - custom_f1: 0.4833 - weighted_custom_f1: 0.4890Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6796 - custom_f1: 0.6030 - weighted_custom_f1: 0.6074 - val_loss: 0.9947 - val_custom_f1: 0.5088 - val_weighted_custom_f1: 0.5201\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6154 - custom_f1: 0.6295 - weighted_custom_f1: 0.6342 - val_loss: 0.9627 - val_custom_f1: 0.4729 - val_weighted_custom_f1: 0.4945\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.6406 - custom_f1: 0.6358 - weighted_custom_f1: 0.6422Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6389 - custom_f1: 0.6171 - weighted_custom_f1: 0.6206 - val_loss: 1.0298 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5481\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9791 - custom_f1: 0.4939 - weighted_custom_f1: 0.4970 - val_loss: 1.2884 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.4954\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7387 - custom_f1: 0.6857 - weighted_custom_f1: 0.6857Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6158 - custom_f1: 0.6285 - weighted_custom_f1: 0.6315 - val_loss: 0.9304 - val_custom_f1: 0.5090 - val_weighted_custom_f1: 0.5174\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9523 - custom_f1: 0.4746 - weighted_custom_f1: 0.4746Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9887 - custom_f1: 0.4867 - weighted_custom_f1: 0.4919 - val_loss: 1.0309 - val_custom_f1: 0.4417 - val_weighted_custom_f1: 0.4412\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6062 - custom_f1: 0.6346 - weighted_custom_f1: 0.6384 - val_loss: 1.0798 - val_custom_f1: 0.5407 - val_weighted_custom_f1: 0.5425\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6013 - custom_f1: 0.6322 - weighted_custom_f1: 0.6368 - val_loss: 1.2229 - val_custom_f1: 0.5334 - val_weighted_custom_f1: 0.5556\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6375 - custom_f1: 0.6248 - weighted_custom_f1: 0.6300 - val_loss: 1.0227 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5205\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6785 - custom_f1: 0.6001 - weighted_custom_f1: 0.6049 - val_loss: 0.9943 - val_custom_f1: 0.4934 - val_weighted_custom_f1: 0.5058\n",
            "Epoch 53/100\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6598 - custom_f1: 0.6168 - weighted_custom_f1: 0.6213 - val_loss: 0.9891 - val_custom_f1: 0.4859 - val_weighted_custom_f1: 0.4968\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5580 - custom_f1: 0.5937 - weighted_custom_f1: 0.5937Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6074 - custom_f1: 0.6336 - weighted_custom_f1: 0.6369 - val_loss: 1.0581 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5047\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5795 - custom_f1: 0.6456 - weighted_custom_f1: 0.6490 - val_loss: 1.1275 - val_custom_f1: 0.4775 - val_weighted_custom_f1: 0.4884\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5708 - custom_f1: 0.6509 - weighted_custom_f1: 0.6562 - val_loss: 1.3117 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5175\n",
            "Epoch 51/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5885 - custom_f1: 0.6098 - weighted_custom_f1: 0.6098Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6876 - custom_f1: 0.5965 - weighted_custom_f1: 0.6024 - val_loss: 1.0459 - val_custom_f1: 0.4868 - val_weighted_custom_f1: 0.4968\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8160 - custom_f1: 0.5364 - weighted_custom_f1: 0.5400 - val_loss: 0.9205 - val_custom_f1: 0.4796 - val_weighted_custom_f1: 0.4920\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.9661 - custom_f1: 0.4825 - weighted_custom_f1: 0.4873Epoch 14/100\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6032 - custom_f1: 0.6344 - weighted_custom_f1: 0.6390 - val_loss: 1.0690 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5326\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5986 - custom_f1: 0.4561 - weighted_custom_f1: 0.4561Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6069 - custom_f1: 0.6358 - weighted_custom_f1: 0.6411 - val_loss: 1.0030 - val_custom_f1: 0.4976 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9800 - custom_f1: 0.4938 - weighted_custom_f1: 0.4977 - val_loss: 1.2544 - val_custom_f1: 0.4427 - val_weighted_custom_f1: 0.4532\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6397 - custom_f1: 0.6209 - weighted_custom_f1: 0.6265 - val_loss: 0.9356 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5319\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6109 - custom_f1: 0.6271 - weighted_custom_f1: 0.6312 - val_loss: 0.9815 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5471\n",
            "Epoch 52/100\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.8108 - custom_f1: 0.5276 - weighted_custom_f1: 0.5345Epoch 53/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9652 - custom_f1: 0.4815 - weighted_custom_f1: 0.4860 - val_loss: 1.0144 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.4912\n",
            "  8/105 [=>............................] - ETA: 1s - loss: 0.6576 - custom_f1: 0.6283 - weighted_custom_f1: 0.6329Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5860 - custom_f1: 0.6458 - weighted_custom_f1: 0.6497 - val_loss: 1.1294 - val_custom_f1: 0.5228 - val_weighted_custom_f1: 0.5246\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6012 - custom_f1: 0.6393 - weighted_custom_f1: 0.6445 - val_loss: 1.1060 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5244\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6879 - custom_f1: 0.5981 - weighted_custom_f1: 0.6034 - val_loss: 0.9489 - val_custom_f1: 0.5486 - val_weighted_custom_f1: 0.5472\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.9770 - custom_f1: 0.4922 - weighted_custom_f1: 0.4977Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6351 - custom_f1: 0.6170 - weighted_custom_f1: 0.6244 - val_loss: 1.0200 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.5129\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.6044 - custom_f1: 0.6344 - weighted_custom_f1: 0.6398Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5883 - custom_f1: 0.6366 - weighted_custom_f1: 0.6409 - val_loss: 1.0721 - val_custom_f1: 0.5276 - val_weighted_custom_f1: 0.5326\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6910 - custom_f1: 0.5945 - weighted_custom_f1: 0.5994 - val_loss: 0.9995 - val_custom_f1: 0.4848 - val_weighted_custom_f1: 0.4947\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8146 - custom_f1: 0.5369 - weighted_custom_f1: 0.5419 - val_loss: 0.9224 - val_custom_f1: 0.4916 - val_weighted_custom_f1: 0.5036\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6630 - custom_f1: 0.6103 - weighted_custom_f1: 0.6154 - val_loss: 1.1296 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5378\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5973 - custom_f1: 0.6321 - weighted_custom_f1: 0.6355 - val_loss: 1.3756 - val_custom_f1: 0.5045 - val_weighted_custom_f1: 0.5258\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7424 - custom_f1: 0.5246 - weighted_custom_f1: 0.5246Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5960 - custom_f1: 0.6370 - weighted_custom_f1: 0.6404 - val_loss: 0.9724 - val_custom_f1: 0.4853 - val_weighted_custom_f1: 0.5078\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5824 - custom_f1: 0.6433 - weighted_custom_f1: 0.6466 - val_loss: 1.3979 - val_custom_f1: 0.5454 - val_weighted_custom_f1: 0.5461\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5788 - custom_f1: 0.6415 - weighted_custom_f1: 0.6466 - val_loss: 1.1148 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5259\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9814 - custom_f1: 0.4846 - weighted_custom_f1: 0.4883 - val_loss: 1.2753 - val_custom_f1: 0.4912 - val_weighted_custom_f1: 0.4961\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.6089 - custom_f1: 0.6320 - weighted_custom_f1: 0.6344Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6465 - custom_f1: 0.6108 - weighted_custom_f1: 0.6172 - val_loss: 0.9299 - val_custom_f1: 0.5177 - val_weighted_custom_f1: 0.5280\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.5808 - custom_f1: 0.6388 - weighted_custom_f1: 0.6437Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6085 - custom_f1: 0.6367 - weighted_custom_f1: 0.6413 - val_loss: 0.9294 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5089\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9685 - custom_f1: 0.4872 - weighted_custom_f1: 0.4928 - val_loss: 1.0303 - val_custom_f1: 0.4851 - val_weighted_custom_f1: 0.4846\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.6605 - custom_f1: 0.5993 - weighted_custom_f1: 0.6028Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5994 - custom_f1: 0.6306 - weighted_custom_f1: 0.6355 - val_loss: 1.0813 - val_custom_f1: 0.4913 - val_weighted_custom_f1: 0.4937\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5832 - custom_f1: 0.6372 - weighted_custom_f1: 0.6433 - val_loss: 1.0904 - val_custom_f1: 0.5433 - val_weighted_custom_f1: 0.5531\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6212 - custom_f1: 0.6273 - weighted_custom_f1: 0.6318 - val_loss: 1.0369 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4986\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6390 - custom_f1: 0.6257 - weighted_custom_f1: 0.6291 - val_loss: 1.0233 - val_custom_f1: 0.5167 - val_weighted_custom_f1: 0.5241\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.9909 - custom_f1: 0.4872 - weighted_custom_f1: 0.4935Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5813 - custom_f1: 0.6410 - weighted_custom_f1: 0.6455 - val_loss: 1.1305 - val_custom_f1: 0.5001 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7970 - custom_f1: 0.5375 - weighted_custom_f1: 0.5432 - val_loss: 0.9368 - val_custom_f1: 0.5168 - val_weighted_custom_f1: 0.5275\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6008 - custom_f1: 0.6385 - weighted_custom_f1: 0.6431 - val_loss: 1.2098 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5282\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6864 - custom_f1: 0.5938 - weighted_custom_f1: 0.5965 - val_loss: 1.0675 - val_custom_f1: 0.4932 - val_weighted_custom_f1: 0.5154\n",
            "Epoch 53/100\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.5421 - custom_f1: 0.6517 - weighted_custom_f1: 0.6557Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6011 - custom_f1: 0.6418 - weighted_custom_f1: 0.6466 - val_loss: 1.0042 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5249\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.6999 - custom_f1: 0.5921 - weighted_custom_f1: 0.5969 - val_loss: 0.9918 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5160\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5742 - custom_f1: 0.6448 - weighted_custom_f1: 0.6489 - val_loss: 1.2861 - val_custom_f1: 0.5259 - val_weighted_custom_f1: 0.5269\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.5726 - custom_f1: 0.6427 - weighted_custom_f1: 0.6475 - val_loss: 1.0559 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5226\n",
            "  6/105 [>.............................] - ETA: 1s - loss: 0.5261 - custom_f1: 0.6803 - weighted_custom_f1: 0.6790Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9792 - custom_f1: 0.4864 - weighted_custom_f1: 0.4910 - val_loss: 1.2791 - val_custom_f1: 0.4638 - val_weighted_custom_f1: 0.4727\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.6589 - custom_f1: 0.5993 - weighted_custom_f1: 0.6035Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6265 - custom_f1: 0.6262 - weighted_custom_f1: 0.6296 - val_loss: 0.9795 - val_custom_f1: 0.4883 - val_weighted_custom_f1: 0.4978\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6098 - custom_f1: 0.6312 - weighted_custom_f1: 0.6362 - val_loss: 0.9321 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5269\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9945 - custom_f1: 0.4946 - weighted_custom_f1: 0.4997 - val_loss: 1.0373 - val_custom_f1: 0.5166 - val_weighted_custom_f1: 0.5081\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.6562 - custom_f1: 0.6056 - weighted_custom_f1: 0.6100Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5891 - custom_f1: 0.6370 - weighted_custom_f1: 0.6428 - val_loss: 1.1458 - val_custom_f1: 0.5274 - val_weighted_custom_f1: 0.5268\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5580 - custom_f1: 0.6561 - weighted_custom_f1: 0.6602 - val_loss: 1.1291 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5299\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6345 - custom_f1: 0.6193 - weighted_custom_f1: 0.6240 - val_loss: 0.9763 - val_custom_f1: 0.5355 - val_weighted_custom_f1: 0.5399\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.6330 - custom_f1: 0.6200 - weighted_custom_f1: 0.6227Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6205 - custom_f1: 0.6300 - weighted_custom_f1: 0.6317 - val_loss: 1.0393 - val_custom_f1: 0.4967 - val_weighted_custom_f1: 0.5179\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5725 - custom_f1: 0.6514 - weighted_custom_f1: 0.6567 - val_loss: 1.1739 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5210\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5841 - custom_f1: 0.6358 - weighted_custom_f1: 0.6436 - val_loss: 1.2880 - val_custom_f1: 0.5225 - val_weighted_custom_f1: 0.5339\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7886 - custom_f1: 0.5442 - weighted_custom_f1: 0.5483 - val_loss: 0.9439 - val_custom_f1: 0.4970 - val_weighted_custom_f1: 0.5068\n",
            "Epoch 54/100\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.9781 - custom_f1: 0.4855 - weighted_custom_f1: 0.4896Epoch 17/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6766 - custom_f1: 0.5995 - weighted_custom_f1: 0.6038 - val_loss: 1.0484 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5384\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6592 - custom_f1: 0.6022 - weighted_custom_f1: 0.6068 - val_loss: 1.0767 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5382\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.5789 - custom_f1: 0.6380 - weighted_custom_f1: 0.6439Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5590 - custom_f1: 0.6536 - weighted_custom_f1: 0.6587 - val_loss: 1.3454 - val_custom_f1: 0.5217 - val_weighted_custom_f1: 0.5200\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.5890 - custom_f1: 0.6422 - weighted_custom_f1: 0.6470Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5983 - custom_f1: 0.6421 - weighted_custom_f1: 0.6449 - val_loss: 1.0098 - val_custom_f1: 0.4565 - val_weighted_custom_f1: 0.4786\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5699 - custom_f1: 0.6484 - weighted_custom_f1: 0.6527 - val_loss: 1.1153 - val_custom_f1: 0.5063 - val_weighted_custom_f1: 0.5143\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.5628 - custom_f1: 0.6461 - weighted_custom_f1: 0.6505Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9779 - custom_f1: 0.4863 - weighted_custom_f1: 0.4896 - val_loss: 1.2834 - val_custom_f1: 0.4790 - val_weighted_custom_f1: 0.4850\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.6191 - custom_f1: 0.6258 - weighted_custom_f1: 0.6305Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6358 - custom_f1: 0.6180 - weighted_custom_f1: 0.6195 - val_loss: 1.0138 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5388\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9530 - custom_f1: 0.5042 - weighted_custom_f1: 0.5092 - val_loss: 0.9762 - val_custom_f1: 0.4735 - val_weighted_custom_f1: 0.4749\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6036 - custom_f1: 0.6351 - weighted_custom_f1: 0.6382 - val_loss: 0.9513 - val_custom_f1: 0.5098 - val_weighted_custom_f1: 0.5187\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5775 - custom_f1: 0.6457 - weighted_custom_f1: 0.6510 - val_loss: 1.0748 - val_custom_f1: 0.5260 - val_weighted_custom_f1: 0.5286\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.6266 - custom_f1: 0.6286 - weighted_custom_f1: 0.6322Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5696 - custom_f1: 0.6586 - weighted_custom_f1: 0.6602 - val_loss: 1.1382 - val_custom_f1: 0.5506 - val_weighted_custom_f1: 0.5568\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.9944 - custom_f1: 0.4982 - weighted_custom_f1: 0.5023Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6487 - custom_f1: 0.6165 - weighted_custom_f1: 0.6222 - val_loss: 1.0396 - val_custom_f1: 0.5526 - val_weighted_custom_f1: 0.5576\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5649 - custom_f1: 0.6500 - weighted_custom_f1: 0.6535 - val_loss: 1.1077 - val_custom_f1: 0.4834 - val_weighted_custom_f1: 0.5054\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7745 - custom_f1: 0.6765 - weighted_custom_f1: 0.6765Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6219 - custom_f1: 0.6291 - weighted_custom_f1: 0.6328 - val_loss: 1.0477 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5198\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.9352 - custom_f1: 0.4972 - weighted_custom_f1: 0.5006Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6911 - custom_f1: 0.5880 - weighted_custom_f1: 0.5945 - val_loss: 1.2699 - val_custom_f1: 0.5208 - val_weighted_custom_f1: 0.5259\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.5983 - custom_f1: 0.6415 - weighted_custom_f1: 0.6448Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7927 - custom_f1: 0.5477 - weighted_custom_f1: 0.5521 - val_loss: 0.9243 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.4887\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5907 - custom_f1: 0.7234 - weighted_custom_f1: 0.7234Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5660 - custom_f1: 0.6530 - weighted_custom_f1: 0.6573 - val_loss: 1.1727 - val_custom_f1: 0.5007 - val_weighted_custom_f1: 0.5109\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.6001 - custom_f1: 0.6187 - weighted_custom_f1: 0.6261Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6499 - custom_f1: 0.6113 - weighted_custom_f1: 0.6143 - val_loss: 1.0667 - val_custom_f1: 0.5601 - val_weighted_custom_f1: 0.5665\n",
            "102/105 [============================>.] - ETA: 0s - loss: 0.6039 - custom_f1: 0.6359 - weighted_custom_f1: 0.6395Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5703 - custom_f1: 0.6499 - weighted_custom_f1: 0.6532 - val_loss: 1.2887 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5237\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.5747 - custom_f1: 0.6527 - weighted_custom_f1: 0.6559Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5961 - custom_f1: 0.6353 - weighted_custom_f1: 0.6394 - val_loss: 1.0283 - val_custom_f1: 0.4847 - val_weighted_custom_f1: 0.5066\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9722 - custom_f1: 0.4874 - weighted_custom_f1: 0.4908 - val_loss: 1.2943 - val_custom_f1: 0.4636 - val_weighted_custom_f1: 0.4714\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.6421 - custom_f1: 0.6056 - weighted_custom_f1: 0.6099Epoch 59/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5558 - custom_f1: 0.6510 - weighted_custom_f1: 0.6545 - val_loss: 1.1227 - val_custom_f1: 0.5275 - val_weighted_custom_f1: 0.5402\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6393 - custom_f1: 0.6168 - weighted_custom_f1: 0.6204 - val_loss: 0.9824 - val_custom_f1: 0.5145 - val_weighted_custom_f1: 0.5366\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6018 - custom_f1: 0.6381 - weighted_custom_f1: 0.6408 - val_loss: 1.0805 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5274\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.6024 - custom_f1: 0.6359 - weighted_custom_f1: 0.6409Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9270 - custom_f1: 0.5021 - weighted_custom_f1: 0.5052 - val_loss: 0.9775 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5004\n",
            "Epoch 56/100\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5727 - custom_f1: 0.6515 - weighted_custom_f1: 0.6551 - val_loss: 1.1407 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5272\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5711 - custom_f1: 0.6472 - weighted_custom_f1: 0.6510 - val_loss: 1.1768 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5423\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6464 - custom_f1: 0.6116 - weighted_custom_f1: 0.6179 - val_loss: 1.0145 - val_custom_f1: 0.5637 - val_weighted_custom_f1: 0.5633\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.9817 - custom_f1: 0.4906 - weighted_custom_f1: 0.4935Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7876 - custom_f1: 0.5404 - weighted_custom_f1: 0.5483 - val_loss: 1.0276 - val_custom_f1: 0.5192 - val_weighted_custom_f1: 0.5276\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6124 - custom_f1: 0.6332 - weighted_custom_f1: 0.6374Epoch 19/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5852 - custom_f1: 0.6434 - weighted_custom_f1: 0.6462 - val_loss: 1.3241 - val_custom_f1: 0.5515 - val_weighted_custom_f1: 0.5571\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6104 - custom_f1: 0.6318 - weighted_custom_f1: 0.6364 - val_loss: 1.0978 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5276\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.6058 - custom_f1: 0.6376 - weighted_custom_f1: 0.6415Epoch 56/100\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6523 - custom_f1: 0.6174 - weighted_custom_f1: 0.6209 - val_loss: 1.0051 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4967\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5723 - custom_f1: 0.6489 - weighted_custom_f1: 0.6518 - val_loss: 1.2916 - val_custom_f1: 0.5011 - val_weighted_custom_f1: 0.5087\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6385 - custom_f1: 0.6104 - weighted_custom_f1: 0.6167 - val_loss: 1.0828 - val_custom_f1: 0.5437 - val_weighted_custom_f1: 0.5500\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5994 - custom_f1: 0.6397 - weighted_custom_f1: 0.6442 - val_loss: 1.0164 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5271\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5253 - custom_f1: 0.6682 - weighted_custom_f1: 0.6715 - val_loss: 1.3149 - val_custom_f1: 0.5376 - val_weighted_custom_f1: 0.5369\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.6338 - custom_f1: 0.6289 - weighted_custom_f1: 0.6307Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6144 - custom_f1: 0.6338 - weighted_custom_f1: 0.6362 - val_loss: 1.0250 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5403\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5558 - custom_f1: 0.6603 - weighted_custom_f1: 0.6653 - val_loss: 1.2448 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5192\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9851 - custom_f1: 0.4788 - weighted_custom_f1: 0.4844 - val_loss: 1.4663 - val_custom_f1: 0.4675 - val_weighted_custom_f1: 0.4598\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6077 - custom_f1: 0.6370 - weighted_custom_f1: 0.6414 - val_loss: 0.9603 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5181\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9679 - custom_f1: 0.4924 - weighted_custom_f1: 0.4961 - val_loss: 1.0681 - val_custom_f1: 0.4928 - val_weighted_custom_f1: 0.4905\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.6499 - custom_f1: 0.6258 - weighted_custom_f1: 0.6287Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5680 - custom_f1: 0.6545 - weighted_custom_f1: 0.6579 - val_loss: 1.0773 - val_custom_f1: 0.5238 - val_weighted_custom_f1: 0.5227\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.5174 - custom_f1: 0.6715 - weighted_custom_f1: 0.6766Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5509 - custom_f1: 0.6604 - weighted_custom_f1: 0.6627 - val_loss: 1.1508 - val_custom_f1: 0.5434 - val_weighted_custom_f1: 0.5500\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7918 - custom_f1: 0.5480 - weighted_custom_f1: 0.5519 - val_loss: 0.9403 - val_custom_f1: 0.4861 - val_weighted_custom_f1: 0.4986\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.5779 - custom_f1: 0.6463 - weighted_custom_f1: 0.6510Epoch 20/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6228 - custom_f1: 0.6294 - weighted_custom_f1: 0.6340 - val_loss: 0.9845 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4978\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5869 - custom_f1: 0.6464 - weighted_custom_f1: 0.6509 - val_loss: 1.2212 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5153\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 0.5523 - custom_f1: 0.6622 - weighted_custom_f1: 0.6658Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6249 - custom_f1: 0.6256 - weighted_custom_f1: 0.6305 - val_loss: 1.1159 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5288\n",
            " 12/105 [==>...........................] - ETA: 0s - loss: 0.6220 - custom_f1: 0.6195 - weighted_custom_f1: 0.6217Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6639 - custom_f1: 0.6084 - weighted_custom_f1: 0.6125 - val_loss: 1.1910 - val_custom_f1: 0.5234 - val_weighted_custom_f1: 0.5328\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.5860 - custom_f1: 0.6458 - weighted_custom_f1: 0.6504Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5669 - custom_f1: 0.6497 - weighted_custom_f1: 0.6536 - val_loss: 1.2602 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5193\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.5672 - custom_f1: 0.6558 - weighted_custom_f1: 0.6593Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6404 - custom_f1: 0.6257 - weighted_custom_f1: 0.6291 - val_loss: 0.9938 - val_custom_f1: 0.4852 - val_weighted_custom_f1: 0.4969\n",
            " 39/105 [==========>...................] - ETA: 0s - loss: 0.7447 - custom_f1: 0.5473 - weighted_custom_f1: 0.5534Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5578 - custom_f1: 0.6529 - weighted_custom_f1: 0.6577 - val_loss: 1.3602 - val_custom_f1: 0.5047 - val_weighted_custom_f1: 0.5025\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5748 - custom_f1: 0.6499 - weighted_custom_f1: 0.6532 - val_loss: 1.0157 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5353\n",
            "Epoch 54/100\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0157 - custom_f1: 0.4759 - weighted_custom_f1: 0.4805 - val_loss: 1.3167 - val_custom_f1: 0.4957 - val_weighted_custom_f1: 0.4907\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5557 - custom_f1: 0.6586 - weighted_custom_f1: 0.6624 - val_loss: 1.1405 - val_custom_f1: 0.4681 - val_weighted_custom_f1: 0.4771\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.5697 - custom_f1: 0.6468 - weighted_custom_f1: 0.6509Epoch 55/100\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.5511 - custom_f1: 0.6520 - weighted_custom_f1: 0.6564Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9400 - custom_f1: 0.5019 - weighted_custom_f1: 0.5055 - val_loss: 1.1157 - val_custom_f1: 0.4315 - val_weighted_custom_f1: 0.4311\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.5495 - custom_f1: 0.6641 - weighted_custom_f1: 0.6680Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6124 - custom_f1: 0.6287 - weighted_custom_f1: 0.6327 - val_loss: 0.9715 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5427\n",
            " 55/105 [==============>...............] - ETA: 0s - loss: 0.6531 - custom_f1: 0.6106 - weighted_custom_f1: 0.6169Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5861 - custom_f1: 0.6437 - weighted_custom_f1: 0.6477 - val_loss: 0.9934 - val_custom_f1: 0.5193 - val_weighted_custom_f1: 0.5423\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5637 - custom_f1: 0.6544 - weighted_custom_f1: 0.6590 - val_loss: 1.0575 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5258\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.6235 - custom_f1: 0.6175 - weighted_custom_f1: 0.6215Epoch 59/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5645 - custom_f1: 0.6497 - weighted_custom_f1: 0.6534 - val_loss: 1.0871 - val_custom_f1: 0.5277 - val_weighted_custom_f1: 0.5344\n",
            " 11/105 [==>...........................] - ETA: 1s - loss: 0.5485 - custom_f1: 0.6664 - weighted_custom_f1: 0.6679Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7691 - custom_f1: 0.5509 - weighted_custom_f1: 0.5561 - val_loss: 0.9529 - val_custom_f1: 0.4973 - val_weighted_custom_f1: 0.5071\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.6102 - custom_f1: 0.6364 - weighted_custom_f1: 0.6392 - val_loss: 1.0835 - val_custom_f1: 0.5014 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5588 - custom_f1: 0.6550 - weighted_custom_f1: 0.6583 - val_loss: 1.1986 - val_custom_f1: 0.5353 - val_weighted_custom_f1: 0.5401\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6276 - custom_f1: 0.6186 - weighted_custom_f1: 0.6238 - val_loss: 1.0896 - val_custom_f1: 0.5599 - val_weighted_custom_f1: 0.5656\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6562 - custom_f1: 0.6141 - weighted_custom_f1: 0.6197 - val_loss: 1.0371 - val_custom_f1: 0.4953 - val_weighted_custom_f1: 0.5052\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5619 - custom_f1: 0.6548 - weighted_custom_f1: 0.6592 - val_loss: 1.4184 - val_custom_f1: 0.5030 - val_weighted_custom_f1: 0.5235\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.5510 - custom_f1: 0.6737 - weighted_custom_f1: 0.6764Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5582 - custom_f1: 0.6538 - weighted_custom_f1: 0.6585 - val_loss: 1.4341 - val_custom_f1: 0.5465 - val_weighted_custom_f1: 0.5454\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6344 - custom_f1: 0.6126 - weighted_custom_f1: 0.6175 - val_loss: 1.0191 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 55/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5706 - custom_f1: 0.7547 - weighted_custom_f1: 0.7547Epoch 52/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9885 - custom_f1: 0.4893 - weighted_custom_f1: 0.4937 - val_loss: 1.2604 - val_custom_f1: 0.4841 - val_weighted_custom_f1: 0.4889\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5656 - custom_f1: 0.6519 - weighted_custom_f1: 0.6547 - val_loss: 1.0049 - val_custom_f1: 0.4804 - val_weighted_custom_f1: 0.5026\n",
            "Epoch 62/100\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0035 - custom_f1: 0.4947 - weighted_custom_f1: 0.4977 - val_loss: 1.0624 - val_custom_f1: 0.4487 - val_weighted_custom_f1: 0.4493\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5540 - custom_f1: 0.6597 - weighted_custom_f1: 0.6631 - val_loss: 1.2015 - val_custom_f1: 0.5136 - val_weighted_custom_f1: 0.5350\n",
            "Epoch 61/100\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.6388 - custom_f1: 0.6254 - weighted_custom_f1: 0.6333Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6135 - custom_f1: 0.6327 - weighted_custom_f1: 0.6376 - val_loss: 1.0965 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5439\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5815 - custom_f1: 0.6405 - weighted_custom_f1: 0.6445 - val_loss: 0.9575 - val_custom_f1: 0.5324 - val_weighted_custom_f1: 0.5420\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5618 - custom_f1: 0.6548 - weighted_custom_f1: 0.6575 - val_loss: 1.1235 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5105\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5608 - custom_f1: 0.6512 - weighted_custom_f1: 0.6553 - val_loss: 1.2795 - val_custom_f1: 0.5378 - val_weighted_custom_f1: 0.5611\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 1.0055 - custom_f1: 0.4871 - weighted_custom_f1: 0.4902Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7737 - custom_f1: 0.5533 - weighted_custom_f1: 0.5576 - val_loss: 0.9349 - val_custom_f1: 0.4918 - val_weighted_custom_f1: 0.5039\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6102 - custom_f1: 0.6349 - weighted_custom_f1: 0.6407 - val_loss: 1.0533 - val_custom_f1: 0.4660 - val_weighted_custom_f1: 0.4790\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5608 - custom_f1: 0.6549 - weighted_custom_f1: 0.6588 - val_loss: 1.1885 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5249\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6426 - custom_f1: 0.6176 - weighted_custom_f1: 0.6238 - val_loss: 0.9886 - val_custom_f1: 0.5054 - val_weighted_custom_f1: 0.5168\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.9929 - custom_f1: 0.4963 - weighted_custom_f1: 0.4998Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6510 - custom_f1: 0.6059 - weighted_custom_f1: 0.6130 - val_loss: 1.1231 - val_custom_f1: 0.5287 - val_weighted_custom_f1: 0.5395\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5788 - custom_f1: 0.6452 - weighted_custom_f1: 0.6499 - val_loss: 1.3393 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5414\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5627 - custom_f1: 0.6533 - weighted_custom_f1: 0.6581 - val_loss: 1.0215 - val_custom_f1: 0.5015 - val_weighted_custom_f1: 0.5239\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9824 - custom_f1: 0.4862 - weighted_custom_f1: 0.4902 - val_loss: 1.2471 - val_custom_f1: 0.4518 - val_weighted_custom_f1: 0.4606\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5362 - custom_f1: 0.6615 - weighted_custom_f1: 0.6673 - val_loss: 1.3099 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5108\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6301 - custom_f1: 0.6204 - weighted_custom_f1: 0.6245 - val_loss: 1.0268 - val_custom_f1: 0.4864 - val_weighted_custom_f1: 0.4948\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5643 - custom_f1: 0.6503 - weighted_custom_f1: 0.6560Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9877 - custom_f1: 0.4996 - weighted_custom_f1: 0.5026 - val_loss: 1.0169 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5038\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.6098 - custom_f1: 0.6290 - weighted_custom_f1: 0.6342Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5584 - custom_f1: 0.6573 - weighted_custom_f1: 0.6610 - val_loss: 1.1410 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5230\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.5438 - custom_f1: 0.6722 - weighted_custom_f1: 0.6744Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6123 - custom_f1: 0.6289 - weighted_custom_f1: 0.6352 - val_loss: 0.9615 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5266\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.6308 - custom_f1: 0.6257 - weighted_custom_f1: 0.6315Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5677 - custom_f1: 0.6514 - weighted_custom_f1: 0.6564 - val_loss: 1.0972 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5113\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5927 - custom_f1: 0.6381 - weighted_custom_f1: 0.6434 - val_loss: 1.0123 - val_custom_f1: 0.5192 - val_weighted_custom_f1: 0.5421\n",
            "Epoch 61/100\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5678 - custom_f1: 0.6516 - weighted_custom_f1: 0.6579 - val_loss: 1.2096 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5228\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.5706 - custom_f1: 0.6482 - weighted_custom_f1: 0.6528Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6335 - custom_f1: 0.6252 - weighted_custom_f1: 0.6295 - val_loss: 1.0343 - val_custom_f1: 0.4920 - val_weighted_custom_f1: 0.5035\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7536 - custom_f1: 0.5570 - weighted_custom_f1: 0.5613 - val_loss: 0.9873 - val_custom_f1: 0.5261 - val_weighted_custom_f1: 0.5351\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.6185 - custom_f1: 0.6283 - weighted_custom_f1: 0.6320Epoch 62/100\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.5925 - custom_f1: 0.6445 - weighted_custom_f1: 0.6481Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6470 - custom_f1: 0.6193 - weighted_custom_f1: 0.6255 - val_loss: 1.0314 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5434 - custom_f1: 0.6612 - weighted_custom_f1: 0.6660 - val_loss: 1.2491 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5355\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.5253 - custom_f1: 0.6546 - weighted_custom_f1: 0.6589Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6316 - custom_f1: 0.6229 - weighted_custom_f1: 0.6281 - val_loss: 1.1171 - val_custom_f1: 0.4659 - val_weighted_custom_f1: 0.4772\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5445 - custom_f1: 0.6640 - weighted_custom_f1: 0.6676 - val_loss: 1.2203 - val_custom_f1: 0.5223 - val_weighted_custom_f1: 0.5309\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5686 - custom_f1: 0.6455 - weighted_custom_f1: 0.6507 - val_loss: 1.1738 - val_custom_f1: 0.5222 - val_weighted_custom_f1: 0.5435\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9801 - custom_f1: 0.4834 - weighted_custom_f1: 0.4880 - val_loss: 1.4125 - val_custom_f1: 0.4085 - val_weighted_custom_f1: 0.4192\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.5201 - custom_f1: 0.6915 - weighted_custom_f1: 0.6967Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5410 - custom_f1: 0.6687 - weighted_custom_f1: 0.6716 - val_loss: 1.3651 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5380\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.5856 - custom_f1: 0.6464 - weighted_custom_f1: 0.6523Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9634 - custom_f1: 0.4988 - weighted_custom_f1: 0.5015 - val_loss: 1.0161 - val_custom_f1: 0.4647 - val_weighted_custom_f1: 0.4646\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6260 - custom_f1: 0.6225 - weighted_custom_f1: 0.6274 - val_loss: 1.1072 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5531\n",
            "Epoch 63/100\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5537 - custom_f1: 0.6590 - weighted_custom_f1: 0.6621 - val_loss: 1.2037 - val_custom_f1: 0.5199 - val_weighted_custom_f1: 0.5427\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5855 - custom_f1: 0.6429 - weighted_custom_f1: 0.6470 - val_loss: 0.9582 - val_custom_f1: 0.5287 - val_weighted_custom_f1: 0.5383\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6002 - custom_f1: 0.6354 - weighted_custom_f1: 0.6395 - val_loss: 0.9851 - val_custom_f1: 0.5199 - val_weighted_custom_f1: 0.5414\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.5387 - custom_f1: 0.6664 - weighted_custom_f1: 0.6708Epoch 62/100\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5608 - custom_f1: 0.6556 - weighted_custom_f1: 0.6588 - val_loss: 1.2058 - val_custom_f1: 0.5389 - val_weighted_custom_f1: 0.5362\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5543 - custom_f1: 0.6551 - weighted_custom_f1: 0.6599 - val_loss: 1.1358 - val_custom_f1: 0.5410 - val_weighted_custom_f1: 0.5473\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5922 - custom_f1: 0.6465 - weighted_custom_f1: 0.6511 - val_loss: 1.0625 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5056\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7601 - custom_f1: 0.5702 - weighted_custom_f1: 0.5749 - val_loss: 0.9739 - val_custom_f1: 0.4995 - val_weighted_custom_f1: 0.5068\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5607 - custom_f1: 0.6515 - weighted_custom_f1: 0.6568 - val_loss: 1.2373 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5205\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5905 - custom_f1: 0.6359 - weighted_custom_f1: 0.6402 - val_loss: 1.0260 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5182\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6326 - custom_f1: 0.6178 - weighted_custom_f1: 0.6208 - val_loss: 1.1032 - val_custom_f1: 0.5144 - val_weighted_custom_f1: 0.5254\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5467 - custom_f1: 0.5714 - weighted_custom_f1: 0.5714Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5705 - custom_f1: 0.6513 - weighted_custom_f1: 0.6579 - val_loss: 1.2565 - val_custom_f1: 0.4717 - val_weighted_custom_f1: 0.4842\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5631 - custom_f1: 0.6529 - weighted_custom_f1: 0.6575 - val_loss: 1.0080 - val_custom_f1: 0.5041 - val_weighted_custom_f1: 0.5268\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.5516 - custom_f1: 0.6619 - weighted_custom_f1: 0.6651Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0320 - custom_f1: 0.4815 - weighted_custom_f1: 0.4854 - val_loss: 1.2605 - val_custom_f1: 0.4532 - val_weighted_custom_f1: 0.4619\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6215 - custom_f1: 0.6225 - weighted_custom_f1: 0.6267 - val_loss: 1.0283 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5087\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5050 - custom_f1: 0.6857 - weighted_custom_f1: 0.6885 - val_loss: 1.3480 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5141\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.5665 - custom_f1: 0.6733 - weighted_custom_f1: 0.6755Epoch 58/100\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.7220 - custom_f1: 0.5759 - weighted_custom_f1: 0.5796Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9421 - custom_f1: 0.4949 - weighted_custom_f1: 0.4978 - val_loss: 0.9765 - val_custom_f1: 0.4741 - val_weighted_custom_f1: 0.4738\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.6054 - custom_f1: 0.6337 - weighted_custom_f1: 0.6387Epoch 64/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5948 - custom_f1: 0.6392 - weighted_custom_f1: 0.6432 - val_loss: 0.9618 - val_custom_f1: 0.5139 - val_weighted_custom_f1: 0.5236\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5226 - custom_f1: 0.6699 - weighted_custom_f1: 0.6726 - val_loss: 1.1697 - val_custom_f1: 0.5065 - val_weighted_custom_f1: 0.5291\n",
            "Epoch 59/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4617 - custom_f1: 0.7750 - weighted_custom_f1: 0.7750Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5784 - custom_f1: 0.6461 - weighted_custom_f1: 0.6506 - val_loss: 0.9535 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5304\n",
            " 10/105 [=>............................] - ETA: 1s - loss: 0.8856 - custom_f1: 0.5073 - weighted_custom_f1: 0.5147Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5516 - custom_f1: 0.6619 - weighted_custom_f1: 0.6651 - val_loss: 1.0976 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5120\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.5962 - custom_f1: 0.6387 - weighted_custom_f1: 0.6421Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5284 - custom_f1: 0.6651 - weighted_custom_f1: 0.6694 - val_loss: 1.1301 - val_custom_f1: 0.4975 - val_weighted_custom_f1: 0.5085\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.5985 - custom_f1: 0.6376 - weighted_custom_f1: 0.6415Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5991 - custom_f1: 0.6363 - weighted_custom_f1: 0.6400 - val_loss: 1.1966 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5294\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 1.0527 - custom_f1: 0.4791 - weighted_custom_f1: 0.4835Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7481 - custom_f1: 0.5678 - weighted_custom_f1: 0.5728 - val_loss: 0.9947 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5158\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.5200 - custom_f1: 0.6650 - weighted_custom_f1: 0.6699Epoch 25/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5503 - custom_f1: 0.6577 - weighted_custom_f1: 0.6615 - val_loss: 1.2587 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5240\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.6176 - custom_f1: 0.6308 - weighted_custom_f1: 0.6341Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6249 - custom_f1: 0.6278 - weighted_custom_f1: 0.6316 - val_loss: 1.0517 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5366\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6047 - custom_f1: 0.6351 - weighted_custom_f1: 0.6378 - val_loss: 1.0563 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5294\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.5279 - custom_f1: 0.6625 - weighted_custom_f1: 0.6676Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5963 - custom_f1: 0.6388 - weighted_custom_f1: 0.6430 - val_loss: 1.2657 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5030\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5592 - custom_f1: 0.6598 - weighted_custom_f1: 0.6638 - val_loss: 1.0224 - val_custom_f1: 0.5009 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9816 - custom_f1: 0.4932 - weighted_custom_f1: 0.4991 - val_loss: 1.2576 - val_custom_f1: 0.4940 - val_weighted_custom_f1: 0.4993\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5166 - custom_f1: 0.6752 - weighted_custom_f1: 0.6789 - val_loss: 1.3300 - val_custom_f1: 0.5254 - val_weighted_custom_f1: 0.5259\n",
            "  5/105 [>.............................] - ETA: 1s - loss: 0.5630 - custom_f1: 0.6429 - weighted_custom_f1: 0.6495Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0401 - custom_f1: 0.4812 - weighted_custom_f1: 0.4855 - val_loss: 1.0188 - val_custom_f1: 0.4563 - val_weighted_custom_f1: 0.4556\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6177 - custom_f1: 0.6292 - weighted_custom_f1: 0.6323 - val_loss: 1.0468 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5378\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.5917 - custom_f1: 0.6538 - weighted_custom_f1: 0.6586Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5909 - custom_f1: 0.6398 - weighted_custom_f1: 0.6454 - val_loss: 1.1018 - val_custom_f1: 0.5221 - val_weighted_custom_f1: 0.5431\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5233 - custom_f1: 0.6648 - weighted_custom_f1: 0.6693 - val_loss: 1.2617 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5236\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.9416 - custom_f1: 0.5153 - weighted_custom_f1: 0.5197Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5739 - custom_f1: 0.6462 - weighted_custom_f1: 0.6511 - val_loss: 0.9762 - val_custom_f1: 0.4820 - val_weighted_custom_f1: 0.4903\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.5232 - custom_f1: 0.6682 - weighted_custom_f1: 0.6719Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5443 - custom_f1: 0.6621 - weighted_custom_f1: 0.6640 - val_loss: 1.2286 - val_custom_f1: 0.5234 - val_weighted_custom_f1: 0.5198\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.6014 - custom_f1: 0.6299 - weighted_custom_f1: 0.6351Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5375 - custom_f1: 0.6630 - weighted_custom_f1: 0.6684 - val_loss: 1.2150 - val_custom_f1: 0.5532 - val_weighted_custom_f1: 0.5600\n",
            " 39/105 [==========>...................] - ETA: 0s - loss: 0.5283 - custom_f1: 0.6827 - weighted_custom_f1: 0.6872Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5922 - custom_f1: 0.6474 - weighted_custom_f1: 0.6512 - val_loss: 1.1845 - val_custom_f1: 0.4942 - val_weighted_custom_f1: 0.5148\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7579 - custom_f1: 0.5604 - weighted_custom_f1: 0.5650 - val_loss: 0.9614 - val_custom_f1: 0.4821 - val_weighted_custom_f1: 0.4905\n",
            "Epoch 65/100\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5408 - custom_f1: 0.6626 - weighted_custom_f1: 0.6662 - val_loss: 1.2654 - val_custom_f1: 0.4747 - val_weighted_custom_f1: 0.4817\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7965 - custom_f1: 0.5750 - weighted_custom_f1: 0.5750Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6033 - custom_f1: 0.6316 - weighted_custom_f1: 0.6353 - val_loss: 1.0640 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5277\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6218 - custom_f1: 0.6245 - weighted_custom_f1: 0.6293 - val_loss: 1.1570 - val_custom_f1: 0.5164 - val_weighted_custom_f1: 0.5242\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5728 - custom_f1: 0.6518 - weighted_custom_f1: 0.6559 - val_loss: 1.0547 - val_custom_f1: 0.4881 - val_weighted_custom_f1: 0.4999\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9858 - custom_f1: 0.4855 - weighted_custom_f1: 0.4906 - val_loss: 1.2631 - val_custom_f1: 0.4491 - val_weighted_custom_f1: 0.4562\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5387 - custom_f1: 0.6595 - weighted_custom_f1: 0.6635 - val_loss: 1.2325 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.5125\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5171 - custom_f1: 0.6727 - weighted_custom_f1: 0.6765 - val_loss: 1.4917 - val_custom_f1: 0.5263 - val_weighted_custom_f1: 0.5259\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.7672 - custom_f1: 0.5444 - weighted_custom_f1: 0.5462Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6225 - custom_f1: 0.6223 - weighted_custom_f1: 0.6275 - val_loss: 1.1458 - val_custom_f1: 0.4925 - val_weighted_custom_f1: 0.5002\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9863 - custom_f1: 0.4988 - weighted_custom_f1: 0.5038 - val_loss: 1.0158 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5096\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5967 - custom_f1: 0.6414 - weighted_custom_f1: 0.6458 - val_loss: 1.0368 - val_custom_f1: 0.5216 - val_weighted_custom_f1: 0.5439\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5289 - custom_f1: 0.6665 - weighted_custom_f1: 0.6709 - val_loss: 1.3553 - val_custom_f1: 0.5093 - val_weighted_custom_f1: 0.5326\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5763 - custom_f1: 0.6493 - weighted_custom_f1: 0.6532 - val_loss: 1.0779 - val_custom_f1: 0.5337 - val_weighted_custom_f1: 0.5439\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5526 - custom_f1: 0.6629 - weighted_custom_f1: 0.6677 - val_loss: 1.2171 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5402\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5263 - custom_f1: 0.6690 - weighted_custom_f1: 0.6729 - val_loss: 1.3044 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5461\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7429 - custom_f1: 0.5644 - weighted_custom_f1: 0.5674 - val_loss: 0.9907 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5096\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5811 - custom_f1: 0.6449 - weighted_custom_f1: 0.6493 - val_loss: 1.1738 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5288\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6408 - custom_f1: 0.5000 - weighted_custom_f1: 0.5000Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5472 - custom_f1: 0.6628 - weighted_custom_f1: 0.6671 - val_loss: 1.3451 - val_custom_f1: 0.5105 - val_weighted_custom_f1: 0.5152\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 0.9270 - custom_f1: 0.5028 - weighted_custom_f1: 0.5065Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6225 - custom_f1: 0.6305 - weighted_custom_f1: 0.6336 - val_loss: 1.0896 - val_custom_f1: 0.5466 - val_weighted_custom_f1: 0.5524\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5094 - custom_f1: 0.6781 - weighted_custom_f1: 0.6830Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6293 - custom_f1: 0.6222 - weighted_custom_f1: 0.6273 - val_loss: 1.0863 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5142\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9882 - custom_f1: 0.4923 - weighted_custom_f1: 0.4971 - val_loss: 1.2888 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.4945\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.5303 - custom_f1: 0.6826 - weighted_custom_f1: 0.6839Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5400 - custom_f1: 0.6660 - weighted_custom_f1: 0.6699 - val_loss: 1.3965 - val_custom_f1: 0.5303 - val_weighted_custom_f1: 0.5347\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.4987 - custom_f1: 0.6794 - weighted_custom_f1: 0.6840Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5567 - custom_f1: 0.6597 - weighted_custom_f1: 0.6633 - val_loss: 1.0559 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5290\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5095 - custom_f1: 0.6850 - weighted_custom_f1: 0.6890 - val_loss: 1.3893 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5132\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6603 - custom_f1: 0.6094 - weighted_custom_f1: 0.6133 - val_loss: 1.0356 - val_custom_f1: 0.5128 - val_weighted_custom_f1: 0.5336\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9295 - custom_f1: 0.5039 - weighted_custom_f1: 0.5083 - val_loss: 0.9744 - val_custom_f1: 0.4713 - val_weighted_custom_f1: 0.4718\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5851 - custom_f1: 0.6416 - weighted_custom_f1: 0.6482 - val_loss: 1.0042 - val_custom_f1: 0.5190 - val_weighted_custom_f1: 0.5408\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.5384 - custom_f1: 0.6667 - weighted_custom_f1: 0.6701Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5669 - custom_f1: 0.6532 - weighted_custom_f1: 0.6571 - val_loss: 0.9954 - val_custom_f1: 0.5246 - val_weighted_custom_f1: 0.5481\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.8675 - custom_f1: 0.5069 - weighted_custom_f1: 0.5109Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5146 - custom_f1: 0.6765 - weighted_custom_f1: 0.6802 - val_loss: 1.1809 - val_custom_f1: 0.5051 - val_weighted_custom_f1: 0.5274\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.5202 - custom_f1: 0.6717 - weighted_custom_f1: 0.6762Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5574 - custom_f1: 0.6590 - weighted_custom_f1: 0.6647 - val_loss: 1.1096 - val_custom_f1: 0.5015 - val_weighted_custom_f1: 0.5024\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5115 - custom_f1: 0.6711 - weighted_custom_f1: 0.6782 - val_loss: 1.3033 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5417\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.6232 - custom_f1: 0.6336 - weighted_custom_f1: 0.6376Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7188 - custom_f1: 0.5785 - weighted_custom_f1: 0.5819 - val_loss: 1.0636 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5319\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.6488 - custom_f1: 0.6156 - weighted_custom_f1: 0.6191Epoch 28/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5935 - custom_f1: 0.6453 - weighted_custom_f1: 0.6501 - val_loss: 1.0893 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5211\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.5628 - custom_f1: 0.6590 - weighted_custom_f1: 0.6636Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5320 - custom_f1: 0.6709 - weighted_custom_f1: 0.6754 - val_loss: 1.3056 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5225\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.5337 - custom_f1: 0.6720 - weighted_custom_f1: 0.6756Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6212 - custom_f1: 0.6344 - weighted_custom_f1: 0.6382 - val_loss: 1.0302 - val_custom_f1: 0.5274 - val_weighted_custom_f1: 0.5347\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9856 - custom_f1: 0.4908 - weighted_custom_f1: 0.4959 - val_loss: 1.2762 - val_custom_f1: 0.4487 - val_weighted_custom_f1: 0.4577\n",
            "Epoch 59/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5081 - custom_f1: 0.7222 - weighted_custom_f1: 0.7222Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6245 - custom_f1: 0.6232 - weighted_custom_f1: 0.6276 - val_loss: 1.0426 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5203\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.5871 - custom_f1: 0.6458 - weighted_custom_f1: 0.6497Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5416 - custom_f1: 0.6671 - weighted_custom_f1: 0.6718 - val_loss: 1.4314 - val_custom_f1: 0.5344 - val_weighted_custom_f1: 0.5455\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5468 - custom_f1: 0.6571 - weighted_custom_f1: 0.6620 - val_loss: 1.0904 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5345\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5041 - custom_f1: 0.6838 - weighted_custom_f1: 0.6867 - val_loss: 1.5633 - val_custom_f1: 0.5447 - val_weighted_custom_f1: 0.5404\n",
            "Epoch 66/100\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5849 - custom_f1: 0.6478 - weighted_custom_f1: 0.6517 - val_loss: 0.9899 - val_custom_f1: 0.5027 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6373 - custom_f1: 0.6207 - weighted_custom_f1: 0.6239 - val_loss: 1.0154 - val_custom_f1: 0.5381 - val_weighted_custom_f1: 0.5467\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.7145 - custom_f1: 0.5723 - weighted_custom_f1: 0.5768Epoch 59/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5615 - custom_f1: 0.6546 - weighted_custom_f1: 0.6611 - val_loss: 0.9659 - val_custom_f1: 0.5237 - val_weighted_custom_f1: 0.5329\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5389 - custom_f1: 0.6684 - weighted_custom_f1: 0.6727 - val_loss: 1.1163 - val_custom_f1: 0.5016 - val_weighted_custom_f1: 0.5009\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5241 - custom_f1: 0.6813 - weighted_custom_f1: 0.6847 - val_loss: 1.2930 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5430\n",
            "Epoch 67/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6008 - custom_f1: 0.6176 - weighted_custom_f1: 0.6176Epoch 63/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.9742 - custom_f1: 0.5023 - weighted_custom_f1: 0.5063 - val_loss: 1.2123 - val_custom_f1: 0.4268 - val_weighted_custom_f1: 0.4241\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.5186 - custom_f1: 0.6731 - weighted_custom_f1: 0.6775Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5381 - custom_f1: 0.6664 - weighted_custom_f1: 0.6709 - val_loss: 1.2136 - val_custom_f1: 0.5349 - val_weighted_custom_f1: 0.5359\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5765 - custom_f1: 0.6515 - weighted_custom_f1: 0.6565 - val_loss: 1.0823 - val_custom_f1: 0.4990 - val_weighted_custom_f1: 0.5108\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7328 - custom_f1: 0.5719 - weighted_custom_f1: 0.5753 - val_loss: 0.9628 - val_custom_f1: 0.5139 - val_weighted_custom_f1: 0.5191\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5369 - custom_f1: 0.6377 - weighted_custom_f1: 0.6377Epoch 29/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5186 - custom_f1: 0.6742 - weighted_custom_f1: 0.6798 - val_loss: 1.2989 - val_custom_f1: 0.5272 - val_weighted_custom_f1: 0.5362\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.9692 - custom_f1: 0.4941 - weighted_custom_f1: 0.5003Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6013 - custom_f1: 0.6385 - weighted_custom_f1: 0.6423 - val_loss: 1.1479 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5538\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.7268 - custom_f1: 0.5511 - weighted_custom_f1: 0.5564Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6234 - custom_f1: 0.6240 - weighted_custom_f1: 0.6306 - val_loss: 1.1303 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5233\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9800 - custom_f1: 0.4891 - weighted_custom_f1: 0.4939 - val_loss: 1.2911 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5018\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5220 - custom_f1: 0.6693 - weighted_custom_f1: 0.6741 - val_loss: 1.4075 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5505\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5714 - custom_f1: 0.6551 - weighted_custom_f1: 0.6599 - val_loss: 1.0384 - val_custom_f1: 0.4792 - val_weighted_custom_f1: 0.5016\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5122 - custom_f1: 0.6803 - weighted_custom_f1: 0.6839 - val_loss: 1.4854 - val_custom_f1: 0.5288 - val_weighted_custom_f1: 0.5245\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7530 - custom_f1: 0.5000 - weighted_custom_f1: 0.5000Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6314 - custom_f1: 0.6248 - weighted_custom_f1: 0.6296 - val_loss: 1.0573 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9606 - custom_f1: 0.4997 - weighted_custom_f1: 0.5040 - val_loss: 1.1064 - val_custom_f1: 0.5062 - val_weighted_custom_f1: 0.4964\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.5503 - custom_f1: 0.6535 - weighted_custom_f1: 0.6594Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5749 - custom_f1: 0.6467 - weighted_custom_f1: 0.6516 - val_loss: 0.9946 - val_custom_f1: 0.5181 - val_weighted_custom_f1: 0.5396\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5361 - custom_f1: 0.6684 - weighted_custom_f1: 0.6734 - val_loss: 1.2016 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5339\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5680 - custom_f1: 0.6504 - weighted_custom_f1: 0.6553 - val_loss: 0.9883 - val_custom_f1: 0.4971 - val_weighted_custom_f1: 0.5073\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5223 - custom_f1: 0.6688 - weighted_custom_f1: 0.6726 - val_loss: 1.2268 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5357\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4938 - custom_f1: 0.6816 - weighted_custom_f1: 0.6866 - val_loss: 1.2655 - val_custom_f1: 0.5054 - val_weighted_custom_f1: 0.5285\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.5446 - custom_f1: 0.6776 - weighted_custom_f1: 0.6816Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5829 - custom_f1: 0.6499 - weighted_custom_f1: 0.6532 - val_loss: 1.2199 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5203\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6519 - custom_f1: 0.6206 - weighted_custom_f1: 0.6247Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7186 - custom_f1: 0.5745 - weighted_custom_f1: 0.5805 - val_loss: 0.9982 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5060\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5169 - custom_f1: 0.6785 - weighted_custom_f1: 0.6829 - val_loss: 1.2753 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5233\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.5061 - custom_f1: 0.6829 - weighted_custom_f1: 0.6878Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7148 - custom_f1: 0.6345 - weighted_custom_f1: 0.6411 - val_loss: 1.0864 - val_custom_f1: 0.5444 - val_weighted_custom_f1: 0.5433\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.5212 - custom_f1: 0.6738 - weighted_custom_f1: 0.6775Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9747 - custom_f1: 0.4911 - weighted_custom_f1: 0.4952 - val_loss: 1.2784 - val_custom_f1: 0.4839 - val_weighted_custom_f1: 0.4886\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6522 - custom_f1: 0.6205 - weighted_custom_f1: 0.6247 - val_loss: 1.0760 - val_custom_f1: 0.4836 - val_weighted_custom_f1: 0.4961\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3422 - custom_f1: 0.6818 - weighted_custom_f1: 0.6818Epoch 71/100\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5411 - custom_f1: 0.6671 - weighted_custom_f1: 0.6721 - val_loss: 1.3207 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5289\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5563 - custom_f1: 0.6603 - weighted_custom_f1: 0.6662 - val_loss: 1.0690 - val_custom_f1: 0.5049 - val_weighted_custom_f1: 0.5276\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.5199 - custom_f1: 0.6743 - weighted_custom_f1: 0.6778Epoch 67/100\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4820 - custom_f1: 0.6929 - weighted_custom_f1: 0.6950 - val_loss: 1.5655 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5070\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.5623 - custom_f1: 0.6379 - weighted_custom_f1: 0.6424Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9933 - custom_f1: 0.4916 - weighted_custom_f1: 0.4979 - val_loss: 1.0578 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.4912\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.4847 - custom_f1: 0.7005 - weighted_custom_f1: 0.7028Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6285 - custom_f1: 0.6204 - weighted_custom_f1: 0.6250 - val_loss: 1.0670 - val_custom_f1: 0.5345 - val_weighted_custom_f1: 0.5442\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5711 - custom_f1: 0.6496 - weighted_custom_f1: 0.6526 - val_loss: 1.0483 - val_custom_f1: 0.5216 - val_weighted_custom_f1: 0.5437\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5310 - custom_f1: 0.6750 - weighted_custom_f1: 0.6786 - val_loss: 1.3894 - val_custom_f1: 0.5366 - val_weighted_custom_f1: 0.5305\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5528 - custom_f1: 0.6582 - weighted_custom_f1: 0.6648 - val_loss: 0.9702 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5189\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7051 - custom_f1: 0.5902 - weighted_custom_f1: 0.5902Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5222 - custom_f1: 0.6708 - weighted_custom_f1: 0.6757 - val_loss: 1.2805 - val_custom_f1: 0.5168 - val_weighted_custom_f1: 0.5391\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5040 - custom_f1: 0.6793 - weighted_custom_f1: 0.6830 - val_loss: 1.1699 - val_custom_f1: 0.5411 - val_weighted_custom_f1: 0.5478\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5726 - custom_f1: 0.6531 - weighted_custom_f1: 0.6575 - val_loss: 1.1054 - val_custom_f1: 0.4601 - val_weighted_custom_f1: 0.4723\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.4506 - custom_f1: 0.6862 - weighted_custom_f1: 0.6912Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.7200 - custom_f1: 0.5744 - weighted_custom_f1: 0.5801 - val_loss: 1.0043 - val_custom_f1: 0.4795 - val_weighted_custom_f1: 0.4914\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5105 - custom_f1: 0.6804 - weighted_custom_f1: 0.6876 - val_loss: 1.2712 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6199 - custom_f1: 0.6257 - weighted_custom_f1: 0.6301 - val_loss: 1.0881 - val_custom_f1: 0.4782 - val_weighted_custom_f1: 0.4899\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.5711 - custom_f1: 0.6558 - weighted_custom_f1: 0.6602Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9623 - custom_f1: 0.4839 - weighted_custom_f1: 0.4893 - val_loss: 1.2942 - val_custom_f1: 0.4407 - val_weighted_custom_f1: 0.4507\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.6640 - custom_f1: 0.6012 - weighted_custom_f1: 0.6086Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5997 - custom_f1: 0.6351 - weighted_custom_f1: 0.6399 - val_loss: 1.1003 - val_custom_f1: 0.5559 - val_weighted_custom_f1: 0.5609\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.4855 - custom_f1: 0.6934 - weighted_custom_f1: 0.6979Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5204 - custom_f1: 0.6763 - weighted_custom_f1: 0.6805 - val_loss: 1.2911 - val_custom_f1: 0.5195 - val_weighted_custom_f1: 0.5308\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5319 - custom_f1: 0.6692 - weighted_custom_f1: 0.6738 - val_loss: 1.1374 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5324\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4915 - custom_f1: 0.6889 - weighted_custom_f1: 0.6932 - val_loss: 1.5747 - val_custom_f1: 0.5647 - val_weighted_custom_f1: 0.5553\n",
            "Epoch 69/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7317 - custom_f1: 0.7674 - weighted_custom_f1: 0.7674Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9691 - custom_f1: 0.4932 - weighted_custom_f1: 0.4980 - val_loss: 1.0590 - val_custom_f1: 0.4990 - val_weighted_custom_f1: 0.4928\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5655 - custom_f1: 0.6562 - weighted_custom_f1: 0.6609 - val_loss: 0.9971 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5299\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 0.5172 - custom_f1: 0.6768 - weighted_custom_f1: 0.6815Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6236 - custom_f1: 0.6269 - weighted_custom_f1: 0.6311 - val_loss: 1.0107 - val_custom_f1: 0.5225 - val_weighted_custom_f1: 0.5344\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6392 - custom_f1: 0.6944 - weighted_custom_f1: 0.6944Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5473 - custom_f1: 0.6645 - weighted_custom_f1: 0.6702 - val_loss: 1.1394 - val_custom_f1: 0.5203 - val_weighted_custom_f1: 0.5227\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4919 - custom_f1: 0.7018 - weighted_custom_f1: 0.7018Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5539 - custom_f1: 0.6574 - weighted_custom_f1: 0.6621 - val_loss: 0.9805 - val_custom_f1: 0.5081 - val_weighted_custom_f1: 0.5171\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.5344 - custom_f1: 0.6685 - weighted_custom_f1: 0.6727Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4875 - custom_f1: 0.6864 - weighted_custom_f1: 0.6921 - val_loss: 1.2973 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5443\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4897 - custom_f1: 0.6896 - weighted_custom_f1: 0.6938 - val_loss: 1.3744 - val_custom_f1: 0.5475 - val_weighted_custom_f1: 0.5473\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.5540 - custom_f1: 0.6619 - weighted_custom_f1: 0.6630Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7276 - custom_f1: 0.5798 - weighted_custom_f1: 0.5844 - val_loss: 1.0209 - val_custom_f1: 0.5083 - val_weighted_custom_f1: 0.5158\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.5690 - custom_f1: 0.6659 - weighted_custom_f1: 0.6676Epoch 32/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5766 - custom_f1: 0.6514 - weighted_custom_f1: 0.6573 - val_loss: 1.0783 - val_custom_f1: 0.4696 - val_weighted_custom_f1: 0.4805\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.5069 - custom_f1: 0.6761 - weighted_custom_f1: 0.6780Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5451 - custom_f1: 0.6715 - weighted_custom_f1: 0.6748 - val_loss: 1.2533 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5274\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5115 - custom_f1: 0.6787 - weighted_custom_f1: 0.6824Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0004 - custom_f1: 0.4800 - weighted_custom_f1: 0.4845 - val_loss: 1.3395 - val_custom_f1: 0.4509 - val_weighted_custom_f1: 0.4600\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6081 - custom_f1: 0.6341 - weighted_custom_f1: 0.6379 - val_loss: 1.2651 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5413\n",
            "Epoch 73/100\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.4938 - custom_f1: 0.6858 - weighted_custom_f1: 0.6877Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5726 - custom_f1: 0.6526 - weighted_custom_f1: 0.6562 - val_loss: 1.0285 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5339\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.4884 - custom_f1: 0.6946 - weighted_custom_f1: 0.6955Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5158 - custom_f1: 0.6795 - weighted_custom_f1: 0.6832 - val_loss: 1.4521 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5378\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5376 - custom_f1: 0.6681 - weighted_custom_f1: 0.6726 - val_loss: 1.0901 - val_custom_f1: 0.5133 - val_weighted_custom_f1: 0.5359\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5320 - custom_f1: 0.6726 - weighted_custom_f1: 0.6780 - val_loss: 1.4270 - val_custom_f1: 0.5192 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9458 - custom_f1: 0.5066 - weighted_custom_f1: 0.5098 - val_loss: 0.9588 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.4913\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5629 - custom_f1: 0.6610 - weighted_custom_f1: 0.6633 - val_loss: 0.9976 - val_custom_f1: 0.4892 - val_weighted_custom_f1: 0.5113\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.4889 - custom_f1: 0.7082 - weighted_custom_f1: 0.7105Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6147 - custom_f1: 0.6336 - weighted_custom_f1: 0.6375 - val_loss: 1.0691 - val_custom_f1: 0.4781 - val_weighted_custom_f1: 0.4852\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5153 - custom_f1: 0.6763 - weighted_custom_f1: 0.6800 - val_loss: 1.2545 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5299\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.9439 - custom_f1: 0.4954 - weighted_custom_f1: 0.5003Epoch 71/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5489 - custom_f1: 0.6636 - weighted_custom_f1: 0.6671 - val_loss: 1.0004 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5338\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5178 - custom_f1: 0.6776 - weighted_custom_f1: 0.6819 - val_loss: 1.1909 - val_custom_f1: 0.4895 - val_weighted_custom_f1: 0.5108\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.4993 - custom_f1: 0.6832 - weighted_custom_f1: 0.6864Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5058 - custom_f1: 0.6840 - weighted_custom_f1: 0.6868 - val_loss: 1.2264 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5294\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.6015 - custom_f1: 0.6413 - weighted_custom_f1: 0.6466Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5805 - custom_f1: 0.6466 - weighted_custom_f1: 0.6514 - val_loss: 1.1210 - val_custom_f1: 0.5052 - val_weighted_custom_f1: 0.5162\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.5242 - custom_f1: 0.6731 - weighted_custom_f1: 0.6777Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6950 - custom_f1: 0.5869 - weighted_custom_f1: 0.5900 - val_loss: 0.9899 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4944\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.9538 - custom_f1: 0.5025 - weighted_custom_f1: 0.5082Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9856 - custom_f1: 0.4864 - weighted_custom_f1: 0.4920 - val_loss: 1.2505 - val_custom_f1: 0.4757 - val_weighted_custom_f1: 0.4829\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5923 - custom_f1: 0.6368 - weighted_custom_f1: 0.6417 - val_loss: 1.1734 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5306\n",
            "Epoch 65/100\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.5888 - custom_f1: 0.6384 - weighted_custom_f1: 0.6424Epoch 74/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5071 - custom_f1: 0.6789 - weighted_custom_f1: 0.6821 - val_loss: 1.3767 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5364\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5918 - custom_f1: 0.6408 - weighted_custom_f1: 0.6462 - val_loss: 1.3290 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5294\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.5791 - custom_f1: 0.6515 - weighted_custom_f1: 0.6579Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5286 - custom_f1: 0.6732 - weighted_custom_f1: 0.6777 - val_loss: 1.2845 - val_custom_f1: 0.5142 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5276 - custom_f1: 0.6719 - weighted_custom_f1: 0.6761 - val_loss: 1.0311 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5326\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4728 - custom_f1: 0.7038 - weighted_custom_f1: 0.7071 - val_loss: 1.5382 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9427 - custom_f1: 0.5028 - weighted_custom_f1: 0.5077 - val_loss: 0.9670 - val_custom_f1: 0.4935 - val_weighted_custom_f1: 0.4955\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.6006 - custom_f1: 0.6396 - weighted_custom_f1: 0.6449Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5906 - custom_f1: 0.6447 - weighted_custom_f1: 0.6493 - val_loss: 1.0423 - val_custom_f1: 0.5195 - val_weighted_custom_f1: 0.5408\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.5925 - custom_f1: 0.6383 - weighted_custom_f1: 0.6432Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5863 - custom_f1: 0.6426 - weighted_custom_f1: 0.6463 - val_loss: 1.1120 - val_custom_f1: 0.5386 - val_weighted_custom_f1: 0.5478\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.4999 - custom_f1: 0.6925 - weighted_custom_f1: 0.6946Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5165 - custom_f1: 0.6821 - weighted_custom_f1: 0.6867 - val_loss: 1.2792 - val_custom_f1: 0.5401 - val_weighted_custom_f1: 0.5374\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.5509 - custom_f1: 0.6606 - weighted_custom_f1: 0.6666Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5156 - custom_f1: 0.6774 - weighted_custom_f1: 0.6816 - val_loss: 1.2679 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5400\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.5013 - custom_f1: 0.6862 - weighted_custom_f1: 0.6886Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5406 - custom_f1: 0.6694 - weighted_custom_f1: 0.6721 - val_loss: 0.9879 - val_custom_f1: 0.5228 - val_weighted_custom_f1: 0.5321\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5035 - custom_f1: 0.6795 - weighted_custom_f1: 0.6860 - val_loss: 1.2736 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5230\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.5169 - custom_f1: 0.6813 - weighted_custom_f1: 0.6857Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5714 - custom_f1: 0.6493 - weighted_custom_f1: 0.6551 - val_loss: 1.1731 - val_custom_f1: 0.5102 - val_weighted_custom_f1: 0.5316\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.5178 - custom_f1: 0.6784 - weighted_custom_f1: 0.6827Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7135 - custom_f1: 0.5846 - weighted_custom_f1: 0.5895 - val_loss: 0.9719 - val_custom_f1: 0.4812 - val_weighted_custom_f1: 0.4938\n",
            " 10/105 [=>............................] - ETA: 0s - loss: 0.5544 - custom_f1: 0.6607 - weighted_custom_f1: 0.6656Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9700 - custom_f1: 0.4877 - weighted_custom_f1: 0.4910 - val_loss: 1.3797 - val_custom_f1: 0.4651 - val_weighted_custom_f1: 0.4571\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6066 - custom_f1: 0.6293 - weighted_custom_f1: 0.6340 - val_loss: 1.1805 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5574\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.5520 - custom_f1: 0.6602 - weighted_custom_f1: 0.6629Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5103 - custom_f1: 0.6817 - weighted_custom_f1: 0.6847 - val_loss: 1.2452 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5110\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5379 - custom_f1: 0.6726 - weighted_custom_f1: 0.6780 - val_loss: 1.2655 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5264\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.5927 - custom_f1: 0.6406 - weighted_custom_f1: 0.6454Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5983 - custom_f1: 0.6408 - weighted_custom_f1: 0.6463 - val_loss: 1.2838 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5297\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4775 - custom_f1: 0.6946 - weighted_custom_f1: 0.7007 - val_loss: 1.6526 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5212\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9618 - custom_f1: 0.5001 - weighted_custom_f1: 0.5054 - val_loss: 0.9820 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.4911\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5252 - custom_f1: 0.6760 - weighted_custom_f1: 0.6796 - val_loss: 1.1050 - val_custom_f1: 0.5155 - val_weighted_custom_f1: 0.5383\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.5815 - custom_f1: 0.6532 - weighted_custom_f1: 0.6568Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5630 - custom_f1: 0.6471 - weighted_custom_f1: 0.6515 - val_loss: 1.0090 - val_custom_f1: 0.4958 - val_weighted_custom_f1: 0.5180\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5162 - custom_f1: 0.6819 - weighted_custom_f1: 0.6867 - val_loss: 1.1610 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5880 - custom_f1: 0.6412 - weighted_custom_f1: 0.6464 - val_loss: 1.1560 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5351\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4857 - custom_f1: 0.6860 - weighted_custom_f1: 0.6910 - val_loss: 1.3581 - val_custom_f1: 0.5179 - val_weighted_custom_f1: 0.5416\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4815 - custom_f1: 0.6909 - weighted_custom_f1: 0.6964 - val_loss: 1.2075 - val_custom_f1: 0.5172 - val_weighted_custom_f1: 0.5402\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5489 - custom_f1: 0.6613 - weighted_custom_f1: 0.6651 - val_loss: 1.0258 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5372\n",
            "Epoch 69/100\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5721 - custom_f1: 0.6531 - weighted_custom_f1: 0.6578 - val_loss: 1.1300 - val_custom_f1: 0.4957 - val_weighted_custom_f1: 0.5072\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.4951 - custom_f1: 0.6827 - weighted_custom_f1: 0.6871Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7052 - custom_f1: 0.5850 - weighted_custom_f1: 0.5891 - val_loss: 1.0425 - val_custom_f1: 0.5151 - val_weighted_custom_f1: 0.5232\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9885 - custom_f1: 0.4858 - weighted_custom_f1: 0.4906 - val_loss: 1.3752 - val_custom_f1: 0.4253 - val_weighted_custom_f1: 0.4352\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5972 - custom_f1: 0.6428 - weighted_custom_f1: 0.6483 - val_loss: 1.1384 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5123\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.5301 - custom_f1: 0.6721 - weighted_custom_f1: 0.6780Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5060 - custom_f1: 0.6853 - weighted_custom_f1: 0.6880 - val_loss: 1.4597 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5277\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.9475 - custom_f1: 0.4731 - weighted_custom_f1: 0.4760Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5382 - custom_f1: 0.6713 - weighted_custom_f1: 0.6746 - val_loss: 1.3184 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5374\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.5535 - custom_f1: 0.6557 - weighted_custom_f1: 0.6576Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5219 - custom_f1: 0.6754 - weighted_custom_f1: 0.6798 - val_loss: 1.0689 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5230\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5777 - custom_f1: 0.6447 - weighted_custom_f1: 0.6522 - val_loss: 1.1103 - val_custom_f1: 0.5572 - val_weighted_custom_f1: 0.5555\n",
            "Epoch 73/100\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4793 - custom_f1: 0.6931 - weighted_custom_f1: 0.6961 - val_loss: 1.8801 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9730 - custom_f1: 0.4937 - weighted_custom_f1: 0.4988 - val_loss: 1.1008 - val_custom_f1: 0.4834 - val_weighted_custom_f1: 0.4804\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5592 - custom_f1: 0.6595 - weighted_custom_f1: 0.6660 - val_loss: 1.0121 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5841 - custom_f1: 0.6403 - weighted_custom_f1: 0.6461 - val_loss: 1.1953 - val_custom_f1: 0.5044 - val_weighted_custom_f1: 0.5258\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.5668 - custom_f1: 0.6742 - weighted_custom_f1: 0.6768Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5152 - custom_f1: 0.6841 - weighted_custom_f1: 0.6887 - val_loss: 1.1801 - val_custom_f1: 0.5190 - val_weighted_custom_f1: 0.5176\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4951 - custom_f1: 0.5778 - weighted_custom_f1: 0.5778Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5211 - custom_f1: 0.6753 - weighted_custom_f1: 0.6811 - val_loss: 1.2690 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5352 - custom_f1: 0.6705 - weighted_custom_f1: 0.6755 - val_loss: 0.9985 - val_custom_f1: 0.5167 - val_weighted_custom_f1: 0.5286\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4919 - custom_f1: 0.6923 - weighted_custom_f1: 0.6967 - val_loss: 1.2311 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5399\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.5046 - custom_f1: 0.6857 - weighted_custom_f1: 0.6894Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5547 - custom_f1: 0.6590 - weighted_custom_f1: 0.6640 - val_loss: 1.1956 - val_custom_f1: 0.5015 - val_weighted_custom_f1: 0.5239\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.5102 - custom_f1: 0.6831 - weighted_custom_f1: 0.6867Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7071 - custom_f1: 0.5894 - weighted_custom_f1: 0.5939 - val_loss: 1.0305 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5259\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.5877 - custom_f1: 0.6433 - weighted_custom_f1: 0.6472Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9955 - custom_f1: 0.4779 - weighted_custom_f1: 0.4813 - val_loss: 1.2703 - val_custom_f1: 0.4816 - val_weighted_custom_f1: 0.4863\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.5073 - custom_f1: 0.6971 - weighted_custom_f1: 0.7029Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5835 - custom_f1: 0.6366 - weighted_custom_f1: 0.6418 - val_loss: 1.2546 - val_custom_f1: 0.5255 - val_weighted_custom_f1: 0.5364\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.5109 - custom_f1: 0.6836 - weighted_custom_f1: 0.6877Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5140 - custom_f1: 0.6765 - weighted_custom_f1: 0.6815 - val_loss: 1.2552 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5112\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5445 - custom_f1: 0.6716 - weighted_custom_f1: 0.6774 - val_loss: 1.4687 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5370\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.5518 - custom_f1: 0.6627 - weighted_custom_f1: 0.6657Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5956 - custom_f1: 0.6431 - weighted_custom_f1: 0.6475 - val_loss: 1.0612 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5116\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5225 - custom_f1: 0.6715 - weighted_custom_f1: 0.6764 - val_loss: 1.1195 - val_custom_f1: 0.5116 - val_weighted_custom_f1: 0.5338\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.5179 - custom_f1: 0.6867 - weighted_custom_f1: 0.6932Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4738 - custom_f1: 0.6988 - weighted_custom_f1: 0.7046 - val_loss: 1.5864 - val_custom_f1: 0.5271 - val_weighted_custom_f1: 0.5255\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.5350 - custom_f1: 0.6640 - weighted_custom_f1: 0.6686Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6121 - custom_f1: 0.6325 - weighted_custom_f1: 0.6370 - val_loss: 1.0405 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5238\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5737 - custom_f1: 0.6491 - weighted_custom_f1: 0.6541 - val_loss: 1.0446 - val_custom_f1: 0.5165 - val_weighted_custom_f1: 0.5387\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9544 - custom_f1: 0.4992 - weighted_custom_f1: 0.5048 - val_loss: 0.9719 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5088 - custom_f1: 0.6839 - weighted_custom_f1: 0.6871 - val_loss: 1.2614 - val_custom_f1: 0.5351 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4836 - custom_f1: 0.6907 - weighted_custom_f1: 0.6936 - val_loss: 1.4171 - val_custom_f1: 0.5526 - val_weighted_custom_f1: 0.5584\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.5362 - custom_f1: 0.6524 - weighted_custom_f1: 0.6565Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5338 - custom_f1: 0.6619 - weighted_custom_f1: 0.6684 - val_loss: 1.0547 - val_custom_f1: 0.5190 - val_weighted_custom_f1: 0.5287\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.5175 - custom_f1: 0.6755 - weighted_custom_f1: 0.6801Epoch 74/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5598 - custom_f1: 0.6614 - weighted_custom_f1: 0.6640 - val_loss: 1.1325 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5021\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.4620 - custom_f1: 0.7109 - weighted_custom_f1: 0.7142Epoch 76/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4972 - custom_f1: 0.6880 - weighted_custom_f1: 0.6919 - val_loss: 1.2581 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5411\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0045 - custom_f1: 0.4823 - weighted_custom_f1: 0.4877 - val_loss: 1.2699 - val_custom_f1: 0.4217 - val_weighted_custom_f1: 0.4315\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6880 - custom_f1: 0.5946 - weighted_custom_f1: 0.5982 - val_loss: 1.0428 - val_custom_f1: 0.4844 - val_weighted_custom_f1: 0.4939\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.4609 - custom_f1: 0.7064 - weighted_custom_f1: 0.7095Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6048 - custom_f1: 0.6389 - weighted_custom_f1: 0.6430 - val_loss: 1.4002 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5140\n",
            " 39/105 [==========>...................] - ETA: 0s - loss: 0.5284 - custom_f1: 0.6851 - weighted_custom_f1: 0.6873Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5165 - custom_f1: 0.6811 - weighted_custom_f1: 0.6877 - val_loss: 1.2968 - val_custom_f1: 0.5176 - val_weighted_custom_f1: 0.5229\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5131 - custom_f1: 0.6758 - weighted_custom_f1: 0.6804 - val_loss: 1.2871 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5115\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5571 - custom_f1: 0.6597 - weighted_custom_f1: 0.6643 - val_loss: 1.2340 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5267\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4708 - custom_f1: 0.6996 - weighted_custom_f1: 0.7031 - val_loss: 1.9255 - val_custom_f1: 0.5354 - val_weighted_custom_f1: 0.5306\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4599 - custom_f1: 0.5556 - weighted_custom_f1: 0.5556Epoch 71/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9429 - custom_f1: 0.5016 - weighted_custom_f1: 0.5075 - val_loss: 0.9914 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5192\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5256 - custom_f1: 0.6750 - weighted_custom_f1: 0.6793 - val_loss: 1.1433 - val_custom_f1: 0.5074 - val_weighted_custom_f1: 0.5306\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5434 - custom_f1: 0.6649 - weighted_custom_f1: 0.6688 - val_loss: 1.0347 - val_custom_f1: 0.4901 - val_weighted_custom_f1: 0.5110\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4958 - custom_f1: 0.6841 - weighted_custom_f1: 0.6881 - val_loss: 1.2340 - val_custom_f1: 0.5312 - val_weighted_custom_f1: 0.5316\n",
            " 95/105 [==========================>...] - ETA: 0s - loss: 0.4655 - custom_f1: 0.7017 - weighted_custom_f1: 0.7059Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5865 - custom_f1: 0.6387 - weighted_custom_f1: 0.6450 - val_loss: 1.0202 - val_custom_f1: 0.5023 - val_weighted_custom_f1: 0.5128\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5013 - custom_f1: 0.6816 - weighted_custom_f1: 0.6858 - val_loss: 1.2609 - val_custom_f1: 0.5086 - val_weighted_custom_f1: 0.5195\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5384 - custom_f1: 0.6672 - weighted_custom_f1: 0.6713 - val_loss: 1.1461 - val_custom_f1: 0.5219 - val_weighted_custom_f1: 0.5439\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.4996 - custom_f1: 0.6901 - weighted_custom_f1: 0.6940Epoch 75/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5464 - custom_f1: 0.6663 - weighted_custom_f1: 0.6697 - val_loss: 1.1998 - val_custom_f1: 0.4963 - val_weighted_custom_f1: 0.5173\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.5157 - custom_f1: 0.6890 - weighted_custom_f1: 0.6927Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4673 - custom_f1: 0.7004 - weighted_custom_f1: 0.7042 - val_loss: 1.4217 - val_custom_f1: 0.5245 - val_weighted_custom_f1: 0.5462\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.5481 - custom_f1: 0.6576 - weighted_custom_f1: 0.6623Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9905 - custom_f1: 0.4931 - weighted_custom_f1: 0.4983 - val_loss: 1.3414 - val_custom_f1: 0.4915 - val_weighted_custom_f1: 0.4862\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7137 - custom_f1: 0.5846 - weighted_custom_f1: 0.5900 - val_loss: 1.1267 - val_custom_f1: 0.4840 - val_weighted_custom_f1: 0.5049\n",
            "Epoch 79/100\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6076 - custom_f1: 0.6357 - weighted_custom_f1: 0.6407 - val_loss: 1.2409 - val_custom_f1: 0.4879 - val_weighted_custom_f1: 0.4987\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4999 - custom_f1: 0.6886 - weighted_custom_f1: 0.6931 - val_loss: 1.4463 - val_custom_f1: 0.5238 - val_weighted_custom_f1: 0.5277\n",
            " 96/105 [==========================>...] - ETA: 0s - loss: 0.5494 - custom_f1: 0.6633 - weighted_custom_f1: 0.6655Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5518 - custom_f1: 0.6561 - weighted_custom_f1: 0.6609 - val_loss: 1.0763 - val_custom_f1: 0.5311 - val_weighted_custom_f1: 0.5356\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5054 - custom_f1: 0.6853 - weighted_custom_f1: 0.6891 - val_loss: 1.4405 - val_custom_f1: 0.5262 - val_weighted_custom_f1: 0.5371\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4662 - custom_f1: 0.7009 - weighted_custom_f1: 0.7054 - val_loss: 1.8358 - val_custom_f1: 0.5321 - val_weighted_custom_f1: 0.5320\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3268 - custom_f1: 0.6786 - weighted_custom_f1: 0.6786Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5210 - custom_f1: 0.6767 - weighted_custom_f1: 0.6805 - val_loss: 1.0759 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5349\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9564 - custom_f1: 0.5037 - weighted_custom_f1: 0.5079 - val_loss: 1.0548 - val_custom_f1: 0.4617 - val_weighted_custom_f1: 0.4636\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5483 - custom_f1: 0.6618 - weighted_custom_f1: 0.6640 - val_loss: 1.0023 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5392\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5041 - custom_f1: 0.6860 - weighted_custom_f1: 0.6915 - val_loss: 1.1771 - val_custom_f1: 0.4799 - val_weighted_custom_f1: 0.4804\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5987 - custom_f1: 0.6395 - weighted_custom_f1: 0.6433 - val_loss: 1.0138 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5067\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 1.0081 - custom_f1: 0.4946 - weighted_custom_f1: 0.5014Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4812 - custom_f1: 0.6968 - weighted_custom_f1: 0.6988 - val_loss: 1.3271 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5346\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5293 - custom_f1: 0.6769 - weighted_custom_f1: 0.6810 - val_loss: 1.0293 - val_custom_f1: 0.5032 - val_weighted_custom_f1: 0.5116\n",
            "Epoch 76/100\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.5053 - custom_f1: 0.6857 - weighted_custom_f1: 0.6896Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6630 - custom_f1: 0.6103 - weighted_custom_f1: 0.6154 - val_loss: 1.1296 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5378\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.8945 - custom_f1: 0.5116 - weighted_custom_f1: 0.5145Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6365 - custom_f1: 0.6154 - weighted_custom_f1: 0.6192 - val_loss: 1.2012 - val_custom_f1: 0.5291 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5708 - custom_f1: 0.6509 - weighted_custom_f1: 0.6562 - val_loss: 1.3117 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5175\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6701 - custom_f1: 0.6054 - weighted_custom_f1: 0.6112 - val_loss: 1.0649 - val_custom_f1: 0.4554 - val_weighted_custom_f1: 0.4682\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9552 - custom_f1: 0.4788 - weighted_custom_f1: 0.4835 - val_loss: 1.0330 - val_custom_f1: 0.4688 - val_weighted_custom_f1: 0.4785\n",
            " 10/105 [=>............................] - ETA: 0s - loss: 0.6540 - custom_f1: 0.6180 - weighted_custom_f1: 0.6194Epoch 7/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9024 - custom_f1: 0.5013 - weighted_custom_f1: 0.5065 - val_loss: 1.0768 - val_custom_f1: 0.4565 - val_weighted_custom_f1: 0.4680\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9026 - custom_f1: 0.5229 - weighted_custom_f1: 0.5272 - val_loss: 0.9478 - val_custom_f1: 0.4929 - val_weighted_custom_f1: 0.4918\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8871 - custom_f1: 0.5202 - weighted_custom_f1: 0.5230 - val_loss: 0.9220 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5169\n",
            " 69/105 [==================>...........] - ETA: 0s - loss: 0.8986 - custom_f1: 0.5071 - weighted_custom_f1: 0.5107Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6008 - custom_f1: 0.6385 - weighted_custom_f1: 0.6431 - val_loss: 1.2098 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5282\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6225 - custom_f1: 0.6226 - weighted_custom_f1: 0.6273 - val_loss: 1.3703 - val_custom_f1: 0.5447 - val_weighted_custom_f1: 0.5498\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6879 - custom_f1: 0.5981 - weighted_custom_f1: 0.6034 - val_loss: 0.9489 - val_custom_f1: 0.5486 - val_weighted_custom_f1: 0.5472\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.5610 - custom_f1: 0.6322 - weighted_custom_f1: 0.6393Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6785 - custom_f1: 0.6001 - weighted_custom_f1: 0.6049 - val_loss: 0.9943 - val_custom_f1: 0.4934 - val_weighted_custom_f1: 0.5058\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.6028 - custom_f1: 0.6354 - weighted_custom_f1: 0.6397Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5905 - custom_f1: 0.6353 - weighted_custom_f1: 0.6419 - val_loss: 1.1403 - val_custom_f1: 0.5361 - val_weighted_custom_f1: 0.5453\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.6338 - custom_f1: 0.6146 - weighted_custom_f1: 0.6185Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9270 - custom_f1: 0.5086 - weighted_custom_f1: 0.5136 - val_loss: 0.9698 - val_custom_f1: 0.5045 - val_weighted_custom_f1: 0.5150\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.9079 - custom_f1: 0.5271 - weighted_custom_f1: 0.5315Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8858 - custom_f1: 0.5103 - weighted_custom_f1: 0.5141 - val_loss: 0.9776 - val_custom_f1: 0.5100 - val_weighted_custom_f1: 0.5201\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.9423 - custom_f1: 0.4864 - weighted_custom_f1: 0.4898Epoch 35/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6999 - custom_f1: 0.5921 - weighted_custom_f1: 0.5969 - val_loss: 0.9918 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5160\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.6779 - custom_f1: 0.6053 - weighted_custom_f1: 0.6076Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6344 - custom_f1: 0.6152 - weighted_custom_f1: 0.6183 - val_loss: 1.2432 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5319\n",
            " 39/105 [==========>...................] - ETA: 0s - loss: 0.5724 - custom_f1: 0.6471 - weighted_custom_f1: 0.6506Epoch 45/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6032 - custom_f1: 0.6344 - weighted_custom_f1: 0.6390 - val_loss: 1.0690 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5326\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5824 - custom_f1: 0.6433 - weighted_custom_f1: 0.6466 - val_loss: 1.3979 - val_custom_f1: 0.5454 - val_weighted_custom_f1: 0.5461\n",
            " 10/105 [=>............................] - ETA: 0s - loss: 0.6485 - custom_f1: 0.6411 - weighted_custom_f1: 0.6480Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6811 - custom_f1: 0.6004 - weighted_custom_f1: 0.6040 - val_loss: 1.0686 - val_custom_f1: 0.4796 - val_weighted_custom_f1: 0.5010\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8979 - custom_f1: 0.5048 - weighted_custom_f1: 0.5092 - val_loss: 1.1186 - val_custom_f1: 0.4706 - val_weighted_custom_f1: 0.4827\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.6817 - custom_f1: 0.6029 - weighted_custom_f1: 0.6062Epoch 41/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9440 - custom_f1: 0.4884 - weighted_custom_f1: 0.4920 - val_loss: 1.0395 - val_custom_f1: 0.4887 - val_weighted_custom_f1: 0.4970\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8643 - custom_f1: 0.5309 - weighted_custom_f1: 0.5348 - val_loss: 1.0328 - val_custom_f1: 0.5212 - val_weighted_custom_f1: 0.5092\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.9216 - custom_f1: 0.4999 - weighted_custom_f1: 0.5050Epoch 35/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9096 - custom_f1: 0.5143 - weighted_custom_f1: 0.5206 - val_loss: 0.9156 - val_custom_f1: 0.5258 - val_weighted_custom_f1: 0.5364\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5841 - custom_f1: 0.6358 - weighted_custom_f1: 0.6436 - val_loss: 1.2880 - val_custom_f1: 0.5225 - val_weighted_custom_f1: 0.5339\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6422 - custom_f1: 0.6160 - weighted_custom_f1: 0.6218 - val_loss: 1.3383 - val_custom_f1: 0.5322 - val_weighted_custom_f1: 0.5370\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.9125 - custom_f1: 0.5015 - weighted_custom_f1: 0.5066Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6390 - custom_f1: 0.6257 - weighted_custom_f1: 0.6291 - val_loss: 1.0233 - val_custom_f1: 0.5167 - val_weighted_custom_f1: 0.5241\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.6454 - custom_f1: 0.6146 - weighted_custom_f1: 0.6194Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6910 - custom_f1: 0.5945 - weighted_custom_f1: 0.5994 - val_loss: 0.9995 - val_custom_f1: 0.4848 - val_weighted_custom_f1: 0.4947\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5882 - custom_f1: 0.6382 - weighted_custom_f1: 0.6425 - val_loss: 1.0269 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5232\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6653 - custom_f1: 0.7353 - weighted_custom_f1: 0.7353Epoch 46/100\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.6465 - custom_f1: 0.6103 - weighted_custom_f1: 0.6161Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8881 - custom_f1: 0.5054 - weighted_custom_f1: 0.5113 - val_loss: 0.9453 - val_custom_f1: 0.5063 - val_weighted_custom_f1: 0.5183\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9369 - custom_f1: 0.5034 - weighted_custom_f1: 0.5074 - val_loss: 0.9735 - val_custom_f1: 0.4861 - val_weighted_custom_f1: 0.4951\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9028 - custom_f1: 0.5517 - weighted_custom_f1: 0.5517Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5788 - custom_f1: 0.6415 - weighted_custom_f1: 0.6466 - val_loss: 1.1148 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5259\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.6525 - custom_f1: 0.5997 - weighted_custom_f1: 0.6033Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6455 - custom_f1: 0.6141 - weighted_custom_f1: 0.6191 - val_loss: 1.2102 - val_custom_f1: 0.4763 - val_weighted_custom_f1: 0.4744\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6766 - custom_f1: 0.5995 - weighted_custom_f1: 0.6038 - val_loss: 1.0484 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5384\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5742 - custom_f1: 0.6448 - weighted_custom_f1: 0.6489 - val_loss: 1.2861 - val_custom_f1: 0.5259 - val_weighted_custom_f1: 0.5269\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.6538 - custom_f1: 0.5958 - weighted_custom_f1: 0.5999Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6496 - custom_f1: 0.6075 - weighted_custom_f1: 0.6135 - val_loss: 1.1389 - val_custom_f1: 0.4867 - val_weighted_custom_f1: 0.5096\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9340 - custom_f1: 0.4903 - weighted_custom_f1: 0.4950 - val_loss: 1.0512 - val_custom_f1: 0.4937 - val_weighted_custom_f1: 0.5042\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.8976 - custom_f1: 0.5238 - weighted_custom_f1: 0.5285Epoch 9/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9092 - custom_f1: 0.5028 - weighted_custom_f1: 0.5068 - val_loss: 0.9989 - val_custom_f1: 0.5028 - val_weighted_custom_f1: 0.5125\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8799 - custom_f1: 0.5245 - weighted_custom_f1: 0.5285 - val_loss: 0.9247 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5205\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8689 - custom_f1: 0.5283 - weighted_custom_f1: 0.5313 - val_loss: 0.9089 - val_custom_f1: 0.4768 - val_weighted_custom_f1: 0.4870\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5660 - custom_f1: 0.6530 - weighted_custom_f1: 0.6573 - val_loss: 1.1727 - val_custom_f1: 0.5007 - val_weighted_custom_f1: 0.5109\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6074 - custom_f1: 0.6336 - weighted_custom_f1: 0.6369 - val_loss: 1.0581 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5047\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6345 - custom_f1: 0.6193 - weighted_custom_f1: 0.6240 - val_loss: 0.9763 - val_custom_f1: 0.5355 - val_weighted_custom_f1: 0.5399\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6864 - custom_f1: 0.5938 - weighted_custom_f1: 0.5965 - val_loss: 1.0675 - val_custom_f1: 0.4932 - val_weighted_custom_f1: 0.5154\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6013 - custom_f1: 0.6322 - weighted_custom_f1: 0.6368 - val_loss: 1.2229 - val_custom_f1: 0.5334 - val_weighted_custom_f1: 0.5556\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5956 - custom_f1: 0.7143 - weighted_custom_f1: 0.7143Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9027 - custom_f1: 0.5096 - weighted_custom_f1: 0.5137 - val_loss: 0.9233 - val_custom_f1: 0.4797 - val_weighted_custom_f1: 0.4918\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9396 - custom_f1: 0.5093 - weighted_custom_f1: 0.5141 - val_loss: 1.0270 - val_custom_f1: 0.4547 - val_weighted_custom_f1: 0.4643\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5726 - custom_f1: 0.6427 - weighted_custom_f1: 0.6475 - val_loss: 1.0559 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5226\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6911 - custom_f1: 0.5880 - weighted_custom_f1: 0.5945 - val_loss: 1.2699 - val_custom_f1: 0.5208 - val_weighted_custom_f1: 0.5259\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6339 - custom_f1: 0.6123 - weighted_custom_f1: 0.6169 - val_loss: 1.1464 - val_custom_f1: 0.5324 - val_weighted_custom_f1: 0.5282\n",
            "Epoch 50/100\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5590 - custom_f1: 0.6536 - weighted_custom_f1: 0.6587 - val_loss: 1.3454 - val_custom_f1: 0.5217 - val_weighted_custom_f1: 0.5200\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6372 - custom_f1: 0.6148 - weighted_custom_f1: 0.6191 - val_loss: 1.0989 - val_custom_f1: 0.4827 - val_weighted_custom_f1: 0.5054\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9462 - custom_f1: 0.4881 - weighted_custom_f1: 0.4936 - val_loss: 1.0164 - val_custom_f1: 0.4821 - val_weighted_custom_f1: 0.4922\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.8462 - custom_f1: 0.5234 - weighted_custom_f1: 0.5259Epoch 10/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8915 - custom_f1: 0.5027 - weighted_custom_f1: 0.5063 - val_loss: 1.0778 - val_custom_f1: 0.4646 - val_weighted_custom_f1: 0.4759\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8518 - custom_f1: 0.5320 - weighted_custom_f1: 0.5384 - val_loss: 0.9789 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5144\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5723 - custom_f1: 0.6489 - weighted_custom_f1: 0.6518 - val_loss: 1.2916 - val_custom_f1: 0.5011 - val_weighted_custom_f1: 0.5087\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.8920 - custom_f1: 0.5051 - weighted_custom_f1: 0.5104Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9235 - custom_f1: 0.5039 - weighted_custom_f1: 0.5079 - val_loss: 0.9508 - val_custom_f1: 0.5172 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 38/100\n",
            " 74/105 [====================>.........] - ETA: 0s - loss: 0.6561 - custom_f1: 0.6170 - weighted_custom_f1: 0.6211Epoch 37/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5883 - custom_f1: 0.6366 - weighted_custom_f1: 0.6409 - val_loss: 1.0721 - val_custom_f1: 0.5276 - val_weighted_custom_f1: 0.5326\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.6232 - custom_f1: 0.6274 - weighted_custom_f1: 0.6309Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6592 - custom_f1: 0.6022 - weighted_custom_f1: 0.6068 - val_loss: 1.0767 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5382\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6487 - custom_f1: 0.6165 - weighted_custom_f1: 0.6222 - val_loss: 1.0396 - val_custom_f1: 0.5526 - val_weighted_custom_f1: 0.5576\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6012 - custom_f1: 0.6393 - weighted_custom_f1: 0.6445 - val_loss: 1.1060 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5244\n",
            " 76/105 [====================>.........] - ETA: 0s - loss: 0.9663 - custom_f1: 0.4847 - weighted_custom_f1: 0.4896Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9396 - custom_f1: 0.5046 - weighted_custom_f1: 0.5081 - val_loss: 0.9807 - val_custom_f1: 0.4953 - val_weighted_custom_f1: 0.5050\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 0.5658 - custom_f1: 0.6488 - weighted_custom_f1: 0.6528Epoch 42/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9001 - custom_f1: 0.5046 - weighted_custom_f1: 0.5088 - val_loss: 0.9837 - val_custom_f1: 0.4841 - val_weighted_custom_f1: 0.4871\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5699 - custom_f1: 0.6484 - weighted_custom_f1: 0.6527 - val_loss: 1.1153 - val_custom_f1: 0.5063 - val_weighted_custom_f1: 0.5143\n",
            "Epoch 38/100\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6523 - custom_f1: 0.6174 - weighted_custom_f1: 0.6209 - val_loss: 1.0051 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4967\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6475 - custom_f1: 0.6158 - weighted_custom_f1: 0.6209 - val_loss: 1.3234 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5099\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5703 - custom_f1: 0.6499 - weighted_custom_f1: 0.6532 - val_loss: 1.2887 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5237\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6372 - custom_f1: 0.6192 - weighted_custom_f1: 0.6218 - val_loss: 1.1136 - val_custom_f1: 0.4773 - val_weighted_custom_f1: 0.4993\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.6784 - custom_f1: 0.6027 - weighted_custom_f1: 0.6061Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9755 - custom_f1: 0.4795 - weighted_custom_f1: 0.4854 - val_loss: 1.0997 - val_custom_f1: 0.5141 - val_weighted_custom_f1: 0.5207\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.5748 - custom_f1: 0.6422 - weighted_custom_f1: 0.6471Epoch 11/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8912 - custom_f1: 0.5083 - weighted_custom_f1: 0.5149 - val_loss: 0.9958 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5183\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8438 - custom_f1: 0.5367 - weighted_custom_f1: 0.5404 - val_loss: 0.9359 - val_custom_f1: 0.4898 - val_weighted_custom_f1: 0.4902\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5669 - custom_f1: 0.6497 - weighted_custom_f1: 0.6536 - val_loss: 1.2602 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8858 - custom_f1: 0.5234 - weighted_custom_f1: 0.5286 - val_loss: 0.9414 - val_custom_f1: 0.5355 - val_weighted_custom_f1: 0.5472\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5813 - custom_f1: 0.6410 - weighted_custom_f1: 0.6455 - val_loss: 1.1305 - val_custom_f1: 0.5001 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 39/100\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6499 - custom_f1: 0.6113 - weighted_custom_f1: 0.6143 - val_loss: 1.0667 - val_custom_f1: 0.5601 - val_weighted_custom_f1: 0.5665\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6464 - custom_f1: 0.6116 - weighted_custom_f1: 0.6179 - val_loss: 1.0145 - val_custom_f1: 0.5637 - val_weighted_custom_f1: 0.5633\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.5426 - custom_f1: 0.6583 - weighted_custom_f1: 0.6627Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5832 - custom_f1: 0.6372 - weighted_custom_f1: 0.6433 - val_loss: 1.0904 - val_custom_f1: 0.5433 - val_weighted_custom_f1: 0.5531\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5558 - custom_f1: 0.6510 - weighted_custom_f1: 0.6545 - val_loss: 1.1227 - val_custom_f1: 0.5275 - val_weighted_custom_f1: 0.5402\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.5586 - custom_f1: 0.6551 - weighted_custom_f1: 0.6598Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8974 - custom_f1: 0.5145 - weighted_custom_f1: 0.5202 - val_loss: 1.0203 - val_custom_f1: 0.5366 - val_weighted_custom_f1: 0.5403\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.9072 - custom_f1: 0.5105 - weighted_custom_f1: 0.5148Epoch 39/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9321 - custom_f1: 0.5075 - weighted_custom_f1: 0.5117 - val_loss: 0.9601 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5124\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6185 - custom_f1: 0.6234 - weighted_custom_f1: 0.6274 - val_loss: 1.4667 - val_custom_f1: 0.5308 - val_weighted_custom_f1: 0.5271\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6639 - custom_f1: 0.6084 - weighted_custom_f1: 0.6125 - val_loss: 1.1910 - val_custom_f1: 0.5234 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 49/100\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5253 - custom_f1: 0.6682 - weighted_custom_f1: 0.6715 - val_loss: 1.3149 - val_custom_f1: 0.5376 - val_weighted_custom_f1: 0.5369\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.5520 - custom_f1: 0.6570 - weighted_custom_f1: 0.6618Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6463 - custom_f1: 0.6099 - weighted_custom_f1: 0.6147 - val_loss: 1.1016 - val_custom_f1: 0.4903 - val_weighted_custom_f1: 0.5120\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.5776 - custom_f1: 0.6352 - weighted_custom_f1: 0.6379Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9428 - custom_f1: 0.4919 - weighted_custom_f1: 0.4944 - val_loss: 1.0924 - val_custom_f1: 0.4267 - val_weighted_custom_f1: 0.4384\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9072 - custom_f1: 0.5105 - weighted_custom_f1: 0.5148 - val_loss: 1.0897 - val_custom_f1: 0.4847 - val_weighted_custom_f1: 0.4972\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5619 - custom_f1: 0.6548 - weighted_custom_f1: 0.6592 - val_loss: 1.4184 - val_custom_f1: 0.5030 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5725 - custom_f1: 0.6514 - weighted_custom_f1: 0.6567 - val_loss: 1.1739 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5210\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.8696 - custom_f1: 0.5260 - weighted_custom_f1: 0.5293 - val_loss: 1.0714 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5125\n",
            "Epoch 54/100\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.9217 - custom_f1: 0.5115 - weighted_custom_f1: 0.5151Epoch 39/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8939 - custom_f1: 0.5246 - weighted_custom_f1: 0.5286 - val_loss: 0.9442 - val_custom_f1: 0.4763 - val_weighted_custom_f1: 0.4855\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6385 - custom_f1: 0.6104 - weighted_custom_f1: 0.6167 - val_loss: 1.0828 - val_custom_f1: 0.5437 - val_weighted_custom_f1: 0.5500\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.6339 - custom_f1: 0.6166 - weighted_custom_f1: 0.6198Epoch 50/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.6228 - custom_f1: 0.6294 - weighted_custom_f1: 0.6340 - val_loss: 0.9845 - val_custom_f1: 0.4882 - val_weighted_custom_f1: 0.4978\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5580 - custom_f1: 0.6561 - weighted_custom_f1: 0.6602 - val_loss: 1.1291 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5299\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8925 - custom_f1: 0.5201 - weighted_custom_f1: 0.5248 - val_loss: 0.9448 - val_custom_f1: 0.4904 - val_weighted_custom_f1: 0.5036\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9218 - custom_f1: 0.5068 - weighted_custom_f1: 0.5131 - val_loss: 1.0106 - val_custom_f1: 0.5124 - val_weighted_custom_f1: 0.5224\n",
            "Epoch 40/100\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5558 - custom_f1: 0.6603 - weighted_custom_f1: 0.6653 - val_loss: 1.2448 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5192\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6197 - custom_f1: 0.6209 - weighted_custom_f1: 0.6252 - val_loss: 1.2662 - val_custom_f1: 0.5312 - val_weighted_custom_f1: 0.5264\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5157 - custom_f1: 0.6780 - weighted_custom_f1: 0.6780Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6562 - custom_f1: 0.6141 - weighted_custom_f1: 0.6197 - val_loss: 1.0371 - val_custom_f1: 0.4953 - val_weighted_custom_f1: 0.5052\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5578 - custom_f1: 0.6529 - weighted_custom_f1: 0.6577 - val_loss: 1.3602 - val_custom_f1: 0.5047 - val_weighted_custom_f1: 0.5025\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.9332 - custom_f1: 0.5235 - weighted_custom_f1: 0.5269Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9037 - custom_f1: 0.5079 - weighted_custom_f1: 0.5132 - val_loss: 1.0905 - val_custom_f1: 0.5329 - val_weighted_custom_f1: 0.5420\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.6605 - custom_f1: 0.5885 - weighted_custom_f1: 0.5946Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6402 - custom_f1: 0.6100 - weighted_custom_f1: 0.6138 - val_loss: 1.1332 - val_custom_f1: 0.4980 - val_weighted_custom_f1: 0.5195\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.5581 - custom_f1: 0.6397 - weighted_custom_f1: 0.6452Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9338 - custom_f1: 0.4948 - weighted_custom_f1: 0.4996 - val_loss: 1.0504 - val_custom_f1: 0.4708 - val_weighted_custom_f1: 0.4817\n",
            " 39/105 [==========>...................] - ETA: 0s - loss: 0.6306 - custom_f1: 0.5996 - weighted_custom_f1: 0.6044Epoch 13/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5788 - custom_f1: 0.6452 - weighted_custom_f1: 0.6499 - val_loss: 1.3393 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5414\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.6070 - custom_f1: 0.6359 - weighted_custom_f1: 0.6399Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5649 - custom_f1: 0.6500 - weighted_custom_f1: 0.6535 - val_loss: 1.1077 - val_custom_f1: 0.4834 - val_weighted_custom_f1: 0.5054\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8585 - custom_f1: 0.5362 - weighted_custom_f1: 0.5400 - val_loss: 1.3854 - val_custom_f1: 0.3531 - val_weighted_custom_f1: 0.3629\n",
            "Epoch 55/100\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.9691 - custom_f1: 0.4921 - weighted_custom_f1: 0.4970Epoch 40/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6404 - custom_f1: 0.6257 - weighted_custom_f1: 0.6291 - val_loss: 0.9938 - val_custom_f1: 0.4852 - val_weighted_custom_f1: 0.4969\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.6126 - custom_f1: 0.6342 - weighted_custom_f1: 0.6378Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8833 - custom_f1: 0.5260 - weighted_custom_f1: 0.5308 - val_loss: 0.9723 - val_custom_f1: 0.4508 - val_weighted_custom_f1: 0.4612\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.6534 - custom_f1: 0.6026 - weighted_custom_f1: 0.6075Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5696 - custom_f1: 0.6586 - weighted_custom_f1: 0.6602 - val_loss: 1.1382 - val_custom_f1: 0.5506 - val_weighted_custom_f1: 0.5568\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6276 - custom_f1: 0.6186 - weighted_custom_f1: 0.6238 - val_loss: 1.0896 - val_custom_f1: 0.5599 - val_weighted_custom_f1: 0.5656\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9359 - custom_f1: 0.5111 - weighted_custom_f1: 0.5154 - val_loss: 1.0355 - val_custom_f1: 0.4585 - val_weighted_custom_f1: 0.4694\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5557 - custom_f1: 0.6586 - weighted_custom_f1: 0.6624 - val_loss: 1.1405 - val_custom_f1: 0.4681 - val_weighted_custom_f1: 0.4771\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.9350 - custom_f1: 0.5105 - weighted_custom_f1: 0.5156Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6510 - custom_f1: 0.6059 - weighted_custom_f1: 0.6130 - val_loss: 1.1231 - val_custom_f1: 0.5287 - val_weighted_custom_f1: 0.5395\n",
            "  8/105 [=>............................] - ETA: 0s - loss: 0.5895 - custom_f1: 0.6610 - weighted_custom_f1: 0.6630Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6160 - custom_f1: 0.6321 - weighted_custom_f1: 0.6356 - val_loss: 1.3730 - val_custom_f1: 0.5330 - val_weighted_custom_f1: 0.5283\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.6423 - custom_f1: 0.6073 - weighted_custom_f1: 0.6155Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8952 - custom_f1: 0.5145 - weighted_custom_f1: 0.5191 - val_loss: 0.9665 - val_custom_f1: 0.4480 - val_weighted_custom_f1: 0.4603\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.9033 - custom_f1: 0.5320 - weighted_custom_f1: 0.5353Epoch 41/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5582 - custom_f1: 0.6538 - weighted_custom_f1: 0.6585 - val_loss: 1.4341 - val_custom_f1: 0.5465 - val_weighted_custom_f1: 0.5454\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.5871 - custom_f1: 0.6484 - weighted_custom_f1: 0.6517Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6996 - custom_f1: 0.6024 - weighted_custom_f1: 0.6073 - val_loss: 1.0141 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.4939\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9311 - custom_f1: 0.4948 - weighted_custom_f1: 0.4982 - val_loss: 1.0950 - val_custom_f1: 0.4805 - val_weighted_custom_f1: 0.4861\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9174 - custom_f1: 0.5054 - weighted_custom_f1: 0.5098 - val_loss: 1.1010 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5386\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.6126 - custom_f1: 0.6246 - weighted_custom_f1: 0.6297Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5445 - custom_f1: 0.6640 - weighted_custom_f1: 0.6676 - val_loss: 1.2203 - val_custom_f1: 0.5223 - val_weighted_custom_f1: 0.5309\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8871 - custom_f1: 0.5302 - weighted_custom_f1: 0.5336 - val_loss: 0.9272 - val_custom_f1: 0.5295 - val_weighted_custom_f1: 0.5283\n",
            " 54/105 [==============>...............] - ETA: 0s - loss: 0.6436 - custom_f1: 0.6236 - weighted_custom_f1: 0.6272Epoch 41/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6344 - custom_f1: 0.6126 - weighted_custom_f1: 0.6175 - val_loss: 1.0191 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5852 - custom_f1: 0.6434 - weighted_custom_f1: 0.6462 - val_loss: 1.3241 - val_custom_f1: 0.5515 - val_weighted_custom_f1: 0.5571\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9079 - custom_f1: 0.5198 - weighted_custom_f1: 0.5231 - val_loss: 0.9603 - val_custom_f1: 0.4687 - val_weighted_custom_f1: 0.4780\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5711 - custom_f1: 0.6472 - weighted_custom_f1: 0.6510 - val_loss: 1.1768 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5423\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.9197 - custom_f1: 0.5064 - weighted_custom_f1: 0.5090Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6426 - custom_f1: 0.6176 - weighted_custom_f1: 0.6238 - val_loss: 0.9886 - val_custom_f1: 0.5054 - val_weighted_custom_f1: 0.5168\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.5358 - custom_f1: 0.6611 - weighted_custom_f1: 0.6668Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5540 - custom_f1: 0.6597 - weighted_custom_f1: 0.6631 - val_loss: 1.2015 - val_custom_f1: 0.5136 - val_weighted_custom_f1: 0.5350\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9653 - custom_f1: 0.5022 - weighted_custom_f1: 0.5074 - val_loss: 0.9782 - val_custom_f1: 0.5116 - val_weighted_custom_f1: 0.5214\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6316 - custom_f1: 0.6229 - weighted_custom_f1: 0.6281 - val_loss: 1.1171 - val_custom_f1: 0.4659 - val_weighted_custom_f1: 0.4772\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.5599 - custom_f1: 0.6565 - weighted_custom_f1: 0.6616Epoch 46/100\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9115 - custom_f1: 0.5159 - weighted_custom_f1: 0.5193 - val_loss: 0.9591 - val_custom_f1: 0.4799 - val_weighted_custom_f1: 0.4921\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6234 - custom_f1: 0.6239 - weighted_custom_f1: 0.6277 - val_loss: 1.2705 - val_custom_f1: 0.5298 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 42/100\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5362 - custom_f1: 0.6615 - weighted_custom_f1: 0.6673 - val_loss: 1.3099 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5108\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6433 - custom_f1: 0.6131 - weighted_custom_f1: 0.6174 - val_loss: 1.0547 - val_custom_f1: 0.4807 - val_weighted_custom_f1: 0.5029\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.8988 - custom_f1: 0.5057 - weighted_custom_f1: 0.5094Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9026 - custom_f1: 0.5089 - weighted_custom_f1: 0.5127 - val_loss: 1.0751 - val_custom_f1: 0.5139 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9229 - custom_f1: 0.4944 - weighted_custom_f1: 0.4991 - val_loss: 1.1088 - val_custom_f1: 0.5081 - val_weighted_custom_f1: 0.5151\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5705 - custom_f1: 0.6513 - weighted_custom_f1: 0.6579 - val_loss: 1.2565 - val_custom_f1: 0.4717 - val_weighted_custom_f1: 0.4842\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8499 - custom_f1: 0.5355 - weighted_custom_f1: 0.5406 - val_loss: 0.9778 - val_custom_f1: 0.5259 - val_weighted_custom_f1: 0.5222\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.6358 - custom_f1: 0.6143 - weighted_custom_f1: 0.6186Epoch 42/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5869 - custom_f1: 0.6464 - weighted_custom_f1: 0.6509 - val_loss: 1.2212 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5153\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6301 - custom_f1: 0.6204 - weighted_custom_f1: 0.6245 - val_loss: 1.0268 - val_custom_f1: 0.4864 - val_weighted_custom_f1: 0.4948\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5553 - custom_f1: 0.6646 - weighted_custom_f1: 0.6678Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8799 - custom_f1: 0.5246 - weighted_custom_f1: 0.5296 - val_loss: 0.9109 - val_custom_f1: 0.4813 - val_weighted_custom_f1: 0.4916\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5509 - custom_f1: 0.6604 - weighted_custom_f1: 0.6627 - val_loss: 1.1508 - val_custom_f1: 0.5434 - val_weighted_custom_f1: 0.5500\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6470 - custom_f1: 0.6193 - weighted_custom_f1: 0.6255 - val_loss: 1.0314 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9278 - custom_f1: 0.5150 - weighted_custom_f1: 0.5194 - val_loss: 0.9701 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5029\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.5990 - custom_f1: 0.6340 - weighted_custom_f1: 0.6384Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8877 - custom_f1: 0.5095 - weighted_custom_f1: 0.5139 - val_loss: 0.9295 - val_custom_f1: 0.5055 - val_weighted_custom_f1: 0.5143\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.5550 - custom_f1: 0.6557 - weighted_custom_f1: 0.6598Epoch 43/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6326 - custom_f1: 0.6178 - weighted_custom_f1: 0.6208 - val_loss: 1.1032 - val_custom_f1: 0.5144 - val_weighted_custom_f1: 0.5254\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5584 - custom_f1: 0.6573 - weighted_custom_f1: 0.6610 - val_loss: 1.1410 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5230\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.8626 - custom_f1: 0.5306 - weighted_custom_f1: 0.5338Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6161 - custom_f1: 0.6235 - weighted_custom_f1: 0.6262 - val_loss: 1.1881 - val_custom_f1: 0.5145 - val_weighted_custom_f1: 0.5139\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6292 - custom_f1: 0.6201 - weighted_custom_f1: 0.6238 - val_loss: 1.1527 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5017\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5410 - custom_f1: 0.6687 - weighted_custom_f1: 0.6716 - val_loss: 1.3651 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5380\n",
            " 71/105 [===================>..........] - ETA: 0s - loss: 0.6147 - custom_f1: 0.6280 - weighted_custom_f1: 0.6321Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8917 - custom_f1: 0.5102 - weighted_custom_f1: 0.5152 - val_loss: 1.0731 - val_custom_f1: 0.4495 - val_weighted_custom_f1: 0.4609\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.9647 - custom_f1: 0.4937 - weighted_custom_f1: 0.4980Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9307 - custom_f1: 0.4910 - weighted_custom_f1: 0.4958 - val_loss: 1.0645 - val_custom_f1: 0.4961 - val_weighted_custom_f1: 0.5075\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5727 - custom_f1: 0.6473 - weighted_custom_f1: 0.6513Epoch 16/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5963 - custom_f1: 0.6388 - weighted_custom_f1: 0.6430 - val_loss: 1.2657 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5030\n",
            " 53/105 [==============>...............] - ETA: 0s - loss: 0.5318 - custom_f1: 0.6690 - weighted_custom_f1: 0.6735Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8484 - custom_f1: 0.5329 - weighted_custom_f1: 0.5365 - val_loss: 0.9364 - val_custom_f1: 0.5335 - val_weighted_custom_f1: 0.5304\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5588 - custom_f1: 0.6550 - weighted_custom_f1: 0.6583 - val_loss: 1.1986 - val_custom_f1: 0.5353 - val_weighted_custom_f1: 0.5401\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6260 - custom_f1: 0.6225 - weighted_custom_f1: 0.6274 - val_loss: 1.1072 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5531\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8771 - custom_f1: 0.5256 - weighted_custom_f1: 0.5308 - val_loss: 0.9530 - val_custom_f1: 0.5098 - val_weighted_custom_f1: 0.5193\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.9276 - custom_f1: 0.5043 - weighted_custom_f1: 0.5087Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5905 - custom_f1: 0.6359 - weighted_custom_f1: 0.6402 - val_loss: 1.0260 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5182\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5645 - custom_f1: 0.6497 - weighted_custom_f1: 0.6534 - val_loss: 1.0871 - val_custom_f1: 0.5277 - val_weighted_custom_f1: 0.5344\n",
            "Epoch 55/100\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6249 - custom_f1: 0.6278 - weighted_custom_f1: 0.6316 - val_loss: 1.0517 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5366\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9327 - custom_f1: 0.5002 - weighted_custom_f1: 0.5055 - val_loss: 1.0689 - val_custom_f1: 0.4612 - val_weighted_custom_f1: 0.4681\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.8295 - custom_f1: 0.5359 - weighted_custom_f1: 0.5404Epoch 48/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8950 - custom_f1: 0.5144 - weighted_custom_f1: 0.5200 - val_loss: 0.9733 - val_custom_f1: 0.5198 - val_weighted_custom_f1: 0.5272\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6195 - custom_f1: 0.6226 - weighted_custom_f1: 0.6276 - val_loss: 1.1448 - val_custom_f1: 0.5055 - val_weighted_custom_f1: 0.5010\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6264 - custom_f1: 0.6244 - weighted_custom_f1: 0.6295 - val_loss: 1.1996 - val_custom_f1: 0.4675 - val_weighted_custom_f1: 0.4873\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5537 - custom_f1: 0.6590 - weighted_custom_f1: 0.6621 - val_loss: 1.2037 - val_custom_f1: 0.5199 - val_weighted_custom_f1: 0.5427\n",
            " 77/105 [=====================>........] - ETA: 0s - loss: 0.8231 - custom_f1: 0.5398 - weighted_custom_f1: 0.5438Epoch 54/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6112 - custom_f1: 0.6349 - weighted_custom_f1: 0.6349Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5050 - custom_f1: 0.6857 - weighted_custom_f1: 0.6885 - val_loss: 1.3480 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5141\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9400 - custom_f1: 0.4944 - weighted_custom_f1: 0.4981 - val_loss: 1.1348 - val_custom_f1: 0.4501 - val_weighted_custom_f1: 0.4618\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.5651 - custom_f1: 0.6535 - weighted_custom_f1: 0.6579Epoch 17/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9058 - custom_f1: 0.5050 - weighted_custom_f1: 0.5116 - val_loss: 1.0875 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5415\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.8900 - custom_f1: 0.5380 - weighted_custom_f1: 0.5405Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5387 - custom_f1: 0.6595 - weighted_custom_f1: 0.6635 - val_loss: 1.2325 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.5125\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.6185 - custom_f1: 0.6296 - weighted_custom_f1: 0.6340Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5608 - custom_f1: 0.6549 - weighted_custom_f1: 0.6588 - val_loss: 1.1885 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5249\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.8977 - custom_f1: 0.5195 - weighted_custom_f1: 0.5222Epoch 59/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8391 - custom_f1: 0.5409 - weighted_custom_f1: 0.5451 - val_loss: 0.9573 - val_custom_f1: 0.4757 - val_weighted_custom_f1: 0.4765\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6215 - custom_f1: 0.6225 - weighted_custom_f1: 0.6267 - val_loss: 1.0283 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5087\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.5378 - custom_f1: 0.6611 - weighted_custom_f1: 0.6641Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5608 - custom_f1: 0.6512 - weighted_custom_f1: 0.6553 - val_loss: 1.2795 - val_custom_f1: 0.5378 - val_weighted_custom_f1: 0.5611\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9260 - custom_f1: 0.5172 - weighted_custom_f1: 0.5208 - val_loss: 0.9779 - val_custom_f1: 0.4691 - val_weighted_custom_f1: 0.4801\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6047 - custom_f1: 0.6351 - weighted_custom_f1: 0.6378 - val_loss: 1.0563 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9511 - custom_f1: 0.5034 - weighted_custom_f1: 0.5072 - val_loss: 1.0067 - val_custom_f1: 0.4788 - val_weighted_custom_f1: 0.4884\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6218 - custom_f1: 0.6245 - weighted_custom_f1: 0.6293 - val_loss: 1.1570 - val_custom_f1: 0.5164 - val_weighted_custom_f1: 0.5242\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5226 - custom_f1: 0.6699 - weighted_custom_f1: 0.6726 - val_loss: 1.1697 - val_custom_f1: 0.5065 - val_weighted_custom_f1: 0.5291\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9028 - custom_f1: 0.5141 - weighted_custom_f1: 0.5172 - val_loss: 0.9385 - val_custom_f1: 0.4869 - val_weighted_custom_f1: 0.4979\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4617 - custom_f1: 0.7750 - weighted_custom_f1: 0.7750Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6247 - custom_f1: 0.6204 - weighted_custom_f1: 0.6248 - val_loss: 1.4294 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5378\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5986 - custom_f1: 0.6384 - weighted_custom_f1: 0.6412 - val_loss: 1.0776 - val_custom_f1: 0.4644 - val_weighted_custom_f1: 0.4758\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.5491 - custom_f1: 0.6593 - weighted_custom_f1: 0.6654Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5166 - custom_f1: 0.6752 - weighted_custom_f1: 0.6789 - val_loss: 1.3300 - val_custom_f1: 0.5254 - val_weighted_custom_f1: 0.5259\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.5483 - custom_f1: 0.6603 - weighted_custom_f1: 0.6650Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8841 - custom_f1: 0.5107 - weighted_custom_f1: 0.5151 - val_loss: 1.1013 - val_custom_f1: 0.4500 - val_weighted_custom_f1: 0.4611\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.5361 - custom_f1: 0.6518 - weighted_custom_f1: 0.6576Epoch 51/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9500 - custom_f1: 0.4918 - weighted_custom_f1: 0.4946 - val_loss: 1.1620 - val_custom_f1: 0.5038 - val_weighted_custom_f1: 0.5114\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.6480 - custom_f1: 0.6343 - weighted_custom_f1: 0.6406Epoch 18/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5400 - custom_f1: 0.6660 - weighted_custom_f1: 0.6699 - val_loss: 1.3965 - val_custom_f1: 0.5303 - val_weighted_custom_f1: 0.5347\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.6198 - custom_f1: 0.6221 - weighted_custom_f1: 0.6284Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5434 - custom_f1: 0.6612 - weighted_custom_f1: 0.6660 - val_loss: 1.2491 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5355\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.5003 - custom_f1: 0.6814 - weighted_custom_f1: 0.6849Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6177 - custom_f1: 0.6292 - weighted_custom_f1: 0.6323 - val_loss: 1.0468 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5378\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8834 - custom_f1: 0.5270 - weighted_custom_f1: 0.5292 - val_loss: 0.9941 - val_custom_f1: 0.5056 - val_weighted_custom_f1: 0.5011\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5678 - custom_f1: 0.6516 - weighted_custom_f1: 0.6579 - val_loss: 1.2096 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5228\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8962 - custom_f1: 0.5186 - weighted_custom_f1: 0.5247 - val_loss: 0.9113 - val_custom_f1: 0.5016 - val_weighted_custom_f1: 0.5126\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3919 - custom_f1: 0.6122 - weighted_custom_f1: 0.6122Epoch 46/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6033 - custom_f1: 0.6316 - weighted_custom_f1: 0.6353 - val_loss: 1.0640 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5277\n",
            " 23/105 [=====>........................] - ETA: 0s - loss: 0.5434 - custom_f1: 0.6842 - weighted_custom_f1: 0.6859Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6293 - custom_f1: 0.6222 - weighted_custom_f1: 0.6273 - val_loss: 1.0863 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5142\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.8972 - custom_f1: 0.5012 - weighted_custom_f1: 0.5049Epoch 59/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9371 - custom_f1: 0.4984 - weighted_custom_f1: 0.5047 - val_loss: 0.9715 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5139\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5233 - custom_f1: 0.6648 - weighted_custom_f1: 0.6693 - val_loss: 1.2617 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5236\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.5275 - custom_f1: 0.6744 - weighted_custom_f1: 0.6789Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9017 - custom_f1: 0.5077 - weighted_custom_f1: 0.5133 - val_loss: 1.0147 - val_custom_f1: 0.5096 - val_weighted_custom_f1: 0.5164\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6146 - custom_f1: 0.6234 - weighted_custom_f1: 0.6285 - val_loss: 1.2436 - val_custom_f1: 0.5035 - val_weighted_custom_f1: 0.4991\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.5168 - custom_f1: 0.6637 - weighted_custom_f1: 0.6690Epoch 46/100\n",
            " 88/105 [========================>.....] - ETA: 0s - loss: 0.5620 - custom_f1: 0.6560 - weighted_custom_f1: 0.6599Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5171 - custom_f1: 0.6727 - weighted_custom_f1: 0.6765 - val_loss: 1.4917 - val_custom_f1: 0.5263 - val_weighted_custom_f1: 0.5259\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.6040 - custom_f1: 0.6400 - weighted_custom_f1: 0.6421Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6166 - custom_f1: 0.6266 - weighted_custom_f1: 0.6298 - val_loss: 1.0842 - val_custom_f1: 0.5077 - val_weighted_custom_f1: 0.5296\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.6222 - custom_f1: 0.6339 - weighted_custom_f1: 0.6381Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8920 - custom_f1: 0.5052 - weighted_custom_f1: 0.5096 - val_loss: 1.0653 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5200\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.4830 - custom_f1: 0.6838 - weighted_custom_f1: 0.6883Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9381 - custom_f1: 0.4911 - weighted_custom_f1: 0.4952 - val_loss: 1.1550 - val_custom_f1: 0.4941 - val_weighted_custom_f1: 0.5001\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 0.9402 - custom_f1: 0.5038 - weighted_custom_f1: 0.5080Epoch 19/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5416 - custom_f1: 0.6671 - weighted_custom_f1: 0.6718 - val_loss: 1.4314 - val_custom_f1: 0.5344 - val_weighted_custom_f1: 0.5455\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5607 - custom_f1: 0.6515 - weighted_custom_f1: 0.6568 - val_loss: 1.2373 - val_custom_f1: 0.5159 - val_weighted_custom_f1: 0.5205\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.9477 - custom_f1: 0.4909 - weighted_custom_f1: 0.4980Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6225 - custom_f1: 0.6223 - weighted_custom_f1: 0.6275 - val_loss: 1.1458 - val_custom_f1: 0.4925 - val_weighted_custom_f1: 0.5002\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8732 - custom_f1: 0.5324 - weighted_custom_f1: 0.5376 - val_loss: 1.0368 - val_custom_f1: 0.4555 - val_weighted_custom_f1: 0.4570\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7186 - custom_f1: 0.3529 - weighted_custom_f1: 0.3529Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6225 - custom_f1: 0.6305 - weighted_custom_f1: 0.6336 - val_loss: 1.0896 - val_custom_f1: 0.5466 - val_weighted_custom_f1: 0.5524\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5543 - custom_f1: 0.6551 - weighted_custom_f1: 0.6599 - val_loss: 1.1358 - val_custom_f1: 0.5410 - val_weighted_custom_f1: 0.5473\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.9604 - custom_f1: 0.4840 - weighted_custom_f1: 0.4898Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8895 - custom_f1: 0.5212 - weighted_custom_f1: 0.5252 - val_loss: 0.9061 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5045\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6245 - custom_f1: 0.6232 - weighted_custom_f1: 0.6276 - val_loss: 1.0426 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5203\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5289 - custom_f1: 0.6665 - weighted_custom_f1: 0.6709 - val_loss: 1.3553 - val_custom_f1: 0.5093 - val_weighted_custom_f1: 0.5326\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9379 - custom_f1: 0.5062 - weighted_custom_f1: 0.5109 - val_loss: 1.0031 - val_custom_f1: 0.4777 - val_weighted_custom_f1: 0.4882\n",
            "Epoch 61/100\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8818 - custom_f1: 0.5165 - weighted_custom_f1: 0.5199 - val_loss: 0.9731 - val_custom_f1: 0.5201 - val_weighted_custom_f1: 0.5269\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5095 - custom_f1: 0.6850 - weighted_custom_f1: 0.6890 - val_loss: 1.3893 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5132\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5895 - custom_f1: 0.6380 - weighted_custom_f1: 0.6422 - val_loss: 1.2914 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5278\n",
            "Epoch 61/100\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6421 - custom_f1: 0.6207 - weighted_custom_f1: 0.6250 - val_loss: 1.1644 - val_custom_f1: 0.4920 - val_weighted_custom_f1: 0.5133\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9729 - custom_f1: 0.4830 - weighted_custom_f1: 0.4867 - val_loss: 1.1238 - val_custom_f1: 0.4814 - val_weighted_custom_f1: 0.4891\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.8775 - custom_f1: 0.5203 - weighted_custom_f1: 0.5241Epoch 20/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9043 - custom_f1: 0.5086 - weighted_custom_f1: 0.5136 - val_loss: 1.1227 - val_custom_f1: 0.4667 - val_weighted_custom_f1: 0.4784\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5503 - custom_f1: 0.6577 - weighted_custom_f1: 0.6615 - val_loss: 1.2587 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5240\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5220 - custom_f1: 0.6693 - weighted_custom_f1: 0.6741 - val_loss: 1.4075 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5505\n",
            "Epoch 66/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4999 - custom_f1: 0.6818 - weighted_custom_f1: 0.6818Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8709 - custom_f1: 0.5337 - weighted_custom_f1: 0.5385 - val_loss: 0.9200 - val_custom_f1: 0.5226 - val_weighted_custom_f1: 0.5209\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6603 - custom_f1: 0.6094 - weighted_custom_f1: 0.6133 - val_loss: 1.0356 - val_custom_f1: 0.5128 - val_weighted_custom_f1: 0.5336\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8668 - custom_f1: 0.6190 - weighted_custom_f1: 0.6190Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6212 - custom_f1: 0.6344 - weighted_custom_f1: 0.6382 - val_loss: 1.0302 - val_custom_f1: 0.5274 - val_weighted_custom_f1: 0.5347\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6234 - custom_f1: 0.6240 - weighted_custom_f1: 0.6306 - val_loss: 1.1303 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5233\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5284 - custom_f1: 0.6651 - weighted_custom_f1: 0.6694 - val_loss: 1.1301 - val_custom_f1: 0.4975 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8735 - custom_f1: 0.5221 - weighted_custom_f1: 0.5260 - val_loss: 0.9573 - val_custom_f1: 0.4714 - val_weighted_custom_f1: 0.4827\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9307 - custom_f1: 0.5047 - weighted_custom_f1: 0.5086 - val_loss: 0.9914 - val_custom_f1: 0.4765 - val_weighted_custom_f1: 0.4875\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.8572 - custom_f1: 0.5451 - weighted_custom_f1: 0.5483Epoch 52/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5146 - custom_f1: 0.6765 - weighted_custom_f1: 0.6802 - val_loss: 1.1809 - val_custom_f1: 0.5051 - val_weighted_custom_f1: 0.5274\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8729 - custom_f1: 0.5252 - weighted_custom_f1: 0.5282 - val_loss: 0.9582 - val_custom_f1: 0.4631 - val_weighted_custom_f1: 0.4754\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.5254 - custom_f1: 0.6644 - weighted_custom_f1: 0.6680Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5041 - custom_f1: 0.6838 - weighted_custom_f1: 0.6867 - val_loss: 1.5633 - val_custom_f1: 0.5447 - val_weighted_custom_f1: 0.5404\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5829 - custom_f1: 0.6450 - weighted_custom_f1: 0.6475 - val_loss: 1.2863 - val_custom_f1: 0.5489 - val_weighted_custom_f1: 0.5444\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4292 - custom_f1: 0.6667 - weighted_custom_f1: 0.6667Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6181 - custom_f1: 0.6281 - weighted_custom_f1: 0.6318 - val_loss: 1.2133 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5279\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9391 - custom_f1: 0.4950 - weighted_custom_f1: 0.5001 - val_loss: 1.1468 - val_custom_f1: 0.4929 - val_weighted_custom_f1: 0.5008\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5510 - custom_f1: 0.6656 - weighted_custom_f1: 0.6711Epoch 21/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9077 - custom_f1: 0.5011 - weighted_custom_f1: 0.5071 - val_loss: 1.3197 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5202\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5411 - custom_f1: 0.6671 - weighted_custom_f1: 0.6721 - val_loss: 1.3207 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5289\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.6033 - custom_f1: 0.6373 - weighted_custom_f1: 0.6420Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5408 - custom_f1: 0.6626 - weighted_custom_f1: 0.6662 - val_loss: 1.2654 - val_custom_f1: 0.4747 - val_weighted_custom_f1: 0.4817\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6373 - custom_f1: 0.6207 - weighted_custom_f1: 0.6239 - val_loss: 1.0154 - val_custom_f1: 0.5381 - val_weighted_custom_f1: 0.5467\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.8822 - custom_f1: 0.5083 - weighted_custom_f1: 0.5135Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8680 - custom_f1: 0.5311 - weighted_custom_f1: 0.5358 - val_loss: 1.0195 - val_custom_f1: 0.4738 - val_weighted_custom_f1: 0.4704\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5375 - custom_f1: 0.6630 - weighted_custom_f1: 0.6684 - val_loss: 1.2150 - val_custom_f1: 0.5532 - val_weighted_custom_f1: 0.5600\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6013 - custom_f1: 0.6385 - weighted_custom_f1: 0.6423 - val_loss: 1.1479 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5538\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.8873 - custom_f1: 0.5129 - weighted_custom_f1: 0.5188Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6522 - custom_f1: 0.6205 - weighted_custom_f1: 0.6247 - val_loss: 1.0760 - val_custom_f1: 0.4836 - val_weighted_custom_f1: 0.4961\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9054 - custom_f1: 0.5166 - weighted_custom_f1: 0.5197 - val_loss: 0.9433 - val_custom_f1: 0.5036 - val_weighted_custom_f1: 0.5100\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9479 - custom_f1: 0.5060 - weighted_custom_f1: 0.5114 - val_loss: 0.9982 - val_custom_f1: 0.4651 - val_weighted_custom_f1: 0.4764\n",
            " 11/105 [==>...........................] - ETA: 1s - loss: 0.5158 - custom_f1: 0.6803 - weighted_custom_f1: 0.6826Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5241 - custom_f1: 0.6813 - weighted_custom_f1: 0.6847 - val_loss: 1.2930 - val_custom_f1: 0.5200 - val_weighted_custom_f1: 0.5430\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9237 - custom_f1: 0.5095 - weighted_custom_f1: 0.5128 - val_loss: 0.9766 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5186\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.6225 - custom_f1: 0.6124 - weighted_custom_f1: 0.6197Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5122 - custom_f1: 0.6803 - weighted_custom_f1: 0.6839 - val_loss: 1.4854 - val_custom_f1: 0.5288 - val_weighted_custom_f1: 0.5245\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5895 - custom_f1: 0.6361 - weighted_custom_f1: 0.6410 - val_loss: 1.1895 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5185\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.7342 - custom_f1: 0.6534 - weighted_custom_f1: 0.6603Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8869 - custom_f1: 0.5111 - weighted_custom_f1: 0.5162 - val_loss: 1.2842 - val_custom_f1: 0.4497 - val_weighted_custom_f1: 0.4610\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5985 - custom_f1: 0.6329 - weighted_custom_f1: 0.6356 - val_loss: 1.1742 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.5103\n",
            "Epoch 55/100\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9494 - custom_f1: 0.4916 - weighted_custom_f1: 0.4956 - val_loss: 1.1646 - val_custom_f1: 0.4548 - val_weighted_custom_f1: 0.4644\n",
            " 33/105 [========>.....................] - ETA: 0s - loss: 0.5693 - custom_f1: 0.6578 - weighted_custom_f1: 0.6612Epoch 22/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5204 - custom_f1: 0.6763 - weighted_custom_f1: 0.6805 - val_loss: 1.2911 - val_custom_f1: 0.5195 - val_weighted_custom_f1: 0.5308\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5472 - custom_f1: 0.6628 - weighted_custom_f1: 0.6671 - val_loss: 1.3451 - val_custom_f1: 0.5105 - val_weighted_custom_f1: 0.5152\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.6166 - custom_f1: 0.6260 - weighted_custom_f1: 0.6312Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6314 - custom_f1: 0.6248 - weighted_custom_f1: 0.6296 - val_loss: 1.0573 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5240\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.5148 - custom_f1: 0.6694 - weighted_custom_f1: 0.6734Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8453 - custom_f1: 0.5415 - weighted_custom_f1: 0.5460 - val_loss: 0.9451 - val_custom_f1: 0.5257 - val_weighted_custom_f1: 0.5223\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.5227 - custom_f1: 0.6880 - weighted_custom_f1: 0.6882Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5263 - custom_f1: 0.6690 - weighted_custom_f1: 0.6729 - val_loss: 1.3044 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5461\n",
            " 10/105 [=>............................] - ETA: 0s - loss: 0.8163 - custom_f1: 0.5471 - weighted_custom_f1: 0.5481Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.7148 - custom_f1: 0.6345 - weighted_custom_f1: 0.6411 - val_loss: 1.0864 - val_custom_f1: 0.5444 - val_weighted_custom_f1: 0.5433\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.5348 - custom_f1: 0.6693 - weighted_custom_f1: 0.6728Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6199 - custom_f1: 0.6257 - weighted_custom_f1: 0.6301 - val_loss: 1.0881 - val_custom_f1: 0.4782 - val_weighted_custom_f1: 0.4899\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9021 - custom_f1: 0.5194 - weighted_custom_f1: 0.5244 - val_loss: 0.9218 - val_custom_f1: 0.5105 - val_weighted_custom_f1: 0.5205\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.6207 - custom_f1: 0.6348 - weighted_custom_f1: 0.6377Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9726 - custom_f1: 0.4961 - weighted_custom_f1: 0.5005 - val_loss: 1.0241 - val_custom_f1: 0.5247 - val_weighted_custom_f1: 0.5348\n",
            " 86/105 [=======================>......] - ETA: 0s - loss: 0.5171 - custom_f1: 0.6829 - weighted_custom_f1: 0.6866Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5223 - custom_f1: 0.6688 - weighted_custom_f1: 0.6726 - val_loss: 1.2268 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5357\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1391 - custom_f1: 0.5614 - weighted_custom_f1: 0.5614Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9069 - custom_f1: 0.5091 - weighted_custom_f1: 0.5137 - val_loss: 0.9271 - val_custom_f1: 0.4918 - val_weighted_custom_f1: 0.5012\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4820 - custom_f1: 0.6929 - weighted_custom_f1: 0.6950 - val_loss: 1.5655 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5070\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5833 - custom_f1: 0.6377 - weighted_custom_f1: 0.6408 - val_loss: 1.3048 - val_custom_f1: 0.5383 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8935 - custom_f1: 0.5108 - weighted_custom_f1: 0.5135 - val_loss: 1.2728 - val_custom_f1: 0.4591 - val_weighted_custom_f1: 0.4666\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5877 - custom_f1: 0.6377 - weighted_custom_f1: 0.6421 - val_loss: 1.1334 - val_custom_f1: 0.4986 - val_weighted_custom_f1: 0.5206\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.9318 - custom_f1: 0.5087 - weighted_custom_f1: 0.5127Epoch 60/100\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9415 - custom_f1: 0.4919 - weighted_custom_f1: 0.4955 - val_loss: 1.2048 - val_custom_f1: 0.4375 - val_weighted_custom_f1: 0.4492\n",
            "  9/105 [=>............................] - ETA: 0s - loss: 0.5874 - custom_f1: 0.6702 - weighted_custom_f1: 0.6740Epoch 23/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5320 - custom_f1: 0.6709 - weighted_custom_f1: 0.6754 - val_loss: 1.3056 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5225\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5158 - custom_f1: 0.6795 - weighted_custom_f1: 0.6832 - val_loss: 1.4521 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5378\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.6136 - custom_f1: 0.6317 - weighted_custom_f1: 0.6359Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6285 - custom_f1: 0.6204 - weighted_custom_f1: 0.6250 - val_loss: 1.0670 - val_custom_f1: 0.5345 - val_weighted_custom_f1: 0.5442\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8569 - custom_f1: 0.5328 - weighted_custom_f1: 0.5370 - val_loss: 0.9573 - val_custom_f1: 0.5410 - val_weighted_custom_f1: 0.5357\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5115 - custom_f1: 0.6711 - weighted_custom_f1: 0.6782 - val_loss: 1.3033 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5417\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5997 - custom_f1: 0.6351 - weighted_custom_f1: 0.6399 - val_loss: 1.1003 - val_custom_f1: 0.5559 - val_weighted_custom_f1: 0.5609\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6081 - custom_f1: 0.6341 - weighted_custom_f1: 0.6379 - val_loss: 1.2651 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5413\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5222 - custom_f1: 0.6708 - weighted_custom_f1: 0.6757 - val_loss: 1.2805 - val_custom_f1: 0.5168 - val_weighted_custom_f1: 0.5391\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8746 - custom_f1: 0.5262 - weighted_custom_f1: 0.5299 - val_loss: 1.0044 - val_custom_f1: 0.4650 - val_weighted_custom_f1: 0.4749\n",
            " 21/105 [=====>........................] - ETA: 0s - loss: 0.5666 - custom_f1: 0.6486 - weighted_custom_f1: 0.6559Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9358 - custom_f1: 0.5101 - weighted_custom_f1: 0.5150 - val_loss: 0.9920 - val_custom_f1: 0.4662 - val_weighted_custom_f1: 0.4775\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8806 - custom_f1: 0.5121 - weighted_custom_f1: 0.5172 - val_loss: 1.0142 - val_custom_f1: 0.4613 - val_weighted_custom_f1: 0.4710\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4915 - custom_f1: 0.6889 - weighted_custom_f1: 0.6932 - val_loss: 1.5747 - val_custom_f1: 0.5647 - val_weighted_custom_f1: 0.5553\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5883 - custom_f1: 0.6355 - weighted_custom_f1: 0.6395 - val_loss: 1.3292 - val_custom_f1: 0.5236 - val_weighted_custom_f1: 0.5174\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8986 - custom_f1: 0.5063 - weighted_custom_f1: 0.5099 - val_loss: 1.1919 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5153\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9595 - custom_f1: 0.4887 - weighted_custom_f1: 0.4931 - val_loss: 1.1588 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4930\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6225 - custom_f1: 0.6261 - weighted_custom_f1: 0.6307Epoch 57/100\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5286 - custom_f1: 0.6732 - weighted_custom_f1: 0.6777 - val_loss: 1.2845 - val_custom_f1: 0.5142 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5943 - custom_f1: 0.6370 - weighted_custom_f1: 0.6413 - val_loss: 1.3155 - val_custom_f1: 0.5038 - val_weighted_custom_f1: 0.5245\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 0.9084 - custom_f1: 0.5156 - weighted_custom_f1: 0.5211Epoch 61/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5186 - custom_f1: 0.6742 - weighted_custom_f1: 0.6798 - val_loss: 1.2989 - val_custom_f1: 0.5272 - val_weighted_custom_f1: 0.5362\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6236 - custom_f1: 0.6269 - weighted_custom_f1: 0.6311 - val_loss: 1.0107 - val_custom_f1: 0.5225 - val_weighted_custom_f1: 0.5344\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5381 - custom_f1: 0.6664 - weighted_custom_f1: 0.6709 - val_loss: 1.2136 - val_custom_f1: 0.5349 - val_weighted_custom_f1: 0.5359\n",
            " 55/105 [==============>...............] - ETA: 0s - loss: 0.9298 - custom_f1: 0.4925 - weighted_custom_f1: 0.4971Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5726 - custom_f1: 0.6526 - weighted_custom_f1: 0.6562 - val_loss: 1.0285 - val_custom_f1: 0.5232 - val_weighted_custom_f1: 0.5339\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8610 - custom_f1: 0.5318 - weighted_custom_f1: 0.5355 - val_loss: 0.9216 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5207\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5923 - custom_f1: 0.6368 - weighted_custom_f1: 0.6417 - val_loss: 1.1734 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5306\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8974 - custom_f1: 0.5223 - weighted_custom_f1: 0.5271 - val_loss: 0.9142 - val_custom_f1: 0.5005 - val_weighted_custom_f1: 0.5120\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4875 - custom_f1: 0.6864 - weighted_custom_f1: 0.6921 - val_loss: 1.2973 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5443\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.9157 - custom_f1: 0.5069 - weighted_custom_f1: 0.5108Epoch 52/100\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9351 - custom_f1: 0.5100 - weighted_custom_f1: 0.5125 - val_loss: 1.0344 - val_custom_f1: 0.4586 - val_weighted_custom_f1: 0.4679\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.8233 - custom_f1: 0.5480 - weighted_custom_f1: 0.5533Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9221 - custom_f1: 0.5072 - weighted_custom_f1: 0.5115 - val_loss: 0.9378 - val_custom_f1: 0.4930 - val_weighted_custom_f1: 0.5040\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.9714 - custom_f1: 0.4803 - weighted_custom_f1: 0.4831Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5320 - custom_f1: 0.6726 - weighted_custom_f1: 0.6780 - val_loss: 1.4270 - val_custom_f1: 0.5192 - val_weighted_custom_f1: 0.5193\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.4669 - custom_f1: 0.7127 - weighted_custom_f1: 0.7155Epoch 66/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5961 - custom_f1: 0.6423 - weighted_custom_f1: 0.6465 - val_loss: 1.4778 - val_custom_f1: 0.5554 - val_weighted_custom_f1: 0.5450\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.5971 - custom_f1: 0.6376 - weighted_custom_f1: 0.6428Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9644 - custom_f1: 0.4905 - weighted_custom_f1: 0.4945 - val_loss: 1.2097 - val_custom_f1: 0.4712 - val_weighted_custom_f1: 0.4783\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5379 - custom_f1: 0.6726 - weighted_custom_f1: 0.6780 - val_loss: 1.2655 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5264\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9178 - custom_f1: 0.5051 - weighted_custom_f1: 0.5091 - val_loss: 1.2145 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5302\n",
            "Epoch 71/100\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 0.8773 - custom_f1: 0.5175 - weighted_custom_f1: 0.5234Epoch 58/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5909 - custom_f1: 0.6397 - weighted_custom_f1: 0.6426 - val_loss: 1.2439 - val_custom_f1: 0.5027 - val_weighted_custom_f1: 0.5239\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5169 - custom_f1: 0.6785 - weighted_custom_f1: 0.6829 - val_loss: 1.2753 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5233\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.5949 - custom_f1: 0.6446 - weighted_custom_f1: 0.6494Epoch 67/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.6147 - custom_f1: 0.6336 - weighted_custom_f1: 0.6375 - val_loss: 1.0691 - val_custom_f1: 0.4781 - val_weighted_custom_f1: 0.4852\n",
            " 45/105 [===========>..................] - ETA: 0s - loss: 0.8886 - custom_f1: 0.5053 - weighted_custom_f1: 0.5103Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4938 - custom_f1: 0.6816 - weighted_custom_f1: 0.6866 - val_loss: 1.2655 - val_custom_f1: 0.5054 - val_weighted_custom_f1: 0.5285\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.5526 - custom_f1: 0.6530 - weighted_custom_f1: 0.6555Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5918 - custom_f1: 0.6408 - weighted_custom_f1: 0.6462 - val_loss: 1.3290 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8596 - custom_f1: 0.5309 - weighted_custom_f1: 0.5350 - val_loss: 0.9987 - val_custom_f1: 0.4909 - val_weighted_custom_f1: 0.4884\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6066 - custom_f1: 0.6293 - weighted_custom_f1: 0.6340 - val_loss: 1.1805 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5574\n",
            " 76/105 [====================>.........] - ETA: 0s - loss: 0.8891 - custom_f1: 0.5132 - weighted_custom_f1: 0.5172Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5178 - custom_f1: 0.6776 - weighted_custom_f1: 0.6819 - val_loss: 1.1909 - val_custom_f1: 0.4895 - val_weighted_custom_f1: 0.5108\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9306 - custom_f1: 0.5092 - weighted_custom_f1: 0.5124 - val_loss: 1.0191 - val_custom_f1: 0.4823 - val_weighted_custom_f1: 0.4929\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8858 - custom_f1: 0.5190 - weighted_custom_f1: 0.5239 - val_loss: 0.9173 - val_custom_f1: 0.4998 - val_weighted_custom_f1: 0.5115\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6058 - custom_f1: 0.6311 - weighted_custom_f1: 0.6347Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4728 - custom_f1: 0.7038 - weighted_custom_f1: 0.7071 - val_loss: 1.5382 - val_custom_f1: 0.5243 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8868 - custom_f1: 0.5171 - weighted_custom_f1: 0.5208 - val_loss: 0.9604 - val_custom_f1: 0.5110 - val_weighted_custom_f1: 0.5202\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.5010 - custom_f1: 0.6848 - weighted_custom_f1: 0.6890Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5592 - custom_f1: 0.6489 - weighted_custom_f1: 0.6512 - val_loss: 1.3376 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5128\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5382 - custom_f1: 0.6713 - weighted_custom_f1: 0.6746 - val_loss: 1.3184 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8943 - custom_f1: 0.5100 - weighted_custom_f1: 0.5154 - val_loss: 1.2370 - val_custom_f1: 0.5020 - val_weighted_custom_f1: 0.5125\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5105 - custom_f1: 0.6804 - weighted_custom_f1: 0.6876 - val_loss: 1.2712 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6066 - custom_f1: 0.6307 - weighted_custom_f1: 0.6344 - val_loss: 1.1458 - val_custom_f1: 0.4743 - val_weighted_custom_f1: 0.4953\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9630 - custom_f1: 0.5023 - weighted_custom_f1: 0.5068 - val_loss: 1.2415 - val_custom_f1: 0.4289 - val_weighted_custom_f1: 0.4407\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 0.8452 - custom_f1: 0.5369 - weighted_custom_f1: 0.5426Epoch 26/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5863 - custom_f1: 0.6426 - weighted_custom_f1: 0.6463 - val_loss: 1.1120 - val_custom_f1: 0.5386 - val_weighted_custom_f1: 0.5478\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.5001 - custom_f1: 0.6815 - weighted_custom_f1: 0.6866Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5040 - custom_f1: 0.6793 - weighted_custom_f1: 0.6830 - val_loss: 1.1699 - val_custom_f1: 0.5411 - val_weighted_custom_f1: 0.5478\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5983 - custom_f1: 0.6408 - weighted_custom_f1: 0.6463 - val_loss: 1.2838 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5297\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.8767 - custom_f1: 0.5209 - weighted_custom_f1: 0.5257Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5972 - custom_f1: 0.6428 - weighted_custom_f1: 0.6483 - val_loss: 1.1384 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5123\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8425 - custom_f1: 0.5322 - weighted_custom_f1: 0.5376 - val_loss: 0.9296 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5008\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5035 - custom_f1: 0.6795 - weighted_custom_f1: 0.6860 - val_loss: 1.2736 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5230\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9399 - custom_f1: 0.5133 - weighted_custom_f1: 0.5163 - val_loss: 0.9698 - val_custom_f1: 0.4992 - val_weighted_custom_f1: 0.5105\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8898 - custom_f1: 0.5198 - weighted_custom_f1: 0.5249 - val_loss: 0.9712 - val_custom_f1: 0.4807 - val_weighted_custom_f1: 0.4887\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4775 - custom_f1: 0.6946 - weighted_custom_f1: 0.7007 - val_loss: 1.6526 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5212\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.4405 - custom_f1: 0.6932 - weighted_custom_f1: 0.6993Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8798 - custom_f1: 0.5188 - weighted_custom_f1: 0.5233 - val_loss: 0.9919 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5379\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.4820 - custom_f1: 0.6952 - weighted_custom_f1: 0.6984Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5508 - custom_f1: 0.6621 - weighted_custom_f1: 0.6644 - val_loss: 1.4580 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5176\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5445 - custom_f1: 0.6716 - weighted_custom_f1: 0.6774 - val_loss: 1.4687 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5370\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9568 - custom_f1: 0.4911 - weighted_custom_f1: 0.4972 - val_loss: 1.1466 - val_custom_f1: 0.4221 - val_weighted_custom_f1: 0.4336\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8936 - custom_f1: 0.5116 - weighted_custom_f1: 0.5155 - val_loss: 1.2025 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5221\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.8905 - custom_f1: 0.5114 - weighted_custom_f1: 0.5153Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6050 - custom_f1: 0.6328 - weighted_custom_f1: 0.6380 - val_loss: 1.1567 - val_custom_f1: 0.4783 - val_weighted_custom_f1: 0.5003\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.5462 - custom_f1: 0.6757 - weighted_custom_f1: 0.6803Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5451 - custom_f1: 0.6715 - weighted_custom_f1: 0.6748 - val_loss: 1.2533 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5274\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.8608 - custom_f1: 0.5242 - weighted_custom_f1: 0.5284Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5880 - custom_f1: 0.6412 - weighted_custom_f1: 0.6464 - val_loss: 1.1560 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5351\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4897 - custom_f1: 0.6896 - weighted_custom_f1: 0.6938 - val_loss: 1.3744 - val_custom_f1: 0.5475 - val_weighted_custom_f1: 0.5473\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5777 - custom_f1: 0.6447 - weighted_custom_f1: 0.6522 - val_loss: 1.1103 - val_custom_f1: 0.5572 - val_weighted_custom_f1: 0.5555\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.5555 - custom_f1: 0.6584 - weighted_custom_f1: 0.6628Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5835 - custom_f1: 0.6366 - weighted_custom_f1: 0.6418 - val_loss: 1.2546 - val_custom_f1: 0.5255 - val_weighted_custom_f1: 0.5364\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.5579 - custom_f1: 0.6519 - weighted_custom_f1: 0.6564Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8375 - custom_f1: 0.5380 - weighted_custom_f1: 0.5427 - val_loss: 0.9207 - val_custom_f1: 0.5110 - val_weighted_custom_f1: 0.5103\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4815 - custom_f1: 0.6909 - weighted_custom_f1: 0.6964 - val_loss: 1.2075 - val_custom_f1: 0.5172 - val_weighted_custom_f1: 0.5402\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9287 - custom_f1: 0.5065 - weighted_custom_f1: 0.5104 - val_loss: 0.9674 - val_custom_f1: 0.4951 - val_weighted_custom_f1: 0.5061\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8729 - custom_f1: 0.5300 - weighted_custom_f1: 0.5334 - val_loss: 0.8988 - val_custom_f1: 0.5028 - val_weighted_custom_f1: 0.5146\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.5710 - custom_f1: 0.6476 - weighted_custom_f1: 0.6508Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4793 - custom_f1: 0.6931 - weighted_custom_f1: 0.6961 - val_loss: 1.8801 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9001 - custom_f1: 0.5134 - weighted_custom_f1: 0.5172 - val_loss: 1.0075 - val_custom_f1: 0.4331 - val_weighted_custom_f1: 0.4450\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 0.5815 - custom_f1: 0.6435 - weighted_custom_f1: 0.6482Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5590 - custom_f1: 0.6509 - weighted_custom_f1: 0.6555 - val_loss: 1.5011 - val_custom_f1: 0.5414 - val_weighted_custom_f1: 0.5305\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9035 - custom_f1: 0.5053 - weighted_custom_f1: 0.5113 - val_loss: 1.3024 - val_custom_f1: 0.4704 - val_weighted_custom_f1: 0.4814\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5131 - custom_f1: 0.6758 - weighted_custom_f1: 0.6804 - val_loss: 1.2871 - val_custom_f1: 0.5003 - val_weighted_custom_f1: 0.5115\n",
            "Epoch 61/100\n",
            "  9/105 [=>............................] - ETA: 0s - loss: 0.9049 - custom_f1: 0.4944 - weighted_custom_f1: 0.4953Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5071 - custom_f1: 0.6789 - weighted_custom_f1: 0.6821 - val_loss: 1.3767 - val_custom_f1: 0.5310 - val_weighted_custom_f1: 0.5364\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9748 - custom_f1: 0.4897 - weighted_custom_f1: 0.4966 - val_loss: 1.2114 - val_custom_f1: 0.4507 - val_weighted_custom_f1: 0.4582\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.4881 - custom_f1: 0.6814 - weighted_custom_f1: 0.6858Epoch 28/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5721 - custom_f1: 0.6449 - weighted_custom_f1: 0.6491 - val_loss: 1.1863 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5193\n",
            "  9/105 [=>............................] - ETA: 1s - loss: 0.9181 - custom_f1: 0.4837 - weighted_custom_f1: 0.4863Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5841 - custom_f1: 0.6403 - weighted_custom_f1: 0.6461 - val_loss: 1.1953 - val_custom_f1: 0.5044 - val_weighted_custom_f1: 0.5258\n",
            " 43/105 [===========>..................] - ETA: 0s - loss: 0.4807 - custom_f1: 0.6932 - weighted_custom_f1: 0.6961Epoch 66/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5058 - custom_f1: 0.6840 - weighted_custom_f1: 0.6868 - val_loss: 1.2264 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5956 - custom_f1: 0.6431 - weighted_custom_f1: 0.6475 - val_loss: 1.0612 - val_custom_f1: 0.5042 - val_weighted_custom_f1: 0.5116\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.5026 - custom_f1: 0.6873 - weighted_custom_f1: 0.6901Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6048 - custom_f1: 0.6389 - weighted_custom_f1: 0.6430 - val_loss: 1.4002 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5140\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.9492 - custom_f1: 0.4938 - weighted_custom_f1: 0.4967Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8563 - custom_f1: 0.5313 - weighted_custom_f1: 0.5363 - val_loss: 1.0059 - val_custom_f1: 0.5099 - val_weighted_custom_f1: 0.5068\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4919 - custom_f1: 0.6923 - weighted_custom_f1: 0.6967 - val_loss: 1.2311 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5399\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8880 - custom_f1: 0.5259 - weighted_custom_f1: 0.5288 - val_loss: 0.9558 - val_custom_f1: 0.4853 - val_weighted_custom_f1: 0.4930\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.6374 - custom_f1: 0.6383 - weighted_custom_f1: 0.6405Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9347 - custom_f1: 0.5115 - weighted_custom_f1: 0.5155 - val_loss: 0.9654 - val_custom_f1: 0.5208 - val_weighted_custom_f1: 0.5314\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.5848 - custom_f1: 0.6396 - weighted_custom_f1: 0.6439Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4738 - custom_f1: 0.6988 - weighted_custom_f1: 0.7046 - val_loss: 1.5864 - val_custom_f1: 0.5271 - val_weighted_custom_f1: 0.5255\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.5131 - custom_f1: 0.6801 - weighted_custom_f1: 0.6831Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8869 - custom_f1: 0.5129 - weighted_custom_f1: 0.5174 - val_loss: 0.9358 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5155\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5803 - custom_f1: 0.6403 - weighted_custom_f1: 0.6473 - val_loss: 1.3676 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4815\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9044 - custom_f1: 0.5084 - weighted_custom_f1: 0.5126 - val_loss: 1.2235 - val_custom_f1: 0.5040 - val_weighted_custom_f1: 0.5144\n",
            "Epoch 66/100\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5054 - custom_f1: 0.6853 - weighted_custom_f1: 0.6891 - val_loss: 1.4405 - val_custom_f1: 0.5262 - val_weighted_custom_f1: 0.5371\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9581 - custom_f1: 0.4941 - weighted_custom_f1: 0.4971 - val_loss: 1.0967 - val_custom_f1: 0.4422 - val_weighted_custom_f1: 0.4533\n",
            " 39/105 [==========>...................] - ETA: 0s - loss: 0.4791 - custom_f1: 0.7007 - weighted_custom_f1: 0.7063Epoch 75/100\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.6121 - custom_f1: 0.6325 - weighted_custom_f1: 0.6370Epoch 29/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5103 - custom_f1: 0.6817 - weighted_custom_f1: 0.6847 - val_loss: 1.2452 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5110\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5709 - custom_f1: 0.6442 - weighted_custom_f1: 0.6497 - val_loss: 1.3022 - val_custom_f1: 0.5091 - val_weighted_custom_f1: 0.5304\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.5545 - custom_f1: 0.6651 - weighted_custom_f1: 0.6673Epoch 66/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6121 - custom_f1: 0.6325 - weighted_custom_f1: 0.6370 - val_loss: 1.0405 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5238\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.9198 - custom_f1: 0.5165 - weighted_custom_f1: 0.5205Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5156 - custom_f1: 0.6774 - weighted_custom_f1: 0.6816 - val_loss: 1.2679 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5400\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5571 - custom_f1: 0.6597 - weighted_custom_f1: 0.6643 - val_loss: 1.2340 - val_custom_f1: 0.5068 - val_weighted_custom_f1: 0.5267\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.5616 - custom_f1: 0.6527 - weighted_custom_f1: 0.6562Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6076 - custom_f1: 0.6357 - weighted_custom_f1: 0.6407 - val_loss: 1.2409 - val_custom_f1: 0.4879 - val_weighted_custom_f1: 0.4987\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.8797 - custom_f1: 0.5125 - weighted_custom_f1: 0.5170Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8662 - custom_f1: 0.5300 - weighted_custom_f1: 0.5362 - val_loss: 0.9671 - val_custom_f1: 0.4900 - val_weighted_custom_f1: 0.4906\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4972 - custom_f1: 0.6880 - weighted_custom_f1: 0.6919 - val_loss: 1.2581 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5411\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9600 - custom_f1: 0.5002 - weighted_custom_f1: 0.5063 - val_loss: 0.9772 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4940\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9292 - custom_f1: 0.5104 - weighted_custom_f1: 0.5151 - val_loss: 0.9391 - val_custom_f1: 0.4901 - val_weighted_custom_f1: 0.5012\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4708 - custom_f1: 0.6996 - weighted_custom_f1: 0.7031 - val_loss: 1.9255 - val_custom_f1: 0.5354 - val_weighted_custom_f1: 0.5306\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8166 - custom_f1: 0.2857 - weighted_custom_f1: 0.2857Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9178 - custom_f1: 0.5085 - weighted_custom_f1: 0.5126 - val_loss: 1.2593 - val_custom_f1: 0.4535 - val_weighted_custom_f1: 0.4652\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5638 - custom_f1: 0.6516 - weighted_custom_f1: 0.6554 - val_loss: 1.4387 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5038\n",
            " 12/105 [==>...........................] - ETA: 0s - loss: 0.4267 - custom_f1: 0.7300 - weighted_custom_f1: 0.7349Epoch 67/100\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8797 - custom_f1: 0.5125 - weighted_custom_f1: 0.5170 - val_loss: 0.9369 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.5028\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4975 - custom_f1: 0.6871 - weighted_custom_f1: 0.6906 - val_loss: 1.3837 - val_custom_f1: 0.5049 - val_weighted_custom_f1: 0.5148\n",
            " 96/105 [==========================>...] - ETA: 0s - loss: 0.4884 - custom_f1: 0.6870 - weighted_custom_f1: 0.6909Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5060 - custom_f1: 0.6853 - weighted_custom_f1: 0.6880 - val_loss: 1.4597 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5277\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.4404 - custom_f1: 0.7133 - weighted_custom_f1: 0.7221Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9255 - custom_f1: 0.5027 - weighted_custom_f1: 0.5059 - val_loss: 1.1400 - val_custom_f1: 0.4586 - val_weighted_custom_f1: 0.4701\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.8489 - custom_f1: 0.5521 - weighted_custom_f1: 0.5547Epoch 30/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5987 - custom_f1: 0.6459 - weighted_custom_f1: 0.6502 - val_loss: 1.2888 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5325\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4857 - custom_f1: 0.6860 - weighted_custom_f1: 0.6910 - val_loss: 1.3581 - val_custom_f1: 0.5179 - val_weighted_custom_f1: 0.5416\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5865 - custom_f1: 0.6387 - weighted_custom_f1: 0.6450 - val_loss: 1.0202 - val_custom_f1: 0.5023 - val_weighted_custom_f1: 0.5128\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5518 - custom_f1: 0.6561 - weighted_custom_f1: 0.6609 - val_loss: 1.0763 - val_custom_f1: 0.5311 - val_weighted_custom_f1: 0.5356\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.4675 - custom_f1: 0.7003 - weighted_custom_f1: 0.7051Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5806 - custom_f1: 0.6384 - weighted_custom_f1: 0.6453 - val_loss: 1.2383 - val_custom_f1: 0.4680 - val_weighted_custom_f1: 0.4793\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.5668 - custom_f1: 0.6539 - weighted_custom_f1: 0.6588Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8319 - custom_f1: 0.5410 - weighted_custom_f1: 0.5462 - val_loss: 0.9375 - val_custom_f1: 0.5143 - val_weighted_custom_f1: 0.5142\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4673 - custom_f1: 0.7004 - weighted_custom_f1: 0.7042 - val_loss: 1.4217 - val_custom_f1: 0.5245 - val_weighted_custom_f1: 0.5462\n",
            "  6/105 [>.............................] - ETA: 1s - loss: 0.8893 - custom_f1: 0.5622 - weighted_custom_f1: 0.5694Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9338 - custom_f1: 0.5061 - weighted_custom_f1: 0.5106 - val_loss: 1.0971 - val_custom_f1: 0.4734 - val_weighted_custom_f1: 0.4764\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4662 - custom_f1: 0.7009 - weighted_custom_f1: 0.7054 - val_loss: 1.8358 - val_custom_f1: 0.5321 - val_weighted_custom_f1: 0.5320\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1130 - custom_f1: 0.5000 - weighted_custom_f1: 0.5000Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8943 - custom_f1: 0.5251 - weighted_custom_f1: 0.5296 - val_loss: 0.9236 - val_custom_f1: 0.4699 - val_weighted_custom_f1: 0.4799\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.9624 - custom_f1: 0.5104 - weighted_custom_f1: 0.5168Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8690 - custom_f1: 0.5249 - weighted_custom_f1: 0.5285 - val_loss: 0.9420 - val_custom_f1: 0.4700 - val_weighted_custom_f1: 0.4833\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4852 - custom_f1: 0.6947 - weighted_custom_f1: 0.6983 - val_loss: 1.5357 - val_custom_f1: 0.5230 - val_weighted_custom_f1: 0.5317\n",
            "  9/105 [=>............................] - ETA: 0s - loss: 0.4871 - custom_f1: 0.6810 - weighted_custom_f1: 0.6849Epoch 77/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5697 - custom_f1: 0.6515 - weighted_custom_f1: 0.6559 - val_loss: 1.5760 - val_custom_f1: 0.5375 - val_weighted_custom_f1: 0.5324\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9084 - custom_f1: 0.5072 - weighted_custom_f1: 0.5115 - val_loss: 1.3548 - val_custom_f1: 0.4998 - val_weighted_custom_f1: 0.5107\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5140 - custom_f1: 0.6765 - weighted_custom_f1: 0.6815 - val_loss: 1.2552 - val_custom_f1: 0.5059 - val_weighted_custom_f1: 0.5112\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9637 - custom_f1: 0.4926 - weighted_custom_f1: 0.4981 - val_loss: 1.1822 - val_custom_f1: 0.4575 - val_weighted_custom_f1: 0.4692\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3388 - custom_f1: 0.6667 - weighted_custom_f1: 0.6667Epoch 31/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5949 - custom_f1: 0.6367 - weighted_custom_f1: 0.6427 - val_loss: 1.2361 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5149\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5990 - custom_f1: 0.6390 - weighted_custom_f1: 0.6431Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5211 - custom_f1: 0.6753 - weighted_custom_f1: 0.6811 - val_loss: 1.2690 - val_custom_f1: 0.5235 - val_weighted_custom_f1: 0.5296\n",
            " 37/105 [=========>....................] - ETA: 0s - loss: 0.5442 - custom_f1: 0.6520 - weighted_custom_f1: 0.6595Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5987 - custom_f1: 0.6395 - weighted_custom_f1: 0.6433 - val_loss: 1.0138 - val_custom_f1: 0.4984 - val_weighted_custom_f1: 0.5067\n",
            " 78/105 [=====================>........] - ETA: 0s - loss: 0.9024 - custom_f1: 0.5102 - weighted_custom_f1: 0.5147Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5423 - custom_f1: 0.6618 - weighted_custom_f1: 0.6667 - val_loss: 1.2463 - val_custom_f1: 0.5336 - val_weighted_custom_f1: 0.5410\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5889 - custom_f1: 0.6418 - weighted_custom_f1: 0.6466 - val_loss: 1.2725 - val_custom_f1: 0.5047 - val_weighted_custom_f1: 0.5158\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.4708 - custom_f1: 0.7031 - weighted_custom_f1: 0.7061Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8276 - custom_f1: 0.5427 - weighted_custom_f1: 0.5469 - val_loss: 0.9428 - val_custom_f1: 0.4968 - val_weighted_custom_f1: 0.4941\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4571 - custom_f1: 0.7051 - weighted_custom_f1: 0.7101 - val_loss: 1.6498 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5294\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4569 - custom_f1: 0.7072 - weighted_custom_f1: 0.7117 - val_loss: 1.3264 - val_custom_f1: 0.5008 - val_weighted_custom_f1: 0.5228\n",
            "Epoch 73/100\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8676 - custom_f1: 0.5311 - weighted_custom_f1: 0.5355 - val_loss: 0.9080 - val_custom_f1: 0.4958 - val_weighted_custom_f1: 0.5068\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4876 - custom_f1: 0.6906 - weighted_custom_f1: 0.6977 - val_loss: 1.3611 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5205\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7134 - custom_f1: 0.5926 - weighted_custom_f1: 0.5926Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8776 - custom_f1: 0.5143 - weighted_custom_f1: 0.5181 - val_loss: 0.9937 - val_custom_f1: 0.4567 - val_weighted_custom_f1: 0.4669\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9060 - custom_f1: 0.5112 - weighted_custom_f1: 0.5156 - val_loss: 1.2779 - val_custom_f1: 0.5009 - val_weighted_custom_f1: 0.5115\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9488 - custom_f1: 0.5030 - weighted_custom_f1: 0.5076 - val_loss: 1.0097 - val_custom_f1: 0.4454 - val_weighted_custom_f1: 0.4556\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.9198 - custom_f1: 0.4629 - weighted_custom_f1: 0.4706Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6057 - custom_f1: 0.6462 - weighted_custom_f1: 0.6496 - val_loss: 1.5954 - val_custom_f1: 0.5407 - val_weighted_custom_f1: 0.5301\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9356 - custom_f1: 0.4955 - weighted_custom_f1: 0.5032 - val_loss: 1.1743 - val_custom_f1: 0.5177 - val_weighted_custom_f1: 0.5265\n",
            "Epoch 69/100\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5165 - custom_f1: 0.6811 - weighted_custom_f1: 0.6877 - val_loss: 1.2968 - val_custom_f1: 0.5176 - val_weighted_custom_f1: 0.5229\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5733 - custom_f1: 0.6443 - weighted_custom_f1: 0.6504 - val_loss: 1.1681 - val_custom_f1: 0.4842 - val_weighted_custom_f1: 0.5054\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.3668 - custom_f1: 0.8000 - weighted_custom_f1: 0.8000Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4836 - custom_f1: 0.6907 - weighted_custom_f1: 0.6936 - val_loss: 1.4171 - val_custom_f1: 0.5526 - val_weighted_custom_f1: 0.5584\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.5777 - custom_f1: 0.6419 - weighted_custom_f1: 0.6486Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5627 - custom_f1: 0.6603 - weighted_custom_f1: 0.6627 - val_loss: 1.0902 - val_custom_f1: 0.4999 - val_weighted_custom_f1: 0.5101\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.6016 - custom_f1: 0.6408 - weighted_custom_f1: 0.6448 - val_loss: 1.0807 - val_custom_f1: 0.5314 - val_weighted_custom_f1: 0.5402\n",
            " 66/105 [=================>............] - ETA: 0s - loss: 0.9570 - custom_f1: 0.4951 - weighted_custom_f1: 0.4984Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5721 - custom_f1: 0.6496 - weighted_custom_f1: 0.6555 - val_loss: 1.3090 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4822 - custom_f1: 0.6917 - weighted_custom_f1: 0.6966 - val_loss: 1.2485 - val_custom_f1: 0.5055 - val_weighted_custom_f1: 0.5277\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8476 - custom_f1: 0.5367 - weighted_custom_f1: 0.5407 - val_loss: 0.9259 - val_custom_f1: 0.5290 - val_weighted_custom_f1: 0.5285\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4637 - custom_f1: 0.7097 - weighted_custom_f1: 0.7133 - val_loss: 1.5884 - val_custom_f1: 0.5219 - val_weighted_custom_f1: 0.5186\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6527 - custom_f1: 0.4000 - weighted_custom_f1: 0.4000Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9129 - custom_f1: 0.5134 - weighted_custom_f1: 0.5183 - val_loss: 0.9189 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5105\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4862 - custom_f1: 0.6945 - weighted_custom_f1: 0.6983 - val_loss: 1.3643 - val_custom_f1: 0.5228 - val_weighted_custom_f1: 0.5341\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9381 - custom_f1: 0.5045 - weighted_custom_f1: 0.5096 - val_loss: 0.9979 - val_custom_f1: 0.5177 - val_weighted_custom_f1: 0.5276\n",
            " 63/105 [=================>............] - ETA: 0s - loss: 0.5825 - custom_f1: 0.6570 - weighted_custom_f1: 0.6595Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8897 - custom_f1: 0.5123 - weighted_custom_f1: 0.5182 - val_loss: 0.9431 - val_custom_f1: 0.4701 - val_weighted_custom_f1: 0.4826\n",
            " 12/105 [==>...........................] - ETA: 0s - loss: 0.4327 - custom_f1: 0.6882 - weighted_custom_f1: 0.6946Epoch 60/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9375 - custom_f1: 0.4900 - weighted_custom_f1: 0.4953 - val_loss: 1.3232 - val_custom_f1: 0.5123 - val_weighted_custom_f1: 0.5087\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5745 - custom_f1: 0.6436 - weighted_custom_f1: 0.6500 - val_loss: 1.4221 - val_custom_f1: 0.5306 - val_weighted_custom_f1: 0.5250\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.5749 - custom_f1: 0.6526 - weighted_custom_f1: 0.6553Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9437 - custom_f1: 0.4941 - weighted_custom_f1: 0.4988 - val_loss: 1.1959 - val_custom_f1: 0.5106 - val_weighted_custom_f1: 0.5202\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4999 - custom_f1: 0.6886 - weighted_custom_f1: 0.6931 - val_loss: 1.4463 - val_custom_f1: 0.5238 - val_weighted_custom_f1: 0.5277\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.5156 - custom_f1: 0.6682 - weighted_custom_f1: 0.6707Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5776 - custom_f1: 0.6441 - weighted_custom_f1: 0.6491 - val_loss: 1.3035 - val_custom_f1: 0.5030 - val_weighted_custom_f1: 0.5235\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5013 - custom_f1: 0.6816 - weighted_custom_f1: 0.6858 - val_loss: 1.2609 - val_custom_f1: 0.5086 - val_weighted_custom_f1: 0.5195\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5956 - custom_f1: 0.6461 - weighted_custom_f1: 0.6506 - val_loss: 1.1580 - val_custom_f1: 0.5194 - val_weighted_custom_f1: 0.5404\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.9148 - custom_f1: 0.5077 - weighted_custom_f1: 0.5133Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5847 - custom_f1: 0.6466 - weighted_custom_f1: 0.6500 - val_loss: 1.0602 - val_custom_f1: 0.5278 - val_weighted_custom_f1: 0.5508\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5864 - custom_f1: 0.6515 - weighted_custom_f1: 0.6560 - val_loss: 1.2766 - val_custom_f1: 0.4965 - val_weighted_custom_f1: 0.5071\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5813 - custom_f1: 0.6516 - weighted_custom_f1: 0.6561Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4852 - custom_f1: 0.6951 - weighted_custom_f1: 0.6982 - val_loss: 1.3199 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5388\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.5604 - custom_f1: 0.6573 - weighted_custom_f1: 0.6616Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8619 - custom_f1: 0.5353 - weighted_custom_f1: 0.5398 - val_loss: 0.9843 - val_custom_f1: 0.4695 - val_weighted_custom_f1: 0.4675\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4483 - custom_f1: 0.7090 - weighted_custom_f1: 0.7123 - val_loss: 1.7396 - val_custom_f1: 0.5415 - val_weighted_custom_f1: 0.5369\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.5895 - custom_f1: 0.6463 - weighted_custom_f1: 0.6496Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9158 - custom_f1: 0.5063 - weighted_custom_f1: 0.5131 - val_loss: 1.2738 - val_custom_f1: 0.5032 - val_weighted_custom_f1: 0.5132\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4730 - custom_f1: 0.6936 - weighted_custom_f1: 0.6975 - val_loss: 1.5233 - val_custom_f1: 0.5212 - val_weighted_custom_f1: 0.5287\n",
            "Epoch 80/100\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.8573 - custom_f1: 0.5369 - weighted_custom_f1: 0.5406Epoch 67/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9440 - custom_f1: 0.5060 - weighted_custom_f1: 0.5114 - val_loss: 1.0471 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5089\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.4992 - custom_f1: 0.7038 - weighted_custom_f1: 0.7100Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8947 - custom_f1: 0.5186 - weighted_custom_f1: 0.5243 - val_loss: 0.9068 - val_custom_f1: 0.5260 - val_weighted_custom_f1: 0.5380\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8953 - custom_f1: 0.5132 - weighted_custom_f1: 0.5179 - val_loss: 0.9506 - val_custom_f1: 0.5014 - val_weighted_custom_f1: 0.5111\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.5453 - custom_f1: 0.6605 - weighted_custom_f1: 0.6654Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5608 - custom_f1: 0.6569 - weighted_custom_f1: 0.6614 - val_loss: 1.4130 - val_custom_f1: 0.5146 - val_weighted_custom_f1: 0.5084\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5078 - custom_f1: 0.6837 - weighted_custom_f1: 0.6876 - val_loss: 1.2622 - val_custom_f1: 0.5104 - val_weighted_custom_f1: 0.5189\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5839 - custom_f1: 0.6483 - weighted_custom_f1: 0.6516 - val_loss: 1.2692 - val_custom_f1: 0.4896 - val_weighted_custom_f1: 0.5101\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.8913 - custom_f1: 0.5009 - weighted_custom_f1: 0.5039Epoch 71/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9707 - custom_f1: 0.4846 - weighted_custom_f1: 0.4914 - val_loss: 1.5071 - val_custom_f1: 0.3865 - val_weighted_custom_f1: 0.3983\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4812 - custom_f1: 0.6968 - weighted_custom_f1: 0.6988 - val_loss: 1.3271 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5346\n",
            " 56/105 [===============>..............] - ETA: 0s - loss: 0.8836 - custom_f1: 0.5105 - weighted_custom_f1: 0.5160Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5812 - custom_f1: 0.6474 - weighted_custom_f1: 0.6507 - val_loss: 1.1087 - val_custom_f1: 0.5387 - val_weighted_custom_f1: 0.5437\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.5591 - custom_f1: 0.6526 - weighted_custom_f1: 0.6577Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5623 - custom_f1: 0.6509 - weighted_custom_f1: 0.6558 - val_loss: 1.2058 - val_custom_f1: 0.5505 - val_weighted_custom_f1: 0.5550\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5964 - custom_f1: 0.6433 - weighted_custom_f1: 0.6468 - val_loss: 1.2273 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5291\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4637 - custom_f1: 0.7092 - weighted_custom_f1: 0.7138 - val_loss: 1.2876 - val_custom_f1: 0.5385 - val_weighted_custom_f1: 0.5613\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8771 - custom_f1: 0.5325 - weighted_custom_f1: 0.5363 - val_loss: 1.0201 - val_custom_f1: 0.4640 - val_weighted_custom_f1: 0.4603\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4845 - custom_f1: 0.6935 - weighted_custom_f1: 0.6979 - val_loss: 1.5629 - val_custom_f1: 0.5213 - val_weighted_custom_f1: 0.5296\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4393 - custom_f1: 0.7150 - weighted_custom_f1: 0.7191 - val_loss: 1.8769 - val_custom_f1: 0.5458 - val_weighted_custom_f1: 0.5404\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9033 - custom_f1: 0.5131 - weighted_custom_f1: 0.5184 - val_loss: 1.2526 - val_custom_f1: 0.4804 - val_weighted_custom_f1: 0.4910\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4374 - custom_f1: 0.7308 - weighted_custom_f1: 0.7308Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8939 - custom_f1: 0.5135 - weighted_custom_f1: 0.5189 - val_loss: 0.9449 - val_custom_f1: 0.4544 - val_weighted_custom_f1: 0.4649\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9251 - custom_f1: 0.5079 - weighted_custom_f1: 0.5168 - val_loss: 0.9622 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5315\n",
            " 60/105 [================>.............] - ETA: 0s - loss: 0.5985 - custom_f1: 0.6437 - weighted_custom_f1: 0.6489Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8761 - custom_f1: 0.5292 - weighted_custom_f1: 0.5336 - val_loss: 0.9138 - val_custom_f1: 0.5251 - val_weighted_custom_f1: 0.5366\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.4969 - custom_f1: 0.6865 - weighted_custom_f1: 0.6917Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5474 - custom_f1: 0.6620 - weighted_custom_f1: 0.6655 - val_loss: 1.6738 - val_custom_f1: 0.5448 - val_weighted_custom_f1: 0.5361\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.4332 - custom_f1: 0.7194 - weighted_custom_f1: 0.7231Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4918 - custom_f1: 0.6964 - weighted_custom_f1: 0.6986 - val_loss: 1.2995 - val_custom_f1: 0.5025 - val_weighted_custom_f1: 0.5072\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9756 - custom_f1: 0.4869 - weighted_custom_f1: 0.4923 - val_loss: 1.1981 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5143\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.5597 - custom_f1: 0.6643 - weighted_custom_f1: 0.6676Epoch 35/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5663 - custom_f1: 0.6509 - weighted_custom_f1: 0.6558 - val_loss: 1.2874 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5278\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.8761 - custom_f1: 0.5170 - weighted_custom_f1: 0.5209Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4921 - custom_f1: 0.6879 - weighted_custom_f1: 0.6948 - val_loss: 1.3555 - val_custom_f1: 0.4983 - val_weighted_custom_f1: 0.5090\n",
            " 60/105 [================>.............] - ETA: 0s - loss: 0.9132 - custom_f1: 0.5276 - weighted_custom_f1: 0.5313Epoch 78/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5528 - custom_f1: 0.6559 - weighted_custom_f1: 0.6613 - val_loss: 1.1202 - val_custom_f1: 0.5241 - val_weighted_custom_f1: 0.5356\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5723 - custom_f1: 0.6558 - weighted_custom_f1: 0.6610 - val_loss: 1.1569 - val_custom_f1: 0.5214 - val_weighted_custom_f1: 0.5258\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5977 - custom_f1: 0.6394 - weighted_custom_f1: 0.6425 - val_loss: 1.2394 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.5040\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.5372 - custom_f1: 0.6463 - weighted_custom_f1: 0.6513Epoch 76/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4533 - custom_f1: 0.7123 - weighted_custom_f1: 0.7151 - val_loss: 1.3920 - val_custom_f1: 0.5053 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8974 - custom_f1: 0.5113 - weighted_custom_f1: 0.5153 - val_loss: 1.2441 - val_custom_f1: 0.5024 - val_weighted_custom_f1: 0.5131\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4666 - custom_f1: 0.7060 - weighted_custom_f1: 0.7098 - val_loss: 1.4090 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5271\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4559 - custom_f1: 0.7095 - weighted_custom_f1: 0.7153 - val_loss: 1.7059 - val_custom_f1: 0.5282 - val_weighted_custom_f1: 0.5267\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8774 - custom_f1: 0.5322 - weighted_custom_f1: 0.5357 - val_loss: 1.0137 - val_custom_f1: 0.5194 - val_weighted_custom_f1: 0.5155\n",
            " 60/105 [================>.............] - ETA: 0s - loss: 0.5432 - custom_f1: 0.6654 - weighted_custom_f1: 0.6702Epoch 62/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9296 - custom_f1: 0.5165 - weighted_custom_f1: 0.5203 - val_loss: 0.9940 - val_custom_f1: 0.4635 - val_weighted_custom_f1: 0.4749\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.4382 - custom_f1: 0.7032 - weighted_custom_f1: 0.7065Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8914 - custom_f1: 0.5123 - weighted_custom_f1: 0.5160 - val_loss: 0.9197 - val_custom_f1: 0.4911 - val_weighted_custom_f1: 0.5009\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9048 - custom_f1: 0.5231 - weighted_custom_f1: 0.5270 - val_loss: 0.9181 - val_custom_f1: 0.4801 - val_weighted_custom_f1: 0.4908\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5282 - custom_f1: 0.6648 - weighted_custom_f1: 0.6695 - val_loss: 1.4558 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9413 - custom_f1: 0.4979 - weighted_custom_f1: 0.5023 - val_loss: 1.2367 - val_custom_f1: 0.5092 - val_weighted_custom_f1: 0.5182\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5485 - custom_f1: 0.6625 - weighted_custom_f1: 0.6675 - val_loss: 1.3162 - val_custom_f1: 0.4917 - val_weighted_custom_f1: 0.5133\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.4988 - custom_f1: 0.6896 - weighted_custom_f1: 0.6950 - val_loss: 1.2572 - val_custom_f1: 0.4893 - val_weighted_custom_f1: 0.4946\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4815 - custom_f1: 0.6944 - weighted_custom_f1: 0.6981 - val_loss: 1.3972 - val_custom_f1: 0.5113 - val_weighted_custom_f1: 0.5345\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.8778 - custom_f1: 0.5365 - weighted_custom_f1: 0.5416Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5885 - custom_f1: 0.6476 - weighted_custom_f1: 0.6517 - val_loss: 1.2348 - val_custom_f1: 0.5487 - val_weighted_custom_f1: 0.5474\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5591 - custom_f1: 0.6575 - weighted_custom_f1: 0.6638 - val_loss: 1.1306 - val_custom_f1: 0.5267 - val_weighted_custom_f1: 0.5347\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5462 - custom_f1: 0.6636 - weighted_custom_f1: 0.6687 - val_loss: 1.3557 - val_custom_f1: 0.5132 - val_weighted_custom_f1: 0.5230\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4636 - custom_f1: 0.7043 - weighted_custom_f1: 0.7080 - val_loss: 1.4044 - val_custom_f1: 0.4643 - val_weighted_custom_f1: 0.4857\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.5576 - custom_f1: 0.6570 - weighted_custom_f1: 0.6625Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8552 - custom_f1: 0.5366 - weighted_custom_f1: 0.5398 - val_loss: 0.9790 - val_custom_f1: 0.4879 - val_weighted_custom_f1: 0.4849\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4650 - custom_f1: 0.6981 - weighted_custom_f1: 0.7043 - val_loss: 1.3817 - val_custom_f1: 0.4943 - val_weighted_custom_f1: 0.5022\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8948 - custom_f1: 0.5113 - weighted_custom_f1: 0.5170 - val_loss: 1.2953 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5258\n",
            "Epoch 83/100\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4721 - custom_f1: 0.7056 - weighted_custom_f1: 0.7090 - val_loss: 1.9283 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5380\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.4748 - custom_f1: 0.6931 - weighted_custom_f1: 0.6981Epoch 78/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9283 - custom_f1: 0.5073 - weighted_custom_f1: 0.5126 - val_loss: 0.9599 - val_custom_f1: 0.5142 - val_weighted_custom_f1: 0.5259\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8855 - custom_f1: 0.5196 - weighted_custom_f1: 0.5244 - val_loss: 1.0711 - val_custom_f1: 0.4318 - val_weighted_custom_f1: 0.4439\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8834 - custom_f1: 0.5258 - weighted_custom_f1: 0.5302 - val_loss: 0.9126 - val_custom_f1: 0.5299 - val_weighted_custom_f1: 0.5420\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5191 - custom_f1: 0.6734 - weighted_custom_f1: 0.6781 - val_loss: 1.5694 - val_custom_f1: 0.5308 - val_weighted_custom_f1: 0.5214\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.4737 - custom_f1: 0.7156 - weighted_custom_f1: 0.7168Epoch 74/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4842 - custom_f1: 0.6949 - weighted_custom_f1: 0.6980 - val_loss: 1.3752 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5229\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6429 - custom_f1: 0.5385 - weighted_custom_f1: 0.5385Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5564 - custom_f1: 0.6539 - weighted_custom_f1: 0.6596 - val_loss: 1.3473 - val_custom_f1: 0.4955 - val_weighted_custom_f1: 0.5172\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9526 - custom_f1: 0.5004 - weighted_custom_f1: 0.5053 - val_loss: 1.2326 - val_custom_f1: 0.4581 - val_weighted_custom_f1: 0.4692\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.4781 - custom_f1: 0.6971 - weighted_custom_f1: 0.7019Epoch 37/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4716 - custom_f1: 0.6954 - weighted_custom_f1: 0.7002 - val_loss: 1.4207 - val_custom_f1: 0.5293 - val_weighted_custom_f1: 0.5298\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 1.0114 - custom_f1: 0.4912 - weighted_custom_f1: 0.4945Epoch 80/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5701 - custom_f1: 0.6503 - weighted_custom_f1: 0.6542 - val_loss: 1.2087 - val_custom_f1: 0.5616 - val_weighted_custom_f1: 0.5681\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5357 - custom_f1: 0.6697 - weighted_custom_f1: 0.6732 - val_loss: 1.2006 - val_custom_f1: 0.5196 - val_weighted_custom_f1: 0.5240\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.4418 - custom_f1: 0.7115 - weighted_custom_f1: 0.7157Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5789 - custom_f1: 0.6516 - weighted_custom_f1: 0.6587 - val_loss: 1.3082 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4959\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4467 - custom_f1: 0.7072 - weighted_custom_f1: 0.7111 - val_loss: 1.4854 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5414\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9086 - custom_f1: 0.5077 - weighted_custom_f1: 0.5134 - val_loss: 1.2571 - val_custom_f1: 0.5241 - val_weighted_custom_f1: 0.5333\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8540 - custom_f1: 0.5341 - weighted_custom_f1: 0.5382 - val_loss: 0.9277 - val_custom_f1: 0.5265 - val_weighted_custom_f1: 0.5240\n",
            " 42/105 [===========>..................] - ETA: 0s - loss: 0.5549 - custom_f1: 0.6516 - weighted_custom_f1: 0.6554Epoch 71/100\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4566 - custom_f1: 0.7098 - weighted_custom_f1: 0.7118 - val_loss: 1.9959 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5411\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4756 - custom_f1: 0.7000 - weighted_custom_f1: 0.7034 - val_loss: 1.4107 - val_custom_f1: 0.5285 - val_weighted_custom_f1: 0.5368\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9256 - custom_f1: 0.5129 - weighted_custom_f1: 0.5164 - val_loss: 0.9647 - val_custom_f1: 0.4923 - val_weighted_custom_f1: 0.5039\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.5657 - custom_f1: 0.6467 - weighted_custom_f1: 0.6505Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5638 - custom_f1: 0.6531 - weighted_custom_f1: 0.6576 - val_loss: 1.6412 - val_custom_f1: 0.5471 - val_weighted_custom_f1: 0.5403\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4744 - custom_f1: 0.6973 - weighted_custom_f1: 0.7033 - val_loss: 1.3526 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5266\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.8986 - custom_f1: 0.5201 - weighted_custom_f1: 0.5259Epoch 75/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1416 - custom_f1: 0.5055 - weighted_custom_f1: 0.5055Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8941 - custom_f1: 0.5177 - weighted_custom_f1: 0.5227 - val_loss: 0.9477 - val_custom_f1: 0.4657 - val_weighted_custom_f1: 0.4765\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.4902 - custom_f1: 0.7066 - weighted_custom_f1: 0.7095Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8756 - custom_f1: 0.5289 - weighted_custom_f1: 0.5337 - val_loss: 0.9492 - val_custom_f1: 0.5443 - val_weighted_custom_f1: 0.5542\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.9805 - custom_f1: 0.4444 - weighted_custom_f1: 0.4444Epoch 65/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9975 - custom_f1: 0.4894 - weighted_custom_f1: 0.4939 - val_loss: 1.2112 - val_custom_f1: 0.5265 - val_weighted_custom_f1: 0.5369\n",
            " 85/105 [=======================>......] - ETA: 0s - loss: 0.5820 - custom_f1: 0.6423 - weighted_custom_f1: 0.6459Epoch 38/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5494 - custom_f1: 0.6671 - weighted_custom_f1: 0.6705 - val_loss: 1.3215 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5148\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.5402 - custom_f1: 0.6673 - weighted_custom_f1: 0.6700Epoch 75/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4609 - custom_f1: 0.7093 - weighted_custom_f1: 0.7121 - val_loss: 1.3514 - val_custom_f1: 0.5242 - val_weighted_custom_f1: 0.5296\n",
            " 60/105 [================>.............] - ETA: 0s - loss: 0.9172 - custom_f1: 0.5113 - weighted_custom_f1: 0.5155Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5789 - custom_f1: 0.6494 - weighted_custom_f1: 0.6533 - val_loss: 1.0949 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5318\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.4653 - custom_f1: 0.7046 - weighted_custom_f1: 0.7068Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5384 - custom_f1: 0.6666 - weighted_custom_f1: 0.6698 - val_loss: 1.2286 - val_custom_f1: 0.5189 - val_weighted_custom_f1: 0.5396\n",
            " 69/105 [==================>...........] - ETA: 0s - loss: 0.5423 - custom_f1: 0.6607 - weighted_custom_f1: 0.6657Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5826 - custom_f1: 0.6482 - weighted_custom_f1: 0.6528 - val_loss: 1.2655 - val_custom_f1: 0.4912 - val_weighted_custom_f1: 0.5005\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.5697 - custom_f1: 0.6543 - weighted_custom_f1: 0.6545Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4488 - custom_f1: 0.7079 - weighted_custom_f1: 0.7151 - val_loss: 1.4691 - val_custom_f1: 0.5033 - val_weighted_custom_f1: 0.5256\n",
            "105/105 [==============================] - ETA: 0s - loss: 0.8857 - custom_f1: 0.5238 - weighted_custom_f1: 0.5316Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9030 - custom_f1: 0.5112 - weighted_custom_f1: 0.5164 - val_loss: 1.2448 - val_custom_f1: 0.4733 - val_weighted_custom_f1: 0.4844\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4872 - custom_f1: 0.7039 - weighted_custom_f1: 0.7083 - val_loss: 1.8434 - val_custom_f1: 0.5494 - val_weighted_custom_f1: 0.5456\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0450 - custom_f1: 0.5067 - weighted_custom_f1: 0.5067Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4650 - custom_f1: 0.7015 - weighted_custom_f1: 0.7040 - val_loss: 1.6680 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5403\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8558 - custom_f1: 0.5299 - weighted_custom_f1: 0.5357 - val_loss: 0.9266 - val_custom_f1: 0.5222 - val_weighted_custom_f1: 0.5200\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5639 - custom_f1: 0.6544 - weighted_custom_f1: 0.6592 - val_loss: 1.6659 - val_custom_f1: 0.5271 - val_weighted_custom_f1: 0.5219\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9300 - custom_f1: 0.5060 - weighted_custom_f1: 0.5109 - val_loss: 0.9686 - val_custom_f1: 0.5188 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 76/100\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4691 - custom_f1: 0.7051 - weighted_custom_f1: 0.7077 - val_loss: 1.4453 - val_custom_f1: 0.5290 - val_weighted_custom_f1: 0.5355\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8857 - custom_f1: 0.5238 - weighted_custom_f1: 0.5316 - val_loss: 0.9123 - val_custom_f1: 0.5430 - val_weighted_custom_f1: 0.5550\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9504 - custom_f1: 0.5030 - weighted_custom_f1: 0.5070 - val_loss: 1.2996 - val_custom_f1: 0.4364 - val_weighted_custom_f1: 0.4471\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.4195 - custom_f1: 0.7157 - weighted_custom_f1: 0.7209Epoch 39/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5533 - custom_f1: 0.6596 - weighted_custom_f1: 0.6648 - val_loss: 1.3284 - val_custom_f1: 0.4829 - val_weighted_custom_f1: 0.5036\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 0.4595 - custom_f1: 0.7099 - weighted_custom_f1: 0.7124Epoch 76/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8937 - custom_f1: 0.5176 - weighted_custom_f1: 0.5228 - val_loss: 0.9491 - val_custom_f1: 0.5215 - val_weighted_custom_f1: 0.5310\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4761 - custom_f1: 0.6960 - weighted_custom_f1: 0.7004 - val_loss: 1.2919 - val_custom_f1: 0.4893 - val_weighted_custom_f1: 0.4979\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.9041 - custom_f1: 0.5031 - weighted_custom_f1: 0.5089Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5356 - custom_f1: 0.6681 - weighted_custom_f1: 0.6754 - val_loss: 1.2159 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5307\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.8579 - custom_f1: 0.5356 - weighted_custom_f1: 0.5401Epoch 78/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5641 - custom_f1: 0.6555 - weighted_custom_f1: 0.6578 - val_loss: 1.2315 - val_custom_f1: 0.5197 - val_weighted_custom_f1: 0.5304\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5517 - custom_f1: 0.6532 - weighted_custom_f1: 0.6588 - val_loss: 1.3029 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5218\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4501 - custom_f1: 0.7155 - weighted_custom_f1: 0.7192 - val_loss: 1.4116 - val_custom_f1: 0.4932 - val_weighted_custom_f1: 0.5159\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4735 - custom_f1: 0.7011 - weighted_custom_f1: 0.7052 - val_loss: 1.4679 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5334\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8623 - custom_f1: 0.5383 - weighted_custom_f1: 0.5435 - val_loss: 1.0307 - val_custom_f1: 0.4693 - val_weighted_custom_f1: 0.4708\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4967 - custom_f1: 0.7000 - weighted_custom_f1: 0.7000Epoch 66/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8969 - custom_f1: 0.4982 - weighted_custom_f1: 0.5038 - val_loss: 1.3316 - val_custom_f1: 0.4915 - val_weighted_custom_f1: 0.5034\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4370 - custom_f1: 0.7193 - weighted_custom_f1: 0.7232 - val_loss: 1.6967 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5035\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 0.5156 - custom_f1: 0.6780 - weighted_custom_f1: 0.6809Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5285 - custom_f1: 0.6596 - weighted_custom_f1: 0.6654 - val_loss: 1.5801 - val_custom_f1: 0.5185 - val_weighted_custom_f1: 0.5119\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9225 - custom_f1: 0.5138 - weighted_custom_f1: 0.5171 - val_loss: 1.0092 - val_custom_f1: 0.5266 - val_weighted_custom_f1: 0.5374\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4907 - custom_f1: 0.6923 - weighted_custom_f1: 0.6973 - val_loss: 1.2959 - val_custom_f1: 0.5172 - val_weighted_custom_f1: 0.5231\n",
            "Epoch 71/100\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9053 - custom_f1: 0.5116 - weighted_custom_f1: 0.5156 - val_loss: 0.9582 - val_custom_f1: 0.4994 - val_weighted_custom_f1: 0.5065\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8789 - custom_f1: 0.5336 - weighted_custom_f1: 0.5377 - val_loss: 0.9654 - val_custom_f1: 0.4653 - val_weighted_custom_f1: 0.4751\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0019 - custom_f1: 0.4687 - weighted_custom_f1: 0.4687Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9662 - custom_f1: 0.5038 - weighted_custom_f1: 0.5085 - val_loss: 1.3194 - val_custom_f1: 0.5119 - val_weighted_custom_f1: 0.5187\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5423 - custom_f1: 0.6601 - weighted_custom_f1: 0.6625 - val_loss: 1.3996 - val_custom_f1: 0.4886 - val_weighted_custom_f1: 0.5089\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4500 - custom_f1: 0.7096 - weighted_custom_f1: 0.7139 - val_loss: 1.4562 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5301\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.8318 - custom_f1: 0.5516 - weighted_custom_f1: 0.5551Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5693 - custom_f1: 0.6558 - weighted_custom_f1: 0.6617 - val_loss: 1.1873 - val_custom_f1: 0.4664 - val_weighted_custom_f1: 0.4803\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.5300 - custom_f1: 0.6662 - weighted_custom_f1: 0.6698Epoch 78/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.5599 - custom_f1: 0.6581 - weighted_custom_f1: 0.6625 - val_loss: 1.2664 - val_custom_f1: 0.4970 - val_weighted_custom_f1: 0.5044\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.9325 - custom_f1: 0.5135 - weighted_custom_f1: 0.5173Epoch 79/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5453 - custom_f1: 0.6663 - weighted_custom_f1: 0.6706 - val_loss: 1.4275 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5260\n",
            " 83/105 [======================>.......] - ETA: 0s - loss: 0.5387 - custom_f1: 0.6682 - weighted_custom_f1: 0.6730Epoch 81/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4612 - custom_f1: 0.7077 - weighted_custom_f1: 0.7107 - val_loss: 1.4785 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5289\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9059 - custom_f1: 0.5087 - weighted_custom_f1: 0.5124 - val_loss: 1.4330 - val_custom_f1: 0.5247 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8468 - custom_f1: 0.5406 - weighted_custom_f1: 0.5445 - val_loss: 0.9263 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5099\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.4085 - custom_f1: 0.7313 - weighted_custom_f1: 0.7368Epoch 67/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4782 - custom_f1: 0.6993 - weighted_custom_f1: 0.7027 - val_loss: 1.4211 - val_custom_f1: 0.5033 - val_weighted_custom_f1: 0.5122\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4305 - custom_f1: 0.7192 - weighted_custom_f1: 0.7241 - val_loss: 1.9234 - val_custom_f1: 0.5443 - val_weighted_custom_f1: 0.5408\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5329 - custom_f1: 0.6645 - weighted_custom_f1: 0.6681 - val_loss: 1.6144 - val_custom_f1: 0.5488 - val_weighted_custom_f1: 0.5414\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9315 - custom_f1: 0.5065 - weighted_custom_f1: 0.5115 - val_loss: 0.9698 - val_custom_f1: 0.4826 - val_weighted_custom_f1: 0.4934\n",
            "Epoch 78/100\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4721 - custom_f1: 0.7021 - weighted_custom_f1: 0.7060 - val_loss: 1.4251 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5205\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9419 - custom_f1: 0.5075 - weighted_custom_f1: 0.5119 - val_loss: 1.3571 - val_custom_f1: 0.4144 - val_weighted_custom_f1: 0.4254\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.5460 - custom_f1: 0.6755 - weighted_custom_f1: 0.6806Epoch 41/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8965 - custom_f1: 0.5159 - weighted_custom_f1: 0.5218 - val_loss: 0.9603 - val_custom_f1: 0.4605 - val_weighted_custom_f1: 0.4729\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.4665 - custom_f1: 0.7128 - weighted_custom_f1: 0.7168Epoch 68/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5476 - custom_f1: 0.6626 - weighted_custom_f1: 0.6679 - val_loss: 1.3435 - val_custom_f1: 0.4779 - val_weighted_custom_f1: 0.4987\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4634 - custom_f1: 0.7058 - weighted_custom_f1: 0.7094 - val_loss: 1.3319 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5220\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.4413 - custom_f1: 0.7161 - weighted_custom_f1: 0.7195Epoch 84/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.8750 - custom_f1: 0.5295 - weighted_custom_f1: 0.5363 - val_loss: 0.9340 - val_custom_f1: 0.4769 - val_weighted_custom_f1: 0.4875\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5314 - custom_f1: 0.6716 - weighted_custom_f1: 0.6759 - val_loss: 1.3035 - val_custom_f1: 0.5376 - val_weighted_custom_f1: 0.5418\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5515 - custom_f1: 0.6642 - weighted_custom_f1: 0.6691 - val_loss: 1.4102 - val_custom_f1: 0.4956 - val_weighted_custom_f1: 0.5051\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 8ms/step - loss: 0.5595 - custom_f1: 0.6581 - weighted_custom_f1: 0.6625 - val_loss: 1.2100 - val_custom_f1: 0.5372 - val_weighted_custom_f1: 0.5454\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4406 - custom_f1: 0.7153 - weighted_custom_f1: 0.7188 - val_loss: 1.4356 - val_custom_f1: 0.5019 - val_weighted_custom_f1: 0.5241\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9012 - custom_f1: 0.5133 - weighted_custom_f1: 0.5172 - val_loss: 1.2467 - val_custom_f1: 0.5007 - val_weighted_custom_f1: 0.5117\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4201 - custom_f1: 0.7283 - weighted_custom_f1: 0.7329 - val_loss: 2.0631 - val_custom_f1: 0.5227 - val_weighted_custom_f1: 0.5244\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8738 - custom_f1: 0.5289 - weighted_custom_f1: 0.5327 - val_loss: 1.2573 - val_custom_f1: 0.3973 - val_weighted_custom_f1: 0.4109\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7636 - custom_f1: 0.5507 - weighted_custom_f1: 0.5507Epoch 83/100\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4518 - custom_f1: 0.7064 - weighted_custom_f1: 0.7104 - val_loss: 1.4150 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5381\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5245 - custom_f1: 0.6720 - weighted_custom_f1: 0.6743 - val_loss: 1.8264 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5239\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9222 - custom_f1: 0.5103 - weighted_custom_f1: 0.5150 - val_loss: 1.0256 - val_custom_f1: 0.4918 - val_weighted_custom_f1: 0.5005\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4782 - custom_f1: 0.6982 - weighted_custom_f1: 0.7012 - val_loss: 1.5673 - val_custom_f1: 0.5253 - val_weighted_custom_f1: 0.5296\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.9455 - custom_f1: 0.5041 - weighted_custom_f1: 0.5099Epoch 84/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9743 - custom_f1: 0.5049 - weighted_custom_f1: 0.5086 - val_loss: 1.2474 - val_custom_f1: 0.4671 - val_weighted_custom_f1: 0.4786\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.5498 - custom_f1: 0.6759 - weighted_custom_f1: 0.6785Epoch 42/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8956 - custom_f1: 0.5165 - weighted_custom_f1: 0.5228 - val_loss: 0.9512 - val_custom_f1: 0.5063 - val_weighted_custom_f1: 0.5158\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8849 - custom_f1: 0.5301 - weighted_custom_f1: 0.5345 - val_loss: 0.9187 - val_custom_f1: 0.4878 - val_weighted_custom_f1: 0.4984\n",
            "Epoch 69/100\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4850 - custom_f1: 0.6966 - weighted_custom_f1: 0.7015 - val_loss: 1.4314 - val_custom_f1: 0.5297 - val_weighted_custom_f1: 0.5385\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5317 - custom_f1: 0.6702 - weighted_custom_f1: 0.6750 - val_loss: 1.5346 - val_custom_f1: 0.5029 - val_weighted_custom_f1: 0.5239\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5451 - custom_f1: 0.6673 - weighted_custom_f1: 0.6732 - val_loss: 1.2608 - val_custom_f1: 0.5204 - val_weighted_custom_f1: 0.5429\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5344 - custom_f1: 0.6710 - weighted_custom_f1: 0.6741 - val_loss: 1.1757 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5394\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5767 - custom_f1: 0.6571 - weighted_custom_f1: 0.6628 - val_loss: 1.3264 - val_custom_f1: 0.4837 - val_weighted_custom_f1: 0.4951\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4191 - custom_f1: 0.7229 - weighted_custom_f1: 0.7275 - val_loss: 1.5174 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5345\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.4641 - custom_f1: 0.7052 - weighted_custom_f1: 0.7087Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8938 - custom_f1: 0.5095 - weighted_custom_f1: 0.5122 - val_loss: 1.2893 - val_custom_f1: 0.5040 - val_weighted_custom_f1: 0.5132\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4187 - custom_f1: 0.7289 - weighted_custom_f1: 0.7339 - val_loss: 1.8249 - val_custom_f1: 0.5191 - val_weighted_custom_f1: 0.5147\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1436 - custom_f1: 0.5246 - weighted_custom_f1: 0.5246Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8688 - custom_f1: 0.5316 - weighted_custom_f1: 0.5371 - val_loss: 0.9679 - val_custom_f1: 0.5362 - val_weighted_custom_f1: 0.5321\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4361 - custom_f1: 0.7168 - weighted_custom_f1: 0.7215 - val_loss: 1.5800 - val_custom_f1: 0.5233 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9420 - custom_f1: 0.5068 - weighted_custom_f1: 0.5123 - val_loss: 1.0509 - val_custom_f1: 0.5328 - val_weighted_custom_f1: 0.5410\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5369 - custom_f1: 0.6686 - weighted_custom_f1: 0.6730 - val_loss: 1.5867 - val_custom_f1: 0.5402 - val_weighted_custom_f1: 0.5341\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4719 - custom_f1: 0.6993 - weighted_custom_f1: 0.7027 - val_loss: 1.4176 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5211\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.5541 - custom_f1: 0.6603 - weighted_custom_f1: 0.6645Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9522 - custom_f1: 0.5048 - weighted_custom_f1: 0.5078 - val_loss: 1.1771 - val_custom_f1: 0.4665 - val_weighted_custom_f1: 0.4782\n",
            " 81/105 [======================>.......] - ETA: 0s - loss: 0.5392 - custom_f1: 0.6685 - weighted_custom_f1: 0.6739Epoch 43/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8914 - custom_f1: 0.5138 - weighted_custom_f1: 0.5187 - val_loss: 0.9758 - val_custom_f1: 0.5318 - val_weighted_custom_f1: 0.5407\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8842 - custom_f1: 0.5242 - weighted_custom_f1: 0.5274 - val_loss: 0.9351 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5323\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4713 - custom_f1: 0.6998 - weighted_custom_f1: 0.7030 - val_loss: 1.4974 - val_custom_f1: 0.5209 - val_weighted_custom_f1: 0.5437\n",
            " 34/105 [========>.....................] - ETA: 0s - loss: 0.4601 - custom_f1: 0.7039 - weighted_custom_f1: 0.7091Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5145 - custom_f1: 0.6745 - weighted_custom_f1: 0.6822 - val_loss: 1.3609 - val_custom_f1: 0.4953 - val_weighted_custom_f1: 0.5158\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.4356 - custom_f1: 0.7222 - weighted_custom_f1: 0.7267Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5483 - custom_f1: 0.6625 - weighted_custom_f1: 0.6671 - val_loss: 1.1914 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5211\n",
            " 53/105 [==============>...............] - ETA: 0s - loss: 0.8877 - custom_f1: 0.5352 - weighted_custom_f1: 0.5408Epoch 82/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5490 - custom_f1: 0.6624 - weighted_custom_f1: 0.6649 - val_loss: 1.1895 - val_custom_f1: 0.5450 - val_weighted_custom_f1: 0.5508\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5469 - custom_f1: 0.6655 - weighted_custom_f1: 0.6695 - val_loss: 1.3168 - val_custom_f1: 0.4999 - val_weighted_custom_f1: 0.5079\n",
            " 90/105 [========================>.....] - ETA: 0s - loss: 0.5066 - custom_f1: 0.6857 - weighted_custom_f1: 0.6900Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4199 - custom_f1: 0.7286 - weighted_custom_f1: 0.7318 - val_loss: 1.5575 - val_custom_f1: 0.5107 - val_weighted_custom_f1: 0.5338\n",
            " 27/105 [======>.......................] - ETA: 0s - loss: 0.4862 - custom_f1: 0.6860 - weighted_custom_f1: 0.6934Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8874 - custom_f1: 0.5090 - weighted_custom_f1: 0.5133 - val_loss: 1.2750 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5208\n",
            " 98/105 [===========================>..] - ETA: 0s - loss: 0.8910 - custom_f1: 0.5345 - weighted_custom_f1: 0.5380Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4611 - custom_f1: 0.7099 - weighted_custom_f1: 0.7152 - val_loss: 1.5593 - val_custom_f1: 0.5142 - val_weighted_custom_f1: 0.5191\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8804 - custom_f1: 0.5315 - weighted_custom_f1: 0.5389 - val_loss: 0.9324 - val_custom_f1: 0.5417 - val_weighted_custom_f1: 0.5359\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4259 - custom_f1: 0.7253 - weighted_custom_f1: 0.7302 - val_loss: 1.9639 - val_custom_f1: 0.5413 - val_weighted_custom_f1: 0.5378\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.5327 - custom_f1: 0.6765 - weighted_custom_f1: 0.6812Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5128 - custom_f1: 0.6745 - weighted_custom_f1: 0.6788 - val_loss: 1.6231 - val_custom_f1: 0.5057 - val_weighted_custom_f1: 0.4981\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4963 - custom_f1: 0.6890 - weighted_custom_f1: 0.6925 - val_loss: 1.4251 - val_custom_f1: 0.4969 - val_weighted_custom_f1: 0.5014\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9421 - custom_f1: 0.5055 - weighted_custom_f1: 0.5098 - val_loss: 0.9882 - val_custom_f1: 0.5362 - val_weighted_custom_f1: 0.5460\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.9462 - custom_f1: 0.5012 - weighted_custom_f1: 0.5054Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9366 - custom_f1: 0.4999 - weighted_custom_f1: 0.5063 - val_loss: 1.3687 - val_custom_f1: 0.5105 - val_weighted_custom_f1: 0.5200\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.3696 - custom_f1: 0.7557 - weighted_custom_f1: 0.7577Epoch 44/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8807 - custom_f1: 0.5282 - weighted_custom_f1: 0.5327 - val_loss: 0.9487 - val_custom_f1: 0.5158 - val_weighted_custom_f1: 0.5254\n",
            " 80/105 [=====================>........] - ETA: 0s - loss: 0.5418 - custom_f1: 0.6661 - weighted_custom_f1: 0.6694Epoch 71/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8882 - custom_f1: 0.5344 - weighted_custom_f1: 0.5370 - val_loss: 0.9620 - val_custom_f1: 0.5174 - val_weighted_custom_f1: 0.5274\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5274 - custom_f1: 0.6723 - weighted_custom_f1: 0.6771Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5069 - custom_f1: 0.6943 - weighted_custom_f1: 0.6984 - val_loss: 1.3983 - val_custom_f1: 0.5184 - val_weighted_custom_f1: 0.5267\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5443 - custom_f1: 0.6556 - weighted_custom_f1: 0.6591 - val_loss: 1.3255 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.4937\n",
            "Epoch 87/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4084 - custom_f1: 0.5854 - weighted_custom_f1: 0.5854Epoch 81/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5621 - custom_f1: 0.6566 - weighted_custom_f1: 0.6623 - val_loss: 1.1656 - val_custom_f1: 0.4933 - val_weighted_custom_f1: 0.5009\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5284 - custom_f1: 0.6708 - weighted_custom_f1: 0.6766 - val_loss: 1.1584 - val_custom_f1: 0.5307 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5403 - custom_f1: 0.6689 - weighted_custom_f1: 0.6714 - val_loss: 1.4011 - val_custom_f1: 0.4909 - val_weighted_custom_f1: 0.5027\n",
            " 89/105 [========================>.....] - ETA: 0s - loss: 0.4708 - custom_f1: 0.7037 - weighted_custom_f1: 0.7078Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4259 - custom_f1: 0.7202 - weighted_custom_f1: 0.7249 - val_loss: 1.5652 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5421\n",
            " 69/105 [==================>...........] - ETA: 0s - loss: 0.5450 - custom_f1: 0.6783 - weighted_custom_f1: 0.6818Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9087 - custom_f1: 0.5059 - weighted_custom_f1: 0.5121 - val_loss: 1.3494 - val_custom_f1: 0.4637 - val_weighted_custom_f1: 0.4751\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3934 - custom_f1: 0.7435 - weighted_custom_f1: 0.7446 - val_loss: 1.9997 - val_custom_f1: 0.5400 - val_weighted_custom_f1: 0.5327\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4446 - custom_f1: 0.7104 - weighted_custom_f1: 0.7153 - val_loss: 1.5249 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5221\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8522 - custom_f1: 0.5397 - weighted_custom_f1: 0.5438 - val_loss: 1.0243 - val_custom_f1: 0.4782 - val_weighted_custom_f1: 0.4783\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5363 - custom_f1: 0.6687 - weighted_custom_f1: 0.6738 - val_loss: 1.5600 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5261\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9251 - custom_f1: 0.5085 - weighted_custom_f1: 0.5132 - val_loss: 1.0275 - val_custom_f1: 0.4630 - val_weighted_custom_f1: 0.4751\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9513 - custom_f1: 0.5046 - weighted_custom_f1: 0.5093 - val_loss: 1.2038 - val_custom_f1: 0.4709 - val_weighted_custom_f1: 0.4786\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4702 - custom_f1: 0.7047 - weighted_custom_f1: 0.7086 - val_loss: 1.4548 - val_custom_f1: 0.5204 - val_weighted_custom_f1: 0.5292\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8894 - custom_f1: 0.5147 - weighted_custom_f1: 0.5198 - val_loss: 0.9431 - val_custom_f1: 0.4995 - val_weighted_custom_f1: 0.5103\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9058 - custom_f1: 0.5202 - weighted_custom_f1: 0.5242 - val_loss: 0.9151 - val_custom_f1: 0.5140 - val_weighted_custom_f1: 0.5251\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4743 - custom_f1: 0.7138 - weighted_custom_f1: 0.7168 - val_loss: 1.3775 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5371\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5615 - custom_f1: 0.6642 - weighted_custom_f1: 0.6676 - val_loss: 1.3045 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5269\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.4319 - custom_f1: 0.7241 - weighted_custom_f1: 0.7271Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5508 - custom_f1: 0.6641 - weighted_custom_f1: 0.6677 - val_loss: 1.1806 - val_custom_f1: 0.5333 - val_weighted_custom_f1: 0.5374\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.5432 - custom_f1: 0.6620 - weighted_custom_f1: 0.6663Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5494 - custom_f1: 0.6620 - weighted_custom_f1: 0.6669 - val_loss: 1.2456 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4348 - custom_f1: 0.7232 - weighted_custom_f1: 0.7255 - val_loss: 1.5743 - val_custom_f1: 0.5161 - val_weighted_custom_f1: 0.5387\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5398 - custom_f1: 0.6682 - weighted_custom_f1: 0.6711 - val_loss: 1.4747 - val_custom_f1: 0.5338 - val_weighted_custom_f1: 0.5418\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4643 - custom_f1: 0.5581 - weighted_custom_f1: 0.5581Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4422 - custom_f1: 0.7106 - weighted_custom_f1: 0.7149 - val_loss: 1.5835 - val_custom_f1: 0.5173 - val_weighted_custom_f1: 0.5257\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9042 - custom_f1: 0.5152 - weighted_custom_f1: 0.5202 - val_loss: 1.2560 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5022\n",
            "Epoch 92/100\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5218 - custom_f1: 0.6732 - weighted_custom_f1: 0.6788 - val_loss: 1.9054 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5113\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4134 - custom_f1: 0.7307 - weighted_custom_f1: 0.7352 - val_loss: 2.1816 - val_custom_f1: 0.5482 - val_weighted_custom_f1: 0.5414\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.5354 - custom_f1: 0.6746 - weighted_custom_f1: 0.6779Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9222 - custom_f1: 0.5089 - weighted_custom_f1: 0.5109 - val_loss: 1.0121 - val_custom_f1: 0.4806 - val_weighted_custom_f1: 0.4899\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.4005 - custom_f1: 0.7224 - weighted_custom_f1: 0.7263Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8685 - custom_f1: 0.5378 - weighted_custom_f1: 0.5410 - val_loss: 0.9168 - val_custom_f1: 0.5285 - val_weighted_custom_f1: 0.5272\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.8714 - custom_f1: 0.5087 - weighted_custom_f1: 0.5123Epoch 72/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4566 - custom_f1: 0.7086 - weighted_custom_f1: 0.7132 - val_loss: 1.4315 - val_custom_f1: 0.5250 - val_weighted_custom_f1: 0.5307\n",
            " 31/105 [=======>......................] - ETA: 0s - loss: 0.9011 - custom_f1: 0.5100 - weighted_custom_f1: 0.5146Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9661 - custom_f1: 0.5090 - weighted_custom_f1: 0.5132 - val_loss: 1.7472 - val_custom_f1: 0.4924 - val_weighted_custom_f1: 0.5031\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8952 - custom_f1: 0.5098 - weighted_custom_f1: 0.5144 - val_loss: 0.9605 - val_custom_f1: 0.4801 - val_weighted_custom_f1: 0.4922\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.4310 - custom_f1: 0.7214 - weighted_custom_f1: 0.7248Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8771 - custom_f1: 0.5303 - weighted_custom_f1: 0.5358 - val_loss: 0.9443 - val_custom_f1: 0.5141 - val_weighted_custom_f1: 0.5261\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.4508 - custom_f1: 0.7088 - weighted_custom_f1: 0.7148Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4421 - custom_f1: 0.7164 - weighted_custom_f1: 0.7191 - val_loss: 1.6009 - val_custom_f1: 0.5211 - val_weighted_custom_f1: 0.5419\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.4301 - custom_f1: 0.7215 - weighted_custom_f1: 0.7267Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5631 - custom_f1: 0.6570 - weighted_custom_f1: 0.6604 - val_loss: 1.2882 - val_custom_f1: 0.4887 - val_weighted_custom_f1: 0.5098\n",
            " 13/105 [==>...........................] - ETA: 0s - loss: 0.8680 - custom_f1: 0.5349 - weighted_custom_f1: 0.5424Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5389 - custom_f1: 0.6683 - weighted_custom_f1: 0.6735 - val_loss: 1.1435 - val_custom_f1: 0.5400 - val_weighted_custom_f1: 0.5446\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.4229 - custom_f1: 0.7308 - weighted_custom_f1: 0.7356Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5563 - custom_f1: 0.6610 - weighted_custom_f1: 0.6645 - val_loss: 1.3039 - val_custom_f1: 0.5670 - val_weighted_custom_f1: 0.5740\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6205 - custom_f1: 0.6061 - weighted_custom_f1: 0.6061Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5315 - custom_f1: 0.6779 - weighted_custom_f1: 0.6814 - val_loss: 1.3205 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5153\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4375 - custom_f1: 0.7189 - weighted_custom_f1: 0.7244 - val_loss: 1.5205 - val_custom_f1: 0.5056 - val_weighted_custom_f1: 0.5280\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4246 - custom_f1: 0.7293 - weighted_custom_f1: 0.7345 - val_loss: 1.9294 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5279\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.9099 - custom_f1: 0.5317 - weighted_custom_f1: 0.5360Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4319 - custom_f1: 0.7205 - weighted_custom_f1: 0.7259 - val_loss: 1.5935 - val_custom_f1: 0.5469 - val_weighted_custom_f1: 0.5559\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8873 - custom_f1: 0.5095 - weighted_custom_f1: 0.5142 - val_loss: 1.3321 - val_custom_f1: 0.5258 - val_weighted_custom_f1: 0.5352\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.8737 - custom_f1: 0.5231 - weighted_custom_f1: 0.5279Epoch 93/100\n",
            " 30/105 [=======>......................] - ETA: 0s - loss: 0.4155 - custom_f1: 0.7343 - weighted_custom_f1: 0.7378Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8521 - custom_f1: 0.5430 - weighted_custom_f1: 0.5483 - val_loss: 0.9422 - val_custom_f1: 0.5071 - val_weighted_custom_f1: 0.5067\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.5366 - custom_f1: 0.6653 - weighted_custom_f1: 0.6700Epoch 73/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5143 - custom_f1: 0.6697 - weighted_custom_f1: 0.6756 - val_loss: 1.8407 - val_custom_f1: 0.4948 - val_weighted_custom_f1: 0.4904\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.7195 - custom_f1: 0.5205 - weighted_custom_f1: 0.5205Epoch 84/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9490 - custom_f1: 0.5021 - weighted_custom_f1: 0.5059 - val_loss: 1.8734 - val_custom_f1: 0.4808 - val_weighted_custom_f1: 0.4859\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9416 - custom_f1: 0.5097 - weighted_custom_f1: 0.5159 - val_loss: 1.0155 - val_custom_f1: 0.4573 - val_weighted_custom_f1: 0.4688\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4569 - custom_f1: 0.7087 - weighted_custom_f1: 0.7131 - val_loss: 1.4351 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5180\n",
            "Epoch 89/100\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.5283 - custom_f1: 0.6807 - weighted_custom_f1: 0.6845Epoch 47/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8719 - custom_f1: 0.5184 - weighted_custom_f1: 0.5246 - val_loss: 0.9512 - val_custom_f1: 0.5155 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9035 - custom_f1: 0.5304 - weighted_custom_f1: 0.5371 - val_loss: 0.9218 - val_custom_f1: 0.5392 - val_weighted_custom_f1: 0.5492\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4468 - custom_f1: 0.7144 - weighted_custom_f1: 0.7196 - val_loss: 1.4575 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5160\n",
            " 40/105 [==========>...................] - ETA: 0s - loss: 0.9580 - custom_f1: 0.5151 - weighted_custom_f1: 0.5194Epoch 74/100\n",
            " 69/105 [==================>...........] - ETA: 0s - loss: 0.4366 - custom_f1: 0.7239 - weighted_custom_f1: 0.7281Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5341 - custom_f1: 0.6607 - weighted_custom_f1: 0.6652 - val_loss: 1.5138 - val_custom_f1: 0.5096 - val_weighted_custom_f1: 0.5306\n",
            " 49/105 [=============>................] - ETA: 0s - loss: 0.5482 - custom_f1: 0.6491 - weighted_custom_f1: 0.6529Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5225 - custom_f1: 0.6790 - weighted_custom_f1: 0.6820 - val_loss: 1.3380 - val_custom_f1: 0.5276 - val_weighted_custom_f1: 0.5495\n",
            " 59/105 [===============>..............] - ETA: 0s - loss: 1.0359 - custom_f1: 0.4674 - weighted_custom_f1: 0.4711Epoch 86/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5440 - custom_f1: 0.6667 - weighted_custom_f1: 0.6704 - val_loss: 1.2073 - val_custom_f1: 0.5164 - val_weighted_custom_f1: 0.5284\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.4551 - custom_f1: 0.7110 - weighted_custom_f1: 0.7145Epoch 85/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5366 - custom_f1: 0.6684 - weighted_custom_f1: 0.6729 - val_loss: 1.3558 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5260\n",
            " 26/105 [======>.......................] - ETA: 0s - loss: 0.5194 - custom_f1: 0.6680 - weighted_custom_f1: 0.6716Epoch 88/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4196 - custom_f1: 0.7241 - weighted_custom_f1: 0.7276 - val_loss: 1.6296 - val_custom_f1: 0.5058 - val_weighted_custom_f1: 0.5279\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4558 - custom_f1: 0.7100 - weighted_custom_f1: 0.7137 - val_loss: 1.6250 - val_custom_f1: 0.5214 - val_weighted_custom_f1: 0.5296\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.5018 - custom_f1: 0.6628 - weighted_custom_f1: 0.6687Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8926 - custom_f1: 0.5113 - weighted_custom_f1: 0.5151 - val_loss: 1.3208 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4351 - custom_f1: 0.7243 - weighted_custom_f1: 0.7289 - val_loss: 1.8111 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5120\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5314 - custom_f1: 0.6658 - weighted_custom_f1: 0.6705 - val_loss: 1.8688 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5322\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8392 - custom_f1: 0.5428 - weighted_custom_f1: 0.5479 - val_loss: 1.0114 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5039\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9464 - custom_f1: 0.5102 - weighted_custom_f1: 0.5152 - val_loss: 0.9828 - val_custom_f1: 0.5387 - val_weighted_custom_f1: 0.5505\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4358 - custom_f1: 0.7198 - weighted_custom_f1: 0.7234 - val_loss: 1.4288 - val_custom_f1: 0.5239 - val_weighted_custom_f1: 0.5286\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0096 - custom_f1: 0.4750 - weighted_custom_f1: 0.4784 - val_loss: 2.0823 - val_custom_f1: 0.3362 - val_weighted_custom_f1: 0.3105\n",
            "Epoch 90/100\n",
            " 24/105 [=====>........................] - ETA: 0s - loss: 0.4121 - custom_f1: 0.7265 - weighted_custom_f1: 0.7286Epoch 48/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9001 - custom_f1: 0.5105 - weighted_custom_f1: 0.5152 - val_loss: 1.0053 - val_custom_f1: 0.5040 - val_weighted_custom_f1: 0.5069\n",
            " 94/105 [=========================>....] - ETA: 0s - loss: 0.5601 - custom_f1: 0.6652 - weighted_custom_f1: 0.6702Epoch 75/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5148 - custom_f1: 0.6816 - weighted_custom_f1: 0.6844 - val_loss: 1.4103 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5172\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.5284 - custom_f1: 0.6751 - weighted_custom_f1: 0.6786Epoch 85/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4355 - custom_f1: 0.7185 - weighted_custom_f1: 0.7234 - val_loss: 1.5243 - val_custom_f1: 0.5477 - val_weighted_custom_f1: 0.5533\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.8722 - custom_f1: 0.5386 - weighted_custom_f1: 0.5429Epoch 91/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8844 - custom_f1: 0.5279 - weighted_custom_f1: 0.5330 - val_loss: 0.9693 - val_custom_f1: 0.4975 - val_weighted_custom_f1: 0.5086\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5659 - custom_f1: 0.6610 - weighted_custom_f1: 0.6644 - val_loss: 1.1854 - val_custom_f1: 0.5560 - val_weighted_custom_f1: 0.5614\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5560 - custom_f1: 0.6630 - weighted_custom_f1: 0.6673 - val_loss: 1.2290 - val_custom_f1: 0.5250 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5208 - custom_f1: 0.6721 - weighted_custom_f1: 0.6773 - val_loss: 1.3487 - val_custom_f1: 0.5294 - val_weighted_custom_f1: 0.5408\n",
            " 60/105 [================>.............] - ETA: 0s - loss: 0.5110 - custom_f1: 0.6812 - weighted_custom_f1: 0.6859Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4253 - custom_f1: 0.7221 - weighted_custom_f1: 0.7252 - val_loss: 1.5504 - val_custom_f1: 0.4946 - val_weighted_custom_f1: 0.5176\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.4369 - custom_f1: 0.7183 - weighted_custom_f1: 0.7225Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4411 - custom_f1: 0.7135 - weighted_custom_f1: 0.7175 - val_loss: 1.5340 - val_custom_f1: 0.5254 - val_weighted_custom_f1: 0.5360\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 0.9098 - custom_f1: 0.5128 - weighted_custom_f1: 0.5186Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3877 - custom_f1: 0.7442 - weighted_custom_f1: 0.7478 - val_loss: 2.0921 - val_custom_f1: 0.5315 - val_weighted_custom_f1: 0.5241\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8892 - custom_f1: 0.5099 - weighted_custom_f1: 0.5139 - val_loss: 1.3179 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5192\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.4982 - custom_f1: 0.6896 - weighted_custom_f1: 0.6936Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5173 - custom_f1: 0.6786 - weighted_custom_f1: 0.6808 - val_loss: 1.7918 - val_custom_f1: 0.5407 - val_weighted_custom_f1: 0.5314\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8589 - custom_f1: 0.5322 - weighted_custom_f1: 0.5371 - val_loss: 0.9542 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5245\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4697 - custom_f1: 0.8519 - weighted_custom_f1: 0.8519Epoch 75/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4229 - custom_f1: 0.7304 - weighted_custom_f1: 0.7359 - val_loss: 1.5124 - val_custom_f1: 0.5148 - val_weighted_custom_f1: 0.5229\n",
            " 14/105 [===>..........................] - ETA: 0s - loss: 0.5146 - custom_f1: 0.7264 - weighted_custom_f1: 0.7271Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0390 - custom_f1: 0.4702 - weighted_custom_f1: 0.4748 - val_loss: 1.9474 - val_custom_f1: 0.4195 - val_weighted_custom_f1: 0.4306\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9168 - custom_f1: 0.5135 - weighted_custom_f1: 0.5188 - val_loss: 0.9685 - val_custom_f1: 0.4980 - val_weighted_custom_f1: 0.5095\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4310 - custom_f1: 0.7223 - weighted_custom_f1: 0.7250 - val_loss: 1.5343 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5248\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9014 - custom_f1: 0.5169 - weighted_custom_f1: 0.5227 - val_loss: 0.9651 - val_custom_f1: 0.4588 - val_weighted_custom_f1: 0.4718\n",
            "Epoch 92/100\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5543 - custom_f1: 0.6617 - weighted_custom_f1: 0.6686 - val_loss: 1.3418 - val_custom_f1: 0.4832 - val_weighted_custom_f1: 0.5045\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8839 - custom_f1: 0.5299 - weighted_custom_f1: 0.5346 - val_loss: 0.9103 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5290\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.5839 - custom_f1: 0.7160 - weighted_custom_f1: 0.7160Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5033 - custom_f1: 0.6802 - weighted_custom_f1: 0.6848 - val_loss: 1.2024 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5534\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5747 - custom_f1: 0.6533 - weighted_custom_f1: 0.6579 - val_loss: 1.2026 - val_custom_f1: 0.5233 - val_weighted_custom_f1: 0.5291\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5337 - custom_f1: 0.6709 - weighted_custom_f1: 0.6749 - val_loss: 1.4246 - val_custom_f1: 0.4930 - val_weighted_custom_f1: 0.5004\n",
            " 68/105 [==================>...........] - ETA: 0s - loss: 0.4091 - custom_f1: 0.7306 - weighted_custom_f1: 0.7344Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4140 - custom_f1: 0.7297 - weighted_custom_f1: 0.7354 - val_loss: 1.8568 - val_custom_f1: 0.5048 - val_weighted_custom_f1: 0.5272\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4453 - custom_f1: 0.7146 - weighted_custom_f1: 0.7185 - val_loss: 1.6531 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5270\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4220 - custom_f1: 0.7309 - weighted_custom_f1: 0.7343 - val_loss: 2.2446 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5132\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9213 - custom_f1: 0.5116 - weighted_custom_f1: 0.5154 - val_loss: 1.3511 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5381\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5034 - custom_f1: 0.6817 - weighted_custom_f1: 0.6863 - val_loss: 1.9277 - val_custom_f1: 0.5372 - val_weighted_custom_f1: 0.5316\n",
            "Epoch 87/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4533 - custom_f1: 0.7500 - weighted_custom_f1: 0.7500Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8341 - custom_f1: 0.5433 - weighted_custom_f1: 0.5485 - val_loss: 0.9395 - val_custom_f1: 0.5434 - val_weighted_custom_f1: 0.5393\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4347 - custom_f1: 0.7199 - weighted_custom_f1: 0.7237 - val_loss: 1.4909 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5370\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0243 - custom_f1: 0.4794 - weighted_custom_f1: 0.4837 - val_loss: 1.8928 - val_custom_f1: 0.4981 - val_weighted_custom_f1: 0.4923\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9347 - custom_f1: 0.5027 - weighted_custom_f1: 0.5055 - val_loss: 0.9706 - val_custom_f1: 0.5085 - val_weighted_custom_f1: 0.5185\n",
            " 97/105 [==========================>...] - ETA: 0s - loss: 0.5184 - custom_f1: 0.6787 - weighted_custom_f1: 0.6826Epoch 81/100\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4092 - custom_f1: 0.7348 - weighted_custom_f1: 0.7378 - val_loss: 1.4803 - val_custom_f1: 0.5266 - val_weighted_custom_f1: 0.5493\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8862 - custom_f1: 0.5180 - weighted_custom_f1: 0.5197 - val_loss: 0.9510 - val_custom_f1: 0.4986 - val_weighted_custom_f1: 0.5082\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.4059 - custom_f1: 0.7392 - weighted_custom_f1: 0.7428Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5299 - custom_f1: 0.6655 - weighted_custom_f1: 0.6693 - val_loss: 1.3337 - val_custom_f1: 0.4761 - val_weighted_custom_f1: 0.4979\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8021 - custom_f1: 0.3922 - weighted_custom_f1: 0.3922Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8729 - custom_f1: 0.5412 - weighted_custom_f1: 0.5438 - val_loss: 0.9578 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5174 - custom_f1: 0.6760 - weighted_custom_f1: 0.6801 - val_loss: 1.3562 - val_custom_f1: 0.5297 - val_weighted_custom_f1: 0.5514\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5353 - custom_f1: 0.6602 - weighted_custom_f1: 0.6655 - val_loss: 1.2332 - val_custom_f1: 0.5375 - val_weighted_custom_f1: 0.5462\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.8603 - custom_f1: 0.5301 - weighted_custom_f1: 0.5339Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5425 - custom_f1: 0.6620 - weighted_custom_f1: 0.6667 - val_loss: 1.4919 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5179\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.8906 - custom_f1: 0.5349 - weighted_custom_f1: 0.5425Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4289 - custom_f1: 0.7272 - weighted_custom_f1: 0.7301 - val_loss: 1.5650 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.5175\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4166 - custom_f1: 0.7310 - weighted_custom_f1: 0.7353 - val_loss: 1.5881 - val_custom_f1: 0.5217 - val_weighted_custom_f1: 0.5326\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8828 - custom_f1: 0.5124 - weighted_custom_f1: 0.5172 - val_loss: 1.3275 - val_custom_f1: 0.4481 - val_weighted_custom_f1: 0.4592\n",
            "Epoch 97/100\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4079 - custom_f1: 0.7376 - weighted_custom_f1: 0.7424 - val_loss: 1.9299 - val_custom_f1: 0.5343 - val_weighted_custom_f1: 0.5293\n",
            " 67/105 [==================>...........] - ETA: 0s - loss: 0.4941 - custom_f1: 0.6801 - weighted_custom_f1: 0.6856Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5090 - custom_f1: 0.6793 - weighted_custom_f1: 0.6852 - val_loss: 1.7489 - val_custom_f1: 0.5302 - val_weighted_custom_f1: 0.5196\n",
            " 99/105 [===========================>..] - ETA: 0s - loss: 0.5441 - custom_f1: 0.6674 - weighted_custom_f1: 0.6725Epoch 88/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4644 - custom_f1: 0.7082 - weighted_custom_f1: 0.7121 - val_loss: 1.6263 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5357\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8427 - custom_f1: 0.5335 - weighted_custom_f1: 0.5397 - val_loss: 0.9260 - val_custom_f1: 0.5053 - val_weighted_custom_f1: 0.5052\n",
            " 52/105 [=============>................] - ETA: 0s - loss: 0.3829 - custom_f1: 0.7500 - weighted_custom_f1: 0.7538Epoch 93/100\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0007 - custom_f1: 0.4799 - weighted_custom_f1: 0.4837 - val_loss: 1.8785 - val_custom_f1: 0.4776 - val_weighted_custom_f1: 0.4830\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.4119 - custom_f1: 0.7388 - weighted_custom_f1: 0.7399Epoch 51/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9229 - custom_f1: 0.5119 - weighted_custom_f1: 0.5169 - val_loss: 0.9770 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5092\n",
            " 19/105 [====>.........................] - ETA: 0s - loss: 0.4559 - custom_f1: 0.6997 - weighted_custom_f1: 0.7046Epoch 82/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8915 - custom_f1: 0.5210 - weighted_custom_f1: 0.5259 - val_loss: 0.9984 - val_custom_f1: 0.4863 - val_weighted_custom_f1: 0.4960\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4287 - custom_f1: 0.7213 - weighted_custom_f1: 0.7261 - val_loss: 1.4781 - val_custom_f1: 0.5160 - val_weighted_custom_f1: 0.5392\n",
            "Epoch 78/100\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5434 - custom_f1: 0.6663 - weighted_custom_f1: 0.6724 - val_loss: 1.2899 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5214\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.5289 - custom_f1: 0.6706 - weighted_custom_f1: 0.6750Epoch 88/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8885 - custom_f1: 0.5336 - weighted_custom_f1: 0.5395 - val_loss: 1.0124 - val_custom_f1: 0.4651 - val_weighted_custom_f1: 0.4751\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5252 - custom_f1: 0.6775 - weighted_custom_f1: 0.6820 - val_loss: 1.3289 - val_custom_f1: 0.5150 - val_weighted_custom_f1: 0.5184\n",
            " 65/105 [=================>............] - ETA: 0s - loss: 0.8796 - custom_f1: 0.5391 - weighted_custom_f1: 0.5432Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5078 - custom_f1: 0.6804 - weighted_custom_f1: 0.6840 - val_loss: 1.3343 - val_custom_f1: 0.5482 - val_weighted_custom_f1: 0.5716\n",
            " 25/105 [======>.......................] - ETA: 0s - loss: 0.9374 - custom_f1: 0.5295 - weighted_custom_f1: 0.5305Epoch 89/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5296 - custom_f1: 0.6709 - weighted_custom_f1: 0.6751 - val_loss: 1.3665 - val_custom_f1: 0.5121 - val_weighted_custom_f1: 0.5205\n",
            " 64/105 [=================>............] - ETA: 0s - loss: 0.9243 - custom_f1: 0.5091 - weighted_custom_f1: 0.5140Epoch 92/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4121 - custom_f1: 0.7295 - weighted_custom_f1: 0.7349 - val_loss: 1.4825 - val_custom_f1: 0.4910 - val_weighted_custom_f1: 0.5139\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.4048 - custom_f1: 0.8000 - weighted_custom_f1: 0.8000Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4222 - custom_f1: 0.7244 - weighted_custom_f1: 0.7281 - val_loss: 1.6905 - val_custom_f1: 0.5356 - val_weighted_custom_f1: 0.5444\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8899 - custom_f1: 0.5142 - weighted_custom_f1: 0.5181 - val_loss: 1.3811 - val_custom_f1: 0.4256 - val_weighted_custom_f1: 0.4356\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.9193 - custom_f1: 0.5083 - weighted_custom_f1: 0.5130Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5384 - custom_f1: 0.6653 - weighted_custom_f1: 0.6703 - val_loss: 1.6720 - val_custom_f1: 0.5151 - val_weighted_custom_f1: 0.5137\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4333 - custom_f1: 0.7295 - weighted_custom_f1: 0.7310 - val_loss: 2.1604 - val_custom_f1: 0.5075 - val_weighted_custom_f1: 0.5038\n",
            "  7/105 [=>............................] - ETA: 0s - loss: 0.4919 - custom_f1: 0.6894 - weighted_custom_f1: 0.6895Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4443 - custom_f1: 0.7143 - weighted_custom_f1: 0.7186 - val_loss: 1.4509 - val_custom_f1: 0.5242 - val_weighted_custom_f1: 0.5289\n",
            " 61/105 [================>.............] - ETA: 0s - loss: 0.5008 - custom_f1: 0.6834 - weighted_custom_f1: 0.6890Epoch 94/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8709 - custom_f1: 0.5369 - weighted_custom_f1: 0.5413 - val_loss: 0.9613 - val_custom_f1: 0.4976 - val_weighted_custom_f1: 0.4961\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.3946 - custom_f1: 0.7309 - weighted_custom_f1: 0.7335Epoch 78/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0063 - custom_f1: 0.4795 - weighted_custom_f1: 0.4838 - val_loss: 1.8999 - val_custom_f1: 0.5107 - val_weighted_custom_f1: 0.5063\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9469 - custom_f1: 0.5027 - weighted_custom_f1: 0.5072 - val_loss: 1.0059 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5175\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5484 - custom_f1: 0.6629 - weighted_custom_f1: 0.6669Epoch 83/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4355 - custom_f1: 0.7196 - weighted_custom_f1: 0.7225 - val_loss: 1.5734 - val_custom_f1: 0.5417 - val_weighted_custom_f1: 0.5482\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0586 - custom_f1: 0.5763 - weighted_custom_f1: 0.5763Epoch 95/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9164 - custom_f1: 0.5113 - weighted_custom_f1: 0.5156 - val_loss: 0.9650 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5071\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5396 - custom_f1: 0.6714 - weighted_custom_f1: 0.6749 - val_loss: 1.3397 - val_custom_f1: 0.4940 - val_weighted_custom_f1: 0.5165\n",
            " 22/105 [=====>........................] - ETA: 0s - loss: 0.9221 - custom_f1: 0.5432 - weighted_custom_f1: 0.5494Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8792 - custom_f1: 0.5362 - weighted_custom_f1: 0.5402 - val_loss: 0.9314 - val_custom_f1: 0.5264 - val_weighted_custom_f1: 0.5385\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.8959 - custom_f1: 0.5076 - weighted_custom_f1: 0.5126Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5485 - custom_f1: 0.6613 - weighted_custom_f1: 0.6663 - val_loss: 1.2213 - val_custom_f1: 0.5240 - val_weighted_custom_f1: 0.5319\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5367 - custom_f1: 0.6756 - weighted_custom_f1: 0.6804 - val_loss: 1.1419 - val_custom_f1: 0.5224 - val_weighted_custom_f1: 0.5332\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5139 - custom_f1: 0.6781 - weighted_custom_f1: 0.6836 - val_loss: 1.5408 - val_custom_f1: 0.5238 - val_weighted_custom_f1: 0.5354\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4276 - custom_f1: 0.7264 - weighted_custom_f1: 0.7303 - val_loss: 1.5720 - val_custom_f1: 0.5169 - val_weighted_custom_f1: 0.5392\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4602 - custom_f1: 0.7044 - weighted_custom_f1: 0.7114 - val_loss: 1.8983 - val_custom_f1: 0.5376 - val_weighted_custom_f1: 0.5367\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8937 - custom_f1: 0.5080 - weighted_custom_f1: 0.5126 - val_loss: 1.3164 - val_custom_f1: 0.5109 - val_weighted_custom_f1: 0.5215\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4900 - custom_f1: 0.6795 - weighted_custom_f1: 0.6831 - val_loss: 1.8198 - val_custom_f1: 0.5205 - val_weighted_custom_f1: 0.5137\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.5258 - custom_f1: 0.6655 - weighted_custom_f1: 0.6689Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4027 - custom_f1: 0.7378 - weighted_custom_f1: 0.7417 - val_loss: 2.3824 - val_custom_f1: 0.5057 - val_weighted_custom_f1: 0.5012\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4382 - custom_f1: 0.7286 - weighted_custom_f1: 0.7305 - val_loss: 1.4865 - val_custom_f1: 0.5066 - val_weighted_custom_f1: 0.5109\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8495 - custom_f1: 0.5328 - weighted_custom_f1: 0.5359 - val_loss: 0.9478 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5067\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0036 - custom_f1: 0.4779 - weighted_custom_f1: 0.4837 - val_loss: 1.9211 - val_custom_f1: 0.4387 - val_weighted_custom_f1: 0.4488\n",
            " 93/105 [=========================>....] - ETA: 0s - loss: 0.5183 - custom_f1: 0.6832 - weighted_custom_f1: 0.6872Epoch 53/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4443 - custom_f1: 0.7135 - weighted_custom_f1: 0.7166 - val_loss: 1.5582 - val_custom_f1: 0.4921 - val_weighted_custom_f1: 0.5027\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9314 - custom_f1: 0.5226 - weighted_custom_f1: 0.5260 - val_loss: 0.9940 - val_custom_f1: 0.4823 - val_weighted_custom_f1: 0.4923\n",
            "Epoch 96/100\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9280 - custom_f1: 0.5016 - weighted_custom_f1: 0.5091 - val_loss: 1.0243 - val_custom_f1: 0.4390 - val_weighted_custom_f1: 0.4513\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 0.8276 - custom_f1: 0.5414 - weighted_custom_f1: 0.5443Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5219 - custom_f1: 0.6751 - weighted_custom_f1: 0.6780 - val_loss: 1.3891 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5287\n",
            " 46/105 [============>.................] - ETA: 0s - loss: 0.8260 - custom_f1: 0.5336 - weighted_custom_f1: 0.5381Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8822 - custom_f1: 0.5312 - weighted_custom_f1: 0.5376 - val_loss: 0.9167 - val_custom_f1: 0.5273 - val_weighted_custom_f1: 0.5392\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5121 - custom_f1: 0.6856 - weighted_custom_f1: 0.6893 - val_loss: 1.2110 - val_custom_f1: 0.5441 - val_weighted_custom_f1: 0.5486\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5253 - custom_f1: 0.6745 - weighted_custom_f1: 0.6792 - val_loss: 1.2326 - val_custom_f1: 0.5461 - val_weighted_custom_f1: 0.5519\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5668 - custom_f1: 0.6576 - weighted_custom_f1: 0.6629 - val_loss: 1.4302 - val_custom_f1: 0.4856 - val_weighted_custom_f1: 0.4972\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4009 - custom_f1: 0.7369 - weighted_custom_f1: 0.7415 - val_loss: 1.6303 - val_custom_f1: 0.5056 - val_weighted_custom_f1: 0.5294\n",
            " 75/105 [====================>.........] - ETA: 0s - loss: 0.9182 - custom_f1: 0.5183 - weighted_custom_f1: 0.5235Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4268 - custom_f1: 0.7257 - weighted_custom_f1: 0.7304 - val_loss: 1.7163 - val_custom_f1: 0.5266 - val_weighted_custom_f1: 0.5352\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4938 - custom_f1: 0.6888 - weighted_custom_f1: 0.6919 - val_loss: 1.7297 - val_custom_f1: 0.5329 - val_weighted_custom_f1: 0.5269\n",
            " 87/105 [=======================>......] - ETA: 0s - loss: 0.8944 - custom_f1: 0.5180 - weighted_custom_f1: 0.5218Epoch 91/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8898 - custom_f1: 0.5098 - weighted_custom_f1: 0.5136 - val_loss: 1.3923 - val_custom_f1: 0.5138 - val_weighted_custom_f1: 0.5255\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3770 - custom_f1: 0.7561 - weighted_custom_f1: 0.7599 - val_loss: 2.0761 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5279\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.4903 - custom_f1: 0.6870 - weighted_custom_f1: 0.6911Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8422 - custom_f1: 0.5401 - weighted_custom_f1: 0.5444 - val_loss: 0.9320 - val_custom_f1: 0.5050 - val_weighted_custom_f1: 0.5028\n",
            " 70/105 [===================>..........] - ETA: 0s - loss: 0.5275 - custom_f1: 0.6796 - weighted_custom_f1: 0.6832Epoch 80/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8898 - custom_f1: 0.5175 - weighted_custom_f1: 0.5226 - val_loss: 0.9385 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4966\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4623 - custom_f1: 0.7094 - weighted_custom_f1: 0.7125 - val_loss: 1.4377 - val_custom_f1: 0.4994 - val_weighted_custom_f1: 0.5069\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 1.0047 - custom_f1: 0.4874 - weighted_custom_f1: 0.4942 - val_loss: 1.8333 - val_custom_f1: 0.4831 - val_weighted_custom_f1: 0.4939\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4287 - custom_f1: 0.7279 - weighted_custom_f1: 0.7314 - val_loss: 1.6284 - val_custom_f1: 0.5034 - val_weighted_custom_f1: 0.5259\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9184 - custom_f1: 0.5179 - weighted_custom_f1: 0.5232 - val_loss: 0.9573 - val_custom_f1: 0.5021 - val_weighted_custom_f1: 0.5139\n",
            " 51/105 [=============>................] - ETA: 0s - loss: 0.3853 - custom_f1: 0.7410 - weighted_custom_f1: 0.7459Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4963 - custom_f1: 0.6833 - weighted_custom_f1: 0.6879 - val_loss: 1.5138 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5138\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8791 - custom_f1: 0.5379 - weighted_custom_f1: 0.5411 - val_loss: 0.9162 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5294\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5007 - custom_f1: 0.6876 - weighted_custom_f1: 0.6911 - val_loss: 1.3259 - val_custom_f1: 0.5422 - val_weighted_custom_f1: 0.5646\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.8615 - custom_f1: 0.5970 - weighted_custom_f1: 0.5970Epoch 93/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5199 - custom_f1: 0.6800 - weighted_custom_f1: 0.6831 - val_loss: 1.2795 - val_custom_f1: 0.5280 - val_weighted_custom_f1: 0.5356\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5285 - custom_f1: 0.6706 - weighted_custom_f1: 0.6746 - val_loss: 1.4367 - val_custom_f1: 0.5163 - val_weighted_custom_f1: 0.5285\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4785 - custom_f1: 0.7186 - weighted_custom_f1: 0.7226 - val_loss: 1.5306 - val_custom_f1: 0.4911 - val_weighted_custom_f1: 0.5140\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4245 - custom_f1: 0.7209 - weighted_custom_f1: 0.7256 - val_loss: 1.7247 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5302\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5001 - custom_f1: 0.6770 - weighted_custom_f1: 0.6829 - val_loss: 1.7861 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8959 - custom_f1: 0.5061 - weighted_custom_f1: 0.5104 - val_loss: 1.3387 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5268\n",
            "100/105 [===========================>..] - ETA: 0s - loss: 0.9229 - custom_f1: 0.5184 - weighted_custom_f1: 0.5237Epoch 88/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3998 - custom_f1: 0.7347 - weighted_custom_f1: 0.7398 - val_loss: 2.1038 - val_custom_f1: 0.5425 - val_weighted_custom_f1: 0.5366\n",
            " 55/105 [==============>...............] - ETA: 0s - loss: 0.5400 - custom_f1: 0.6759 - weighted_custom_f1: 0.6804Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4247 - custom_f1: 0.7268 - weighted_custom_f1: 0.7301 - val_loss: 1.6217 - val_custom_f1: 0.5408 - val_weighted_custom_f1: 0.5452\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.8719 - custom_f1: 0.5077 - weighted_custom_f1: 0.5111Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4161 - custom_f1: 0.7294 - weighted_custom_f1: 0.7330 - val_loss: 1.5854 - val_custom_f1: 0.5272 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9194 - custom_f1: 0.5209 - weighted_custom_f1: 0.5256 - val_loss: 1.0198 - val_custom_f1: 0.4318 - val_weighted_custom_f1: 0.4437\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0007 - custom_f1: 0.4857 - weighted_custom_f1: 0.4905 - val_loss: 1.9962 - val_custom_f1: 0.4090 - val_weighted_custom_f1: 0.4184\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.4698 - custom_f1: 0.7088 - weighted_custom_f1: 0.7122Epoch 82/100\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8567 - custom_f1: 0.5367 - weighted_custom_f1: 0.5410 - val_loss: 0.9425 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5268\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9358 - custom_f1: 0.5087 - weighted_custom_f1: 0.5137 - val_loss: 0.9538 - val_custom_f1: 0.5040 - val_weighted_custom_f1: 0.5154\n",
            "Epoch 81/100\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.5272 - custom_f1: 0.6730 - weighted_custom_f1: 0.6777Epoch 86/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4980 - custom_f1: 0.6814 - weighted_custom_f1: 0.6851 - val_loss: 1.5642 - val_custom_f1: 0.5074 - val_weighted_custom_f1: 0.5285\n",
            " 20/105 [====>.........................] - ETA: 0s - loss: 0.9417 - custom_f1: 0.5176 - weighted_custom_f1: 0.5208Epoch 92/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8867 - custom_f1: 0.5310 - weighted_custom_f1: 0.5362 - val_loss: 0.9707 - val_custom_f1: 0.4651 - val_weighted_custom_f1: 0.4754\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5068 - custom_f1: 0.6873 - weighted_custom_f1: 0.6910 - val_loss: 1.2224 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5292\n",
            " 62/105 [================>.............] - ETA: 0s - loss: 0.4179 - custom_f1: 0.7253 - weighted_custom_f1: 0.7279Epoch 94/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5117 - custom_f1: 0.6798 - weighted_custom_f1: 0.6840 - val_loss: 1.5488 - val_custom_f1: 0.4841 - val_weighted_custom_f1: 0.4946\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5272 - custom_f1: 0.6725 - weighted_custom_f1: 0.6767 - val_loss: 1.3857 - val_custom_f1: 0.5111 - val_weighted_custom_f1: 0.5319\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4110 - custom_f1: 0.7373 - weighted_custom_f1: 0.7407 - val_loss: 1.7905 - val_custom_f1: 0.5080 - val_weighted_custom_f1: 0.5307\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.4261 - custom_f1: 0.7228 - weighted_custom_f1: 0.7260Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8896 - custom_f1: 0.5048 - weighted_custom_f1: 0.5101 - val_loss: 1.2836 - val_custom_f1: 0.4640 - val_weighted_custom_f1: 0.4743\n",
            "Epoch 89/100\n",
            "33/33 [==============================] - 0s 3ms/step loss: 0.8611 - custom_f1: 0.5374 - weighted_custom_f1: 0.54\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.4863 - custom_f1: 0.7000 - weighted_custom_f1: 0.7027 - val_loss: 1.9889 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.3865 - custom_f1: 0.7492 - weighted_custom_f1: 0.7515 - val_loss: 2.3379 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5188\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4313 - custom_f1: 0.7221 - weighted_custom_f1: 0.7257 - val_loss: 1.4710 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5360\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4167 - custom_f1: 0.7283 - weighted_custom_f1: 0.7332 - val_loss: 1.5965 - val_custom_f1: 0.5270 - val_weighted_custom_f1: 0.5260\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.4903 - custom_f1: 0.6895 - weighted_custom_f1: 0.6924Epoch 99/100\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8777 - custom_f1: 0.5287 - weighted_custom_f1: 0.5341 - val_loss: 1.0069 - val_custom_f1: 0.4929 - val_weighted_custom_f1: 0.4893\n",
            " 12/105 [==>...........................] - ETA: 0s - loss: 0.3543 - custom_f1: 0.7555 - weighted_custom_f1: 0.7609Epoch 82/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9917 - custom_f1: 0.4828 - weighted_custom_f1: 0.4849 - val_loss: 1.9051 - val_custom_f1: 0.4074 - val_weighted_custom_f1: 0.4187\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8920 - custom_f1: 0.5119 - weighted_custom_f1: 0.5162 - val_loss: 1.0061 - val_custom_f1: 0.4855 - val_weighted_custom_f1: 0.4914\n",
            "Epoch 56/100\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9281 - custom_f1: 0.5143 - weighted_custom_f1: 0.5185 - val_loss: 0.9976 - val_custom_f1: 0.4928 - val_weighted_custom_f1: 0.5029\n",
            " 15/105 [===>..........................] - ETA: 0s - loss: 0.3621 - custom_f1: 0.7421 - weighted_custom_f1: 0.7464Epoch 87/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5212 - custom_f1: 0.6738 - weighted_custom_f1: 0.6783 - val_loss: 1.4645 - val_custom_f1: 0.4857 - val_weighted_custom_f1: 0.5065\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5029 - custom_f1: 0.6880 - weighted_custom_f1: 0.6907 - val_loss: 1.4153 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5447\n",
            " 41/105 [==========>...................] - ETA: 0s - loss: 0.9488 - custom_f1: 0.5144 - weighted_custom_f1: 0.5183Epoch 95/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8737 - custom_f1: 0.5345 - weighted_custom_f1: 0.5383 - val_loss: 0.9457 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5582\n",
            " 79/105 [=====================>........] - ETA: 0s - loss: 0.3940 - custom_f1: 0.7407 - weighted_custom_f1: 0.7433Epoch 83/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5138 - custom_f1: 0.6803 - weighted_custom_f1: 0.6853 - val_loss: 1.2935 - val_custom_f1: 0.5417 - val_weighted_custom_f1: 0.5465\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.5166 - custom_f1: 0.6833 - weighted_custom_f1: 0.6880 - val_loss: 1.3828 - val_custom_f1: 0.4959 - val_weighted_custom_f1: 0.5058\n",
            "Epoch 94/100\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3974 - custom_f1: 0.7411 - weighted_custom_f1: 0.7448 - val_loss: 1.5888 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5158\n",
            " 23/131 [====>.........................] - ETA: 0sEpoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4911 - custom_f1: 0.6911 - weighted_custom_f1: 0.6943 - val_loss: 2.0349 - val_custom_f1: 0.5126 - val_weighted_custom_f1: 0.5012\n",
            " 91/105 [=========================>....] - ETA: 0s - loss: 1.0233 - custom_f1: 0.4676 - weighted_custom_f1: 0.4714Epoch 94/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8865 - custom_f1: 0.5083 - weighted_custom_f1: 0.5140 - val_loss: 1.3210 - val_custom_f1: 0.4635 - val_weighted_custom_f1: 0.4743\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.6378 - custom_f1: 0.6286 - weighted_custom_f1: 0.6286Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3712 - custom_f1: 0.7611 - weighted_custom_f1: 0.7646 - val_loss: 2.1418 - val_custom_f1: 0.5320 - val_weighted_custom_f1: 0.5288\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.4957 - custom_f1: 0.6922 - weighted_custom_f1: 0.6964Epoch 98/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4183 - custom_f1: 0.7320 - weighted_custom_f1: 0.7351 - val_loss: 1.4889 - val_custom_f1: 0.5370 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4090 - custom_f1: 0.7296 - weighted_custom_f1: 0.7330 - val_loss: 1.4540 - val_custom_f1: 0.5288 - val_weighted_custom_f1: 0.5340\n",
            "  1/105 [..............................] - ETA: 0s - loss: 0.2857 - custom_f1: 0.8254 - weighted_custom_f1: 0.8254Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8545 - custom_f1: 0.5358 - weighted_custom_f1: 0.5424 - val_loss: 1.1570 - val_custom_f1: 0.4836 - val_weighted_custom_f1: 0.4743\n",
            "Epoch 83/100\n",
            "131/131 [==============================] - 0s 3ms/steposs: 1.1340 - custom_f1: 0.4516 - weighted_custom_f1: 0.4540\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0147 - custom_f1: 0.4701 - weighted_custom_f1: 0.4735 - val_loss: 1.9420 - val_custom_f1: 0.4428 - val_weighted_custom_f1: 0.4512\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9388 - custom_f1: 0.5101 - weighted_custom_f1: 0.5139 - val_loss: 1.0158 - val_custom_f1: 0.4811 - val_weighted_custom_f1: 0.4903\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0117 - custom_f1: 0.4819 - weighted_custom_f1: 0.4819Epoch 88/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.9615 - custom_f1: 0.4856 - weighted_custom_f1: 0.4898 - val_loss: 0.9537 - val_custom_f1: 0.4871 - val_weighted_custom_f1: 0.4957\n",
            " 18/105 [====>.........................] - ETA: 0s - loss: 0.9783 - custom_f1: 0.4621 - weighted_custom_f1: 0.4651Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5090 - custom_f1: 0.6794 - weighted_custom_f1: 0.6830 - val_loss: 1.3616 - val_custom_f1: 0.4912 - val_weighted_custom_f1: 0.5129\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5144 - custom_f1: 0.6838 - weighted_custom_f1: 0.6858 - val_loss: 1.1877 - val_custom_f1: 0.5215 - val_weighted_custom_f1: 0.5316\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5396 - custom_f1: 0.6766 - weighted_custom_f1: 0.6801 - val_loss: 1.3059 - val_custom_f1: 0.4982 - val_weighted_custom_f1: 0.5063\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8898 - custom_f1: 0.5346 - weighted_custom_f1: 0.5378 - val_loss: 0.9101 - val_custom_f1: 0.5259 - val_weighted_custom_f1: 0.5360\n",
            " 47/105 [============>.................] - ETA: 0s - loss: 0.8987 - custom_f1: 0.4934 - weighted_custom_f1: 0.4985Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4009 - custom_f1: 0.7417 - weighted_custom_f1: 0.7442 - val_loss: 1.5971 - val_custom_f1: 0.4997 - val_weighted_custom_f1: 0.5228\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5180 - custom_f1: 0.6788 - weighted_custom_f1: 0.6822 - val_loss: 1.5842 - val_custom_f1: 0.5095 - val_weighted_custom_f1: 0.5223\n",
            " 82/105 [======================>.......] - ETA: 0s - loss: 0.8892 - custom_f1: 0.5415 - weighted_custom_f1: 0.5462Epoch 98/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5080 - custom_f1: 0.6826 - weighted_custom_f1: 0.6864 - val_loss: 1.7036 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5155\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8824 - custom_f1: 0.5138 - weighted_custom_f1: 0.5195 - val_loss: 1.2861 - val_custom_f1: 0.5257 - val_weighted_custom_f1: 0.5327\n",
            " 29/105 [=======>......................] - ETA: 0s - loss: 0.3825 - custom_f1: 0.7503 - weighted_custom_f1: 0.7556Epoch 91/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3721 - custom_f1: 0.7550 - weighted_custom_f1: 0.7579 - val_loss: 2.1903 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5165\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4324 - custom_f1: 0.7258 - weighted_custom_f1: 0.7302 - val_loss: 1.7088 - val_custom_f1: 0.5413 - val_weighted_custom_f1: 0.5466\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3996 - custom_f1: 0.7429 - weighted_custom_f1: 0.7462 - val_loss: 1.4728 - val_custom_f1: 0.5201 - val_weighted_custom_f1: 0.5261\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8764 - custom_f1: 0.5325 - weighted_custom_f1: 0.5374 - val_loss: 0.9203 - val_custom_f1: 0.5187 - val_weighted_custom_f1: 0.5170\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0124 - custom_f1: 0.4812 - weighted_custom_f1: 0.4852 - val_loss: 1.8456 - val_custom_f1: 0.4739 - val_weighted_custom_f1: 0.4819\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9249 - custom_f1: 0.5101 - weighted_custom_f1: 0.5155 - val_loss: 1.0125 - val_custom_f1: 0.5166 - val_weighted_custom_f1: 0.5258\n",
            " 53/105 [==============>...............] - ETA: 0s - loss: 0.3781 - custom_f1: 0.7471 - weighted_custom_f1: 0.7501Epoch 89/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9134 - custom_f1: 0.5046 - weighted_custom_f1: 0.5091 - val_loss: 0.9786 - val_custom_f1: 0.4577 - val_weighted_custom_f1: 0.4681\n",
            " 38/105 [=========>....................] - ETA: 0s - loss: 0.3982 - custom_f1: 0.7393 - weighted_custom_f1: 0.7423Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5111 - custom_f1: 0.6808 - weighted_custom_f1: 0.6852 - val_loss: 1.5410 - val_custom_f1: 0.5178 - val_weighted_custom_f1: 0.5395\n",
            " 84/105 [=======================>......] - ETA: 0s - loss: 0.8946 - custom_f1: 0.5114 - weighted_custom_f1: 0.5168Epoch 95/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5245 - custom_f1: 0.6815 - weighted_custom_f1: 0.6854 - val_loss: 1.3516 - val_custom_f1: 0.4881 - val_weighted_custom_f1: 0.4951\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8695 - custom_f1: 0.5388 - weighted_custom_f1: 0.5439 - val_loss: 0.9741 - val_custom_f1: 0.4752 - val_weighted_custom_f1: 0.4865\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5062 - custom_f1: 0.6822 - weighted_custom_f1: 0.6869 - val_loss: 1.4442 - val_custom_f1: 0.5322 - val_weighted_custom_f1: 0.5541\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.3907 - custom_f1: 0.7431 - weighted_custom_f1: 0.7465 - val_loss: 1.6032 - val_custom_f1: 0.4966 - val_weighted_custom_f1: 0.5184\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5089 - custom_f1: 0.6833 - weighted_custom_f1: 0.6901 - val_loss: 1.6112 - val_custom_f1: 0.5342 - val_weighted_custom_f1: 0.5447\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8877 - custom_f1: 0.5097 - weighted_custom_f1: 0.5150 - val_loss: 1.3095 - val_custom_f1: 0.4720 - val_weighted_custom_f1: 0.4834\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5187 - custom_f1: 0.6706 - weighted_custom_f1: 0.6743 - val_loss: 1.7997 - val_custom_f1: 0.5213 - val_weighted_custom_f1: 0.5113\n",
            " 73/105 [===================>..........] - ETA: 0s - loss: 0.8966 - custom_f1: 0.5195 - weighted_custom_f1: 0.5251Epoch 96/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4054 - custom_f1: 0.7368 - weighted_custom_f1: 0.7407 - val_loss: 2.0951 - val_custom_f1: 0.5371 - val_weighted_custom_f1: 0.5298\n",
            " 44/105 [===========>..................] - ETA: 0s - loss: 0.4676 - custom_f1: 0.6983 - weighted_custom_f1: 0.7032Epoch 100/100\n",
            "33/33 [==============================] - 0s 4ms/step loss: 0.5702 - custom_f1: 0.6664 - weighted_custom_f1: 0.67\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4118 - custom_f1: 0.7308 - weighted_custom_f1: 0.7337 - val_loss: 1.7730 - val_custom_f1: 0.5294 - val_weighted_custom_f1: 0.5358\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8335 - custom_f1: 0.5390 - weighted_custom_f1: 0.5442 - val_loss: 0.9179 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5300\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.9335 - custom_f1: 0.5079 - weighted_custom_f1: 0.5127 - val_loss: 0.9973 - val_custom_f1: 0.4591 - val_weighted_custom_f1: 0.4690\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 1.0033 - custom_f1: 0.4763 - weighted_custom_f1: 0.4816 - val_loss: 1.9132 - val_custom_f1: 0.4242 - val_weighted_custom_f1: 0.4335\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8986 - custom_f1: 0.5121 - weighted_custom_f1: 0.5186 - val_loss: 0.9517 - val_custom_f1: 0.5082 - val_weighted_custom_f1: 0.5194\n",
            " 17/105 [===>..........................] - ETA: 0s - loss: 1.0044 - custom_f1: 0.4765 - weighted_custom_f1: 0.4789Epoch 86/100\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0049 - custom_f1: 0.6923 - weighted_custom_f1: 0.6923Epoch 1/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5732 - custom_f1: 0.6641 - weighted_custom_f1: 0.6685 - val_loss: 1.5082 - val_custom_f1: 0.4825 - val_weighted_custom_f1: 0.4927\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.6145 - custom_f1: 0.6520 - weighted_custom_f1: 0.6567 - val_loss: 1.2825 - val_custom_f1: 0.5184 - val_weighted_custom_f1: 0.5262\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.3966 - custom_f1: 0.7381 - weighted_custom_f1: 0.7421 - val_loss: 1.7662 - val_custom_f1: 0.5116 - val_weighted_custom_f1: 0.5338\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.5187 - custom_f1: 0.6831 - weighted_custom_f1: 0.6864 - val_loss: 1.2568 - val_custom_f1: 0.5134 - val_weighted_custom_f1: 0.5171\n",
            " 16/105 [===>..........................] - ETA: 0s - loss: 0.5498 - custom_f1: 0.6596 - weighted_custom_f1: 0.6637Epoch 98/100\n",
            "105/105 [==============================] - 1s 7ms/step - loss: 0.8839 - custom_f1: 0.5350 - weighted_custom_f1: 0.5394 - val_loss: 0.9244 - val_custom_f1: 0.5157 - val_weighted_custom_f1: 0.5272\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4906 - custom_f1: 0.6870 - weighted_custom_f1: 0.6916 - val_loss: 1.6095 - val_custom_f1: 0.5093 - val_weighted_custom_f1: 0.5203\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4812 - custom_f1: 0.6924 - weighted_custom_f1: 0.6956 - val_loss: 2.1855 - val_custom_f1: 0.5288 - val_weighted_custom_f1: 0.5175\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.8933 - custom_f1: 0.5114 - weighted_custom_f1: 0.5171 - val_loss: 1.3328 - val_custom_f1: 0.5087 - val_weighted_custom_f1: 0.5112\n",
            " 35/105 [=========>....................] - ETA: 0s - loss: 0.5172 - custom_f1: 0.6934 - weighted_custom_f1: 0.6975Epoch 93/100\n",
            "105/105 [==============================] - 1s 6ms/step - loss: 0.4204 - custom_f1: 0.7311 - weighted_custom_f1: 0.7338 - val_loss: 2.4641 - val_custom_f1: 0.5227 - val_weighted_custom_f1: 0.5190\n",
            "33/33 [==============================] - 0s 3ms/step loss: 0.5090 - custom_f1: 0.6874 - weighted_custom_f1: 0.69\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8509 - custom_f1: 0.5359 - weighted_custom_f1: 0.5376 - val_loss: 0.9256 - val_custom_f1: 0.5426 - val_weighted_custom_f1: 0.5397\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9915 - custom_f1: 0.4798 - weighted_custom_f1: 0.4830 - val_loss: 1.8530 - val_custom_f1: 0.4791 - val_weighted_custom_f1: 0.4842\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9579 - custom_f1: 0.5084 - weighted_custom_f1: 0.5139 - val_loss: 1.0086 - val_custom_f1: 0.4572 - val_weighted_custom_f1: 0.4687\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.0300 - custom_f1: 0.4571 - weighted_custom_f1: 0.4571Epoch 91/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9104 - custom_f1: 0.5059 - weighted_custom_f1: 0.5098 - val_loss: 0.9762 - val_custom_f1: 0.4584 - val_weighted_custom_f1: 0.4685\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5988 - custom_f1: 0.6577 - weighted_custom_f1: 0.6611 - val_loss: 1.3843 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5142\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5568 - custom_f1: 0.6615 - weighted_custom_f1: 0.6663 - val_loss: 1.2225 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5262\n",
            "131/131 [==============================] - 0s 2ms/steposs: 0.9655 - custom_f1: 0.4998 - weighted_custom_f1: 0.50\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.5122 - custom_f1: 0.6812 - weighted_custom_f1: 0.6858 - val_loss: 1.5195 - val_custom_f1: 0.5065 - val_weighted_custom_f1: 0.5183\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.9204 - custom_f1: 0.5212 - weighted_custom_f1: 0.52\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4799 - custom_f1: 0.6963 - weighted_custom_f1: 0.7012 - val_loss: 1.4522 - val_custom_f1: 0.5451 - val_weighted_custom_f1: 0.5446\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8882 - custom_f1: 0.5412 - weighted_custom_f1: 0.5449 - val_loss: 0.9568 - val_custom_f1: 0.4724 - val_weighted_custom_f1: 0.4832\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4732 - custom_f1: 0.6954 - weighted_custom_f1: 0.6990 - val_loss: 1.9463 - val_custom_f1: 0.5293 - val_weighted_custom_f1: 0.5220\n",
            "Epoch 87/100\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9186 - custom_f1: 0.5082 - weighted_custom_f1: 0.5132 - val_loss: 1.2989 - val_custom_f1: 0.5128 - val_weighted_custom_f1: 0.5217\n",
            "Epoch 94/100\n",
            "33/33 [==============================] - 0s 2ms/step\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8447 - custom_f1: 0.5317 - weighted_custom_f1: 0.5372 - val_loss: 1.1526 - val_custom_f1: 0.4861 - val_weighted_custom_f1: 0.4774\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.9868 - custom_f1: 0.4750 - weighted_custom_f1: 0.4801 - val_loss: 1.8433 - val_custom_f1: 0.4859 - val_weighted_custom_f1: 0.4904\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9184 - custom_f1: 0.5125 - weighted_custom_f1: 0.5170 - val_loss: 0.9828 - val_custom_f1: 0.4687 - val_weighted_custom_f1: 0.4790\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9253 - custom_f1: 0.5050 - weighted_custom_f1: 0.5105 - val_loss: 0.9798 - val_custom_f1: 0.5145 - val_weighted_custom_f1: 0.5220\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5971 - custom_f1: 0.6544 - weighted_custom_f1: 0.6586 - val_loss: 1.4139 - val_custom_f1: 0.4949 - val_weighted_custom_f1: 0.5171\n",
            " 1/33 [..............................] - ETA: 6sEpoch 98/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5003 - custom_f1: 0.6836 - weighted_custom_f1: 0.6859 - val_loss: 1.3198 - val_custom_f1: 0.5230 - val_weighted_custom_f1: 0.5309\n",
            "Epoch 99/100\n",
            "33/33 [==============================] - 0s 2ms/step loss: 0.4674 - custom_f1: 0.7130 - weighted_custom_f1: 0.718\n",
            "131/131 [==============================] - 0s 3ms/step\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4751 - custom_f1: 0.6984 - weighted_custom_f1: 0.7031 - val_loss: 1.3826 - val_custom_f1: 0.5412 - val_weighted_custom_f1: 0.5462\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.4819 - custom_f1: 0.6885 - weighted_custom_f1: 0.6928 - val_loss: 2.0669 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5072\n",
            " 72/105 [===================>..........] - ETA: 0s - loss: 0.8854 - custom_f1: 0.5329 - weighted_custom_f1: 0.5366Epoch 99/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8856 - custom_f1: 0.5332 - weighted_custom_f1: 0.5386 - val_loss: 0.9349 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5223\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8996 - custom_f1: 0.5160 - weighted_custom_f1: 0.5210 - val_loss: 1.3277 - val_custom_f1: 0.4856 - val_weighted_custom_f1: 0.4980\n",
            "Epoch 95/100\n",
            "131/131 [==============================] - 0s 2ms/steposs: 0.4631 - custom_f1: 0.6856 - weighted_custom_f1: 0.68\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8897 - custom_f1: 0.5301 - weighted_custom_f1: 0.5352 - val_loss: 0.9512 - val_custom_f1: 0.5149 - val_weighted_custom_f1: 0.5105\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.8625 - custom_f1: 0.5419 - weighted_custom_f1: 0.5463Epoch 88/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.9244 - custom_f1: 0.5156 - weighted_custom_f1: 0.5183 - val_loss: 1.1367 - val_custom_f1: 0.4874 - val_weighted_custom_f1: 0.4914\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 1.0346 - custom_f1: 0.4748 - weighted_custom_f1: 0.4777 - val_loss: 1.8741 - val_custom_f1: 0.4730 - val_weighted_custom_f1: 0.4800\n",
            " 48/105 [============>.................] - ETA: 0s - loss: 0.8871 - custom_f1: 0.5120 - weighted_custom_f1: 0.5173Epoch 62/100\n",
            "108/131 [=======================>......] - ETA: 0sEpoch 93/100811 - custom_f1: 0.4789 - weighted_custom_f1: 0.47\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9024 - custom_f1: 0.5100 - weighted_custom_f1: 0.5138 - val_loss: 0.9932 - val_custom_f1: 0.5189 - val_weighted_custom_f1: 0.5287\n",
            "131/131 [==============================] - 0s 2ms/step\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.5089 - custom_f1: 0.6788 - weighted_custom_f1: 0.6836 - val_loss: 1.2512 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5281\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5271 - custom_f1: 0.6703 - weighted_custom_f1: 0.6731 - val_loss: 1.5116 - val_custom_f1: 0.4965 - val_weighted_custom_f1: 0.5173\n",
            "103/105 [============================>.] - ETA: 0s - loss: 0.8662 - custom_f1: 0.5371 - weighted_custom_f1: 0.5411Epoch 99/100\n",
            "Epoch 1/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4975 - custom_f1: 0.6853 - weighted_custom_f1: 0.6896 - val_loss: 1.8098 - val_custom_f1: 0.4937 - val_weighted_custom_f1: 0.4870\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.4993 - custom_f1: 0.6884 - weighted_custom_f1: 0.6935 - val_loss: 1.4541 - val_custom_f1: 0.5630 - val_weighted_custom_f1: 0.5633\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.8653 - custom_f1: 0.5340 - weighted_custom_f1: 0.5398 - val_loss: 0.9578 - val_custom_f1: 0.5400 - val_weighted_custom_f1: 0.5504\n",
            " 50/105 [=============>................] - ETA: 0s - loss: 0.4999 - custom_f1: 0.6772 - weighted_custom_f1: 0.6820Epoch 89/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.8962 - custom_f1: 0.5108 - weighted_custom_f1: 0.5154 - val_loss: 1.3232 - val_custom_f1: 0.4960 - val_weighted_custom_f1: 0.5048\n",
            "Epoch 96/100\n",
            "131/131 [==============================] - 0s 3ms/steposs: 0.8492 - custom_f1: 0.5579 - weighted_custom_f1: 0.56\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 0.9976 - custom_f1: 0.4847 - weighted_custom_f1: 0.4884 - val_loss: 1.8628 - val_custom_f1: 0.4324 - val_weighted_custom_f1: 0.4433\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.8532 - custom_f1: 0.5369 - weighted_custom_f1: 0.5436 - val_loss: 0.9610 - val_custom_f1: 0.4818 - val_weighted_custom_f1: 0.4845\n",
            "Epoch 63/100\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.9689 - custom_f1: 0.4937 - weighted_custom_f1: 0.5002 - val_loss: 0.9678 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.5028\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 5ms/step - loss: 0.8906 - custom_f1: 0.5156 - weighted_custom_f1: 0.5197 - val_loss: 0.9880 - val_custom_f1: 0.4486 - val_weighted_custom_f1: 0.4597\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5053 - custom_f1: 0.6836 - weighted_custom_f1: 0.6860 - val_loss: 1.3475 - val_custom_f1: 0.5423 - val_weighted_custom_f1: 0.5505\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 0.5020 - custom_f1: 0.6798 - weighted_custom_f1: 0.6832 - val_loss: 1.4184 - val_custom_f1: 0.4971 - val_weighted_custom_f1: 0.5195\n",
            "Epoch 100/100\n",
            " 28/105 [=======>......................] - ETA: 0s - loss: 0.9155 - custom_f1: 0.5273 - weighted_custom_f1: 0.5317Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0311 - custom_f1: 0.4755 - weighted_custom_f1: 0.4801 - val_loss: 1.1777 - val_custom_f1: 0.4668 - val_weighted_custom_f1: 0.4597\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9600 - custom_f1: 0.5020 - weighted_custom_f1: 0.5028 - val_loss: 1.1309 - val_custom_f1: 0.4819 - val_weighted_custom_f1: 0.4760\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2652 - custom_f1: 0.2716 - weighted_custom_f1: 0.2750 - val_loss: 1.4261 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9729 - custom_f1: 0.4892 - weighted_custom_f1: 0.4930 - val_loss: 1.2514 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.4945\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0031 - custom_f1: 0.4822 - weighted_custom_f1: 0.4864 - val_loss: 1.0408 - val_custom_f1: 0.4402 - val_weighted_custom_f1: 0.4497\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9856 - custom_f1: 0.4908 - weighted_custom_f1: 0.4936 - val_loss: 0.9763 - val_custom_f1: 0.5108 - val_weighted_custom_f1: 0.5095\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9791 - custom_f1: 0.4939 - weighted_custom_f1: 0.4970 - val_loss: 1.2884 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.4954\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2641 - custom_f1: 0.2709 - weighted_custom_f1: 0.2741 - val_loss: 1.4225 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0212 - custom_f1: 0.4826 - weighted_custom_f1: 0.4868 - val_loss: 1.0771 - val_custom_f1: 0.4867 - val_weighted_custom_f1: 0.4919\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9658 - custom_f1: 0.4889 - weighted_custom_f1: 0.4937 - val_loss: 1.0945 - val_custom_f1: 0.4642 - val_weighted_custom_f1: 0.4637\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9800 - custom_f1: 0.4938 - weighted_custom_f1: 0.4977 - val_loss: 1.2544 - val_custom_f1: 0.4427 - val_weighted_custom_f1: 0.4532\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2630 - custom_f1: 0.2614 - weighted_custom_f1: 0.2645 - val_loss: 1.4220 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0165 - custom_f1: 0.4890 - weighted_custom_f1: 0.4940 - val_loss: 1.0479 - val_custom_f1: 0.4802 - val_weighted_custom_f1: 0.4871\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9887 - custom_f1: 0.4867 - weighted_custom_f1: 0.4919 - val_loss: 1.0309 - val_custom_f1: 0.4417 - val_weighted_custom_f1: 0.4412\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9814 - custom_f1: 0.4846 - weighted_custom_f1: 0.4883 - val_loss: 1.2753 - val_custom_f1: 0.4912 - val_weighted_custom_f1: 0.4961\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2656 - custom_f1: 0.2665 - weighted_custom_f1: 0.2695 - val_loss: 1.4238 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9940 - custom_f1: 0.4850 - weighted_custom_f1: 0.4885 - val_loss: 1.0404 - val_custom_f1: 0.4677 - val_weighted_custom_f1: 0.4764\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9652 - custom_f1: 0.4815 - weighted_custom_f1: 0.4860 - val_loss: 1.0144 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.4912\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9792 - custom_f1: 0.4864 - weighted_custom_f1: 0.4910 - val_loss: 1.2791 - val_custom_f1: 0.4638 - val_weighted_custom_f1: 0.4727\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2624 - custom_f1: 0.2844 - weighted_custom_f1: 0.2885 - val_loss: 1.4237 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0102 - custom_f1: 0.4884 - weighted_custom_f1: 0.4918 - val_loss: 1.0470 - val_custom_f1: 0.4656 - val_weighted_custom_f1: 0.4744\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9779 - custom_f1: 0.4863 - weighted_custom_f1: 0.4896 - val_loss: 1.2834 - val_custom_f1: 0.4790 - val_weighted_custom_f1: 0.4850\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9685 - custom_f1: 0.4872 - weighted_custom_f1: 0.4928 - val_loss: 1.0303 - val_custom_f1: 0.4851 - val_weighted_custom_f1: 0.4846\n",
            "  1/105 [..............................] - ETA: 0s - loss: 1.1087 - custom_f1: 0.5070 - weighted_custom_f1: 0.5070Epoch 55/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2643 - custom_f1: 0.2840 - weighted_custom_f1: 0.2888 - val_loss: 1.4224 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0014 - custom_f1: 0.4835 - weighted_custom_f1: 0.4858 - val_loss: 1.0405 - val_custom_f1: 0.4471 - val_weighted_custom_f1: 0.4567\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9722 - custom_f1: 0.4874 - weighted_custom_f1: 0.4908 - val_loss: 1.2943 - val_custom_f1: 0.4636 - val_weighted_custom_f1: 0.4714\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9945 - custom_f1: 0.4946 - weighted_custom_f1: 0.4997 - val_loss: 1.0373 - val_custom_f1: 0.5166 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2639 - custom_f1: 0.2579 - weighted_custom_f1: 0.2623 - val_loss: 1.4290 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0226 - custom_f1: 0.4793 - weighted_custom_f1: 0.4836 - val_loss: 1.0350 - val_custom_f1: 0.4717 - val_weighted_custom_f1: 0.4792\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9851 - custom_f1: 0.4788 - weighted_custom_f1: 0.4844 - val_loss: 1.4663 - val_custom_f1: 0.4675 - val_weighted_custom_f1: 0.4598\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9530 - custom_f1: 0.5042 - weighted_custom_f1: 0.5092 - val_loss: 0.9762 - val_custom_f1: 0.4735 - val_weighted_custom_f1: 0.4749\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2625 - custom_f1: 0.2844 - weighted_custom_f1: 0.2886 - val_loss: 1.4234 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0071 - custom_f1: 0.4788 - weighted_custom_f1: 0.4824 - val_loss: 1.0407 - val_custom_f1: 0.4707 - val_weighted_custom_f1: 0.4811\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0157 - custom_f1: 0.4759 - weighted_custom_f1: 0.4805 - val_loss: 1.3167 - val_custom_f1: 0.4957 - val_weighted_custom_f1: 0.4907\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2629 - custom_f1: 0.2845 - weighted_custom_f1: 0.2889 - val_loss: 1.4293 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9270 - custom_f1: 0.5021 - weighted_custom_f1: 0.5052 - val_loss: 0.9775 - val_custom_f1: 0.5017 - val_weighted_custom_f1: 0.5004\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9885 - custom_f1: 0.4893 - weighted_custom_f1: 0.4937 - val_loss: 1.2604 - val_custom_f1: 0.4841 - val_weighted_custom_f1: 0.4889\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0090 - custom_f1: 0.4785 - weighted_custom_f1: 0.4831 - val_loss: 1.0645 - val_custom_f1: 0.4775 - val_weighted_custom_f1: 0.4848\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2648 - custom_f1: 0.2743 - weighted_custom_f1: 0.2776 - val_loss: 1.4226 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9679 - custom_f1: 0.4924 - weighted_custom_f1: 0.4961 - val_loss: 1.0681 - val_custom_f1: 0.4928 - val_weighted_custom_f1: 0.4905\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9824 - custom_f1: 0.4862 - weighted_custom_f1: 0.4902 - val_loss: 1.2471 - val_custom_f1: 0.4518 - val_weighted_custom_f1: 0.4606\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0126 - custom_f1: 0.4745 - weighted_custom_f1: 0.4801 - val_loss: 1.0497 - val_custom_f1: 0.4631 - val_weighted_custom_f1: 0.4720\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2638 - custom_f1: 0.2326 - weighted_custom_f1: 0.2397 - val_loss: 1.4222 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.9400 - custom_f1: 0.5019 - weighted_custom_f1: 0.5055 - val_loss: 1.1157 - val_custom_f1: 0.4315 - val_weighted_custom_f1: 0.4311\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9801 - custom_f1: 0.4834 - weighted_custom_f1: 0.4880 - val_loss: 1.4125 - val_custom_f1: 0.4085 - val_weighted_custom_f1: 0.4192\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.0386 - custom_f1: 0.4729 - weighted_custom_f1: 0.4777 - val_loss: 1.0571 - val_custom_f1: 0.4765 - val_weighted_custom_f1: 0.4804\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.2632 - custom_f1: 0.2784 - weighted_custom_f1: 0.2813 - val_loss: 1.4227 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0035 - custom_f1: 0.4947 - weighted_custom_f1: 0.4977 - val_loss: 1.0624 - val_custom_f1: 0.4487 - val_weighted_custom_f1: 0.4493\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0320 - custom_f1: 0.4815 - weighted_custom_f1: 0.4854 - val_loss: 1.2605 - val_custom_f1: 0.4532 - val_weighted_custom_f1: 0.4619\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0298 - custom_f1: 0.4814 - weighted_custom_f1: 0.4852 - val_loss: 1.0661 - val_custom_f1: 0.4797 - val_weighted_custom_f1: 0.4843\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2635 - custom_f1: 0.2844 - weighted_custom_f1: 0.2888 - val_loss: 1.4223 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9877 - custom_f1: 0.4996 - weighted_custom_f1: 0.5026 - val_loss: 1.0169 - val_custom_f1: 0.5069 - val_weighted_custom_f1: 0.5038\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9816 - custom_f1: 0.4932 - weighted_custom_f1: 0.4991 - val_loss: 1.2576 - val_custom_f1: 0.4940 - val_weighted_custom_f1: 0.4993\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2625 - custom_f1: 0.2845 - weighted_custom_f1: 0.2884 - val_loss: 1.4228 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0571 - custom_f1: 0.4683 - weighted_custom_f1: 0.4718 - val_loss: 1.0703 - val_custom_f1: 0.4253 - val_weighted_custom_f1: 0.4357\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9634 - custom_f1: 0.4988 - weighted_custom_f1: 0.5015 - val_loss: 1.0161 - val_custom_f1: 0.4647 - val_weighted_custom_f1: 0.4646\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9858 - custom_f1: 0.4855 - weighted_custom_f1: 0.4906 - val_loss: 1.2631 - val_custom_f1: 0.4491 - val_weighted_custom_f1: 0.4562\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2631 - custom_f1: 0.2846 - weighted_custom_f1: 0.2888 - val_loss: 1.4223 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 92/105 [=========================>....] - ETA: 0s - loss: 0.9471 - custom_f1: 0.4936 - weighted_custom_f1: 0.4968Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9950 - custom_f1: 0.4806 - weighted_custom_f1: 0.4846 - val_loss: 1.0509 - val_custom_f1: 0.4742 - val_weighted_custom_f1: 0.4812\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9421 - custom_f1: 0.4949 - weighted_custom_f1: 0.4978 - val_loss: 0.9765 - val_custom_f1: 0.4741 - val_weighted_custom_f1: 0.4738\n",
            "101/105 [===========================>..] - ETA: 0s - loss: 0.9890 - custom_f1: 0.4924 - weighted_custom_f1: 0.4967Epoch 64/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9882 - custom_f1: 0.4923 - weighted_custom_f1: 0.4971 - val_loss: 1.2888 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.4945\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.9430 - custom_f1: 0.5033 - weighted_custom_f1: 0.5071Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2632 - custom_f1: 0.2845 - weighted_custom_f1: 0.2880 - val_loss: 1.4278 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0574 - custom_f1: 0.4701 - weighted_custom_f1: 0.4747 - val_loss: 1.0531 - val_custom_f1: 0.4813 - val_weighted_custom_f1: 0.4882\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0401 - custom_f1: 0.4812 - weighted_custom_f1: 0.4855 - val_loss: 1.0188 - val_custom_f1: 0.4563 - val_weighted_custom_f1: 0.4556\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9856 - custom_f1: 0.4908 - weighted_custom_f1: 0.4959 - val_loss: 1.2762 - val_custom_f1: 0.4487 - val_weighted_custom_f1: 0.4577\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2628 - custom_f1: 0.2845 - weighted_custom_f1: 0.2885 - val_loss: 1.4226 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0268 - custom_f1: 0.4832 - weighted_custom_f1: 0.4897 - val_loss: 1.0246 - val_custom_f1: 0.4701 - val_weighted_custom_f1: 0.4786\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9863 - custom_f1: 0.4988 - weighted_custom_f1: 0.5038 - val_loss: 1.0158 - val_custom_f1: 0.5120 - val_weighted_custom_f1: 0.5096\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9800 - custom_f1: 0.4891 - weighted_custom_f1: 0.4939 - val_loss: 1.2911 - val_custom_f1: 0.5060 - val_weighted_custom_f1: 0.5018\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2635 - custom_f1: 0.2843 - weighted_custom_f1: 0.2880 - val_loss: 1.4241 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0121 - custom_f1: 0.4831 - weighted_custom_f1: 0.4870 - val_loss: 1.0647 - val_custom_f1: 0.4869 - val_weighted_custom_f1: 0.4950\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9295 - custom_f1: 0.5039 - weighted_custom_f1: 0.5083 - val_loss: 0.9744 - val_custom_f1: 0.4713 - val_weighted_custom_f1: 0.4718\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9747 - custom_f1: 0.4911 - weighted_custom_f1: 0.4952 - val_loss: 1.2784 - val_custom_f1: 0.4839 - val_weighted_custom_f1: 0.4886\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2641 - custom_f1: 0.2661 - weighted_custom_f1: 0.2706 - val_loss: 1.4272 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0107 - custom_f1: 0.4808 - weighted_custom_f1: 0.4879 - val_loss: 1.0586 - val_custom_f1: 0.4742 - val_weighted_custom_f1: 0.4831\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9623 - custom_f1: 0.4839 - weighted_custom_f1: 0.4893 - val_loss: 1.2942 - val_custom_f1: 0.4407 - val_weighted_custom_f1: 0.4507\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9742 - custom_f1: 0.5023 - weighted_custom_f1: 0.5063 - val_loss: 1.2123 - val_custom_f1: 0.4268 - val_weighted_custom_f1: 0.4241\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2645 - custom_f1: 0.2844 - weighted_custom_f1: 0.2886 - val_loss: 1.4255 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0296 - custom_f1: 0.4779 - weighted_custom_f1: 0.4811 - val_loss: 1.0434 - val_custom_f1: 0.4631 - val_weighted_custom_f1: 0.4698\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0004 - custom_f1: 0.4800 - weighted_custom_f1: 0.4845 - val_loss: 1.3395 - val_custom_f1: 0.4509 - val_weighted_custom_f1: 0.4600\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9606 - custom_f1: 0.4997 - weighted_custom_f1: 0.5040 - val_loss: 1.1064 - val_custom_f1: 0.5062 - val_weighted_custom_f1: 0.4964\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2651 - custom_f1: 0.2534 - weighted_custom_f1: 0.2576 - val_loss: 1.4224 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0052 - custom_f1: 0.4833 - weighted_custom_f1: 0.4867 - val_loss: 1.0390 - val_custom_f1: 0.4777 - val_weighted_custom_f1: 0.4844\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9856 - custom_f1: 0.4864 - weighted_custom_f1: 0.4920 - val_loss: 1.2505 - val_custom_f1: 0.4757 - val_weighted_custom_f1: 0.4829\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9933 - custom_f1: 0.4916 - weighted_custom_f1: 0.4979 - val_loss: 1.0578 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.4912\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2628 - custom_f1: 0.2845 - weighted_custom_f1: 0.2878 - val_loss: 1.4234 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9700 - custom_f1: 0.4877 - weighted_custom_f1: 0.4910 - val_loss: 1.3797 - val_custom_f1: 0.4651 - val_weighted_custom_f1: 0.4571\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.0033 - custom_f1: 0.4861 - weighted_custom_f1: 0.4892 - val_loss: 1.1513 - val_custom_f1: 0.4746 - val_weighted_custom_f1: 0.4693\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.9691 - custom_f1: 0.4932 - weighted_custom_f1: 0.4980 - val_loss: 1.0590 - val_custom_f1: 0.4990 - val_weighted_custom_f1: 0.4928\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2644 - custom_f1: 0.2656 - weighted_custom_f1: 0.2722 - val_loss: 1.4233 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9885 - custom_f1: 0.4858 - weighted_custom_f1: 0.4906 - val_loss: 1.3752 - val_custom_f1: 0.4253 - val_weighted_custom_f1: 0.4352\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0134 - custom_f1: 0.4782 - weighted_custom_f1: 0.4820 - val_loss: 1.0526 - val_custom_f1: 0.4520 - val_weighted_custom_f1: 0.4620\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9458 - custom_f1: 0.5066 - weighted_custom_f1: 0.5098 - val_loss: 0.9588 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.4913\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2621 - custom_f1: 0.2847 - weighted_custom_f1: 0.2883 - val_loss: 1.4221 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 32/105 [========>.....................] - ETA: 0s - loss: 0.9451 - custom_f1: 0.4966 - weighted_custom_f1: 0.5010Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9955 - custom_f1: 0.4779 - weighted_custom_f1: 0.4813 - val_loss: 1.2703 - val_custom_f1: 0.4816 - val_weighted_custom_f1: 0.4863\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0219 - custom_f1: 0.4742 - weighted_custom_f1: 0.4785 - val_loss: 1.1891 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.4657\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9427 - custom_f1: 0.5028 - weighted_custom_f1: 0.5077 - val_loss: 0.9670 - val_custom_f1: 0.4935 - val_weighted_custom_f1: 0.4955\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2649 - custom_f1: 0.2649 - weighted_custom_f1: 0.2691 - val_loss: 1.4220 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0045 - custom_f1: 0.4823 - weighted_custom_f1: 0.4877 - val_loss: 1.2699 - val_custom_f1: 0.4217 - val_weighted_custom_f1: 0.4315\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0281 - custom_f1: 0.4812 - weighted_custom_f1: 0.4864 - val_loss: 1.0407 - val_custom_f1: 0.4806 - val_weighted_custom_f1: 0.4870\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9618 - custom_f1: 0.5001 - weighted_custom_f1: 0.5054 - val_loss: 0.9820 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.4911\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2637 - custom_f1: 0.2848 - weighted_custom_f1: 0.2884 - val_loss: 1.4251 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9905 - custom_f1: 0.4931 - weighted_custom_f1: 0.4983 - val_loss: 1.3414 - val_custom_f1: 0.4915 - val_weighted_custom_f1: 0.4862\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9880 - custom_f1: 0.4871 - weighted_custom_f1: 0.4914 - val_loss: 1.0341 - val_custom_f1: 0.4773 - val_weighted_custom_f1: 0.4844\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9730 - custom_f1: 0.4937 - weighted_custom_f1: 0.4988 - val_loss: 1.1008 - val_custom_f1: 0.4834 - val_weighted_custom_f1: 0.4804\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2644 - custom_f1: 0.2843 - weighted_custom_f1: 0.2891 - val_loss: 1.4222 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0032 - custom_f1: 0.4878 - weighted_custom_f1: 0.4945 - val_loss: 1.3019 - val_custom_f1: 0.4180 - val_weighted_custom_f1: 0.4285\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9882 - custom_f1: 0.4797 - weighted_custom_f1: 0.4848 - val_loss: 1.0630 - val_custom_f1: 0.4681 - val_weighted_custom_f1: 0.4788\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9544 - custom_f1: 0.4992 - weighted_custom_f1: 0.5048 - val_loss: 0.9719 - val_custom_f1: 0.5101 - val_weighted_custom_f1: 0.5081\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2637 - custom_f1: 0.2625 - weighted_custom_f1: 0.2665 - val_loss: 1.4237 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9757 - custom_f1: 0.4883 - weighted_custom_f1: 0.4924 - val_loss: 1.2576 - val_custom_f1: 0.4690 - val_weighted_custom_f1: 0.4764\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0234 - custom_f1: 0.4773 - weighted_custom_f1: 0.4804 - val_loss: 1.0835 - val_custom_f1: 0.4433 - val_weighted_custom_f1: 0.4527\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9429 - custom_f1: 0.5016 - weighted_custom_f1: 0.5075 - val_loss: 0.9914 - val_custom_f1: 0.5220 - val_weighted_custom_f1: 0.5192\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2641 - custom_f1: 0.2640 - weighted_custom_f1: 0.2661 - val_loss: 1.4286 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9749 - custom_f1: 0.4902 - weighted_custom_f1: 0.4951 - val_loss: 1.3366 - val_custom_f1: 0.4274 - val_weighted_custom_f1: 0.4367\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0029 - custom_f1: 0.4843 - weighted_custom_f1: 0.4894 - val_loss: 1.0563 - val_custom_f1: 0.4910 - val_weighted_custom_f1: 0.4966\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9564 - custom_f1: 0.5037 - weighted_custom_f1: 0.5079 - val_loss: 1.0548 - val_custom_f1: 0.4617 - val_weighted_custom_f1: 0.4636\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2683 - custom_f1: 0.2557 - weighted_custom_f1: 0.2600 - val_loss: 1.4321 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9923 - custom_f1: 0.4902 - weighted_custom_f1: 0.4935 - val_loss: 1.2963 - val_custom_f1: 0.4469 - val_weighted_custom_f1: 0.4538\n",
            " 36/105 [=========>....................] - ETA: 0s - loss: 1.2660 - custom_f1: 0.2838 - weighted_custom_f1: 0.2878Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0171 - custom_f1: 0.4850 - weighted_custom_f1: 0.4899 - val_loss: 1.0499 - val_custom_f1: 0.4791 - val_weighted_custom_f1: 0.4860\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9843 - custom_f1: 0.4854 - weighted_custom_f1: 0.4897Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2632 - custom_f1: 0.2749 - weighted_custom_f1: 0.2807 - val_loss: 1.4417 - val_custom_f1: 0.0026 - val_weighted_custom_f1: 0.0031\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9751 - custom_f1: 0.4938 - weighted_custom_f1: 0.4973 - val_loss: 1.0277 - val_custom_f1: 0.4852 - val_weighted_custom_f1: 0.4833\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9839 - custom_f1: 0.4848 - weighted_custom_f1: 0.4894 - val_loss: 1.3312 - val_custom_f1: 0.4907 - val_weighted_custom_f1: 0.4854\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2651 - custom_f1: 0.2697 - weighted_custom_f1: 0.2726 - val_loss: 1.4226 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9786 - custom_f1: 0.4833 - weighted_custom_f1: 0.4881 - val_loss: 1.0114 - val_custom_f1: 0.4743 - val_weighted_custom_f1: 0.4752\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0287 - custom_f1: 0.4718 - weighted_custom_f1: 0.4775 - val_loss: 1.0879 - val_custom_f1: 0.4578 - val_weighted_custom_f1: 0.4665\n",
            "Epoch 80/100\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9937 - custom_f1: 0.4919 - weighted_custom_f1: 0.4964 - val_loss: 1.2888 - val_custom_f1: 0.4368 - val_weighted_custom_f1: 0.4467\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2629 - custom_f1: 0.2843 - weighted_custom_f1: 0.2884 - val_loss: 1.4293 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9987 - custom_f1: 0.4846 - weighted_custom_f1: 0.4885 - val_loss: 1.0558 - val_custom_f1: 0.4945 - val_weighted_custom_f1: 0.4918\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0224 - custom_f1: 0.4740 - weighted_custom_f1: 0.4756 - val_loss: 1.0409 - val_custom_f1: 0.4830 - val_weighted_custom_f1: 0.4899\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9984 - custom_f1: 0.4839 - weighted_custom_f1: 0.4893 - val_loss: 1.2576 - val_custom_f1: 0.4845 - val_weighted_custom_f1: 0.4892\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2625 - custom_f1: 0.2595 - weighted_custom_f1: 0.2636 - val_loss: 1.4238 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9724 - custom_f1: 0.4907 - weighted_custom_f1: 0.4946 - val_loss: 1.2894 - val_custom_f1: 0.4178 - val_weighted_custom_f1: 0.4276\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9973 - custom_f1: 0.4795 - weighted_custom_f1: 0.4838 - val_loss: 1.0320 - val_custom_f1: 0.4473 - val_weighted_custom_f1: 0.4470\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9945 - custom_f1: 0.4880 - weighted_custom_f1: 0.4924 - val_loss: 1.0352 - val_custom_f1: 0.4582 - val_weighted_custom_f1: 0.4678\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.2636 - custom_f1: 0.2651 - weighted_custom_f1: 0.2689 - val_loss: 1.4303 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.9827 - custom_f1: 0.4865 - weighted_custom_f1: 0.4919 - val_loss: 1.5482 - val_custom_f1: 0.5020 - val_weighted_custom_f1: 0.4968\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.9887 - custom_f1: 0.4877 - weighted_custom_f1: 0.4914 - val_loss: 1.0399 - val_custom_f1: 0.4795 - val_weighted_custom_f1: 0.4862\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.9792 - custom_f1: 0.4837 - weighted_custom_f1: 0.4894 - val_loss: 1.2309 - val_custom_f1: 0.4206 - val_weighted_custom_f1: 0.4135\n",
            "Epoch 83/100\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9715 - custom_f1: 0.4922 - weighted_custom_f1: 0.4971 - val_loss: 1.5278 - val_custom_f1: 0.4964 - val_weighted_custom_f1: 0.5019\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2627 - custom_f1: 0.2841 - weighted_custom_f1: 0.2882 - val_loss: 1.4295 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9924 - custom_f1: 0.4869 - weighted_custom_f1: 0.4906 - val_loss: 1.0440 - val_custom_f1: 0.4756 - val_weighted_custom_f1: 0.4830\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.0007 - custom_f1: 0.4853 - weighted_custom_f1: 0.4898 - val_loss: 1.0204 - val_custom_f1: 0.4805 - val_weighted_custom_f1: 0.4772\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9858 - custom_f1: 0.4912 - weighted_custom_f1: 0.4956 - val_loss: 1.4964 - val_custom_f1: 0.4326 - val_weighted_custom_f1: 0.4427\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.2635 - custom_f1: 0.2738 - weighted_custom_f1: 0.2792 - val_loss: 1.4371 - val_custom_f1: 0.0026 - val_weighted_custom_f1: 0.0031\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.0014 - custom_f1: 0.4895 - weighted_custom_f1: 0.4949 - val_loss: 1.0828 - val_custom_f1: 0.4102 - val_weighted_custom_f1: 0.4197\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 0.9754 - custom_f1: 0.4856 - weighted_custom_f1: 0.4910 - val_loss: 1.0532 - val_custom_f1: 0.4784 - val_weighted_custom_f1: 0.4775\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9985 - custom_f1: 0.4860 - weighted_custom_f1: 0.4914 - val_loss: 1.5093 - val_custom_f1: 0.4879 - val_weighted_custom_f1: 0.4919\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2643 - custom_f1: 0.2671 - weighted_custom_f1: 0.2699 - val_loss: 1.4222 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0190 - custom_f1: 0.4814 - weighted_custom_f1: 0.4866 - val_loss: 1.1057 - val_custom_f1: 0.4870 - val_weighted_custom_f1: 0.4829\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9660 - custom_f1: 0.4847 - weighted_custom_f1: 0.4870 - val_loss: 1.0095 - val_custom_f1: 0.4608 - val_weighted_custom_f1: 0.4621\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9763 - custom_f1: 0.4938 - weighted_custom_f1: 0.4975 - val_loss: 1.5245 - val_custom_f1: 0.4823 - val_weighted_custom_f1: 0.4874\n",
            " 58/105 [===============>..............] - ETA: 0s - loss: 0.9983 - custom_f1: 0.4890 - weighted_custom_f1: 0.4935Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2647 - custom_f1: 0.2503 - weighted_custom_f1: 0.2544 - val_loss: 1.4220 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            " 57/105 [===============>..............] - ETA: 0s - loss: 0.9875 - custom_f1: 0.4830 - weighted_custom_f1: 0.4889Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0250 - custom_f1: 0.4925 - weighted_custom_f1: 0.4947 - val_loss: 1.0370 - val_custom_f1: 0.4644 - val_weighted_custom_f1: 0.4712\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0025 - custom_f1: 0.4855 - weighted_custom_f1: 0.4901 - val_loss: 1.2007 - val_custom_f1: 0.4341 - val_weighted_custom_f1: 0.4278\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9990 - custom_f1: 0.4852 - weighted_custom_f1: 0.4893 - val_loss: 1.4932 - val_custom_f1: 0.4469 - val_weighted_custom_f1: 0.4574\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2638 - custom_f1: 0.2654 - weighted_custom_f1: 0.2679 - val_loss: 1.4220 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 93/100\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0317 - custom_f1: 0.4871 - weighted_custom_f1: 0.4923 - val_loss: 1.1073 - val_custom_f1: 0.4952 - val_weighted_custom_f1: 0.4918\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0082 - custom_f1: 0.4852 - weighted_custom_f1: 0.4911 - val_loss: 1.0435 - val_custom_f1: 0.4638 - val_weighted_custom_f1: 0.4615\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0905 - custom_f1: 0.4152 - weighted_custom_f1: 0.4197 - val_loss: 1.6022 - val_custom_f1: 0.4784 - val_weighted_custom_f1: 0.4726\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2639 - custom_f1: 0.2842 - weighted_custom_f1: 0.2887 - val_loss: 1.4230 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0075 - custom_f1: 0.4794 - weighted_custom_f1: 0.4857 - val_loss: 1.2035 - val_custom_f1: 0.4360 - val_weighted_custom_f1: 0.4264\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9843 - custom_f1: 0.4860 - weighted_custom_f1: 0.4921 - val_loss: 1.0227 - val_custom_f1: 0.4870 - val_weighted_custom_f1: 0.4872\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0118 - custom_f1: 0.4842 - weighted_custom_f1: 0.4885 - val_loss: 1.4815 - val_custom_f1: 0.4503 - val_weighted_custom_f1: 0.4608\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2640 - custom_f1: 0.2499 - weighted_custom_f1: 0.2533 - val_loss: 1.4267 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0106 - custom_f1: 0.4880 - weighted_custom_f1: 0.4926 - val_loss: 1.0538 - val_custom_f1: 0.4407 - val_weighted_custom_f1: 0.4476\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9968 - custom_f1: 0.4873 - weighted_custom_f1: 0.4912 - val_loss: 1.4985 - val_custom_f1: 0.4888 - val_weighted_custom_f1: 0.4952\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9860 - custom_f1: 0.4886 - weighted_custom_f1: 0.4935 - val_loss: 1.0161 - val_custom_f1: 0.4833 - val_weighted_custom_f1: 0.4801\n",
            "Epoch 96/100\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2632 - custom_f1: 0.2842 - weighted_custom_f1: 0.2884 - val_loss: 1.4235 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0140 - custom_f1: 0.4862 - weighted_custom_f1: 0.4908 - val_loss: 1.1269 - val_custom_f1: 0.4948 - val_weighted_custom_f1: 0.4901\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9840 - custom_f1: 0.4835 - weighted_custom_f1: 0.4883 - val_loss: 1.4860 - val_custom_f1: 0.4830 - val_weighted_custom_f1: 0.4872\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9798 - custom_f1: 0.4857 - weighted_custom_f1: 0.4899 - val_loss: 1.0423 - val_custom_f1: 0.4480 - val_weighted_custom_f1: 0.4486\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2635 - custom_f1: 0.2840 - weighted_custom_f1: 0.2888 - val_loss: 1.4227 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9905 - custom_f1: 0.4897 - weighted_custom_f1: 0.4932 - val_loss: 1.5524 - val_custom_f1: 0.4899 - val_weighted_custom_f1: 0.4847\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0091 - custom_f1: 0.4901 - weighted_custom_f1: 0.4939 - val_loss: 1.0541 - val_custom_f1: 0.4809 - val_weighted_custom_f1: 0.4881\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0001 - custom_f1: 0.4831 - weighted_custom_f1: 0.4884 - val_loss: 1.0186 - val_custom_f1: 0.5024 - val_weighted_custom_f1: 0.5001\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2640 - custom_f1: 0.2806 - weighted_custom_f1: 0.2836 - val_loss: 1.4237 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9825 - custom_f1: 0.4878 - weighted_custom_f1: 0.4909 - val_loss: 1.4932 - val_custom_f1: 0.4911 - val_weighted_custom_f1: 0.4925\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0037 - custom_f1: 0.4806 - weighted_custom_f1: 0.4840 - val_loss: 1.0350 - val_custom_f1: 0.4440 - val_weighted_custom_f1: 0.4539\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0058 - custom_f1: 0.4798 - weighted_custom_f1: 0.4835 - val_loss: 1.0228 - val_custom_f1: 0.4899 - val_weighted_custom_f1: 0.4868\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.2624 - custom_f1: 0.2845 - weighted_custom_f1: 0.2884 - val_loss: 1.4225 - val_custom_f1: 0.2789 - val_weighted_custom_f1: 0.2889\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9751 - custom_f1: 0.4876 - weighted_custom_f1: 0.4918 - val_loss: 1.4995 - val_custom_f1: 0.4683 - val_weighted_custom_f1: 0.4749\n",
            "Epoch 100/100\n",
            "33/33 [==============================] - 0s 1ms/step loss: 0.9947 - custom_f1: 0.4941 - weighted_custom_f1: 0.4924\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9896 - custom_f1: 0.4924 - weighted_custom_f1: 0.4983 - val_loss: 1.0356 - val_custom_f1: 0.5010 - val_weighted_custom_f1: 0.4979\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 1.0585 - custom_f1: 0.4656 - weighted_custom_f1: 0.4689 - val_loss: 1.0711 - val_custom_f1: 0.4432 - val_weighted_custom_f1: 0.4530\n",
            "Epoch 94/100\n",
            "131/131 [==============================] - 0s 874us/steps: 0.9780 - custom_f1: 0.4905 - weighted_custom_f1: 0.4932\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9717 - custom_f1: 0.4856 - weighted_custom_f1: 0.4897 - val_loss: 1.4915 - val_custom_f1: 0.4830 - val_weighted_custom_f1: 0.4902\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9981 - custom_f1: 0.4808 - weighted_custom_f1: 0.4840 - val_loss: 1.0915 - val_custom_f1: 0.4525 - val_weighted_custom_f1: 0.4528\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0129 - custom_f1: 0.4854 - weighted_custom_f1: 0.4876 - val_loss: 1.0737 - val_custom_f1: 0.4156 - val_weighted_custom_f1: 0.4248\n",
            "Epoch 95/100\n",
            "33/33 [==============================] - 0s 897us/steposs: 1.0426 - custom_f1: 0.4714 - weighted_custom_f1: 0.4715\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9838 - custom_f1: 0.4829 - weighted_custom_f1: 0.4884 - val_loss: 1.0238 - val_custom_f1: 0.4454 - val_weighted_custom_f1: 0.4461\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0086 - custom_f1: 0.4815 - weighted_custom_f1: 0.4854 - val_loss: 1.0384 - val_custom_f1: 0.4684 - val_weighted_custom_f1: 0.4751\n",
            "Epoch 96/100\n",
            "131/131 [==============================] - 0s 842us/steps: 0.9622 - custom_f1: 0.4892 - weighted_custom_f1: 0.49\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9635 - custom_f1: 0.4895 - weighted_custom_f1: 0.4925 - val_loss: 1.0079 - val_custom_f1: 0.4741 - val_weighted_custom_f1: 0.4729\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0248 - custom_f1: 0.4820 - weighted_custom_f1: 0.4862 - val_loss: 1.0779 - val_custom_f1: 0.4151 - val_weighted_custom_f1: 0.4253\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9771 - custom_f1: 0.4861 - weighted_custom_f1: 0.4919 - val_loss: 1.1909 - val_custom_f1: 0.4463 - val_weighted_custom_f1: 0.4436\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0350 - custom_f1: 0.4741 - weighted_custom_f1: 0.4778 - val_loss: 1.1023 - val_custom_f1: 0.4899 - val_weighted_custom_f1: 0.4855\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9956 - custom_f1: 0.4903 - weighted_custom_f1: 0.4953 - val_loss: 1.0501 - val_custom_f1: 0.4343 - val_weighted_custom_f1: 0.4344\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0136 - custom_f1: 0.4841 - weighted_custom_f1: 0.4882 - val_loss: 1.0390 - val_custom_f1: 0.4857 - val_weighted_custom_f1: 0.4930\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9858 - custom_f1: 0.4855 - weighted_custom_f1: 0.4897 - val_loss: 1.0127 - val_custom_f1: 0.4678 - val_weighted_custom_f1: 0.4662\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9991 - custom_f1: 0.4880 - weighted_custom_f1: 0.4920 - val_loss: 1.0564 - val_custom_f1: 0.4766 - val_weighted_custom_f1: 0.4836\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 0.9940 - custom_f1: 0.4829 - weighted_custom_f1: 0.4861 - val_loss: 1.0281 - val_custom_f1: 0.4516 - val_weighted_custom_f1: 0.4522\n",
            "105/105 [==============================] - 0s 2ms/step - loss: 1.0058 - custom_f1: 0.4900 - weighted_custom_f1: 0.4945 - val_loss: 1.0961 - val_custom_f1: 0.4933 - val_weighted_custom_f1: 0.4891\n",
            "33/33 [==============================] - 0s 793us/step\n",
            "33/33 [==============================] - 0s 744us/step\n",
            "131/131 [==============================] - 0s 775us/step\n",
            "131/131 [==============================] - 0s 783us/step\n",
            "Epoch 1/100\n",
            "131/131 [==============================] - 1s 3ms/step - loss: 1.2186 - custom_f1: 0.4025 - weighted_custom_f1: 0.4073 - val_loss: 1.0557 - val_custom_f1: 0.4457 - val_weighted_custom_f1: 0.4482\n",
            "Epoch 2/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 1.0466 - custom_f1: 0.4405 - weighted_custom_f1: 0.4446 - val_loss: 1.0238 - val_custom_f1: 0.4330 - val_weighted_custom_f1: 0.4368\n",
            "Epoch 3/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.9965 - custom_f1: 0.4657 - weighted_custom_f1: 0.4707 - val_loss: 1.0568 - val_custom_f1: 0.4802 - val_weighted_custom_f1: 0.4842\n",
            "Epoch 4/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.9531 - custom_f1: 0.4821 - weighted_custom_f1: 0.4861 - val_loss: 0.9653 - val_custom_f1: 0.4527 - val_weighted_custom_f1: 0.4573\n",
            "Epoch 5/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.9402 - custom_f1: 0.4869 - weighted_custom_f1: 0.4910 - val_loss: 1.0760 - val_custom_f1: 0.4059 - val_weighted_custom_f1: 0.4110\n",
            "Epoch 6/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.9171 - custom_f1: 0.5001 - weighted_custom_f1: 0.5040 - val_loss: 0.9847 - val_custom_f1: 0.4625 - val_weighted_custom_f1: 0.4666\n",
            "Epoch 7/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.9173 - custom_f1: 0.4944 - weighted_custom_f1: 0.4985 - val_loss: 0.9413 - val_custom_f1: 0.4650 - val_weighted_custom_f1: 0.4699\n",
            "Epoch 8/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.8956 - custom_f1: 0.5080 - weighted_custom_f1: 0.5137 - val_loss: 0.9251 - val_custom_f1: 0.5044 - val_weighted_custom_f1: 0.5092\n",
            "Epoch 9/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.9065 - custom_f1: 0.5006 - weighted_custom_f1: 0.5056 - val_loss: 0.9534 - val_custom_f1: 0.4625 - val_weighted_custom_f1: 0.4675\n",
            "Epoch 10/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.8458 - custom_f1: 0.5279 - weighted_custom_f1: 0.5319 - val_loss: 0.9268 - val_custom_f1: 0.4846 - val_weighted_custom_f1: 0.4885\n",
            "Epoch 11/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.8658 - custom_f1: 0.5186 - weighted_custom_f1: 0.5227 - val_loss: 0.9749 - val_custom_f1: 0.5070 - val_weighted_custom_f1: 0.5113\n",
            "Epoch 12/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.8374 - custom_f1: 0.5302 - weighted_custom_f1: 0.5359 - val_loss: 0.9506 - val_custom_f1: 0.5237 - val_weighted_custom_f1: 0.5276\n",
            "Epoch 13/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.8180 - custom_f1: 0.5373 - weighted_custom_f1: 0.5418 - val_loss: 0.9220 - val_custom_f1: 0.4977 - val_weighted_custom_f1: 0.5028\n",
            "Epoch 14/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.8154 - custom_f1: 0.5356 - weighted_custom_f1: 0.5410 - val_loss: 0.9421 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5023\n",
            "Epoch 15/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.8076 - custom_f1: 0.5400 - weighted_custom_f1: 0.5451 - val_loss: 0.9186 - val_custom_f1: 0.5096 - val_weighted_custom_f1: 0.5138\n",
            "Epoch 16/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.8080 - custom_f1: 0.5409 - weighted_custom_f1: 0.5440 - val_loss: 0.9197 - val_custom_f1: 0.4931 - val_weighted_custom_f1: 0.4970\n",
            "Epoch 17/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.8065 - custom_f1: 0.5432 - weighted_custom_f1: 0.5483 - val_loss: 0.9425 - val_custom_f1: 0.4927 - val_weighted_custom_f1: 0.4957\n",
            "Epoch 18/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7850 - custom_f1: 0.5528 - weighted_custom_f1: 0.5559 - val_loss: 0.9944 - val_custom_f1: 0.5429 - val_weighted_custom_f1: 0.5465\n",
            "Epoch 19/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7859 - custom_f1: 0.5509 - weighted_custom_f1: 0.5546 - val_loss: 0.9348 - val_custom_f1: 0.5216 - val_weighted_custom_f1: 0.5252\n",
            "Epoch 20/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7923 - custom_f1: 0.5535 - weighted_custom_f1: 0.5583 - val_loss: 0.9725 - val_custom_f1: 0.5264 - val_weighted_custom_f1: 0.5297\n",
            "Epoch 21/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7690 - custom_f1: 0.5582 - weighted_custom_f1: 0.5629 - val_loss: 0.9197 - val_custom_f1: 0.5148 - val_weighted_custom_f1: 0.5184\n",
            "Epoch 22/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7634 - custom_f1: 0.5590 - weighted_custom_f1: 0.5623 - val_loss: 0.9995 - val_custom_f1: 0.5347 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 23/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.7621 - custom_f1: 0.5640 - weighted_custom_f1: 0.5686 - val_loss: 0.9678 - val_custom_f1: 0.4604 - val_weighted_custom_f1: 0.4650\n",
            "Epoch 24/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.7512 - custom_f1: 0.5652 - weighted_custom_f1: 0.5697 - val_loss: 0.9481 - val_custom_f1: 0.5292 - val_weighted_custom_f1: 0.5315\n",
            "Epoch 25/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.7320 - custom_f1: 0.5731 - weighted_custom_f1: 0.5774 - val_loss: 0.9322 - val_custom_f1: 0.5143 - val_weighted_custom_f1: 0.5187\n",
            "Epoch 26/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.7406 - custom_f1: 0.5753 - weighted_custom_f1: 0.5806 - val_loss: 0.9231 - val_custom_f1: 0.5075 - val_weighted_custom_f1: 0.5114\n",
            "Epoch 27/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.7261 - custom_f1: 0.5752 - weighted_custom_f1: 0.5787 - val_loss: 0.9490 - val_custom_f1: 0.5088 - val_weighted_custom_f1: 0.5119\n",
            "Epoch 28/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.7473 - custom_f1: 0.5733 - weighted_custom_f1: 0.5770 - val_loss: 1.0137 - val_custom_f1: 0.5379 - val_weighted_custom_f1: 0.5410\n",
            "Epoch 29/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7124 - custom_f1: 0.5795 - weighted_custom_f1: 0.5838 - val_loss: 0.9915 - val_custom_f1: 0.5130 - val_weighted_custom_f1: 0.5165\n",
            "Epoch 30/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7036 - custom_f1: 0.5861 - weighted_custom_f1: 0.5905 - val_loss: 0.9598 - val_custom_f1: 0.4637 - val_weighted_custom_f1: 0.4685\n",
            "Epoch 31/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6967 - custom_f1: 0.5943 - weighted_custom_f1: 0.6001 - val_loss: 1.0025 - val_custom_f1: 0.4914 - val_weighted_custom_f1: 0.4956\n",
            "Epoch 32/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6946 - custom_f1: 0.5934 - weighted_custom_f1: 0.5983 - val_loss: 1.0404 - val_custom_f1: 0.5323 - val_weighted_custom_f1: 0.5363\n",
            "Epoch 33/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6859 - custom_f1: 0.5981 - weighted_custom_f1: 0.6020 - val_loss: 0.9944 - val_custom_f1: 0.5043 - val_weighted_custom_f1: 0.5088\n",
            "Epoch 34/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.7048 - custom_f1: 0.5860 - weighted_custom_f1: 0.5906 - val_loss: 1.0009 - val_custom_f1: 0.4716 - val_weighted_custom_f1: 0.4757\n",
            "Epoch 35/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6849 - custom_f1: 0.6005 - weighted_custom_f1: 0.6040 - val_loss: 0.9777 - val_custom_f1: 0.5151 - val_weighted_custom_f1: 0.5181\n",
            "Epoch 36/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6705 - custom_f1: 0.6018 - weighted_custom_f1: 0.6051 - val_loss: 0.9804 - val_custom_f1: 0.5122 - val_weighted_custom_f1: 0.5160\n",
            "Epoch 37/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.6779 - custom_f1: 0.6034 - weighted_custom_f1: 0.6075 - val_loss: 1.0631 - val_custom_f1: 0.5324 - val_weighted_custom_f1: 0.5360\n",
            "Epoch 38/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6796 - custom_f1: 0.5970 - weighted_custom_f1: 0.6016 - val_loss: 0.9973 - val_custom_f1: 0.4981 - val_weighted_custom_f1: 0.5021\n",
            "Epoch 39/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6678 - custom_f1: 0.6120 - weighted_custom_f1: 0.6157 - val_loss: 1.0570 - val_custom_f1: 0.5186 - val_weighted_custom_f1: 0.5221\n",
            "Epoch 40/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6617 - custom_f1: 0.6045 - weighted_custom_f1: 0.6091 - val_loss: 1.0690 - val_custom_f1: 0.5211 - val_weighted_custom_f1: 0.5248\n",
            "Epoch 41/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.6602 - custom_f1: 0.6125 - weighted_custom_f1: 0.6162 - val_loss: 1.0509 - val_custom_f1: 0.5289 - val_weighted_custom_f1: 0.5331\n",
            "Epoch 42/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.6514 - custom_f1: 0.6109 - weighted_custom_f1: 0.6156 - val_loss: 1.0403 - val_custom_f1: 0.4995 - val_weighted_custom_f1: 0.5036\n",
            "Epoch 43/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6328 - custom_f1: 0.6167 - weighted_custom_f1: 0.6226 - val_loss: 1.0530 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5048\n",
            "Epoch 44/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6336 - custom_f1: 0.6205 - weighted_custom_f1: 0.6237 - val_loss: 1.0907 - val_custom_f1: 0.5271 - val_weighted_custom_f1: 0.5297\n",
            "Epoch 45/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6270 - custom_f1: 0.6251 - weighted_custom_f1: 0.6293 - val_loss: 1.0575 - val_custom_f1: 0.5296 - val_weighted_custom_f1: 0.5337\n",
            "Epoch 46/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6416 - custom_f1: 0.6215 - weighted_custom_f1: 0.6248 - val_loss: 1.1134 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5270\n",
            "Epoch 47/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6126 - custom_f1: 0.6260 - weighted_custom_f1: 0.6303 - val_loss: 1.0687 - val_custom_f1: 0.5241 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 48/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6295 - custom_f1: 0.6249 - weighted_custom_f1: 0.6283 - val_loss: 1.1061 - val_custom_f1: 0.5175 - val_weighted_custom_f1: 0.5205\n",
            "Epoch 49/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6091 - custom_f1: 0.6318 - weighted_custom_f1: 0.6364 - val_loss: 1.1296 - val_custom_f1: 0.5284 - val_weighted_custom_f1: 0.5322\n",
            "Epoch 50/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.6160 - custom_f1: 0.6259 - weighted_custom_f1: 0.6294 - val_loss: 1.2333 - val_custom_f1: 0.5333 - val_weighted_custom_f1: 0.5358\n",
            "Epoch 51/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6171 - custom_f1: 0.6296 - weighted_custom_f1: 0.6337 - val_loss: 1.2016 - val_custom_f1: 0.5136 - val_weighted_custom_f1: 0.5170\n",
            "Epoch 52/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.6039 - custom_f1: 0.6332 - weighted_custom_f1: 0.6378 - val_loss: 1.1445 - val_custom_f1: 0.4897 - val_weighted_custom_f1: 0.4944\n",
            "Epoch 53/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.6041 - custom_f1: 0.6362 - weighted_custom_f1: 0.6411 - val_loss: 1.1488 - val_custom_f1: 0.4907 - val_weighted_custom_f1: 0.4943\n",
            "Epoch 54/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.6102 - custom_f1: 0.6339 - weighted_custom_f1: 0.6379 - val_loss: 1.1779 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5004\n",
            "Epoch 55/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5985 - custom_f1: 0.6360 - weighted_custom_f1: 0.6408 - val_loss: 1.2522 - val_custom_f1: 0.5390 - val_weighted_custom_f1: 0.5423\n",
            "Epoch 56/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5864 - custom_f1: 0.6404 - weighted_custom_f1: 0.6452 - val_loss: 1.1910 - val_custom_f1: 0.5103 - val_weighted_custom_f1: 0.5143\n",
            "Epoch 57/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5820 - custom_f1: 0.6446 - weighted_custom_f1: 0.6497 - val_loss: 1.3542 - val_custom_f1: 0.5305 - val_weighted_custom_f1: 0.5345\n",
            "Epoch 58/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5871 - custom_f1: 0.6371 - weighted_custom_f1: 0.6416 - val_loss: 1.2625 - val_custom_f1: 0.5234 - val_weighted_custom_f1: 0.5268\n",
            "Epoch 59/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5633 - custom_f1: 0.6518 - weighted_custom_f1: 0.6554 - val_loss: 1.2777 - val_custom_f1: 0.5396 - val_weighted_custom_f1: 0.5423\n",
            "Epoch 60/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5673 - custom_f1: 0.6486 - weighted_custom_f1: 0.6539 - val_loss: 1.2545 - val_custom_f1: 0.4961 - val_weighted_custom_f1: 0.4987\n",
            "Epoch 61/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5827 - custom_f1: 0.6403 - weighted_custom_f1: 0.6461 - val_loss: 1.3829 - val_custom_f1: 0.5324 - val_weighted_custom_f1: 0.5348\n",
            "Epoch 62/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5679 - custom_f1: 0.6550 - weighted_custom_f1: 0.6584 - val_loss: 1.2097 - val_custom_f1: 0.5208 - val_weighted_custom_f1: 0.5240\n",
            "Epoch 63/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5642 - custom_f1: 0.6537 - weighted_custom_f1: 0.6561 - val_loss: 1.2973 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5202\n",
            "Epoch 64/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5530 - custom_f1: 0.6576 - weighted_custom_f1: 0.6623 - val_loss: 1.3160 - val_custom_f1: 0.5305 - val_weighted_custom_f1: 0.5328\n",
            "Epoch 65/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5461 - custom_f1: 0.6576 - weighted_custom_f1: 0.6612 - val_loss: 1.2456 - val_custom_f1: 0.5347 - val_weighted_custom_f1: 0.5379\n",
            "Epoch 66/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5513 - custom_f1: 0.6606 - weighted_custom_f1: 0.6640 - val_loss: 1.2765 - val_custom_f1: 0.5422 - val_weighted_custom_f1: 0.5463\n",
            "Epoch 67/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5551 - custom_f1: 0.6613 - weighted_custom_f1: 0.6652 - val_loss: 1.2972 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5209\n",
            "Epoch 68/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5644 - custom_f1: 0.6524 - weighted_custom_f1: 0.6569 - val_loss: 1.2618 - val_custom_f1: 0.5266 - val_weighted_custom_f1: 0.5300\n",
            "Epoch 69/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5366 - custom_f1: 0.6689 - weighted_custom_f1: 0.6729 - val_loss: 1.3390 - val_custom_f1: 0.5365 - val_weighted_custom_f1: 0.5400\n",
            "Epoch 70/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5464 - custom_f1: 0.6597 - weighted_custom_f1: 0.6644 - val_loss: 1.2993 - val_custom_f1: 0.5218 - val_weighted_custom_f1: 0.5252\n",
            "Epoch 71/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5544 - custom_f1: 0.6501 - weighted_custom_f1: 0.6553 - val_loss: 1.2876 - val_custom_f1: 0.5317 - val_weighted_custom_f1: 0.5357\n",
            "Epoch 72/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5454 - custom_f1: 0.6638 - weighted_custom_f1: 0.6689 - val_loss: 1.3711 - val_custom_f1: 0.5328 - val_weighted_custom_f1: 0.5356\n",
            "Epoch 73/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5231 - custom_f1: 0.6752 - weighted_custom_f1: 0.6801 - val_loss: 1.3874 - val_custom_f1: 0.5332 - val_weighted_custom_f1: 0.5366\n",
            "Epoch 74/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5343 - custom_f1: 0.6674 - weighted_custom_f1: 0.6709 - val_loss: 1.3644 - val_custom_f1: 0.5241 - val_weighted_custom_f1: 0.5289\n",
            "Epoch 75/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5263 - custom_f1: 0.6689 - weighted_custom_f1: 0.6729 - val_loss: 1.3030 - val_custom_f1: 0.5012 - val_weighted_custom_f1: 0.5053\n",
            "Epoch 76/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5168 - custom_f1: 0.6755 - weighted_custom_f1: 0.6791 - val_loss: 1.4386 - val_custom_f1: 0.5513 - val_weighted_custom_f1: 0.5540\n",
            "Epoch 77/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5179 - custom_f1: 0.6809 - weighted_custom_f1: 0.6845 - val_loss: 1.4573 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5197\n",
            "Epoch 78/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5292 - custom_f1: 0.6712 - weighted_custom_f1: 0.6755 - val_loss: 1.4859 - val_custom_f1: 0.5407 - val_weighted_custom_f1: 0.5439\n",
            "Epoch 79/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.6195 - custom_f1: 0.6503 - weighted_custom_f1: 0.6560 - val_loss: 1.3355 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5281\n",
            "Epoch 80/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.5318 - custom_f1: 0.6741 - weighted_custom_f1: 0.6787 - val_loss: 1.2920 - val_custom_f1: 0.5062 - val_weighted_custom_f1: 0.5098\n",
            "Epoch 81/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5184 - custom_f1: 0.6753 - weighted_custom_f1: 0.6788 - val_loss: 1.4575 - val_custom_f1: 0.5345 - val_weighted_custom_f1: 0.5379\n",
            "Epoch 82/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5131 - custom_f1: 0.6774 - weighted_custom_f1: 0.6811 - val_loss: 1.2826 - val_custom_f1: 0.5151 - val_weighted_custom_f1: 0.5187\n",
            "Epoch 83/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5246 - custom_f1: 0.6778 - weighted_custom_f1: 0.6818 - val_loss: 1.5417 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5499\n",
            "Epoch 84/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5009 - custom_f1: 0.6859 - weighted_custom_f1: 0.6900 - val_loss: 1.2986 - val_custom_f1: 0.5181 - val_weighted_custom_f1: 0.5218\n",
            "Epoch 85/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4961 - custom_f1: 0.6918 - weighted_custom_f1: 0.6960 - val_loss: 1.4775 - val_custom_f1: 0.4969 - val_weighted_custom_f1: 0.5008\n",
            "Epoch 86/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5112 - custom_f1: 0.6828 - weighted_custom_f1: 0.6865 - val_loss: 1.4764 - val_custom_f1: 0.5324 - val_weighted_custom_f1: 0.5353\n",
            "Epoch 87/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4992 - custom_f1: 0.6879 - weighted_custom_f1: 0.6911 - val_loss: 1.4034 - val_custom_f1: 0.5206 - val_weighted_custom_f1: 0.5249\n",
            "Epoch 88/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.4839 - custom_f1: 0.6950 - weighted_custom_f1: 0.6984 - val_loss: 1.4762 - val_custom_f1: 0.5465 - val_weighted_custom_f1: 0.5506\n",
            "Epoch 89/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4742 - custom_f1: 0.6988 - weighted_custom_f1: 0.7032 - val_loss: 1.4758 - val_custom_f1: 0.5202 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 90/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.5088 - custom_f1: 0.6873 - weighted_custom_f1: 0.6919 - val_loss: 1.6538 - val_custom_f1: 0.5378 - val_weighted_custom_f1: 0.5411\n",
            "Epoch 91/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4793 - custom_f1: 0.6972 - weighted_custom_f1: 0.7019 - val_loss: 1.4824 - val_custom_f1: 0.5443 - val_weighted_custom_f1: 0.5472\n",
            "Epoch 92/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.4749 - custom_f1: 0.6991 - weighted_custom_f1: 0.7029 - val_loss: 1.4813 - val_custom_f1: 0.5377 - val_weighted_custom_f1: 0.5417\n",
            "Epoch 93/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.4826 - custom_f1: 0.6964 - weighted_custom_f1: 0.7001 - val_loss: 1.8046 - val_custom_f1: 0.5331 - val_weighted_custom_f1: 0.5367\n",
            "Epoch 94/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4912 - custom_f1: 0.6888 - weighted_custom_f1: 0.6929 - val_loss: 1.4718 - val_custom_f1: 0.5173 - val_weighted_custom_f1: 0.5208\n",
            "Epoch 95/100\n",
            "131/131 [==============================] - 0s 2ms/step - loss: 0.4698 - custom_f1: 0.6971 - weighted_custom_f1: 0.7020 - val_loss: 1.5297 - val_custom_f1: 0.5385 - val_weighted_custom_f1: 0.5410\n",
            "Epoch 96/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4847 - custom_f1: 0.6952 - weighted_custom_f1: 0.6991 - val_loss: 1.5068 - val_custom_f1: 0.5106 - val_weighted_custom_f1: 0.5142\n",
            "Epoch 97/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4697 - custom_f1: 0.7043 - weighted_custom_f1: 0.7078 - val_loss: 1.6051 - val_custom_f1: 0.5327 - val_weighted_custom_f1: 0.5358\n",
            "Epoch 98/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4687 - custom_f1: 0.6993 - weighted_custom_f1: 0.7032 - val_loss: 1.7739 - val_custom_f1: 0.5394 - val_weighted_custom_f1: 0.5426\n",
            "Epoch 99/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4756 - custom_f1: 0.7050 - weighted_custom_f1: 0.7092 - val_loss: 1.5736 - val_custom_f1: 0.5170 - val_weighted_custom_f1: 0.5209\n",
            "Epoch 100/100\n",
            "131/131 [==============================] - 0s 1ms/step - loss: 0.4725 - custom_f1: 0.7028 - weighted_custom_f1: 0.7077 - val_loss: 1.7328 - val_custom_f1: 0.5357 - val_weighted_custom_f1: 0.5381\n"
          ]
        }
      ],
      "source": [
        "# Run gridsearch on above parameter dictionary\n",
        "\n",
        "grid = GridSearchCV(pipe,params,\n",
        "                    cv=5,\n",
        "                    n_jobs=-1,\n",
        "                    scoring= scoring,\n",
        "                    return_train_score=True,\n",
        "                    refit='f1',\n",
        "                    verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "results = grid.fit(X_train,\n",
        "                   y_train,\n",
        "                   # model__batch_size=2048,\n",
        "                   model__sample_weight=weights\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE7MCI-7itYs"
      },
      "source": [
        "## Model Performance Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86mJdaMYitYs"
      },
      "source": [
        "Optimize for F1 but looked at several metrics in tandem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zQGhIsXitYs",
        "outputId": "a0b06b7d-8f5e-4cc4-b5f2-00c5425d66db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>6</th>\n",
              "      <th>11</th>\n",
              "      <th>16</th>\n",
              "      <th>2</th>\n",
              "      <th>17</th>\n",
              "      <th>7</th>\n",
              "      <th>12</th>\n",
              "      <th>0</th>\n",
              "      <th>5</th>\n",
              "      <th>10</th>\n",
              "      <th>15</th>\n",
              "      <th>3</th>\n",
              "      <th>8</th>\n",
              "      <th>18</th>\n",
              "      <th>13</th>\n",
              "      <th>9</th>\n",
              "      <th>4</th>\n",
              "      <th>14</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean_test_accuracy</th>\n",
              "      <td>0.807076</td>\n",
              "      <td>0.807076</td>\n",
              "      <td>0.807076</td>\n",
              "      <td>0.807076</td>\n",
              "      <td>0.802241</td>\n",
              "      <td>0.802241</td>\n",
              "      <td>0.802241</td>\n",
              "      <td>0.802241</td>\n",
              "      <td>0.798411</td>\n",
              "      <td>0.798411</td>\n",
              "      <td>0.798411</td>\n",
              "      <td>0.798411</td>\n",
              "      <td>0.745415</td>\n",
              "      <td>0.745415</td>\n",
              "      <td>0.745415</td>\n",
              "      <td>0.745415</td>\n",
              "      <td>0.6176</td>\n",
              "      <td>0.6176</td>\n",
              "      <td>0.6176</td>\n",
              "      <td>0.6176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_precision</th>\n",
              "      <td>0.683131</td>\n",
              "      <td>0.683131</td>\n",
              "      <td>0.683131</td>\n",
              "      <td>0.683131</td>\n",
              "      <td>0.680732</td>\n",
              "      <td>0.680732</td>\n",
              "      <td>0.680732</td>\n",
              "      <td>0.680732</td>\n",
              "      <td>0.679088</td>\n",
              "      <td>0.679088</td>\n",
              "      <td>0.679088</td>\n",
              "      <td>0.679088</td>\n",
              "      <td>0.663951</td>\n",
              "      <td>0.663951</td>\n",
              "      <td>0.663951</td>\n",
              "      <td>0.663951</td>\n",
              "      <td>0.636317</td>\n",
              "      <td>0.636317</td>\n",
              "      <td>0.636317</td>\n",
              "      <td>0.636317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_recall</th>\n",
              "      <td>0.737216</td>\n",
              "      <td>0.737216</td>\n",
              "      <td>0.737216</td>\n",
              "      <td>0.737216</td>\n",
              "      <td>0.740519</td>\n",
              "      <td>0.740519</td>\n",
              "      <td>0.740519</td>\n",
              "      <td>0.740519</td>\n",
              "      <td>0.740066</td>\n",
              "      <td>0.740066</td>\n",
              "      <td>0.740066</td>\n",
              "      <td>0.740066</td>\n",
              "      <td>0.75765</td>\n",
              "      <td>0.75765</td>\n",
              "      <td>0.75765</td>\n",
              "      <td>0.75765</td>\n",
              "      <td>0.682731</td>\n",
              "      <td>0.682731</td>\n",
              "      <td>0.682731</td>\n",
              "      <td>0.682731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_f1</th>\n",
              "      <td>0.81954</td>\n",
              "      <td>0.81954</td>\n",
              "      <td>0.81954</td>\n",
              "      <td>0.81954</td>\n",
              "      <td>0.816267</td>\n",
              "      <td>0.816267</td>\n",
              "      <td>0.816267</td>\n",
              "      <td>0.816267</td>\n",
              "      <td>0.813328</td>\n",
              "      <td>0.813328</td>\n",
              "      <td>0.813328</td>\n",
              "      <td>0.813328</td>\n",
              "      <td>0.773651</td>\n",
              "      <td>0.773651</td>\n",
              "      <td>0.773651</td>\n",
              "      <td>0.773651</td>\n",
              "      <td>0.616964</td>\n",
              "      <td>0.616964</td>\n",
              "      <td>0.616964</td>\n",
              "      <td>0.616964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank_test_f1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_model__batch_size</th>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_model__dropout_rate</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_model__learning_rate</th>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  1         6         11        16        2   \\\n",
              "mean_test_accuracy          0.807076  0.807076  0.807076  0.807076  0.802241   \n",
              "mean_test_precision         0.683131  0.683131  0.683131  0.683131  0.680732   \n",
              "mean_test_recall            0.737216  0.737216  0.737216  0.737216  0.740519   \n",
              "mean_test_f1                 0.81954   0.81954   0.81954   0.81954  0.816267   \n",
              "rank_test_f1                       1         1         1         1         5   \n",
              "param_model__batch_size          128       128       128       128       128   \n",
              "param_model__dropout_rate      0.001      0.01      0.05       0.1     0.001   \n",
              "param_model__learning_rate     0.005     0.005     0.005     0.005      0.01   \n",
              "\n",
              "                                  17        7         12        0         5   \\\n",
              "mean_test_accuracy          0.802241  0.802241  0.802241  0.798411  0.798411   \n",
              "mean_test_precision         0.680732  0.680732  0.680732  0.679088  0.679088   \n",
              "mean_test_recall            0.740519  0.740519  0.740519  0.740066  0.740066   \n",
              "mean_test_f1                0.816267  0.816267  0.816267  0.813328  0.813328   \n",
              "rank_test_f1                       5         5         5         9         9   \n",
              "param_model__batch_size          128       128       128       128       128   \n",
              "param_model__dropout_rate        0.1      0.01      0.05     0.001      0.01   \n",
              "param_model__learning_rate      0.01      0.01      0.01     0.001     0.001   \n",
              "\n",
              "                                  10        15        3         8         18  \\\n",
              "mean_test_accuracy          0.798411  0.798411  0.745415  0.745415  0.745415   \n",
              "mean_test_precision         0.679088  0.679088  0.663951  0.663951  0.663951   \n",
              "mean_test_recall            0.740066  0.740066   0.75765   0.75765   0.75765   \n",
              "mean_test_f1                0.813328  0.813328  0.773651  0.773651  0.773651   \n",
              "rank_test_f1                       9         9        13        13        13   \n",
              "param_model__batch_size          128       128       128       128       128   \n",
              "param_model__dropout_rate       0.05       0.1     0.001      0.01       0.1   \n",
              "param_model__learning_rate     0.001     0.001      0.05      0.05      0.05   \n",
              "\n",
              "                                  13        9         4         14        19  \n",
              "mean_test_accuracy          0.745415    0.6176    0.6176    0.6176    0.6176  \n",
              "mean_test_precision         0.663951  0.636317  0.636317  0.636317  0.636317  \n",
              "mean_test_recall             0.75765  0.682731  0.682731  0.682731  0.682731  \n",
              "mean_test_f1                0.773651  0.616964  0.616964  0.616964  0.616964  \n",
              "rank_test_f1                      13        17        17        17        17  \n",
              "param_model__batch_size          128       128       128       128       128  \n",
              "param_model__dropout_rate       0.05      0.01     0.001      0.05       0.1  \n",
              "param_model__learning_rate      0.05       0.1       0.1       0.1       0.1  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtain metrics from each model run\n",
        "metrics = pd.DataFrame(results.cv_results_)\n",
        "param_cols = [x for x in metrics.columns if 'param_model' in x]\n",
        "metric_cols = [x for x in metrics.columns if 'mean_test' in x] + ['rank_test_f1', ] + param_cols\n",
        "metrics[metric_cols].sort_values('rank_test_f1').T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ZBlDwRnDitYs",
        "outputId": "46213743-287c-421f-9d78-aba3a297dec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 0s 686us/step\n",
            "164/164 [==============================] - 0s 679us/step\n",
            "Accuracy: 0.8805112738762028\n",
            "Precision: 0.9087748692102907\n",
            "Recall: 0.8805112738762028\n",
            "F1 Score: 0.8887191587661427\n",
            "AUC Score: 0.9389910348873957\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_preds = results.predict(X_train)\n",
        "y_preds_proba = results.predict_proba(X_train)[:,1]\n",
        "generate_matrix(y_train, y_preds, y_preds_proba,_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "LLn-LDvIitYt",
        "outputId": "1a186846-93cf-43bc-d7ee-624d7fbeb227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 821us/step\n",
            "41/41 [==============================] - 0s 757us/step\n",
            "Accuracy: 0.8238560214436148\n",
            "Precision: 0.8528618417077554\n",
            "Recall: 0.8238560214436148\n",
            "F1 Score: 0.8346240930977888\n",
            "AUC Score: 0.830093791835991\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_preds = results.predict(X_val)\n",
        "y_preds_proba = results.predict_proba(X_val)[:,1]\n",
        "generate_matrix(y_val, y_preds, y_preds_proba,_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOMv80xritYt"
      },
      "source": [
        "## Statistical Test to Determine Representativness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnkqeAweitYt",
        "outputId": "9ed5a328-c61c-4f95-bbb2-372ec1c23176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21760 4352\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Set</th>\n",
              "      <th>Counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Neg</td>\n",
              "      <td>Downsample</td>\n",
              "      <td>21760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pos</td>\n",
              "      <td>Downsample</td>\n",
              "      <td>4352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Neg</td>\n",
              "      <td>Full</td>\n",
              "      <td>288826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pos</td>\n",
              "      <td>Full</td>\n",
              "      <td>4346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Class         Set  Counts\n",
              "0   Neg  Downsample   21760\n",
              "1   Pos  Downsample    4352\n",
              "2   Neg        Full  288826\n",
              "3   Pos        Full    4346"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.concatenate((y_train,y_val))\n",
        "y_neg, y_pos = np.bincount(y)\n",
        "print(y_neg, y_pos)\n",
        "y_all = df_all['Weather_Label']\n",
        "y_neg_all, y_pos_all = np.bincount(y_all)\n",
        "\n",
        "df = pd.DataFrame({'Class': ['Neg','Pos','Neg','Pos'],\n",
        "             'Set': ['Downsample','Downsample','Full','Full'],\n",
        "              'Counts': [y_neg, y_pos, y_neg_all, y_pos_all] }\n",
        "\n",
        "                 )\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_hRDr2SitYt",
        "outputId": "53215a26-0bcc-44aa-bc31-13a3f6a9d610"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Set</th>\n",
              "      <th>Downsample</th>\n",
              "      <th>Full</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Neg</th>\n",
              "      <td>21760</td>\n",
              "      <td>288826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pos</th>\n",
              "      <td>4352</td>\n",
              "      <td>4346</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Set    Downsample    Full\n",
              "Class                    \n",
              "Neg         21760  288826\n",
              "Pos          4352    4346"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c_table = pd.crosstab(df['Class'], df['Set'], values=df['Counts'], aggfunc='first')\n",
        "c_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaZF3r0RitYt",
        "outputId": "a8127adb-b481-4e5d-a6cf-6c64616775dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import scipy.stats as stats\n",
        "res = stats.chi2_contingency(c_table)\n",
        "res.pvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Nbvgx1U_itYt"
      },
      "source": [
        "## Fit New (Final) Model with Combined Train + Val Data\n",
        "Once best parameters are obtained, re-run over the combined train + val dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-9OBVgVitYt"
      },
      "outputs": [],
      "source": [
        "y=X['Weather_Label']\n",
        "weights = X['weights']\n",
        "X.drop(['Weather_Label','weights'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvtLJLnUitYu"
      },
      "outputs": [],
      "source": [
        "new_estimator = KerasClassifier(model=create_model,\n",
        "                            epochs=100,\n",
        "                            verbose=1,\n",
        "                            dropout_rate=0.001,\n",
        "                            learning_rate=0.005,\n",
        "                            batch_size=128,\n",
        "                            validation_split=.2,\n",
        "                            shuffle=True,\n",
        "                            random_state=42,\n",
        "                            class_weight=None,\n",
        "                            output_bias=-4.19656855)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "7wZEEwIVitYx",
        "outputId": "7ec3be84-dd3d-437b-e430-89f48e8c4d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-04 17:27:16.314693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-04 17:27:16.314864: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "82/82 [==============================] - 1s 4ms/step - loss: 1.2709 - custom_f1: 0.3927 - weighted_custom_f1: 0.3977 - val_loss: 1.1195 - val_custom_f1: 0.4672 - val_weighted_custom_f1: 0.4766\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 1s 4ms/step - loss: 1.3069 - custom_f1: 0.3742 - weighted_custom_f1: 0.3776 - val_loss: 1.0918 - val_custom_f1: 0.3566 - val_weighted_custom_f1: 0.3889\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.0416 - custom_f1: 0.4395 - weighted_custom_f1: 0.4439 - val_loss: 1.1120 - val_custom_f1: 0.4669 - val_weighted_custom_f1: 0.4737\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.1472 - custom_f1: 0.4240 - weighted_custom_f1: 0.4287 - val_loss: 1.0953 - val_custom_f1: 0.4164 - val_weighted_custom_f1: 0.4512\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.0118 - custom_f1: 0.4578 - weighted_custom_f1: 0.4614 - val_loss: 1.1515 - val_custom_f1: 0.4708 - val_weighted_custom_f1: 0.4851\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 1.0103 - custom_f1: 0.4529 - weighted_custom_f1: 0.4552 - val_loss: 0.9829 - val_custom_f1: 0.4283 - val_weighted_custom_f1: 0.4671\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9603 - custom_f1: 0.4712 - weighted_custom_f1: 0.4745 - val_loss: 1.0665 - val_custom_f1: 0.4657 - val_weighted_custom_f1: 0.4737\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9971 - custom_f1: 0.4627 - weighted_custom_f1: 0.4665 - val_loss: 1.0073 - val_custom_f1: 0.4275 - val_weighted_custom_f1: 0.4652\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9488 - custom_f1: 0.4767 - weighted_custom_f1: 0.4794 - val_loss: 0.9443 - val_custom_f1: 0.4525 - val_weighted_custom_f1: 0.4913\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9765 - custom_f1: 0.4797 - weighted_custom_f1: 0.4837 - val_loss: 1.1417 - val_custom_f1: 0.3980 - val_weighted_custom_f1: 0.4023\n",
            "Epoch 6/100\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9345 - custom_f1: 0.4839 - weighted_custom_f1: 0.4889 - val_loss: 0.9545 - val_custom_f1: 0.4542 - val_weighted_custom_f1: 0.4926\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9227 - custom_f1: 0.4901 - weighted_custom_f1: 0.4962 - val_loss: 1.2222 - val_custom_f1: 0.3863 - val_weighted_custom_f1: 0.3922\n",
            "Epoch 7/100\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9554 - custom_f1: 0.4847 - weighted_custom_f1: 0.4891 - val_loss: 0.9807 - val_custom_f1: 0.4523 - val_weighted_custom_f1: 0.4920\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9187 - custom_f1: 0.4914 - weighted_custom_f1: 0.4944 - val_loss: 1.1490 - val_custom_f1: 0.4976 - val_weighted_custom_f1: 0.5054\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9397 - custom_f1: 0.4816 - weighted_custom_f1: 0.4875 - val_loss: 0.9967 - val_custom_f1: 0.3960 - val_weighted_custom_f1: 0.4306\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.9290 - custom_f1: 0.5015 - weighted_custom_f1: 0.5056 - val_loss: 1.0257 - val_custom_f1: 0.4707 - val_weighted_custom_f1: 0.4809\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8857 - custom_f1: 0.5143 - weighted_custom_f1: 0.5187 - val_loss: 0.9859 - val_custom_f1: 0.4161 - val_weighted_custom_f1: 0.4521\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8911 - custom_f1: 0.5132 - weighted_custom_f1: 0.5190 - val_loss: 1.0690 - val_custom_f1: 0.4440 - val_weighted_custom_f1: 0.4486\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8810 - custom_f1: 0.4997 - weighted_custom_f1: 0.5052 - val_loss: 1.0002 - val_custom_f1: 0.4143 - val_weighted_custom_f1: 0.4498\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8772 - custom_f1: 0.5143 - weighted_custom_f1: 0.5185 - val_loss: 1.0826 - val_custom_f1: 0.4834 - val_weighted_custom_f1: 0.4905\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8659 - custom_f1: 0.5118 - weighted_custom_f1: 0.5178 - val_loss: 0.9132 - val_custom_f1: 0.4510 - val_weighted_custom_f1: 0.4882\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8638 - custom_f1: 0.5152 - weighted_custom_f1: 0.5213 - val_loss: 1.0846 - val_custom_f1: 0.4517 - val_weighted_custom_f1: 0.4572\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8389 - custom_f1: 0.5278 - weighted_custom_f1: 0.5337 - val_loss: 0.9259 - val_custom_f1: 0.4513 - val_weighted_custom_f1: 0.4884\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8269 - custom_f1: 0.5346 - weighted_custom_f1: 0.5404 - val_loss: 1.1314 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5207\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8293 - custom_f1: 0.5275 - weighted_custom_f1: 0.5328 - val_loss: 0.9581 - val_custom_f1: 0.4692 - val_weighted_custom_f1: 0.5058\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8122 - custom_f1: 0.5354 - weighted_custom_f1: 0.5409 - val_loss: 1.0630 - val_custom_f1: 0.4785 - val_weighted_custom_f1: 0.4855\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8409 - custom_f1: 0.5276 - weighted_custom_f1: 0.5317 - val_loss: 1.0451 - val_custom_f1: 0.3971 - val_weighted_custom_f1: 0.4322\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8163 - custom_f1: 0.5441 - weighted_custom_f1: 0.5478 - val_loss: 1.0541 - val_custom_f1: 0.4529 - val_weighted_custom_f1: 0.4605\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8236 - custom_f1: 0.5400 - weighted_custom_f1: 0.5441 - val_loss: 1.0360 - val_custom_f1: 0.4888 - val_weighted_custom_f1: 0.5276\n",
            "Epoch 16/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.8116 - custom_f1: 0.5377 - weighted_custom_f1: 0.5429 - val_loss: 1.0691 - val_custom_f1: 0.4620 - val_weighted_custom_f1: 0.4676\n",
            "Epoch 16/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7930 - custom_f1: 0.5461 - weighted_custom_f1: 0.5495 - val_loss: 0.9756 - val_custom_f1: 0.4289 - val_weighted_custom_f1: 0.4652\n",
            "Epoch 17/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7834 - custom_f1: 0.5512 - weighted_custom_f1: 0.5548 - val_loss: 1.0658 - val_custom_f1: 0.4865 - val_weighted_custom_f1: 0.4946\n",
            "Epoch 17/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7906 - custom_f1: 0.5428 - weighted_custom_f1: 0.5472 - val_loss: 1.0680 - val_custom_f1: 0.4782 - val_weighted_custom_f1: 0.5132\n",
            "Epoch 18/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7841 - custom_f1: 0.5605 - weighted_custom_f1: 0.5662 - val_loss: 1.0827 - val_custom_f1: 0.4890 - val_weighted_custom_f1: 0.4986\n",
            "Epoch 18/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7849 - custom_f1: 0.5490 - weighted_custom_f1: 0.5539 - val_loss: 1.0233 - val_custom_f1: 0.4119 - val_weighted_custom_f1: 0.4479\n",
            "Epoch 19/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7883 - custom_f1: 0.5574 - weighted_custom_f1: 0.5628 - val_loss: 1.1336 - val_custom_f1: 0.4488 - val_weighted_custom_f1: 0.4567\n",
            "Epoch 19/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7740 - custom_f1: 0.5526 - weighted_custom_f1: 0.5572 - val_loss: 0.9873 - val_custom_f1: 0.4945 - val_weighted_custom_f1: 0.5329\n",
            "Epoch 20/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7713 - custom_f1: 0.5677 - weighted_custom_f1: 0.5715 - val_loss: 1.1690 - val_custom_f1: 0.4945 - val_weighted_custom_f1: 0.5043\n",
            "Epoch 20/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7608 - custom_f1: 0.5603 - weighted_custom_f1: 0.5662 - val_loss: 0.9723 - val_custom_f1: 0.4780 - val_weighted_custom_f1: 0.5156\n",
            "Epoch 21/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7670 - custom_f1: 0.5572 - weighted_custom_f1: 0.5615 - val_loss: 1.1731 - val_custom_f1: 0.4848 - val_weighted_custom_f1: 0.4920\n",
            "Epoch 21/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7499 - custom_f1: 0.5674 - weighted_custom_f1: 0.5704 - val_loss: 0.9928 - val_custom_f1: 0.4648 - val_weighted_custom_f1: 0.5035\n",
            "Epoch 22/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7418 - custom_f1: 0.5628 - weighted_custom_f1: 0.5671 - val_loss: 1.2207 - val_custom_f1: 0.4754 - val_weighted_custom_f1: 0.4823\n",
            "Epoch 22/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7446 - custom_f1: 0.5656 - weighted_custom_f1: 0.5694 - val_loss: 1.0333 - val_custom_f1: 0.4922 - val_weighted_custom_f1: 0.5303\n",
            "Epoch 23/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7234 - custom_f1: 0.5769 - weighted_custom_f1: 0.5799 - val_loss: 1.1916 - val_custom_f1: 0.5051 - val_weighted_custom_f1: 0.5085\n",
            "Epoch 23/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7277 - custom_f1: 0.5755 - weighted_custom_f1: 0.5810 - val_loss: 1.0099 - val_custom_f1: 0.4732 - val_weighted_custom_f1: 0.5090\n",
            "Epoch 24/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7162 - custom_f1: 0.5848 - weighted_custom_f1: 0.5893 - val_loss: 1.1794 - val_custom_f1: 0.4822 - val_weighted_custom_f1: 0.4890\n",
            "Epoch 24/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7296 - custom_f1: 0.5808 - weighted_custom_f1: 0.5851 - val_loss: 0.9927 - val_custom_f1: 0.4708 - val_weighted_custom_f1: 0.5078\n",
            "Epoch 25/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7221 - custom_f1: 0.5711 - weighted_custom_f1: 0.5755 - val_loss: 1.4852 - val_custom_f1: 0.4844 - val_weighted_custom_f1: 0.4968\n",
            "Epoch 25/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7222 - custom_f1: 0.5792 - weighted_custom_f1: 0.5839 - val_loss: 1.0115 - val_custom_f1: 0.4500 - val_weighted_custom_f1: 0.4880\n",
            "Epoch 26/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7165 - custom_f1: 0.5848 - weighted_custom_f1: 0.5872 - val_loss: 1.3080 - val_custom_f1: 0.4878 - val_weighted_custom_f1: 0.4946\n",
            "Epoch 26/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7072 - custom_f1: 0.5788 - weighted_custom_f1: 0.5829 - val_loss: 1.0538 - val_custom_f1: 0.4616 - val_weighted_custom_f1: 0.4984\n",
            "Epoch 27/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6843 - custom_f1: 0.5955 - weighted_custom_f1: 0.6013 - val_loss: 1.3671 - val_custom_f1: 0.5143 - val_weighted_custom_f1: 0.5232\n",
            "Epoch 27/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7135 - custom_f1: 0.5768 - weighted_custom_f1: 0.5821 - val_loss: 1.0443 - val_custom_f1: 0.4488 - val_weighted_custom_f1: 0.4836\n",
            "Epoch 28/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6857 - custom_f1: 0.5936 - weighted_custom_f1: 0.5991 - val_loss: 1.2307 - val_custom_f1: 0.5102 - val_weighted_custom_f1: 0.5154\n",
            "Epoch 28/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7509 - custom_f1: 0.5749 - weighted_custom_f1: 0.5790 - val_loss: 1.0523 - val_custom_f1: 0.4597 - val_weighted_custom_f1: 0.4983\n",
            "Epoch 29/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6815 - custom_f1: 0.6022 - weighted_custom_f1: 0.6048 - val_loss: 1.2399 - val_custom_f1: 0.5147 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 29/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7154 - custom_f1: 0.5803 - weighted_custom_f1: 0.5834 - val_loss: 1.0717 - val_custom_f1: 0.4726 - val_weighted_custom_f1: 0.5114\n",
            "Epoch 30/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6818 - custom_f1: 0.5923 - weighted_custom_f1: 0.5972 - val_loss: 1.2154 - val_custom_f1: 0.4756 - val_weighted_custom_f1: 0.4824\n",
            "Epoch 30/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6804 - custom_f1: 0.5909 - weighted_custom_f1: 0.5939 - val_loss: 1.2281 - val_custom_f1: 0.4918 - val_weighted_custom_f1: 0.5293\n",
            "Epoch 31/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6658 - custom_f1: 0.6019 - weighted_custom_f1: 0.6053 - val_loss: 1.3232 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5178\n",
            "Epoch 31/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6643 - custom_f1: 0.5991 - weighted_custom_f1: 0.6059 - val_loss: 1.1287 - val_custom_f1: 0.4599 - val_weighted_custom_f1: 0.4964\n",
            "Epoch 32/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6646 - custom_f1: 0.6080 - weighted_custom_f1: 0.6127 - val_loss: 1.1877 - val_custom_f1: 0.4859 - val_weighted_custom_f1: 0.4931\n",
            "Epoch 32/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6632 - custom_f1: 0.6027 - weighted_custom_f1: 0.6068 - val_loss: 1.2130 - val_custom_f1: 0.4766 - val_weighted_custom_f1: 0.5135\n",
            "Epoch 33/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6539 - custom_f1: 0.6101 - weighted_custom_f1: 0.6140 - val_loss: 1.1941 - val_custom_f1: 0.4687 - val_weighted_custom_f1: 0.4737\n",
            "Epoch 33/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6634 - custom_f1: 0.6074 - weighted_custom_f1: 0.6103 - val_loss: 1.1515 - val_custom_f1: 0.4274 - val_weighted_custom_f1: 0.4634\n",
            "Epoch 34/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6464 - custom_f1: 0.6103 - weighted_custom_f1: 0.6145 - val_loss: 1.2125 - val_custom_f1: 0.4966 - val_weighted_custom_f1: 0.5017\n",
            "Epoch 34/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6692 - custom_f1: 0.6002 - weighted_custom_f1: 0.6023 - val_loss: 1.3047 - val_custom_f1: 0.4885 - val_weighted_custom_f1: 0.5244\n",
            "Epoch 35/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6226 - custom_f1: 0.6227 - weighted_custom_f1: 0.6262 - val_loss: 1.2902 - val_custom_f1: 0.5004 - val_weighted_custom_f1: 0.5039\n",
            "Epoch 35/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.7042 - custom_f1: 0.5900 - weighted_custom_f1: 0.5937 - val_loss: 1.1264 - val_custom_f1: 0.4592 - val_weighted_custom_f1: 0.4962\n",
            "Epoch 36/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6472 - custom_f1: 0.6119 - weighted_custom_f1: 0.6173 - val_loss: 1.6403 - val_custom_f1: 0.4958 - val_weighted_custom_f1: 0.5038\n",
            "Epoch 36/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6339 - custom_f1: 0.6129 - weighted_custom_f1: 0.6183 - val_loss: 1.2464 - val_custom_f1: 0.4677 - val_weighted_custom_f1: 0.5042\n",
            "Epoch 37/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6765 - custom_f1: 0.6086 - weighted_custom_f1: 0.6134 - val_loss: 1.2810 - val_custom_f1: 0.4735 - val_weighted_custom_f1: 0.4798\n",
            "Epoch 37/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6197 - custom_f1: 0.6215 - weighted_custom_f1: 0.6259 - val_loss: 1.3824 - val_custom_f1: 0.4791 - val_weighted_custom_f1: 0.5155\n",
            "Epoch 38/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6390 - custom_f1: 0.6112 - weighted_custom_f1: 0.6164 - val_loss: 1.4421 - val_custom_f1: 0.4414 - val_weighted_custom_f1: 0.4450\n",
            "Epoch 38/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6184 - custom_f1: 0.6346 - weighted_custom_f1: 0.6391 - val_loss: 1.2143 - val_custom_f1: 0.4275 - val_weighted_custom_f1: 0.4646\n",
            "Epoch 39/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6348 - custom_f1: 0.6161 - weighted_custom_f1: 0.6223 - val_loss: 1.5194 - val_custom_f1: 0.4992 - val_weighted_custom_f1: 0.5110\n",
            "Epoch 39/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6542 - custom_f1: 0.6088 - weighted_custom_f1: 0.6142 - val_loss: 1.2104 - val_custom_f1: 0.4769 - val_weighted_custom_f1: 0.5141\n",
            "Epoch 40/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6092 - custom_f1: 0.6254 - weighted_custom_f1: 0.6311 - val_loss: 1.7332 - val_custom_f1: 0.4985 - val_weighted_custom_f1: 0.5027\n",
            "Epoch 40/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6264 - custom_f1: 0.6166 - weighted_custom_f1: 0.6221 - val_loss: 1.2100 - val_custom_f1: 0.4503 - val_weighted_custom_f1: 0.4867\n",
            "Epoch 41/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5934 - custom_f1: 0.6293 - weighted_custom_f1: 0.6342 - val_loss: 1.4899 - val_custom_f1: 0.4720 - val_weighted_custom_f1: 0.4780\n",
            "Epoch 41/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5969 - custom_f1: 0.6352 - weighted_custom_f1: 0.6395 - val_loss: 1.2358 - val_custom_f1: 0.4674 - val_weighted_custom_f1: 0.5057\n",
            "Epoch 42/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5955 - custom_f1: 0.6318 - weighted_custom_f1: 0.6366 - val_loss: 1.5499 - val_custom_f1: 0.5137 - val_weighted_custom_f1: 0.5214\n",
            "Epoch 42/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.6002 - custom_f1: 0.6399 - weighted_custom_f1: 0.6440 - val_loss: 1.4525 - val_custom_f1: 0.4907 - val_weighted_custom_f1: 0.5267\n",
            "Epoch 43/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5830 - custom_f1: 0.6312 - weighted_custom_f1: 0.6379 - val_loss: 1.5436 - val_custom_f1: 0.4779 - val_weighted_custom_f1: 0.4859\n",
            "Epoch 43/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5902 - custom_f1: 0.6413 - weighted_custom_f1: 0.6458 - val_loss: 1.2925 - val_custom_f1: 0.4487 - val_weighted_custom_f1: 0.4863\n",
            "Epoch 44/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5815 - custom_f1: 0.6378 - weighted_custom_f1: 0.6429 - val_loss: 1.5929 - val_custom_f1: 0.4959 - val_weighted_custom_f1: 0.5024\n",
            "Epoch 44/100\n",
            "82/82 [==============================] - 0s 1ms/step - loss: 0.5697 - custom_f1: 0.6520 - weighted_custom_f1: 0.6565 - val_loss: 1.3508 - val_custom_f1: 0.4742 - val_weighted_custom_f1: 0.5130\n",
            "Epoch 45/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5778 - custom_f1: 0.6450 - weighted_custom_f1: 0.6487 - val_loss: 1.6369 - val_custom_f1: 0.5018 - val_weighted_custom_f1: 0.5114\n",
            "Epoch 45/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5594 - custom_f1: 0.6588 - weighted_custom_f1: 0.6630 - val_loss: 1.4358 - val_custom_f1: 0.4769 - val_weighted_custom_f1: 0.5152\n",
            "Epoch 46/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5861 - custom_f1: 0.6426 - weighted_custom_f1: 0.6475 - val_loss: 1.5389 - val_custom_f1: 0.4903 - val_weighted_custom_f1: 0.4980\n",
            "Epoch 46/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5473 - custom_f1: 0.6527 - weighted_custom_f1: 0.6563 - val_loss: 1.5639 - val_custom_f1: 0.4756 - val_weighted_custom_f1: 0.5104\n",
            "Epoch 47/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5822 - custom_f1: 0.6350 - weighted_custom_f1: 0.6391 - val_loss: 1.8696 - val_custom_f1: 0.5035 - val_weighted_custom_f1: 0.5117\n",
            "Epoch 47/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5864 - custom_f1: 0.6483 - weighted_custom_f1: 0.6537 - val_loss: 1.4716 - val_custom_f1: 0.4255 - val_weighted_custom_f1: 0.4614\n",
            "Epoch 48/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5732 - custom_f1: 0.6433 - weighted_custom_f1: 0.6489 - val_loss: 1.4764 - val_custom_f1: 0.4695 - val_weighted_custom_f1: 0.5070\n",
            "Epoch 49/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5622 - custom_f1: 0.6441 - weighted_custom_f1: 0.6496 - val_loss: 1.8067 - val_custom_f1: 0.4946 - val_weighted_custom_f1: 0.5026\n",
            " 1/82 [..............................] - ETA: 0s - loss: 0.6355 - custom_f1: 0.5862 - weighted_custom_f1: 0.5862Epoch 48/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5642 - custom_f1: 0.6584 - weighted_custom_f1: 0.6636 - val_loss: 1.6479 - val_custom_f1: 0.4638 - val_weighted_custom_f1: 0.5009\n",
            "Epoch 50/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5844 - custom_f1: 0.6354 - weighted_custom_f1: 0.6403 - val_loss: 1.8056 - val_custom_f1: 0.5125 - val_weighted_custom_f1: 0.5193\n",
            "Epoch 49/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5278 - custom_f1: 0.6725 - weighted_custom_f1: 0.6768 - val_loss: 1.4650 - val_custom_f1: 0.4863 - val_weighted_custom_f1: 0.5236\n",
            "Epoch 51/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5542 - custom_f1: 0.6536 - weighted_custom_f1: 0.6573 - val_loss: 1.8962 - val_custom_f1: 0.4907 - val_weighted_custom_f1: 0.5004\n",
            "Epoch 50/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5392 - custom_f1: 0.6691 - weighted_custom_f1: 0.6735 - val_loss: 1.4765 - val_custom_f1: 0.4702 - val_weighted_custom_f1: 0.5076\n",
            "Epoch 52/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5457 - custom_f1: 0.6568 - weighted_custom_f1: 0.6597 - val_loss: 1.7484 - val_custom_f1: 0.5009 - val_weighted_custom_f1: 0.5090\n",
            "Epoch 51/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5367 - custom_f1: 0.6621 - weighted_custom_f1: 0.6669 - val_loss: 1.6585 - val_custom_f1: 0.4842 - val_weighted_custom_f1: 0.5222\n",
            "Epoch 53/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5189 - custom_f1: 0.6689 - weighted_custom_f1: 0.6732 - val_loss: 1.8089 - val_custom_f1: 0.4945 - val_weighted_custom_f1: 0.5043\n",
            "Epoch 52/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5402 - custom_f1: 0.6622 - weighted_custom_f1: 0.6658 - val_loss: 1.5107 - val_custom_f1: 0.4624 - val_weighted_custom_f1: 0.4998\n",
            "Epoch 54/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5500 - custom_f1: 0.6575 - weighted_custom_f1: 0.6622 - val_loss: 1.6815 - val_custom_f1: 0.4690 - val_weighted_custom_f1: 0.4767\n",
            "Epoch 53/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5919 - custom_f1: 0.6445 - weighted_custom_f1: 0.6506 - val_loss: 1.4232 - val_custom_f1: 0.4567 - val_weighted_custom_f1: 0.4942\n",
            "Epoch 55/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5364 - custom_f1: 0.6629 - weighted_custom_f1: 0.6675 - val_loss: 1.6711 - val_custom_f1: 0.4893 - val_weighted_custom_f1: 0.4954\n",
            "Epoch 54/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5349 - custom_f1: 0.6693 - weighted_custom_f1: 0.6727 - val_loss: 1.5093 - val_custom_f1: 0.4604 - val_weighted_custom_f1: 0.4989\n",
            "Epoch 56/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5263 - custom_f1: 0.6757 - weighted_custom_f1: 0.6809 - val_loss: 1.7696 - val_custom_f1: 0.4844 - val_weighted_custom_f1: 0.4901\n",
            "Epoch 55/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5095 - custom_f1: 0.6815 - weighted_custom_f1: 0.6859 - val_loss: 1.5633 - val_custom_f1: 0.4729 - val_weighted_custom_f1: 0.5087\n",
            "Epoch 57/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5450 - custom_f1: 0.6595 - weighted_custom_f1: 0.6653 - val_loss: 1.7978 - val_custom_f1: 0.5079 - val_weighted_custom_f1: 0.5145\n",
            "Epoch 56/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4933 - custom_f1: 0.6879 - weighted_custom_f1: 0.6924 - val_loss: 1.6057 - val_custom_f1: 0.4702 - val_weighted_custom_f1: 0.5049\n",
            "Epoch 58/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5361 - custom_f1: 0.6733 - weighted_custom_f1: 0.6780 - val_loss: 2.1896 - val_custom_f1: 0.4888 - val_weighted_custom_f1: 0.4969\n",
            "Epoch 57/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4901 - custom_f1: 0.6922 - weighted_custom_f1: 0.6959 - val_loss: 1.7270 - val_custom_f1: 0.4682 - val_weighted_custom_f1: 0.5044\n",
            "Epoch 59/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5087 - custom_f1: 0.6696 - weighted_custom_f1: 0.6748 - val_loss: 2.0316 - val_custom_f1: 0.4816 - val_weighted_custom_f1: 0.4886\n",
            "Epoch 58/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4815 - custom_f1: 0.6921 - weighted_custom_f1: 0.6964 - val_loss: 1.6839 - val_custom_f1: 0.4730 - val_weighted_custom_f1: 0.5102\n",
            "Epoch 60/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4985 - custom_f1: 0.6826 - weighted_custom_f1: 0.6869 - val_loss: 2.1731 - val_custom_f1: 0.4918 - val_weighted_custom_f1: 0.5035\n",
            "Epoch 59/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4945 - custom_f1: 0.6851 - weighted_custom_f1: 0.6884 - val_loss: 1.8283 - val_custom_f1: 0.4752 - val_weighted_custom_f1: 0.5061\n",
            "Epoch 61/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4908 - custom_f1: 0.6825 - weighted_custom_f1: 0.6879 - val_loss: 2.0896 - val_custom_f1: 0.4916 - val_weighted_custom_f1: 0.4965\n",
            "Epoch 60/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5076 - custom_f1: 0.6806 - weighted_custom_f1: 0.6838 - val_loss: 1.8790 - val_custom_f1: 0.4771 - val_weighted_custom_f1: 0.5122\n",
            "Epoch 62/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4798 - custom_f1: 0.6859 - weighted_custom_f1: 0.6890 - val_loss: 2.1231 - val_custom_f1: 0.4932 - val_weighted_custom_f1: 0.5006\n",
            "Epoch 61/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4954 - custom_f1: 0.6917 - weighted_custom_f1: 0.6951 - val_loss: 1.8370 - val_custom_f1: 0.4693 - val_weighted_custom_f1: 0.5043\n",
            "Epoch 63/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4771 - custom_f1: 0.6911 - weighted_custom_f1: 0.6941 - val_loss: 2.3358 - val_custom_f1: 0.4985 - val_weighted_custom_f1: 0.5090\n",
            "Epoch 62/100\n",
            "82/82 [==============================] - 0s 1ms/step - loss: 0.4545 - custom_f1: 0.7054 - weighted_custom_f1: 0.7094 - val_loss: 1.7776 - val_custom_f1: 0.4688 - val_weighted_custom_f1: 0.5058\n",
            "Epoch 64/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4798 - custom_f1: 0.6931 - weighted_custom_f1: 0.6970 - val_loss: 2.5570 - val_custom_f1: 0.4868 - val_weighted_custom_f1: 0.4943\n",
            "Epoch 63/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4834 - custom_f1: 0.6906 - weighted_custom_f1: 0.6947 - val_loss: 1.8232 - val_custom_f1: 0.4784 - val_weighted_custom_f1: 0.5148\n",
            "Epoch 65/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.5066 - custom_f1: 0.6825 - weighted_custom_f1: 0.6856 - val_loss: 2.4398 - val_custom_f1: 0.4881 - val_weighted_custom_f1: 0.4967\n",
            "Epoch 64/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4948 - custom_f1: 0.6928 - weighted_custom_f1: 0.6962 - val_loss: 2.0563 - val_custom_f1: 0.4784 - val_weighted_custom_f1: 0.5135\n",
            "Epoch 66/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4731 - custom_f1: 0.6896 - weighted_custom_f1: 0.6950 - val_loss: 2.4929 - val_custom_f1: 0.4800 - val_weighted_custom_f1: 0.4883\n",
            "Epoch 65/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4500 - custom_f1: 0.7080 - weighted_custom_f1: 0.7125 - val_loss: 1.8831 - val_custom_f1: 0.4764 - val_weighted_custom_f1: 0.5132\n",
            "Epoch 67/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4794 - custom_f1: 0.6966 - weighted_custom_f1: 0.7009 - val_loss: 2.3673 - val_custom_f1: 0.4974 - val_weighted_custom_f1: 0.5053\n",
            "Epoch 66/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4743 - custom_f1: 0.7016 - weighted_custom_f1: 0.7048 - val_loss: 1.8704 - val_custom_f1: 0.4812 - val_weighted_custom_f1: 0.5177\n",
            "Epoch 68/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4500 - custom_f1: 0.7005 - weighted_custom_f1: 0.7046 - val_loss: 2.4899 - val_custom_f1: 0.4919 - val_weighted_custom_f1: 0.4979\n",
            "Epoch 67/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4698 - custom_f1: 0.6948 - weighted_custom_f1: 0.6986 - val_loss: 1.8419 - val_custom_f1: 0.4676 - val_weighted_custom_f1: 0.5014\n",
            "Epoch 69/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4491 - custom_f1: 0.7081 - weighted_custom_f1: 0.7123 - val_loss: 2.5328 - val_custom_f1: 0.4835 - val_weighted_custom_f1: 0.4961\n",
            "Epoch 68/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4705 - custom_f1: 0.6986 - weighted_custom_f1: 0.7034 - val_loss: 2.0800 - val_custom_f1: 0.4605 - val_weighted_custom_f1: 0.4974\n",
            "Epoch 70/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4769 - custom_f1: 0.6950 - weighted_custom_f1: 0.7004 - val_loss: 2.4134 - val_custom_f1: 0.4941 - val_weighted_custom_f1: 0.5005\n",
            "Epoch 69/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4548 - custom_f1: 0.7078 - weighted_custom_f1: 0.7129 - val_loss: 1.8238 - val_custom_f1: 0.4590 - val_weighted_custom_f1: 0.4983\n",
            "Epoch 71/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4577 - custom_f1: 0.7086 - weighted_custom_f1: 0.7121 - val_loss: 2.6507 - val_custom_f1: 0.5229 - val_weighted_custom_f1: 0.5293\n",
            "Epoch 70/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4412 - custom_f1: 0.7125 - weighted_custom_f1: 0.7148 - val_loss: 2.0668 - val_custom_f1: 0.4705 - val_weighted_custom_f1: 0.5083\n",
            "Epoch 72/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4388 - custom_f1: 0.7118 - weighted_custom_f1: 0.7183 - val_loss: 2.4175 - val_custom_f1: 0.4950 - val_weighted_custom_f1: 0.5021\n",
            "Epoch 71/100\n",
            "82/82 [==============================] - 0s 1ms/step - loss: 0.4546 - custom_f1: 0.7072 - weighted_custom_f1: 0.7113 - val_loss: 2.2939 - val_custom_f1: 0.4665 - val_weighted_custom_f1: 0.5020\n",
            "Epoch 73/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4440 - custom_f1: 0.7073 - weighted_custom_f1: 0.7113 - val_loss: 2.4013 - val_custom_f1: 0.4879 - val_weighted_custom_f1: 0.4960\n",
            "Epoch 72/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4286 - custom_f1: 0.7221 - weighted_custom_f1: 0.7270 - val_loss: 2.1378 - val_custom_f1: 0.4674 - val_weighted_custom_f1: 0.5016\n",
            "Epoch 74/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4589 - custom_f1: 0.7066 - weighted_custom_f1: 0.7114 - val_loss: 2.5543 - val_custom_f1: 0.4786 - val_weighted_custom_f1: 0.4881\n",
            "Epoch 73/100\n",
            "82/82 [==============================] - 0s 1ms/step - loss: 0.4446 - custom_f1: 0.7198 - weighted_custom_f1: 0.7225 - val_loss: 2.1231 - val_custom_f1: 0.4642 - val_weighted_custom_f1: 0.4987\n",
            "Epoch 75/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4274 - custom_f1: 0.7191 - weighted_custom_f1: 0.7221 - val_loss: 2.0731 - val_custom_f1: 0.4717 - val_weighted_custom_f1: 0.5070\n",
            "Epoch 76/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4351 - custom_f1: 0.7167 - weighted_custom_f1: 0.7203 - val_loss: 2.6484 - val_custom_f1: 0.5025 - val_weighted_custom_f1: 0.5101\n",
            " 1/82 [..............................] - ETA: 0s - loss: 0.4443 - custom_f1: 0.6809 - weighted_custom_f1: 0.6809Epoch 74/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4249 - custom_f1: 0.7208 - weighted_custom_f1: 0.7272 - val_loss: 2.4135 - val_custom_f1: 0.4604 - val_weighted_custom_f1: 0.4966\n",
            "Epoch 77/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4494 - custom_f1: 0.7124 - weighted_custom_f1: 0.7177 - val_loss: 2.4339 - val_custom_f1: 0.4755 - val_weighted_custom_f1: 0.4854\n",
            "Epoch 75/100\n",
            "82/82 [==============================] - 0s 1ms/step - loss: 0.4210 - custom_f1: 0.7228 - weighted_custom_f1: 0.7262 - val_loss: 2.3093 - val_custom_f1: 0.4622 - val_weighted_custom_f1: 0.4968\n",
            "Epoch 78/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4338 - custom_f1: 0.7197 - weighted_custom_f1: 0.7229 - val_loss: 2.4427 - val_custom_f1: 0.4936 - val_weighted_custom_f1: 0.5056\n",
            "Epoch 76/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4170 - custom_f1: 0.7261 - weighted_custom_f1: 0.7326 - val_loss: 2.4333 - val_custom_f1: 0.4621 - val_weighted_custom_f1: 0.4991\n",
            "Epoch 79/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4295 - custom_f1: 0.7227 - weighted_custom_f1: 0.7267 - val_loss: 2.7967 - val_custom_f1: 0.5015 - val_weighted_custom_f1: 0.5128\n",
            "Epoch 77/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4206 - custom_f1: 0.7335 - weighted_custom_f1: 0.7364 - val_loss: 2.2779 - val_custom_f1: 0.4570 - val_weighted_custom_f1: 0.4930\n",
            "Epoch 80/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4247 - custom_f1: 0.7253 - weighted_custom_f1: 0.7302 - val_loss: 2.7014 - val_custom_f1: 0.4961 - val_weighted_custom_f1: 0.5036\n",
            "Epoch 78/100\n",
            "82/82 [==============================] - 0s 1ms/step - loss: 0.3956 - custom_f1: 0.7389 - weighted_custom_f1: 0.7425 - val_loss: 2.2788 - val_custom_f1: 0.4766 - val_weighted_custom_f1: 0.5139\n",
            "Epoch 81/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4341 - custom_f1: 0.7154 - weighted_custom_f1: 0.7196 - val_loss: 2.9025 - val_custom_f1: 0.4851 - val_weighted_custom_f1: 0.4969\n",
            "Epoch 79/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3836 - custom_f1: 0.7455 - weighted_custom_f1: 0.7495 - val_loss: 2.0403 - val_custom_f1: 0.4606 - val_weighted_custom_f1: 0.4977\n",
            "Epoch 82/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4515 - custom_f1: 0.7200 - weighted_custom_f1: 0.7221 - val_loss: 2.6372 - val_custom_f1: 0.4745 - val_weighted_custom_f1: 0.4839\n",
            "Epoch 80/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3821 - custom_f1: 0.7473 - weighted_custom_f1: 0.7524 - val_loss: 2.5728 - val_custom_f1: 0.4579 - val_weighted_custom_f1: 0.4933\n",
            "Epoch 83/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4406 - custom_f1: 0.7181 - weighted_custom_f1: 0.7213 - val_loss: 2.8596 - val_custom_f1: 0.4978 - val_weighted_custom_f1: 0.5052\n",
            "Epoch 81/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4067 - custom_f1: 0.7353 - weighted_custom_f1: 0.7390 - val_loss: 2.1821 - val_custom_f1: 0.4722 - val_weighted_custom_f1: 0.5090\n",
            "Epoch 84/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4093 - custom_f1: 0.7348 - weighted_custom_f1: 0.7384 - val_loss: 2.9157 - val_custom_f1: 0.5171 - val_weighted_custom_f1: 0.5263\n",
            "Epoch 82/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4182 - custom_f1: 0.7283 - weighted_custom_f1: 0.7332 - val_loss: 2.2168 - val_custom_f1: 0.4634 - val_weighted_custom_f1: 0.5000\n",
            "Epoch 85/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3964 - custom_f1: 0.7389 - weighted_custom_f1: 0.7419 - val_loss: 2.8706 - val_custom_f1: 0.4943 - val_weighted_custom_f1: 0.5044\n",
            "Epoch 83/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4180 - custom_f1: 0.7221 - weighted_custom_f1: 0.7260 - val_loss: 2.4952 - val_custom_f1: 0.4632 - val_weighted_custom_f1: 0.4987\n",
            "Epoch 86/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4127 - custom_f1: 0.7253 - weighted_custom_f1: 0.7311 - val_loss: 2.6048 - val_custom_f1: 0.4801 - val_weighted_custom_f1: 0.4890\n",
            "Epoch 84/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.4004 - custom_f1: 0.7357 - weighted_custom_f1: 0.7386 - val_loss: 2.3964 - val_custom_f1: 0.4652 - val_weighted_custom_f1: 0.5024\n",
            "Epoch 87/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3989 - custom_f1: 0.7370 - weighted_custom_f1: 0.7431 - val_loss: 2.7502 - val_custom_f1: 0.5076 - val_weighted_custom_f1: 0.5153\n",
            "Epoch 85/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3701 - custom_f1: 0.7522 - weighted_custom_f1: 0.7549 - val_loss: 2.3647 - val_custom_f1: 0.4652 - val_weighted_custom_f1: 0.5010\n",
            "Epoch 88/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3981 - custom_f1: 0.7426 - weighted_custom_f1: 0.7446 - val_loss: 2.8053 - val_custom_f1: 0.4920 - val_weighted_custom_f1: 0.5022\n",
            "Epoch 86/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3733 - custom_f1: 0.7531 - weighted_custom_f1: 0.7585 - val_loss: 2.5585 - val_custom_f1: 0.4544 - val_weighted_custom_f1: 0.4897\n",
            "Epoch 89/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3962 - custom_f1: 0.7423 - weighted_custom_f1: 0.7452 - val_loss: 2.7103 - val_custom_f1: 0.4898 - val_weighted_custom_f1: 0.4959\n",
            "Epoch 87/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3814 - custom_f1: 0.7508 - weighted_custom_f1: 0.7536 - val_loss: 2.6241 - val_custom_f1: 0.4735 - val_weighted_custom_f1: 0.5091\n",
            "Epoch 90/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3879 - custom_f1: 0.7479 - weighted_custom_f1: 0.7521 - val_loss: 2.8431 - val_custom_f1: 0.4979 - val_weighted_custom_f1: 0.5076\n",
            "Epoch 88/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3702 - custom_f1: 0.7603 - weighted_custom_f1: 0.7627 - val_loss: 2.3550 - val_custom_f1: 0.4715 - val_weighted_custom_f1: 0.5071\n",
            "41/82 [==============>...............] - ETA: 0s - loss: 0.3757 - custom_f1: 0.7513 - weighted_custom_f1: 0.7537Epoch 91/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3913 - custom_f1: 0.7422 - weighted_custom_f1: 0.7460 - val_loss: 2.9559 - val_custom_f1: 0.5043 - val_weighted_custom_f1: 0.5105\n",
            "Epoch 89/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3637 - custom_f1: 0.7634 - weighted_custom_f1: 0.7669 - val_loss: 2.4393 - val_custom_f1: 0.4517 - val_weighted_custom_f1: 0.4869\n",
            "Epoch 92/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3708 - custom_f1: 0.7525 - weighted_custom_f1: 0.7552 - val_loss: 3.1386 - val_custom_f1: 0.5114 - val_weighted_custom_f1: 0.5143\n",
            "Epoch 90/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3879 - custom_f1: 0.7489 - weighted_custom_f1: 0.7528 - val_loss: 2.9172 - val_custom_f1: 0.4342 - val_weighted_custom_f1: 0.4689\n",
            "Epoch 93/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3857 - custom_f1: 0.7456 - weighted_custom_f1: 0.7496 - val_loss: 2.6853 - val_custom_f1: 0.4957 - val_weighted_custom_f1: 0.5069\n",
            "Epoch 91/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3823 - custom_f1: 0.7504 - weighted_custom_f1: 0.7527 - val_loss: 2.6007 - val_custom_f1: 0.4636 - val_weighted_custom_f1: 0.4992\n",
            "Epoch 94/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3603 - custom_f1: 0.7538 - weighted_custom_f1: 0.7594 - val_loss: 2.9947 - val_custom_f1: 0.4872 - val_weighted_custom_f1: 0.4975\n",
            "Epoch 92/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3715 - custom_f1: 0.7539 - weighted_custom_f1: 0.7567 - val_loss: 2.5107 - val_custom_f1: 0.4783 - val_weighted_custom_f1: 0.5135\n",
            "Epoch 95/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3637 - custom_f1: 0.7666 - weighted_custom_f1: 0.7689 - val_loss: 2.8592 - val_custom_f1: 0.4877 - val_weighted_custom_f1: 0.4947\n",
            "Epoch 93/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3833 - custom_f1: 0.7437 - weighted_custom_f1: 0.7473 - val_loss: 2.4641 - val_custom_f1: 0.4654 - val_weighted_custom_f1: 0.5018\n",
            "Epoch 96/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3637 - custom_f1: 0.7610 - weighted_custom_f1: 0.7641 - val_loss: 2.9883 - val_custom_f1: 0.4964 - val_weighted_custom_f1: 0.5028\n",
            "Epoch 94/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3672 - custom_f1: 0.7588 - weighted_custom_f1: 0.7629 - val_loss: 2.7051 - val_custom_f1: 0.4578 - val_weighted_custom_f1: 0.4914\n",
            "Epoch 97/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3515 - custom_f1: 0.7610 - weighted_custom_f1: 0.7650 - val_loss: 3.0137 - val_custom_f1: 0.4958 - val_weighted_custom_f1: 0.5057\n",
            "Epoch 95/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3653 - custom_f1: 0.7609 - weighted_custom_f1: 0.7650 - val_loss: 2.5293 - val_custom_f1: 0.4457 - val_weighted_custom_f1: 0.4825\n",
            "Epoch 98/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3592 - custom_f1: 0.7607 - weighted_custom_f1: 0.7642 - val_loss: 2.9131 - val_custom_f1: 0.4827 - val_weighted_custom_f1: 0.4901\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3796 - custom_f1: 0.7527 - weighted_custom_f1: 0.7552 - val_loss: 3.0926 - val_custom_f1: 0.4604 - val_weighted_custom_f1: 0.4952\n",
            "Epoch 96/100\n",
            "Epoch 99/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3573 - custom_f1: 0.7747 - weighted_custom_f1: 0.7786 - val_loss: 2.7237 - val_custom_f1: 0.4750 - val_weighted_custom_f1: 0.5123\n",
            "Epoch 100/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3805 - custom_f1: 0.7515 - weighted_custom_f1: 0.7556 - val_loss: 3.0891 - val_custom_f1: 0.4818 - val_weighted_custom_f1: 0.4953\n",
            "Epoch 97/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3645 - custom_f1: 0.7588 - weighted_custom_f1: 0.7620 - val_loss: 2.7636 - val_custom_f1: 0.4607 - val_weighted_custom_f1: 0.4966\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3771 - custom_f1: 0.7544 - weighted_custom_f1: 0.7572 - val_loss: 3.4801 - val_custom_f1: 0.4959 - val_weighted_custom_f1: 0.5051\n",
            "Epoch 98/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3689 - custom_f1: 0.7562 - weighted_custom_f1: 0.7627 - val_loss: 3.2623 - val_custom_f1: 0.4800 - val_weighted_custom_f1: 0.4931\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 711us/step 0.3683 - custom_f1: 0.7628 - weighted_custom_f1: 0.76\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3565 - custom_f1: 0.7597 - weighted_custom_f1: 0.7646 - val_loss: 3.2613 - val_custom_f1: 0.4807 - val_weighted_custom_f1: 0.4920\n",
            "Epoch 100/100\n",
            "82/82 [==============================] - 0s 2ms/step - loss: 0.3417 - custom_f1: 0.7698 - weighted_custom_f1: 0.7740 - val_loss: 2.9873 - val_custom_f1: 0.4817 - val_weighted_custom_f1: 0.4899\n",
            "102/102 [==============================] - 0s 697us/step\n",
            "102/102 [==============================] - 0s 675us/step\n",
            "102/102 [==============================] - 0s 666us/step\n",
            "Epoch 1/100\n",
            "164/164 [==============================] - 1s 2ms/step - loss: 1.2116 - custom_f1: 0.4026 - weighted_custom_f1: 0.4068 - val_loss: 1.0478 - val_custom_f1: 0.4636 - val_weighted_custom_f1: 0.4685\n",
            "Epoch 2/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0778 - custom_f1: 0.4374 - weighted_custom_f1: 0.4416 - val_loss: 1.0345 - val_custom_f1: 0.4052 - val_weighted_custom_f1: 0.4101\n",
            "Epoch 3/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.9969 - custom_f1: 0.4586 - weighted_custom_f1: 0.4639 - val_loss: 1.0394 - val_custom_f1: 0.3899 - val_weighted_custom_f1: 0.3950\n",
            "Epoch 4/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.9872 - custom_f1: 0.4690 - weighted_custom_f1: 0.4746 - val_loss: 0.9777 - val_custom_f1: 0.4347 - val_weighted_custom_f1: 0.4405\n",
            "Epoch 5/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.9269 - custom_f1: 0.4907 - weighted_custom_f1: 0.4943 - val_loss: 0.9280 - val_custom_f1: 0.4962 - val_weighted_custom_f1: 0.5002\n",
            "Epoch 6/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9396 - custom_f1: 0.4962 - weighted_custom_f1: 0.5009 - val_loss: 0.9186 - val_custom_f1: 0.5016 - val_weighted_custom_f1: 0.5053\n",
            "Epoch 7/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8821 - custom_f1: 0.5099 - weighted_custom_f1: 0.5143 - val_loss: 0.9398 - val_custom_f1: 0.4783 - val_weighted_custom_f1: 0.4831\n",
            "Epoch 8/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8760 - custom_f1: 0.5107 - weighted_custom_f1: 0.5157 - val_loss: 0.9253 - val_custom_f1: 0.5323 - val_weighted_custom_f1: 0.5357\n",
            "Epoch 9/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8736 - custom_f1: 0.5199 - weighted_custom_f1: 0.5248 - val_loss: 0.9170 - val_custom_f1: 0.4733 - val_weighted_custom_f1: 0.4779\n",
            "Epoch 10/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8658 - custom_f1: 0.5252 - weighted_custom_f1: 0.5305 - val_loss: 0.9094 - val_custom_f1: 0.4739 - val_weighted_custom_f1: 0.4778\n",
            "Epoch 11/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8588 - custom_f1: 0.5198 - weighted_custom_f1: 0.5251 - val_loss: 0.8866 - val_custom_f1: 0.5180 - val_weighted_custom_f1: 0.5213\n",
            "Epoch 12/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8436 - custom_f1: 0.5281 - weighted_custom_f1: 0.5335 - val_loss: 0.9143 - val_custom_f1: 0.4724 - val_weighted_custom_f1: 0.4766\n",
            "Epoch 13/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.8270 - custom_f1: 0.5288 - weighted_custom_f1: 0.5339 - val_loss: 0.9929 - val_custom_f1: 0.5392 - val_weighted_custom_f1: 0.5411\n",
            "Epoch 14/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8198 - custom_f1: 0.5381 - weighted_custom_f1: 0.5438 - val_loss: 0.9016 - val_custom_f1: 0.5112 - val_weighted_custom_f1: 0.5144\n",
            "Epoch 15/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8317 - custom_f1: 0.5384 - weighted_custom_f1: 0.5433 - val_loss: 0.9407 - val_custom_f1: 0.4674 - val_weighted_custom_f1: 0.4715\n",
            "Epoch 16/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7950 - custom_f1: 0.5471 - weighted_custom_f1: 0.5518 - val_loss: 0.9002 - val_custom_f1: 0.5210 - val_weighted_custom_f1: 0.5243\n",
            "Epoch 17/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.8183 - custom_f1: 0.5376 - weighted_custom_f1: 0.5426 - val_loss: 0.9819 - val_custom_f1: 0.5491 - val_weighted_custom_f1: 0.5521\n",
            "Epoch 18/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7960 - custom_f1: 0.5418 - weighted_custom_f1: 0.5463 - val_loss: 0.9256 - val_custom_f1: 0.5489 - val_weighted_custom_f1: 0.5515\n",
            "Epoch 19/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7778 - custom_f1: 0.5574 - weighted_custom_f1: 0.5612 - val_loss: 0.9319 - val_custom_f1: 0.5316 - val_weighted_custom_f1: 0.5351\n",
            "Epoch 20/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7922 - custom_f1: 0.5485 - weighted_custom_f1: 0.5540 - val_loss: 0.9561 - val_custom_f1: 0.4752 - val_weighted_custom_f1: 0.4792\n",
            "Epoch 21/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7776 - custom_f1: 0.5532 - weighted_custom_f1: 0.5589 - val_loss: 0.9305 - val_custom_f1: 0.5162 - val_weighted_custom_f1: 0.5205\n",
            "Epoch 22/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7825 - custom_f1: 0.5522 - weighted_custom_f1: 0.5567 - val_loss: 0.9261 - val_custom_f1: 0.5286 - val_weighted_custom_f1: 0.5319\n",
            "Epoch 23/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7562 - custom_f1: 0.5646 - weighted_custom_f1: 0.5681 - val_loss: 0.9487 - val_custom_f1: 0.5350 - val_weighted_custom_f1: 0.5380\n",
            "Epoch 24/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7586 - custom_f1: 0.5610 - weighted_custom_f1: 0.5649 - val_loss: 0.9380 - val_custom_f1: 0.5124 - val_weighted_custom_f1: 0.5158\n",
            "Epoch 25/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7556 - custom_f1: 0.5614 - weighted_custom_f1: 0.5669 - val_loss: 0.9377 - val_custom_f1: 0.5183 - val_weighted_custom_f1: 0.5216\n",
            "Epoch 26/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7526 - custom_f1: 0.5758 - weighted_custom_f1: 0.5796 - val_loss: 0.9495 - val_custom_f1: 0.5334 - val_weighted_custom_f1: 0.5361\n",
            "Epoch 27/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7286 - custom_f1: 0.5760 - weighted_custom_f1: 0.5822 - val_loss: 1.0023 - val_custom_f1: 0.5500 - val_weighted_custom_f1: 0.5542\n",
            "Epoch 28/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.7344 - custom_f1: 0.5740 - weighted_custom_f1: 0.5782 - val_loss: 0.9925 - val_custom_f1: 0.5231 - val_weighted_custom_f1: 0.5264\n",
            "Epoch 29/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7264 - custom_f1: 0.5760 - weighted_custom_f1: 0.5824 - val_loss: 0.9694 - val_custom_f1: 0.5154 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 30/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7429 - custom_f1: 0.5723 - weighted_custom_f1: 0.5781 - val_loss: 0.9487 - val_custom_f1: 0.5414 - val_weighted_custom_f1: 0.5437\n",
            "Epoch 31/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.7167 - custom_f1: 0.5843 - weighted_custom_f1: 0.5895 - val_loss: 1.0276 - val_custom_f1: 0.4647 - val_weighted_custom_f1: 0.4688\n",
            "Epoch 32/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.7109 - custom_f1: 0.5829 - weighted_custom_f1: 0.5874 - val_loss: 0.9606 - val_custom_f1: 0.5252 - val_weighted_custom_f1: 0.5283\n",
            "Epoch 33/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.7089 - custom_f1: 0.5836 - weighted_custom_f1: 0.5904 - val_loss: 0.9896 - val_custom_f1: 0.5435 - val_weighted_custom_f1: 0.5460\n",
            "Epoch 34/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7019 - custom_f1: 0.5866 - weighted_custom_f1: 0.5912 - val_loss: 1.0113 - val_custom_f1: 0.4686 - val_weighted_custom_f1: 0.4731\n",
            "Epoch 35/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.7167 - custom_f1: 0.5824 - weighted_custom_f1: 0.5855 - val_loss: 1.0162 - val_custom_f1: 0.5064 - val_weighted_custom_f1: 0.5097\n",
            "Epoch 36/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6930 - custom_f1: 0.5884 - weighted_custom_f1: 0.5924 - val_loss: 1.0825 - val_custom_f1: 0.5353 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 37/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6763 - custom_f1: 0.5971 - weighted_custom_f1: 0.6019 - val_loss: 1.0428 - val_custom_f1: 0.5435 - val_weighted_custom_f1: 0.5470\n",
            "Epoch 38/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6876 - custom_f1: 0.5954 - weighted_custom_f1: 0.6000 - val_loss: 1.0225 - val_custom_f1: 0.5141 - val_weighted_custom_f1: 0.5173\n",
            "Epoch 39/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6821 - custom_f1: 0.5943 - weighted_custom_f1: 0.6001 - val_loss: 1.0961 - val_custom_f1: 0.5499 - val_weighted_custom_f1: 0.5527\n",
            "Epoch 40/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.6738 - custom_f1: 0.6036 - weighted_custom_f1: 0.6071 - val_loss: 1.0707 - val_custom_f1: 0.4814 - val_weighted_custom_f1: 0.4857\n",
            "Epoch 41/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6856 - custom_f1: 0.5985 - weighted_custom_f1: 0.6017 - val_loss: 1.1296 - val_custom_f1: 0.5386 - val_weighted_custom_f1: 0.5418\n",
            "Epoch 42/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6736 - custom_f1: 0.6011 - weighted_custom_f1: 0.6051 - val_loss: 1.1452 - val_custom_f1: 0.5534 - val_weighted_custom_f1: 0.5556\n",
            "Epoch 43/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6538 - custom_f1: 0.6040 - weighted_custom_f1: 0.6117 - val_loss: 1.1600 - val_custom_f1: 0.5564 - val_weighted_custom_f1: 0.5599\n",
            "Epoch 44/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6568 - custom_f1: 0.6119 - weighted_custom_f1: 0.6158 - val_loss: 1.1095 - val_custom_f1: 0.5325 - val_weighted_custom_f1: 0.5352\n",
            "Epoch 45/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6520 - custom_f1: 0.6120 - weighted_custom_f1: 0.6170 - val_loss: 1.1162 - val_custom_f1: 0.5397 - val_weighted_custom_f1: 0.5421\n",
            "Epoch 46/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.6437 - custom_f1: 0.6142 - weighted_custom_f1: 0.6182 - val_loss: 1.1735 - val_custom_f1: 0.5452 - val_weighted_custom_f1: 0.5480\n",
            "Epoch 47/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6349 - custom_f1: 0.6222 - weighted_custom_f1: 0.6262 - val_loss: 1.0916 - val_custom_f1: 0.5203 - val_weighted_custom_f1: 0.5237\n",
            "Epoch 48/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6376 - custom_f1: 0.6163 - weighted_custom_f1: 0.6193 - val_loss: 1.2198 - val_custom_f1: 0.5500 - val_weighted_custom_f1: 0.5539\n",
            "Epoch 49/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6412 - custom_f1: 0.6179 - weighted_custom_f1: 0.6219 - val_loss: 1.1005 - val_custom_f1: 0.5140 - val_weighted_custom_f1: 0.5169\n",
            "Epoch 50/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.6187 - custom_f1: 0.6241 - weighted_custom_f1: 0.6286 - val_loss: 1.1383 - val_custom_f1: 0.5309 - val_weighted_custom_f1: 0.5346\n",
            "Epoch 51/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.6376 - custom_f1: 0.6169 - weighted_custom_f1: 0.6231 - val_loss: 1.1730 - val_custom_f1: 0.5468 - val_weighted_custom_f1: 0.5503\n",
            "Epoch 52/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6287 - custom_f1: 0.6199 - weighted_custom_f1: 0.6279 - val_loss: 1.1356 - val_custom_f1: 0.5129 - val_weighted_custom_f1: 0.5160\n",
            "Epoch 53/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6061 - custom_f1: 0.6307 - weighted_custom_f1: 0.6343 - val_loss: 1.3113 - val_custom_f1: 0.5517 - val_weighted_custom_f1: 0.5563\n",
            "Epoch 54/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6155 - custom_f1: 0.6306 - weighted_custom_f1: 0.6342 - val_loss: 1.2980 - val_custom_f1: 0.5625 - val_weighted_custom_f1: 0.5650\n",
            "Epoch 55/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6005 - custom_f1: 0.6350 - weighted_custom_f1: 0.6399 - val_loss: 1.2191 - val_custom_f1: 0.5182 - val_weighted_custom_f1: 0.5208\n",
            "Epoch 56/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6069 - custom_f1: 0.6268 - weighted_custom_f1: 0.6310 - val_loss: 1.1992 - val_custom_f1: 0.5119 - val_weighted_custom_f1: 0.5160\n",
            "Epoch 57/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6002 - custom_f1: 0.6374 - weighted_custom_f1: 0.6426 - val_loss: 1.2094 - val_custom_f1: 0.5207 - val_weighted_custom_f1: 0.5234\n",
            "Epoch 58/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5904 - custom_f1: 0.6324 - weighted_custom_f1: 0.6390 - val_loss: 1.2580 - val_custom_f1: 0.5333 - val_weighted_custom_f1: 0.5374\n",
            "Epoch 59/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.6056 - custom_f1: 0.6312 - weighted_custom_f1: 0.6370 - val_loss: 1.2835 - val_custom_f1: 0.5441 - val_weighted_custom_f1: 0.5480\n",
            "Epoch 60/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.6018 - custom_f1: 0.6335 - weighted_custom_f1: 0.6387 - val_loss: 1.2532 - val_custom_f1: 0.5205 - val_weighted_custom_f1: 0.5236\n",
            "Epoch 61/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5757 - custom_f1: 0.6473 - weighted_custom_f1: 0.6515 - val_loss: 1.3816 - val_custom_f1: 0.5557 - val_weighted_custom_f1: 0.5588\n",
            "Epoch 62/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5772 - custom_f1: 0.6440 - weighted_custom_f1: 0.6492 - val_loss: 1.2918 - val_custom_f1: 0.5267 - val_weighted_custom_f1: 0.5293\n",
            "Epoch 63/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5837 - custom_f1: 0.6432 - weighted_custom_f1: 0.6464 - val_loss: 1.3404 - val_custom_f1: 0.5096 - val_weighted_custom_f1: 0.5121\n",
            "Epoch 64/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5896 - custom_f1: 0.6394 - weighted_custom_f1: 0.6432 - val_loss: 1.3498 - val_custom_f1: 0.5114 - val_weighted_custom_f1: 0.5145\n",
            "Epoch 65/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5801 - custom_f1: 0.6461 - weighted_custom_f1: 0.6500 - val_loss: 1.4217 - val_custom_f1: 0.4541 - val_weighted_custom_f1: 0.4579\n",
            "Epoch 66/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5796 - custom_f1: 0.6419 - weighted_custom_f1: 0.6460 - val_loss: 1.4204 - val_custom_f1: 0.5583 - val_weighted_custom_f1: 0.5605\n",
            "Epoch 67/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5705 - custom_f1: 0.6503 - weighted_custom_f1: 0.6531 - val_loss: 1.4219 - val_custom_f1: 0.5504 - val_weighted_custom_f1: 0.5535\n",
            "Epoch 68/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5539 - custom_f1: 0.6557 - weighted_custom_f1: 0.6596 - val_loss: 1.3677 - val_custom_f1: 0.5304 - val_weighted_custom_f1: 0.5334\n",
            "Epoch 69/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5728 - custom_f1: 0.6507 - weighted_custom_f1: 0.6544 - val_loss: 1.4803 - val_custom_f1: 0.5409 - val_weighted_custom_f1: 0.5419\n",
            "Epoch 70/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5631 - custom_f1: 0.6530 - weighted_custom_f1: 0.6566 - val_loss: 1.4228 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5274\n",
            "Epoch 71/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5577 - custom_f1: 0.6528 - weighted_custom_f1: 0.6560 - val_loss: 1.4839 - val_custom_f1: 0.5494 - val_weighted_custom_f1: 0.5518\n",
            "Epoch 72/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5543 - custom_f1: 0.6537 - weighted_custom_f1: 0.6588 - val_loss: 1.4167 - val_custom_f1: 0.5165 - val_weighted_custom_f1: 0.5196\n",
            "Epoch 73/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5465 - custom_f1: 0.6561 - weighted_custom_f1: 0.6623 - val_loss: 1.4521 - val_custom_f1: 0.5375 - val_weighted_custom_f1: 0.5398\n",
            "Epoch 74/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5446 - custom_f1: 0.6597 - weighted_custom_f1: 0.6639 - val_loss: 1.5392 - val_custom_f1: 0.5244 - val_weighted_custom_f1: 0.5264\n",
            "Epoch 75/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5545 - custom_f1: 0.6517 - weighted_custom_f1: 0.6582 - val_loss: 1.6252 - val_custom_f1: 0.5433 - val_weighted_custom_f1: 0.5463\n",
            "Epoch 76/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5291 - custom_f1: 0.6716 - weighted_custom_f1: 0.6748 - val_loss: 1.5760 - val_custom_f1: 0.5518 - val_weighted_custom_f1: 0.5542\n",
            "Epoch 77/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5381 - custom_f1: 0.6676 - weighted_custom_f1: 0.6722 - val_loss: 1.6799 - val_custom_f1: 0.5485 - val_weighted_custom_f1: 0.5503\n",
            "Epoch 78/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5324 - custom_f1: 0.6603 - weighted_custom_f1: 0.6685 - val_loss: 1.6500 - val_custom_f1: 0.5651 - val_weighted_custom_f1: 0.5678\n",
            "Epoch 79/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5282 - custom_f1: 0.6680 - weighted_custom_f1: 0.6735 - val_loss: 1.6162 - val_custom_f1: 0.5578 - val_weighted_custom_f1: 0.5605\n",
            "Epoch 80/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5098 - custom_f1: 0.6764 - weighted_custom_f1: 0.6813 - val_loss: 1.5609 - val_custom_f1: 0.5626 - val_weighted_custom_f1: 0.5655\n",
            "Epoch 81/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5254 - custom_f1: 0.6662 - weighted_custom_f1: 0.6704 - val_loss: 1.6120 - val_custom_f1: 0.5294 - val_weighted_custom_f1: 0.5323\n",
            "Epoch 82/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5673 - custom_f1: 0.6686 - weighted_custom_f1: 0.6734 - val_loss: 1.5420 - val_custom_f1: 0.5300 - val_weighted_custom_f1: 0.5320\n",
            "Epoch 83/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5380 - custom_f1: 0.6665 - weighted_custom_f1: 0.6720 - val_loss: 1.6223 - val_custom_f1: 0.5299 - val_weighted_custom_f1: 0.5330\n",
            "Epoch 84/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5161 - custom_f1: 0.6723 - weighted_custom_f1: 0.6769 - val_loss: 1.7710 - val_custom_f1: 0.5584 - val_weighted_custom_f1: 0.5612\n",
            "Epoch 85/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5108 - custom_f1: 0.6797 - weighted_custom_f1: 0.6827 - val_loss: 1.5245 - val_custom_f1: 0.5204 - val_weighted_custom_f1: 0.5230\n",
            "Epoch 86/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5160 - custom_f1: 0.6738 - weighted_custom_f1: 0.6791 - val_loss: 1.6175 - val_custom_f1: 0.5486 - val_weighted_custom_f1: 0.5510\n",
            "Epoch 87/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5144 - custom_f1: 0.6782 - weighted_custom_f1: 0.6842 - val_loss: 1.6947 - val_custom_f1: 0.5421 - val_weighted_custom_f1: 0.5464\n",
            "Epoch 88/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5139 - custom_f1: 0.6752 - weighted_custom_f1: 0.6787 - val_loss: 1.6546 - val_custom_f1: 0.5476 - val_weighted_custom_f1: 0.5495\n",
            "Epoch 89/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5050 - custom_f1: 0.6816 - weighted_custom_f1: 0.6843 - val_loss: 1.7423 - val_custom_f1: 0.5578 - val_weighted_custom_f1: 0.5608\n",
            "Epoch 90/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.4873 - custom_f1: 0.6876 - weighted_custom_f1: 0.6934 - val_loss: 1.6983 - val_custom_f1: 0.5639 - val_weighted_custom_f1: 0.5663\n",
            "Epoch 91/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.4990 - custom_f1: 0.6864 - weighted_custom_f1: 0.6891 - val_loss: 1.7821 - val_custom_f1: 0.5580 - val_weighted_custom_f1: 0.5613\n",
            "Epoch 92/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5055 - custom_f1: 0.6851 - weighted_custom_f1: 0.6891 - val_loss: 1.7520 - val_custom_f1: 0.5430 - val_weighted_custom_f1: 0.5457\n",
            "Epoch 93/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5002 - custom_f1: 0.6825 - weighted_custom_f1: 0.6874 - val_loss: 1.7287 - val_custom_f1: 0.5534 - val_weighted_custom_f1: 0.5569\n",
            "Epoch 94/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.4901 - custom_f1: 0.6900 - weighted_custom_f1: 0.6932 - val_loss: 1.7368 - val_custom_f1: 0.5410 - val_weighted_custom_f1: 0.5435\n",
            "Epoch 95/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.5085 - custom_f1: 0.6796 - weighted_custom_f1: 0.6841 - val_loss: 1.6746 - val_custom_f1: 0.5395 - val_weighted_custom_f1: 0.5421\n",
            "Epoch 96/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.5041 - custom_f1: 0.6796 - weighted_custom_f1: 0.6855 - val_loss: 1.8168 - val_custom_f1: 0.5441 - val_weighted_custom_f1: 0.5470\n",
            "Epoch 97/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.4871 - custom_f1: 0.6898 - weighted_custom_f1: 0.6949 - val_loss: 1.9179 - val_custom_f1: 0.5613 - val_weighted_custom_f1: 0.5645\n",
            "Epoch 98/100\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.4796 - custom_f1: 0.6972 - weighted_custom_f1: 0.7005 - val_loss: 1.8059 - val_custom_f1: 0.5473 - val_weighted_custom_f1: 0.5496\n",
            "Epoch 99/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.4833 - custom_f1: 0.6947 - weighted_custom_f1: 0.6978 - val_loss: 1.8588 - val_custom_f1: 0.5553 - val_weighted_custom_f1: 0.5581\n",
            "Epoch 100/100\n",
            "164/164 [==============================] - 0s 1ms/step - loss: 0.4772 - custom_f1: 0.6973 - weighted_custom_f1: 0.7036 - val_loss: 1.8452 - val_custom_f1: 0.5605 - val_weighted_custom_f1: 0.5625\n"
          ]
        }
      ],
      "source": [
        "params = {}\n",
        "\n",
        "\n",
        "pipe_all = Pipeline(steps=[\n",
        "                       # ('replace',mis_replace),\n",
        "                       ('scale', stdscales),\n",
        "                       ('tensor',XTransform()),\n",
        "                       ('model',new_estimator)\n",
        "                      ])\n",
        "\n",
        "\n",
        "grid = GridSearchCV(pipe_all,params,\n",
        "                    cv=2,\n",
        "                    n_jobs=-1,\n",
        "                    scoring= scoring,\n",
        "                    return_train_score=True,\n",
        "                    refit='f1',\n",
        "                    verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "results = grid.fit(X,\n",
        "                   y,\n",
        "                   # model__batch_size=2048,\n",
        "                   model__sample_weight=weights\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "-DfYAoxFitYy"
      },
      "outputs": [],
      "source": [
        "# Run the pipeline and pass the transformed data to be fit.\n",
        "best = results.best_estimator_\n",
        "X_scaled = best.named_steps['scale'].fit_transform(X)\n",
        "X_trans = best.named_steps['tensor'].fit_transform(X_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "oxnGmQHxitYy",
        "outputId": "74b46873-3f0f-4f9d-c014-b1660eea9c76"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_accuracy</th>\n",
              "      <th>split1_test_accuracy</th>\n",
              "      <th>mean_test_accuracy</th>\n",
              "      <th>std_test_accuracy</th>\n",
              "      <th>rank_test_accuracy</th>\n",
              "      <th>split0_train_accuracy</th>\n",
              "      <th>split1_train_accuracy</th>\n",
              "      <th>mean_train_accuracy</th>\n",
              "      <th>std_train_accuracy</th>\n",
              "      <th>split0_test_precision</th>\n",
              "      <th>split1_test_precision</th>\n",
              "      <th>mean_test_precision</th>\n",
              "      <th>std_test_precision</th>\n",
              "      <th>rank_test_precision</th>\n",
              "      <th>split0_train_precision</th>\n",
              "      <th>split1_train_precision</th>\n",
              "      <th>mean_train_precision</th>\n",
              "      <th>std_train_precision</th>\n",
              "      <th>split0_test_recall</th>\n",
              "      <th>split1_test_recall</th>\n",
              "      <th>mean_test_recall</th>\n",
              "      <th>std_test_recall</th>\n",
              "      <th>rank_test_recall</th>\n",
              "      <th>split0_train_recall</th>\n",
              "      <th>split1_train_recall</th>\n",
              "      <th>mean_train_recall</th>\n",
              "      <th>std_train_recall</th>\n",
              "      <th>split0_test_f1</th>\n",
              "      <th>split1_test_f1</th>\n",
              "      <th>mean_test_f1</th>\n",
              "      <th>std_test_f1</th>\n",
              "      <th>rank_test_f1</th>\n",
              "      <th>split0_train_f1</th>\n",
              "      <th>split1_train_f1</th>\n",
              "      <th>mean_train_f1</th>\n",
              "      <th>std_train_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.214009</td>\n",
              "      <td>0.199316</td>\n",
              "      <td>0.251523</td>\n",
              "      <td>0.006333</td>\n",
              "      <td>{}</td>\n",
              "      <td>0.76777</td>\n",
              "      <td>0.770374</td>\n",
              "      <td>0.769072</td>\n",
              "      <td>0.001302</td>\n",
              "      <td>1</td>\n",
              "      <td>0.850184</td>\n",
              "      <td>0.856541</td>\n",
              "      <td>0.853362</td>\n",
              "      <td>0.003179</td>\n",
              "      <td>0.659264</td>\n",
              "      <td>0.660149</td>\n",
              "      <td>0.659706</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>1</td>\n",
              "      <td>0.755285</td>\n",
              "      <td>0.761655</td>\n",
              "      <td>0.75847</td>\n",
              "      <td>0.003185</td>\n",
              "      <td>0.740074</td>\n",
              "      <td>0.739246</td>\n",
              "      <td>0.73966</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>1</td>\n",
              "      <td>0.878676</td>\n",
              "      <td>0.884145</td>\n",
              "      <td>0.881411</td>\n",
              "      <td>0.002734</td>\n",
              "      <td>0.790695</td>\n",
              "      <td>0.792593</td>\n",
              "      <td>0.791644</td>\n",
              "      <td>0.000949</td>\n",
              "      <td>1</td>\n",
              "      <td>0.864448</td>\n",
              "      <td>0.869872</td>\n",
              "      <td>0.86716</td>\n",
              "      <td>0.002712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time params  \\\n",
              "0      14.214009      0.199316         0.251523        0.006333     {}   \n",
              "\n",
              "   split0_test_accuracy  split1_test_accuracy  mean_test_accuracy  \\\n",
              "0               0.76777              0.770374            0.769072   \n",
              "\n",
              "   std_test_accuracy  rank_test_accuracy  split0_train_accuracy  \\\n",
              "0           0.001302                   1               0.850184   \n",
              "\n",
              "   split1_train_accuracy  mean_train_accuracy  std_train_accuracy  \\\n",
              "0               0.856541             0.853362            0.003179   \n",
              "\n",
              "   split0_test_precision  split1_test_precision  mean_test_precision  \\\n",
              "0               0.659264               0.660149             0.659706   \n",
              "\n",
              "   std_test_precision  rank_test_precision  split0_train_precision  \\\n",
              "0            0.000442                    1                0.755285   \n",
              "\n",
              "   split1_train_precision  mean_train_precision  std_train_precision  \\\n",
              "0                0.761655               0.75847             0.003185   \n",
              "\n",
              "   split0_test_recall  split1_test_recall  mean_test_recall  std_test_recall  \\\n",
              "0            0.740074            0.739246           0.73966         0.000414   \n",
              "\n",
              "   rank_test_recall  split0_train_recall  split1_train_recall  \\\n",
              "0                 1             0.878676             0.884145   \n",
              "\n",
              "   mean_train_recall  std_train_recall  split0_test_f1  split1_test_f1  \\\n",
              "0           0.881411          0.002734        0.790695        0.792593   \n",
              "\n",
              "   mean_test_f1  std_test_f1  rank_test_f1  split0_train_f1  split1_train_f1  \\\n",
              "0      0.791644     0.000949             1         0.864448         0.869872   \n",
              "\n",
              "   mean_train_f1  std_train_f1  \n",
              "0        0.86716      0.002712  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(results.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YToi6f5HitYy",
        "outputId": "8826b3e7-7c67-4039-cf52-97271a383994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "204/204 [==============================] - 0s 672us/step\n",
            "204/204 [==============================] - 0s 673us/step\n",
            "Accuracy: 0.8765701593137255\n",
            "Precision: 0.9087134854485702\n",
            "Recall: 0.8765701593137255\n",
            "F1 Score: 0.8856501453981707\n",
            "AUC Score: 0.9390410320981565\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAwUlEQVR4nO3dd3xUVf7/8fekh0CCtBCSAKFJU0ooAiKCdBbhuxZsCK66YqWs7g/EFUEU7AgKKiCoi8qqwFoQCSqdRSlBJPQQQ0kIoSShpM79/REZjEmGScjMnZm8no/HPB73nnvvzGeuyLw5995zLIZhGAIAAPASPmYXAAAAUJEINwAAwKsQbgAAgFch3AAAAK9CuAEAAF6FcAMAALwK4QYAAHgVP7MLcDWr1apjx46pWrVqslgsZpcDAAAcYBiGsrKyVK9ePfn42O+bqXTh5tixY4qOjja7DAAAUA6HDx9WVFSU3X0qXbipVq2apMKTExoaanI1AADAEZmZmYqOjrb9jttT6cLNxUtRoaGhhBsAADyMI7eUcEMxAADwKoQbAADgVQg3AADAqxBuAACAVyHcAAAAr0K4AQAAXoVwAwAAvArhBgAAeBXCDQAA8CqEGwAA4FVMDTdr167V4MGDVa9ePVksFi1btuyyx6xZs0axsbEKCgpSo0aN9M477zi/UAAA4DFMDTfnzp1TmzZt9NZbbzm0/6FDhzRw4EB1795d27dv19NPP60nnnhCX3zxhZMrBQAAnsLUiTMHDBigAQMGOLz/O++8o/r162vGjBmSpBYtWmjLli169dVXdcsttzipSscUWA2lZFyQJEVdVcXUWgAAqMw86p6bTZs2qW/fvkXa+vXrpy1btigvL6/EY3JycpSZmVnk5Qwnz+Xo+pd+1A0v/+iU9wcAAI7xqHCTmpqq8PDwIm3h4eHKz89Xenp6icdMmzZNYWFhtld0dLQrSgUAACbxqHAjSRaLpci6YRgltl80YcIEZWRk2F6HDx92eo0AAMA8pt5zU1Z169ZVampqkba0tDT5+fmpZs2aJR4TGBiowMBAV5QHAADcgEf13HTp0kVxcXFF2lauXKkOHTrI39/fpKoAAIA7MTXcnD17VvHx8YqPj5dU+Kh3fHy8kpOTJRVeUrr33ntt+48aNUq//fabxo0bp927d+v999/X/Pnz9eSTT5pRPgAAcEOmXpbasmWLevbsaVsfN26cJGnEiBFauHChUlJSbEFHkmJiYrR8+XKNHTtWb7/9turVq6eZM2ea/hg4AABwH6aGmxtvvNF2Q3BJFi5cWKytR48e2rZtmxOrAgAAnsyj7rkBAAC4HMINAADwKoQbAADgVQg3AADAqxBuAACAVyHcAAAAr0K4AQAAXoVw4wEMw9B/fj6s4fM36+ekU2aXAwCAW/OoiTMro6T0c/rn57/op99DTWT1YHVsWMPkqgAAcF+EGze29bdTuu2dTbL+YRDnlIxs8woCAMADcFnKTX39yzHd/u7/bMGmVb1QSdKafSf04540EysDAMC9EW5McC4nX1Zr6XNqfbblsB77eLsKrIZaR4Zq6zO9i2zfk5rl7BIBAPBYXJZyEcMwdCIrRwdOnNVdczerU8MaevGvrWUY0rr96QoL9teGA+k6cvqC7f6a7k1rad6IDgr089X7Izuq84vfS5JmrNqne7s0kK+PRfGHz6h53Wo6lH5OUVdV0ZakU4pteJUCfH1UvUqAmV8ZAABTEG5cZPj8n7T+QLpt/aekU+r9+tpS929VL1QLRnaUn29h51p4aJBqhgTo5Llc5eRb1WrSd5f9zMk3t9KIrg2vuHYAADwJl6VcwGo1igQbR3zxcFdbsLlo9t3ty/Qek77cpVEfbVVOfkGZjgMAwJPRc+MCX+9MKdP+cWNvUJC/b7H2zo1qlnpMoJ+PggN8deZ8XpH2FbtSNfTtjfL1kQ6dOKefJvZWSCD/2QEA3otfORd4Z/VBh/e9s1O0moZXK3V70vRBOp6ZrQUbkjSuTzNZLJK/b/EOuIbjv7Et707JtC23mvSdHuweo4mDWjpcEwAAnoRw4wIJfwgXf3Z9k1pq3+AqPdaziQL8HLtKGB4apPEDmtvdJ2n6IPV8dbUOpZ8rtm3uukMaP6CFfH0sDn0eAACehHDjZCeycoq1JU0fJEm6kFug4IDil58qylePX69//+83dWxYQ2HB/ur9+hrbtnX7T+jGq+s47bMBADALNxQ72Te/HLMtX9eohr58rJtt3ZnBRpKqBvppVI/Gim1wlZrUqarEFwfatp0+nyur1VB2HjcbAwC8Cz03TrZiV6okKaZWiD79exdTa/Hxsajn1bX1494TGrt4h8Yu3iFJeqhHIw1oHaG20dWLHWMYhk6ey1WtqoEurhYAgPIh3DjZtt/OSJJuaFrL3EJ+9+PeE8Xa3l2TqHfXJOqGZrXVo1lt7TxyRsvijxXZp25okE6dz9XMO9qpf+u6rioXAIAy47JUBTMkpWZkK+NCni7kFii3wCpJ6tncPe5vefOOtrqqin+J29buO6Hnv04oFmwkKTUzW7n5Vo3691ZnlwgAwBWh56aCGYZ03bTvi7V3aVz6GDWuNKRtpIa0jZQknT6Xq//GH9VzXyWU6T1eX7lXd3aur4iwYGeUCADAFbEYhlH6DI5eKDMzU2FhYcrIyFBoaGiFva/VauiOuf/Ttt9Oq8Aw9OezevEJKXd1NidfSenndC4nX51iakiSLBaLrFZDKxNSlZ1n1ZjF8cWOC/b3VYuIanrkxiaqVz1Y9aoH6atfUhRVPdhteqsAAJ6vLL/fhBsneHrpTn28Odm2HhEWpE0TbnLKZ7lKgdVQ46eXl+mYhfd15HFzAECFKMvvN/fcOMGfx8a7vol73Ex8JXx9LEqaPkhz7+2gayLDHDpm5IKftaGMc2oBAHCluOfGCXwsRdNNTO0QkyqpeH1ahqtPy/AibZ9vPaInPyt8rPy129roH78vS9Ld8zbr3/d31vVu8rQYAMD7EW6c4M+TGjSpXdWUOlzl1tgo3RobZVu/JTZK1zz3nbKy8yVJ98zfrKTpg7Q3NUtzVh/QrmOZWjn2BlksTP8AAKh4hBsnyC0oehtTiwjn3NvjzrY801tXP7PCtt7vjbXaezzLtj579UENbRepWlUDFOjn3JGaAQCVC/fcOEFaZnaR9airKt8j04F+vto3dYBt/Y/BRpJe+W6vuk3/QVc/s0I/7k1Tbr5Vq/emFZnBHACA8qDnxgm+35NWZL2yXn4J8PNR1UA/nc3JV9+W4Rrdu6kGzVxfbL/7FvxcZH3X5H4KCeSPJgCgfPgFgVPtfK6vsnLyFRpUOCpy0vRBWrvvhP6z5bC+/iWlxGNaTfpOs+9urwGt61baYAgAKD8uS8GpLBaLLdhcdEOz2nrrrvZKmj5I93VrKElqVa/ofUmPLNqmmAnLVWA19OvRDB05fd5VJQMAPByD+DlBw/Hf2JZ3PtdX1YJKnssJRR05fV7Xv/Rjqds/G9VF9aoHq1bVAPn5+Mj3TwMK5RVYtSrhuNYfSNdtHaJLnOUcAOCZyvL7zWUpJyPYOC7qqipKmj5I+49nqc8ba4ttv+2dTcXaJt/cSpO+3CVJqlU1QOlncyVJizYna/kT3dUioppyC6zKKzBU9ff7eE5k5ah6FX/5+9JxCQDeiJ4bJ/j0p2SNX7JT/+x/tR65sYlTPsPb/bgnTfctLLzReHCbevpqR/GZyq9U4osD5fPn4aQBAG6JuaXscEW4kaSM83kKq0KvTUX5cU+a1u1P14W8An3yU3KJ+7x+exs1rBWiv87e6PD77pjUV2HB/rr4v0F2nlXBAYy7AwDuhnBjh6vCDZyrwGroQNpZNa4dIr8SLi/tOHxGQ97eoPo1qqh9/epaFl/Y8/NYzyZ668cDl33/D/7WSdWD/dUiIlQBfly+AgCzEW7sINxg5a5U/f2jrWU+7q/tIvVkv6u193iWDp04p6Xbj+rRnk3Uv3VdJ1QJAPgjwo0dhBtcNGHJTv2cdErHM7KVlZN/Re/VtE5VvfjXa9SxYY0Kqg4A8EeEGzsIN7ic3SmZKrAa2nTwpF5YvrvMx//30W5qw2PoAFChCDd2EG5QXvPXH1KAn4/+2i5SIYF+2px4UsPe+5/dY/x8LFo+uruahVdzUZUA4J0IN3YQbuAM3+5M0cOLttnd5+vHr1fryDAXVQQA3qUsv988BgJUgAHXRChp+iDd26VBqfv8ZdZ6NX56uX7cm1bqPgCAK0fPDeBEr8ft08zv9xdr//jBzjIMqUVEqGqEBJhQGQB4Fi5L2UG4gRlW703TyAU/l7p97r0d1KdluAsrAgDPQrixg3ADM/1xUtXLmXN3e93QrLZCApkCDgAIN3YQbmCmtMxs7TiSoWsiw5Sbb9UNr5Q+C/ofTR3aWl0a11Tj2lWdXCEAuCfCjR2EG7ibbcmnlZR+TifP5io4wFfPLPvV7v7XRoVpycNdS5x2AgC8FeHGDsINPMHZnHwtWH9Ir8XtK3Wfe66rr6lDr3FhVQBgHsKNHYQbeJqM83nalJiuUf8ueRydpOmDVGA19MuRM4qsHqw6oUEurhAAnI9wYwfhBp7syx3H9MQn2y+7357n+yvI39cFFQGAaxBu7CDcwBtk5xWo+b9WXHa/EV0a6NnBreTrY3FBVQDgPIxQDHi5IH9f7X9hgG19zt3t9fEDnYvt98Gm39T46eWuLA0ATEfPDeBl5qw+qJdW7Cl1+0f3d9L1TWrJYqE3B4Dn4LKUHYQbVBaOXLr69/2d1bVxTflw2QqAm+OyFAAF+ftq7VM9bev+vsUDzD3zN+vvH211ZVkA4HT03ACVSIHV0DPLftUnPyUXaR90TYRevvVapnoA4La4LGUH4QYotHbfCd37/k/F2u/uXF9/uz6GqR4AuBXCjR2EG+CSRz/epm9+SSl1e5uoMCWdPK+B10TouZtbKtCPsXMAmINwYwfhBijuP1sO65+f/+LQvnd2qm+7rHXghQHMcQXAJQg3dhBuAPsu5BaoxbOXHyDwjwL9fLR7Sn+eugLgNIQbOwg3QNlYrYZeWL5b89cfkiTdeHVtrd57otT9ezSrreOZ2erTMlz3dYtRjZAAV5UKwIsRbuwg3ABXbueRDA1+a70iqwfr6JkLdvd9qEcjTRjQwkWVAfBWhBs7CDdAxcs4n6c2U1aWut1ikbY+00eSlJNfoIiwYFeVBsBLEG7sINwArvHv//2mZ5b9WuK265vU0r9LmAsLAEpDuLGDcAO4zulzuWr3fJzdfVaN66EmdRhTB4B9hBs7CDeA62Vm50mSEk+c09C3NxTbfl2jGvr0711cXRYAD8LcUgDcSmiQv0KD/NU2uroOTRuol2+5tsj2/yWe0u3vblLyyfPFjj11LlfHM7NltVaqf4cBuAKm99zMnj1br7zyilJSUtSqVSvNmDFD3bt3L3X/RYsW6eWXX9b+/fsVFham/v3769VXX1XNmjUd+jx6bgD38evRDP1l1vpi7W2iq+v076EmJ99aZNuiBzqrW5NarioRgJvwmMtSixcv1vDhwzV79mx169ZN7777rubNm6eEhATVr1+/2P7r169Xjx499MYbb2jw4ME6evSoRo0apaZNm2rp0qUOfSbhBnAvmdl5uva50p+0sifqqmBNGdJK1zWqqSoBTPoJeDOPCTedO3dW+/btNWfOHFtbixYtNHToUE2bNq3Y/q+++qrmzJmjgwcP2tpmzZqll19+WYcPH3boMwk3gPvJL7Dq5Llc3T1vsw6kndXEgS3UqHaImtSpqqtCAjRz1X7N+30QQXtqVwvUv/7SUje3qeeCqgG4kkeEm9zcXFWpUkWfffaZ/u///s/WPnr0aMXHx2vNmjXFjtm4caN69uyppUuXasCAAUpLS9Ptt9+uFi1a6J133inxc3JycpSTk2Nbz8zMVHR0NOEG8EAZF/LU9401Op6Zc/mdf9e1cU0tvK+TAvy4xRDwZGUJN6b146anp6ugoEDh4eFF2sPDw5WamlriMV27dtWiRYs0bNgwZWdnKz8/XzfffLNmzZpV6udMmzZNkydPrtDaAZgjLNhfm5/uXaQt/WyOOkxdVeoxGw+eVLNnvrWt+1ik/9e/uXq3DFdEWJCC/X1lsTAnFuBNTOu5OXbsmCIjI7Vx40Z16XLpEdAXXnhBH330kfbs2VPsmISEBPXu3Vtjx45Vv379lJKSoqeeekodO3bU/PnzS/wcem6AyiM7r0CTv9qlczkF+nLHMYePa1qnqmbd1U7N6/J3AuCuvPay1PDhw5Wdna3PPvvM1rZ+/Xp1795dx44dU0RExGU/l3tugMpl2fajemnFHrWqF6ZVu4/b3ffW2Cg92rOJYmqFuKg6AI7yiMtSAQEBio2NVVxcXJFwExcXpyFDhpR4zPnz5+XnV7RkX19fSVIlG4sQgIOGtovU0HaRRdryCqzKzivQN7+kaNYPB2yTf36+9Yg+33pEUuGlq04xNdS+fnUuWwEexi0eBX/nnXfUpUsXvffee5o7d6527dqlBg0aaMKECTp69Kg+/PBDSdLChQv14IMPaubMmbbLUmPGjJGPj482b97s0GfScwPgz77blaqHPtpa6vawYH/Vr1FF/320m3x8CDqAGTyi50aShg0bppMnT2rKlClKSUlR69attXz5cjVo0ECSlJKSouTkZNv+I0eOVFZWlt566y394x//UPXq1dWrVy+99NJLZn0FAF6gX6u6Spo+SIZhqM3klcrMzi+yPeNCnnYezVCjp5dLkibf3EojujY0oVIAjjB9hGJXo+cGgCMMw9BDH23VyoTS79MZ3KaeZgxrK196cwCn84gbis1CuAFQHqfO5Wrbb6f1wIdbim1b/Pfr1LmRY1PAACgfwo0dhBsAV+LYmQvqOv2HErfF1ArRrDvbqXVkmIurArwfs4IDgJPUqx6spOmDdPDFgbotNqrItkPp5/SXWev10aYkXcgtMKlCAPTcAMAV+H73cd3/wRY1rFlFSSfPF9teLyxISx7pprphQSZUB3gPLkvZQbgB4CxTvkrQ+xtKn+Dzi4e7Mm4OUE6EGzsINwCcLSs7Tz8nndLfFha/+ViS6oYGKTUzW//6S0v9rVtDwg7gAMKNHYQbAK6UnVegLtO+1+nzeXb3O/jiQB4pB+wg3NhBuAFgBsMw9I//7FB0jSo6cz5XH2z6rcT9Eqb0U5UAU8dXBdwS4cYOwg0Ad2AYhr7ZmaLHPt5ebNszg1qoRUSoujauySUr4HeEGzsINwDczYYD6bp7Xsnz4z0/pJVu6xCtIH9fF1cFuBfCjR2EGwDuasaqfZqxan+p29f9s6eia1RxYUWA+yDc2EG4AeAJ5q1L1NRvdpe4bUDrupo0uBVj56BSIdzYQbgB4CmsVkNZOfmauHSnvv4lpdj2OzvV1+SbWynAj8Hm4f2YfgEAvICPj0Vhwf566672+vBvnVQ3tGhPzSc/JavZM99qc+JJVbJ/pwJ20XMDAB7m250penjRthK3tY4M1eejunIDMrwOl6XsINwA8BZz1ybqheUl35cjSS/fcq1u7xjtwooA5yHc2EG4AeBN8gusWrErVV/vSNGKXaml7ndNZJgWPdhZoUH+LqwOqDiEGzsINwC8WWpGtrq//IPyCkr/q52pHuCJuKEYACqpumFB2v/CQO2bOkDVgkqexqHx08t1+NR5F1cGuA49NwBQCRw9c0Hdpv9QrH35E90V6O8ji6SGNUPkQ48O3BSXpewg3ACozEZ/ul3/jT922f1uaR+lqUNbKziAp67gHgg3dhBuAFR2VquhRk8vd2jf54e00vAuDZ1bEOAAwo0dhBsAuMRqNeTjY1HCsUx98lOyPvrfb8X2qRLgqw4Na2jhyI5ctoJpCDd2EG4A4PKWbT+qMYvji7WPH9BcD1wfIz9fnkeBaxFu7CDcAIBj8gqs2p58Rg9+uEUZF/KKbf/LtRG6o2N9Xd+0lgnVobIh3NhBuAGAsjEMQ+9vSNLzXyeUus+6f/ZUdI0qLqwKlQ3hxg7CDQCUX26+VS8u363jmdn69tfiIyJP++s1urNTfRMqg7cj3NhBuAGAitNw/Dcltlss0tzhHXR901pM4okKQbixg3ADABWrwGrotZV7NXv1wVL3+c9DXdQppoYLq4K3IdzYQbgBAOf59KdkrUw4rh/2pBXbFhEWpI8fvE4xtUJMqAyejnBjB+EGAFwj43yehry9Xkkni89j9d9Hu6lNdHXXFwWPRbixg3ADAK61KuG4Hvl4m3LzrcW2/aNPMz14QyPuy8FlEW7sINwAgDly8gvUbfoPSj+bW+L2TRN6KSIs2MVVwVOU5febISYBAC4R6OerLc/00Z7n++vxXk2Kbe8y7Qd9t6v44+VAWdFzAwAwTfLJ8+o3Y60u5BUUaf/4gc7q2oSRj3EJl6XsINwAgPv5Yc9x/W3hlmLtW5/prZpVA02oCO6Gy1IAAI/Sq3m4dk3uV6w9duoqNRz/jeISjptQFTwVPTcAALcze/UBvbxib5G2a6PCNGlwS8U2YDDAyojLUnYQbgDAM1zILdC4/8QXm8OqQ4Or9NmoLrJYLCZVBjMQbuwg3ACAZzly+rxumbNRxzNzirRf36SW/v1AZ5OqgqsRbuwg3ACAZzp1Llftn48r1v7lY910bVR11xcElyLc2EG4AQDPZbUa+nFvmu7/oOiTVX4+Fn34t07q3KimfH24XOWNCDd2EG4AwDu8uHy33lubWKz918n9VDXQz4SK4Ew8Cg4A8HpPD2yhgy8O1D/7X11kpvHWk74zsSq4A8INAMBj+fpY9MiNTfTjkzfqlvZRtvaPNyebWBXMRrgBAHiF125vY1t+eulOPbpom4nVwEyEGwCA1/j68etty9/sTFHD8d/ovbUHVcluL630uKEYAOBVjp25oK7TfyjW3r1pLT3V72oeG/dQPC1lB+EGALzf2Zx8PfmfHVqxK7XE7Xun9legn6+Lq8KVINzYQbgBgMplx+EzGvL2hmLtf7+hkZ4e2MKEilAePAoOAMDv2kRXV9L0QTrwwoAi7e+tTdT+41kmVQVnItwAACoFP18fJU0fpBVjutva+ryxVhnn80ysCs5AuAEAVCrN64bqzTva2tbbTFmpDzclmVYPKh7hBgBQ6QxpG6mpQ1vb1p/97y41HP+NLuQWmFgVKkq5big+d+6cpk+fru+//15paWmyWq1FticmFp/rw11wQzEA4KL4w2c09E83G48f0FyjejQ2qSKUpiy/3+WaWeyBBx7QmjVrNHz4cEVERMhiYQZWAIDnaRtdXYemDVSPV1Yr+dR5SdL0b/fo6OkLev4PPTvwLOXqualevbq++eYbdevWzRk1ORU9NwCAkiSeOKter60p0ja2dzON7t3UpIrwR05/FPyqq65SjRo1ylUcAADuqFHtqtrxbN8ibW+s2qeer642pyCUW7nCzfPPP69nn31W58+fr+h6AAAwTVgVf+2bOkAv33qtre1Q+jk1HP8N81N5kHJdlmrXrp0OHiyciKxhw4by9/cvsn3bNvediZXLUgAAR5w8m6PYqauKtG19prdqVg00qaLKzek3FA8dOrQ8hwEA4DFqVg1U0vRBajj+G1tb7NRVevjGxnqq79Xy8eFhGnfF3FIAANhhtRpq8ewK5eQXHfYkbuwNahpezaSqKh+XTZy5detW7d69WxaLRS1btlS7du3K+1YuQ7gBAJTH/xJP6h//2aGjZy4Uaf/PQ13UKYaHbJzN6eEmLS1Nd9xxh1avXq3q1avLMAxlZGSoZ8+e+vTTT1W7du1yF+9shBsAwJVYlXBcD3y4pVj7r5P7qWpgue72gAOc/ij4448/rszMTO3atUunTp3S6dOn9euvvyozM1NPPPFEuYoGAMAT9G4Zrj3P91eDmlWKtLee9J2O/alXB+YoV89NWFiYVq1apY4dOxZp/+mnn9S3b1+dOXOmouqrcPTcAAAq0sgFP2n13hO29S8f66Zro6qbV5CXcnrPjdVqLfb4tyT5+/sXm2cKAABvtvC+Tpp3bwfb+s1vbVB2HhNwmqlc4aZXr14aPXq0jh07Zms7evSoxo4dq5tuuqnCigMAwBP0bhmu94bH2tab/2uFsrLzTKyocitXuHnrrbeUlZWlhg0bqnHjxmrSpIliYmKUlZWlWbNmVXSNAAC4vb6t6mpI23q29WueW6kLufTgmOGKHgWPi4vTnj17ZBiGWrZsqd69e1dkbU7BPTcAAGf617Jf9dH/fpMktYgI1beju5tckXdw+j03F/Xp00ePP/64nnjiiXIHm9mzZysmJkZBQUGKjY3VunXr7O6fk5OjiRMnqkGDBgoMDFTjxo31/vvvl+uzAQCoaFOGtFKj2iGSpN0pmTqbk29yRZWPww/kz5w5U3//+98VFBSkmTNn2t3X0cfBFy9erDFjxmj27Nnq1q2b3n33XQ0YMEAJCQmqX79+icfcfvvtOn78uObPn68mTZooLS1N+fn8wQEAuAeLxaKlD3dTmykrJRU+Ip4wpZ+qBDAGjqs4fFkqJiZGW7ZsUc2aNRUTE1P6G1osSkxMdOjDO3furPbt22vOnDm2thYtWmjo0KGaNm1asf1XrFihO+64Q4mJiapRw7HRIHNycpSTk2Nbz8zMVHR0NJelAABONf3bPXpnzUHb+oKRHdWzeR0TK/JsTrksdejQIdWsWdO2XNrL0WCTm5urrVu3qm/fvkXa+/btq40bN5Z4zJdffqkOHTro5ZdfVmRkpJo1a6Ynn3xSFy6UPmjStGnTFBYWZntFR0c7+I0BACi/8QOa685Ol35z7lv4s6Z+nWBiRZXHFd1zc1FBQYHi4+N1+vRph49JT09XQUGBwsPDi7SHh4crNTW1xGMSExO1fv16/frrr1q6dKlmzJihzz//XI8++mipnzNhwgRlZGTYXocPH3a4RgAArsS0v16r90deGgNn3vpDmvbtbhMrqhzKFW7GjBmj+fPnSyoMNjfccIPat2+v6OhorV69ukzvZbEUnTLeMIxibRdZrVZZLBYtWrRInTp10sCBA/X6669r4cKFpfbeBAYGKjQ0tMgLAABX6dU8XN//o4dt/d01iXpt5V4TK/J+5Qo3n3/+udq0aSNJ+uqrr5SUlKQ9e/ZozJgxmjhxokPvUatWLfn6+hbrpUlLSyvWm3NRRESEIiMjFRYWZmtr0aKFDMPQkSNHyvNVAABwusa1q2rbv/rY1mf9cMD2uDgqXrnCTXp6uurWrStJWr58uW677TY1a9ZM999/v3bu3OnQewQEBCg2NlZxcXFF2uPi4tS1a9cSj+nWrZuOHTums2fP2tr27dsnHx8fRUVFleerAADgEjVCArRj0qX7TP+17FceE3eScoWb8PBwJSQkqKCgQCtWrLCNcXP+/Hn5+vo6/D7jxo3TvHnz9P7772v37t0aO3askpOTNWrUKEmF98vce++9tv3vuusu1axZU/fdd58SEhK0du1aPfXUU/rb3/6m4ODg8nwVAABcJizYv8g8VK0nfafT53JNrMg7lSvc3Hfffbr99tvVunVrWSwW9elT2NW2efNmNW/e3OH3GTZsmGbMmKEpU6aobdu2Wrt2rZYvX64GDRpIklJSUpScnGzbv2rVqoqLi9OZM2fUoUMH3X333Ro8ePBlx90BAMBd9G4ZrnuuuzSWW7vn42S1lnuyAJSg3NMvfP755zp8+LBuu+022yWhDz74QNWrV9eQIUMqtMiKxPQLAAB3cM+8zVp/IN22vv+FAfL3rZCHmL1SWX6/r2huKU9EuAEAuItn//urPtx06cbixBcHysen5CeGK7uy/H6bOv0CAACV2ZQhrSXJFnCe+HS73rqrvZkleQVTp18wAz03AAB30/jp5Sr4/b6b7//RQ41rVzW5IvfDZSk7CDcAAHdz7MwFdZ3+g209afogE6txT06ZWwoAADhHverBuqPjpXmo9qZmmViN5ytXuLn11ls1ffr0Yu2vvPKKbrvttisuCgCAymbykFa25X4z1iq/wGpiNZ6tXOFmzZo1GjSoeJdZ//79tXbt2isuCgCAyibQz1cjuza0rTeZ+K2+/uWYeQV5sHKFm7NnzyogIKBYu7+/vzIzM6+4KAAAKqP/17+5alUNtK0/vcSxKY1QVLnCTevWrbV48eJi7Z9++qlatmx5xUUBAFAZBQf4asszvfXu8FhJUmZ2vhqO/8bkqjyPw+Pc/NG//vUv3XLLLTp48KB69eolSfr+++/1ySef6LPPPqvQAgEAqGz6tgxXj2a1tWbfCUnSR5uSNLxLQ3OL8iDl6rm5+eabtWzZMh04cECPPPKI/vGPf+jIkSNatWqVhg4dWsElAgBQuVgsFr0/sqNt/V//3aXjmdkmVuRZGOcGAAA3tetYhgbNXG9br8zj37hknJszZ85o3rx5evrpp3Xq1ClJ0rZt23T06NHyviUAAPiDVvXC1LxuNdv6wRNnTazGc5Qr3Pzyyy9q1qyZXnrpJb3yyis6c+aMJGnp0qWaMGFCRdYHAECltuSRrrblm15bo0p2waVcyhVuxo0bp5EjR2r//v0KCgqytQ8YMIBxbgAAqEBVAvw06852tvVp3+4xsRrPUK5w8/PPP+uhhx4q1h4ZGanU1NQrLgoAAFwyuE091QwpHF/uvbWJ2nH4jLkFublyhZugoKASB+vbu3evateufcVFAQCAor54+NLlqSFvb9Dpc7kmVuPeyhVuhgwZoilTpigvL09S4SNrycnJGj9+vG655ZYKLRAAAEgNa4XopVuusa23ez5OF3ILTKzIfZUr3Lz66qs6ceKE6tSpowsXLqhHjx5q0qSJqlWrphdeeKGiawQAAJKGdayvcX2a2dZbPLvCxGrcV7lGKA4NDdX69ev1ww8/aNu2bbJarWrfvr169+5d0fUBAIA/eOKmpkrJyNYnPyVLkuISjqtPy3CTq3IvZR7ELz8/X0FBQYqPj1fr1q2dVZfTMIgfAMAb/HHOqUPTBspisZhYjfM5dRA/Pz8/NWjQQAUFXOcDAMAs79zT3ra861jxh3wqs3Ldc/PMM89owoQJtpGJAQCAa/VvHWFbfuijrSZW4n7Kdc/NzJkzdeDAAdWrV08NGjRQSEhIke3btm2rkOIAAEDpHr6xseasPqijZy7orR/267FeTc0uyS2UK9wMHTpUFouFIaABADDRuD7NNGf1QUnSqyv3aXiXhgoL9je5KvOVKdycP39eTz31lJYtW6a8vDzddNNNmjVrlmrVquWs+gAAQCn8fX20Y1JftZm8UpK0fGeK7uxU3+SqzFeme24mTZqkhQsXatCgQbrzzju1atUqPfzww86qDQAAXEZYsL/a168uSZqwZKcKrFxVKVO4WbJkiebPn6/33ntPb775pr755hstW7aMJ6cAADDR2D8M7LdgwyETK3EPZQo3hw8fVvfu3W3rnTp1kp+fn44dO1bhhQEAAMd0b3ppXsep3+w2sRL3UKZwU1BQoICAgCJtfn5+ys/Pr9CiAABA2bxy67W25XX7T5hYifnKNEKxj4+PBgwYoMDAQFvbV199pV69ehV5HHzJkiUVW2UFYoRiAIC3+uOoxftfGCB/33INZ+eWnDZC8YgRI1SnTh2FhYXZXvfcc4/q1atXpA0AALjeq7e1sS03nfhtpR2ypUyPgi9YsMBZdQAAgCt0a2yUPttyWJsPFc4gsGhzsu65roHJVbme9/RXAQAALX6oi6oGFvZdPLPsV5OrMQfhBgAALzPrrna25fwCq4mVmINwAwCAl7nhD4+GL9yYZF4hJiHcAADgZXx9LLblyjjuDeEGAAAv9P/6N7ctp2Vmm1iJ6xFuAADwQqN6NLItf77tiImVuB7hBgAAL2SxWNStSU1J0ssr9ppcjWsRbgAA8FKx9a+yLWfnVZ5Jrgk3AAB4qQduuHRpavq3e0ysxLUINwAAeKnQIH81r1tNUuEj4edyKsdE14QbAAC82MRBLWzL076tHI+FE24AAPBi3ZvWVouIwlm0//2/ZJOrcQ3CDQAAXu6+bg1ty3mVYDoGwg0AAF5uaNtI2/IvRzJMrMQ1CDcAAHi5AL9LP/dPfLLdxEpcg3ADAEAl0DmmhiTp6JkLOu7l0zEQbgAAqATeuSfWttz5xe9NrMT5CDcAAFQCV4UEqEujmrb1U+dyTazGuQg3AABUEu+P7GhbHrs43rxCnIxwAwBAJREc4KvGtUMkSWv2nTC5Guch3AAAUIm8fGsb2/KmgydNrMR5CDcAAFQisQ0uzRS+/fBpEytxHsINAACVTO8WdSRJW5MINwAAwAtUrxIgSfp+T5ryvXA6BsINAACVzJC29WzL7Z+PM7ES5yDcAABQyXRvWtu2nJmdr62/nTKxmopHuAEAoBLaO7W/bXnE+z+bWEnFI9wAAFAJBfr5avpfr5Eknc3J18ETZ02uqOIQbgAAqKSGdYy2LY/7zw4TK6lYhBsAACopi8Wivi3DJUk7Dp8xt5gKRLgBAKASe6RnE9vyd7tSTayk4hBuAACoxNpGV7ctP/TRVvMKqUCEGwAAKrnuTWvZlnPyC0yspGIQbgAAqOTmj+hoW044lmliJRWDcAMAQCUX4HcpDkxYstPESioG4QYAAOihHo0kSXtSs2QYhsnVXBnTw83s2bMVExOjoKAgxcbGat26dQ4dt2HDBvn5+alt27bOLRAAgEpg+HUNbMvf704zsZIrZ2q4Wbx4scaMGaOJEydq+/bt6t69uwYMGKDk5GS7x2VkZOjee+/VTTfd5KJKAQDwblFXVVFIgK8k6a0fD5hczZUxNdy8/vrruv/++/XAAw+oRYsWmjFjhqKjozVnzhy7xz300EO666671KVLFxdVCgCA97u/e+GlqfjDZzz6qSnTwk1ubq62bt2qvn37Fmnv27evNm7cWOpxCxYs0MGDBzVp0iSHPicnJ0eZmZlFXgAAoLi/dWtoWx48a715hVwh08JNenq6CgoKFB4eXqQ9PDxcqaklj5C4f/9+jR8/XosWLZKfn59DnzNt2jSFhYXZXtHR0Zc/CACASqh6lQDboH77jnvuRJqm31BssViKrBuGUaxNkgoKCnTXXXdp8uTJatasmcPvP2HCBGVkZNhehw8fvuKaAQDwVv+vf3PbcoHVM5+acqz7wwlq1aolX1/fYr00aWlpxXpzJCkrK0tbtmzR9u3b9dhjj0mSrFarDMOQn5+fVq5cqV69ehU7LjAwUIGBgc75EgAAeJk20WG25T2pmWpVL8zO3u7JtJ6bgIAAxcbGKi4urkh7XFycunbtWmz/0NBQ7dy5U/Hx8bbXqFGjdPXVVys+Pl6dO3d2VekAAHitKgGX+j02HEg3sZLyM63nRpLGjRun4cOHq0OHDurSpYvee+89JScna9SoUZIKLykdPXpUH374oXx8fNS6desix9epU0dBQUHF2gEAQPk1qFlFv508r7d/PKi/39DY7HLKzNRwM2zYMJ08eVJTpkxRSkqKWrdureXLl6tBg8KBhFJSUi475g0AAKhY/VvX1btrEpVxIc/sUsrFYnj6GMtllJmZqbCwMGVkZCg0NNTscgAAcDt7U7PUb8ZaSVLS9EEmV1OoLL/fpj8tBQAA3Ev9GlVsy5543w3hBgAAFBH8+zQMkrRyV8ljz7kzwg0AACjmukY1JEm7U7NMrqTsCDcAAKCYAa0jJEk/HTplciVlR7gBAADF9Gl5aUDdrb95VsAh3AAAgGLqVQ+2LU/9ZreJlZQd4QYAAJRo4DV1JUnbk8+YW0gZEW4AAECJxva+NFF1Tn6BiZWUDeEGAACUqHHtqrblHYczTKykbAg3AACgRD4+FlUNLJyp6fZ3N5lcjeMINwAAoFSD2xQ+Et6odojJlTiOcAMAAEp1V6fCyawTT5yTp0xHSbgBAACliq5x6ZHwszn5JlbiOMINAAAoVfUqAbZlT5lEk3ADAADsCg0qvKl41L+3mVyJYwg3AADArvuvb2R2CWVCuAEAAHbdEhspSfL3tZhciWMINwAAwK5gf19JUl6BIavV/Z+YItwAAAC7AvwuxYXcAquJlTiGcAMAAOwK+r3nRpIOpJ01sRLHEG4AAIBd/r6X4sL25NMmVuIYwg0AALishjWrSCqcb8rdEW4AAMBlXRNVXZKUmpFtbiEOINwAAIDL8v+9x2bV7jSTK7k8wg0AALismlULp2HYnZJpciWXR7gBAACXNejaerbljAt5JlZyeYQbAABwWW2iwmzL+49nmVjJ5RFuAADAZVksFjWtU1WStONIhsnV2Ee4AQAADsnMLrwclX42x+RK7CPcAAAAh/S8uo4kaf3+dJMrsY9wAwAAHNKgZogkyc/NZwcn3AAAAIc0j6gmSdqefMbcQi6DcAMAABxSM6RwrJtqQX4mV2If4QYAADjkqiqF4SavwGpyJfYRbgAAgEMC/QpjQ16BYXIl9hFuAACAQ/x9C2NDgdVw694bwg0AAHDIH++1ST513sRK7CPcAAAAh/j5+uiqKv6SpM+3HjG5mtIRbgAAgMNOny8cpTgr230nzyTcAAAAh42+qakkacOBkyZXUjrCDQAAKLPqv1+eckeEGwAA4LBrIsMkSVar+z4OTrgBAAAOC/h9rJucfB4FBwAAXuBiuNmTmuW2vTeEGwAA4LBm4dVsyxkX3POJKcINAABwWI3fJ8+UpFw3HaWYcAMAAMok2N9XkpTrpvfdEG4AAECZXLzvZndKpsmVlIxwAwAAyuTivTZbfjttciUlI9wAAIAyufHq2pIkPx+LyZWUjHADAADKpFW9UEnSil2pJldSMsINAAAoE19LYY/NkVMXTK6kZIQbAABQJq1/n4IhyN89Y4R7VgUAANxWTK0QSZIP99wAAABvEPT7ODdnzjNCMQAA8AIXw40kJZ44a2IlJSPcAACAMqldLdC2fM+8zSZWUjLCDQAAKLOhbetJko5lZJtcSXGEGwAAUGbj+lxtW16y7YiJlRRHuAEAAGVWv2YV2/LafSdMrKQ4wg0AACiXAa3rSpKqBfmbXElRhBsAAFAu10ZVlyT9sCfN3EL+hHADAADKpUZIYY/N8Uz3uqmYcAMAAMqlf+sISVK+1dCF3AKTq7mEcAMAAMqlWqCfbfmgGw3mR7gBAADl4uNjUVhw4aWpU+dyTa7mEsINAAAot4ujFX+wMcncQv6AcAMAAMrNMAxJ0vbDZ8wt5A8INwAAoNxGdouRxGUpAADgJXpeXdu2nJ3nHk9MmR5uZs+erZiYGAUFBSk2Nlbr1q0rdd8lS5aoT58+ql27tkJDQ9WlSxd99913LqwWAAD8UWT1YNty4olzJlZyianhZvHixRozZowmTpyo7du3q3v37howYICSk5NL3H/t2rXq06ePli9frq1bt6pnz54aPHiwtm/f7uLKAQCAJFksFtvy2Zx8Eyu5xGJcvBPIBJ07d1b79u01Z84cW1uLFi00dOhQTZs2zaH3aNWqlYYNG6Znn322xO05OTnKycmxrWdmZio6OloZGRkKDQ29si8AAAA08M11SkjJ1Ft3tdNfrq3nlM/IzMxUWFiYQ7/fpvXc5ObmauvWrerbt2+R9r59+2rjxo0OvYfValVWVpZq1KhR6j7Tpk1TWFiY7RUdHX1FdQMAgKIC/QvjxIQlO02upJBp4SY9PV0FBQUKDw8v0h4eHq7U1FSH3uO1117TuXPndPvtt5e6z4QJE5SRkWF7HT58+IrqBgAARdUNDZIkBfr5mlxJIb/L7+Jcf7xWJxU+L//ntpJ88skneu655/Tf//5XderUKXW/wMBABQYGXnGdAACgZPdc10Df/pqqqoGVPNzUqlVLvr6+xXpp0tLSivXm/NnixYt1//3367PPPlPv3r2dWSYAALiMakGFcSIn32pyJYVMuywVEBCg2NhYxcXFFWmPi4tT165dSz3uk08+0ciRI/Xxxx9r0KBBzi4TAABcxsXLUSkZ2SZXUsjUy1Ljxo3T8OHD1aFDB3Xp0kXvvfeekpOTNWrUKEmF98scPXpUH374oaTCYHPvvffqzTff1HXXXWfr9QkODlZYWJhp3wMAgMosPPTS7R+Z2XkKDfI3sRqTx7kZNmyYZsyYoSlTpqht27Zau3atli9frgYNGkiSUlJSiox58+677yo/P1+PPvqoIiIibK/Ro0eb9RUAAKj0qlcJsC3PWX3QxEoKmTrOjRnK8pw8AABwTL831mrv8SxFVg/WhvG9Kvz9PWKcGwAA4D3G9mkqSTp65oKsVnP7TQg3AADgil3f9NIEmhsPnjSxEsINAACoAFUDLz2jtOW3UyZWQrgBAAAVpHHtEElSAZelAACAN7jx6sIZA7Ylnza1DsINAACoENWDC8e32XCAe24AAIAXGNymnmpXC1R0jWBT6zB94kwAAOAdGtYK0c8TzZ/zkZ4bAADgVQg3AADAqxBuAACAVyHcAAAAr0K4AQAAXoVwAwAAvArhBgAAeBXCDQAA8CqEGwAA4FUINwAAwKsQbgAAgFch3AAAAK9CuAEAAF6FcAMAALyKn9kFuJphGJKkzMxMkysBAACOuvi7ffF33J5KF26ysrIkSdHR0SZXAgAAyiorK0thYWF297EYjkQgL2K1WnXs2DFVq1ZNFoulQt87MzNT0dHROnz4sEJDQyv0vXEJ59k1OM+uwXl2Hc61azjrPBuGoaysLNWrV08+Pvbvqql0PTc+Pj6Kiopy6meEhobyP44LcJ5dg/PsGpxn1+Fcu4YzzvPlemwu4oZiAADgVQg3AADAqxBuKlBgYKAmTZqkwMBAs0vxapxn1+A8uwbn2XU4167hDue50t1QDAAAvBs9NwAAwKsQbgAAgFch3AAAAK9CuAEAAF6FcFNGs2fPVkxMjIKCghQbG6t169bZ3X/NmjWKjY1VUFCQGjVqpHfeecdFlXq2spznJUuWqE+fPqpdu7ZCQ0PVpUsXfffddy6s1nOV9c/zRRs2bJCfn5/atm3r3AK9RFnPc05OjiZOnKgGDRooMDBQjRs31vvvv++iaj1XWc/zokWL1KZNG1WpUkURERG67777dPLkSRdV65nWrl2rwYMHq169erJYLFq2bNlljzHld9CAwz799FPD39/fmDt3rpGQkGCMHj3aCAkJMX777bcS909MTDSqVKlijB492khISDDmzp1r+Pv7G59//rmLK/csZT3Po0ePNl566SXjp59+Mvbt22dMmDDB8Pf3N7Zt2+biyj1LWc/zRWfOnDEaNWpk9O3b12jTpo1rivVg5TnPN998s9G5c2cjLi7OOHTokLF582Zjw4YNLqza85T1PK9bt87w8fEx3nzzTSMxMdFYt26d0apVK2Po0KEurtyzLF++3Jg4caLxxRdfGJKMpUuX2t3frN9Bwk0ZdOrUyRg1alSRtubNmxvjx48vcf9//vOfRvPmzYu0PfTQQ8Z1113ntBq9QVnPc0latmxpTJ48uaJL8yrlPc/Dhg0znnnmGWPSpEmEGweU9Tx/++23RlhYmHHy5ElXlOc1ynqeX3nlFaNRo0ZF2mbOnGlERUU5rUZv40i4Met3kMtSDsrNzdXWrVvVt2/fIu19+/bVxo0bSzxm06ZNxfbv16+ftmzZory8PKfV6snKc57/zGq1KisrSzVq1HBGiV6hvOd5wYIFOnjwoCZNmuTsEr1Cec7zl19+qQ4dOujll19WZGSkmjVrpieffFIXLlxwRckeqTznuWvXrjpy5IiWL18uwzB0/Phxff755xo0aJArSq40zPodrHQTZ5ZXenq6CgoKFB4eXqQ9PDxcqampJR6Tmppa4v75+flKT09XRESE0+r1VOU5z3/22muv6dy5c7r99tudUaJXKM953r9/v8aPH69169bJz4+/OhxRnvOcmJio9evXKygoSEuXLlV6eroeeeQRnTp1ivtuSlGe89y1a1ctWrRIw4YNU3Z2tvLz83XzzTdr1qxZrii50jDrd5CemzKyWCxF1g3DKNZ2uf1LakdRZT3PF33yySd67rnntHjxYtWpU8dZ5XkNR89zQUGB7rrrLk2ePFnNmjVzVXleoyx/nq1WqywWixYtWqROnTpp4MCBev3117Vw4UJ6by6jLOc5ISFBTzzxhJ599llt3bpVK1as0KFDhzRq1ChXlFqpmPE7yD+/HFSrVi35+voW+1dAWlpasVR6Ud26dUvc38/PTzVr1nRarZ6sPOf5osWLF+v+++/XZ599pt69ezuzTI9X1vOclZWlLVu2aPv27XrsscckFf4IG4YhPz8/rVy5Ur169XJJ7Z6kPH+eIyIiFBkZqbCwMFtbixYtZBiGjhw5oqZNmzq1Zk9UnvM8bdo0devWTU899ZQk6dprr1VISIi6d++uqVOn0rNeQcz6HaTnxkEBAQGKjY1VXFxckfa4uDh17dq1xGO6dOlSbP+VK1eqQ4cO8vf3d1qtnqw851kq7LEZOXKkPv74Y66ZO6Cs5zk0NFQ7d+5UfHy87TVq1ChdffXVio+PV+fOnV1Vukcpz5/nbt266dixYzp79qytbd++ffLx8VFUVJRT6/VU5TnP58+fl49P0Z9AX19fSZd6FnDlTPsddOrtyl7m4qOG8+fPNxISEowxY8YYISEhRlJSkmEYhjF+/Hhj+PDhtv0vPgI3duxYIyEhwZg/fz6PgjugrOf5448/Nvz8/Iy3337bSElJsb3OnDlj1lfwCGU9z3/G01KOKet5zsrKMqKiooxbb73V2LVrl7FmzRqjadOmxgMPPGDWV/AIZT3PCxYsMPz8/IzZs2cbBw8eNNavX2906NDB6NSpk1lfwSNkZWUZ27dvN7Zv325IMl5//XVj+/bttkfu3eV3kHBTRm+//bbRoEEDIyAgwGjfvr2xZs0a27YRI0YYPXr0KLL/6tWrjXbt2hkBAQFGw4YNjTlz5ri4Ys9UlvPco0cPQ1Kx14gRI1xfuIcp65/nPyLcOK6s53n37t1G7969jeDgYCMqKsoYN26ccf78eRdX7XnKep5nzpxptGzZ0ggODjYiIiKMu+++2zhy5IiLq/YsP/74o92/b93ld9BiGPS/AQAA78E9NwAAwKsQbgAAgFch3AAAAK9CuAEAAF6FcAMAALwK4QYAAHgVwg0AAPAqhBsAAOBVCDcAIKlhw4aaMWOGbd1isWjZsmWm1QOg/Ag3AEw3cuRIWSwWWSwW+fn5qX79+nr44Yd1+vRps0sD4IEINwDcQv/+/ZWSkqKkpCTNmzdPX331lR555BGzywLggQg3ANxCYGCg6tatq6ioKPXt21fDhg3TypUrbdsXLFigFi1aKCgoSM2bN9fs2bOLHH/kyBHdcccdqlGjhkJCQtShQwdt3rxZknTw4EENGTJE4eHhqlq1qjp27KhVq1a59PsBcB0/swsAgD9LTEzUihUr5O/vL0maO3euJk2apLfeekvt2rXT9u3b9eCDDyokJEQjRozQ2bNn1aNHD0VGRurLL79U3bp1tW3bNlmtVknS2bNnNXDgQE2dOlVBQUH64IMPNHjwYO3du1f169c386sCcALCDQC38PXXX6tq1aoqKChQdna2JOn111+XJD3//PN67bXX9Ne//lWSFBMTo4SEBL377rsaMWKEPv74Y504cUI///yzatSoIUlq0qSJ7b3btGmjNm3a2NanTp2qpUuX6ssvv9Rjjz3mqq8IwEUINwDcQs+ePTVnzhydP39e8+bN0759+/T444/rxIkTOnz4sO6//349+OCDtv3z8/MVFhYmSYqPj1e7du1swebPzp07p8mTJ+vrr7/WsWPHlJ+frwsXLig5Odkl3w2AaxFuALiFkJAQW2/LzJkz1bNnT02ePNnWszJ37lx17ty5yDG+vr6SpODgYLvv/dRTT+m7777Tq6++qiZNmig4OFi33nqrcnNznfBNAJiNcAPALU2aNEkDBgzQww8/rMjISCUmJuruu+8ucd9rr71W8+bN06lTp0rsvVm3bp1Gjhyp//u//5NUeA9OUlKSM8sHYCKelgLglm688Ua1atVKL774op577jlNmzZNb775pvbt26edO3dqwYIFtnty7rzzTtWtW1dDhw7Vhg0blJiYqC+++EKbNm2SVHj/zZIlSxQfH68dO3borrvust1sDMD7EG4AuK1x48Zp7ty56tevn+bNm6eFCxfqmmuuUY8ePbRw4ULFxMRIkgICArRy5UrVqVNHAwcO1DXXXKPp06fbLlu98cYbuuqqq9S1a1cNHjxY/fr1U/v27c38agCcyGIYhmF2EQAAABWFnhsAAOBVCDcAAMCrEG4AAIBXIdwAAACvQrgBAABehXADAAC8CuEGAAB4FcINAADwKoQbAADgVQg3AADAqxBuAACAV/n/hSlH5OGRwBEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_preds = results.predict(X)\n",
        "y_preds_proba =results.predict_proba(X)[:,1]\n",
        "generate_matrix(y, y_preds, y_preds_proba,_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6zUOJBpitYy",
        "outputId": "a2b616a0-9ad3-4f57-d974-ee4bf1370915"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;function create_model at 0x7f7c820f01f0&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=42\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=128\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.2\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tdropout_rate=0.001\n",
              "\tlearning_rate=0.005\n",
              "\toutput_bias=-4.19656855\n",
              "\tclass_weight=None\n",
              ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;function create_model at 0x7f7c820f01f0&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=42\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=128\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.2\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tdropout_rate=0.001\n",
              "\tlearning_rate=0.005\n",
              "\toutput_bias=-4.19656855\n",
              "\tclass_weight=None\n",
              ")</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KerasClassifier(\n",
              "\tmodel=<function create_model at 0x7f7c820f01f0>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=42\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=128\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.2\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tdropout_rate=0.001\n",
              "\tlearning_rate=0.005\n",
              "\toutput_bias=-4.19656855\n",
              "\tclass_weight=None\n",
              ")"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results.best_estimator_.named_steps['model']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTIQazvKitYy"
      },
      "source": [
        "## Saving Final Model and Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ifr3WnQitYy"
      },
      "outputs": [],
      "source": [
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "qiMhLZcMitYz",
        "outputId": "23e37779-6343-4436-e117-abf0d47abc83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidboudia/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['sklearn_pipeline.pkl']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Code provided by https://stackoverflow.com/questions/37984304/how-to-save-a-scikit-learn-pipline-with-keras-regressor-inside-to-disk\n",
        "best_model = results.best_estimator_\n",
        "\n",
        "# Save the Keras model first:\n",
        "# results.best_estimator_.model_.save('best_model.h5')\n",
        "best_model.named_steps['model'].model_.save('best_model.h5')\n",
        "\n",
        "# This hack allows us to save the sklearn pipeline:\n",
        "best_model.named_steps['model'].model_ = None\n",
        "\n",
        "# Finally, save the pipeline:\n",
        "joblib.dump(best_model, 'sklearn_pipeline.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBfzQ-lPitYz",
        "outputId": "6990df4b-eec0-43be-8297-0ceec8dfb198"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;function create_model at 0x7f7faa029480&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=42\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=128\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.2\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tdropout_rate=0.001\n",
              "\tlearning_rate=0.005\n",
              "\toutput_bias=[-4.19656855]\n",
              "\tclass_weight=None\n",
              ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
              "\tmodel=&lt;function create_model at 0x7f7faa029480&gt;\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=42\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=128\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.2\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tdropout_rate=0.001\n",
              "\tlearning_rate=0.005\n",
              "\toutput_bias=[-4.19656855]\n",
              "\tclass_weight=None\n",
              ")</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KerasClassifier(\n",
              "\tmodel=<function create_model at 0x7f7faa029480>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=42\n",
              "\toptimizer=rmsprop\n",
              "\tloss=None\n",
              "\tmetrics=None\n",
              "\tbatch_size=128\n",
              "\tvalidation_batch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.2\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=100\n",
              "\tdropout_rate=0.001\n",
              "\tlearning_rate=0.005\n",
              "\toutput_bias=[-4.19656855]\n",
              "\tclass_weight=None\n",
              ")"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX2mXOxlitYz"
      },
      "source": [
        "## Feature Importance From Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKy_3lOCitYz"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "W3wW25VNitYz",
        "outputId": "d74caee8-c5b7-45e6-fd35-1dbd0f71d4a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 0s 734us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 763us/step\n",
            "41/41 [==============================] - 0s 727us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 720us/step\n",
            "41/41 [==============================] - 0s 710us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 733us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 767us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 835us/step\n",
            "41/41 [==============================] - 0s 734us/step\n",
            "41/41 [==============================] - 0s 706us/step\n",
            "41/41 [==============================] - 0s 725us/step\n",
            "41/41 [==============================] - 0s 824us/step\n",
            "41/41 [==============================] - 0s 790us/step\n",
            "41/41 [==============================] - 0s 769us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 717us/step\n",
            "41/41 [==============================] - 0s 734us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 923us/step\n",
            "41/41 [==============================] - 0s 844us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 783us/step\n",
            "41/41 [==============================] - 0s 734us/step\n",
            "41/41 [==============================] - 0s 748us/step\n",
            "41/41 [==============================] - 0s 779us/step\n",
            "41/41 [==============================] - 0s 746us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 615us/step\n",
            "41/41 [==============================] - 0s 722us/step\n",
            "41/41 [==============================] - 0s 747us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 714us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 580us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 740us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 608us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 588us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 873us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 748us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 612us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 712us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 602us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 723us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 725us/step\n",
            "41/41 [==============================] - 0s 745us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 718us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 714us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 718us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 763us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 598us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 608us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 602us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 617us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 604us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 612us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 789us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 723us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 727us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 722us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 727us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 746us/step\n",
            "41/41 [==============================] - 0s 747us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 738us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 759us/step\n",
            "41/41 [==============================] - 0s 737us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 735us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 718us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 783us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 746us/step\n",
            "41/41 [==============================] - 0s 799us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 612us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 784us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 610us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 722us/step\n",
            "41/41 [==============================] - 0s 736us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 746us/step\n",
            "41/41 [==============================] - 0s 730us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 753us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 740us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 603us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 718us/step\n",
            "41/41 [==============================] - 0s 757us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 749us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 741us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 712us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 744us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 808us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 738us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 756us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 617us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 804us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 761us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 839us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 736us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 718us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 823us/step\n",
            "41/41 [==============================] - 0s 742us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 616us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 615us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 837us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 718us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 730us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 612us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 712us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 616us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 706us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 732us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 739us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 602us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 608us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 609us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 785us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 722us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 741us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 708us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 894us/step\n",
            "41/41 [==============================] - 0s 803us/step\n",
            "41/41 [==============================] - 0s 738us/step\n",
            "41/41 [==============================] - 0s 775us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 792us/step\n",
            "41/41 [==============================] - 0s 893us/step\n",
            "41/41 [==============================] - 0s 768us/step\n",
            "41/41 [==============================] - 0s 733us/step\n",
            "41/41 [==============================] - 0s 734us/step\n",
            "41/41 [==============================] - 0s 747us/step\n",
            "41/41 [==============================] - 0s 825us/step\n",
            "41/41 [==============================] - 0s 796us/step\n",
            "41/41 [==============================] - 0s 904us/step\n",
            "41/41 [==============================] - 0s 822us/step\n",
            "41/41 [==============================] - 0s 826us/step\n",
            "41/41 [==============================] - 0s 795us/step\n",
            "41/41 [==============================] - 0s 999us/step\n",
            "41/41 [==============================] - 0s 863us/step\n",
            "41/41 [==============================] - 0s 883us/step\n",
            "41/41 [==============================] - 0s 798us/step\n",
            "41/41 [==============================] - 0s 799us/step\n",
            "41/41 [==============================] - 0s 767us/step\n",
            "41/41 [==============================] - 0s 997us/step\n",
            "41/41 [==============================] - 0s 827us/step\n",
            "41/41 [==============================] - 0s 759us/step\n",
            "41/41 [==============================] - 0s 805us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 844us/step\n",
            "41/41 [==============================] - 0s 993us/step\n",
            "41/41 [==============================] - 0s 845us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 813us/step\n",
            "41/41 [==============================] - 0s 744us/step\n",
            "41/41 [==============================] - 0s 827us/step\n",
            "41/41 [==============================] - 0s 895us/step\n",
            "41/41 [==============================] - 0s 789us/step\n",
            "41/41 [==============================] - 0s 768us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 735us/step\n",
            "41/41 [==============================] - 0s 745us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 759us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 734us/step\n",
            "41/41 [==============================] - 0s 730us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 772us/step\n",
            "41/41 [==============================] - 0s 712us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 751us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 728us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 714us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 611us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 710us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 610us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 706us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 738us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 749us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 817us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 717us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 759us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 717us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 604us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 756us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 608us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 615us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 597us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 616us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 730us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 744us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 616us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 614us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 603us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 744us/step\n",
            "41/41 [==============================] - 0s 728us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 600us/step\n",
            "41/41 [==============================] - 0s 613us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 609us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 727us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 739us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 921us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 795us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 868us/step\n",
            "41/41 [==============================] - 0s 748us/step\n",
            "41/41 [==============================] - 0s 890us/step\n",
            "41/41 [==============================] - 0s 791us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 760us/step\n",
            "41/41 [==============================] - 0s 927us/step\n",
            "41/41 [==============================] - 0s 772us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 798us/step\n",
            "41/41 [==============================] - 0s 827us/step\n",
            "41/41 [==============================] - 0s 747us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 794us/step\n",
            "41/41 [==============================] - 0s 783us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 795us/step\n",
            "41/41 [==============================] - 0s 868us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 763us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 812us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 720us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 746us/step\n",
            "41/41 [==============================] - 0s 718us/step\n",
            "41/41 [==============================] - 0s 801us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 717us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 733us/step\n",
            "41/41 [==============================] - 0s 785us/step\n",
            "41/41 [==============================] - 0s 762us/step\n",
            "41/41 [==============================] - 0s 706us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 750us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 727us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 846us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 706us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 736us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 805us/step\n",
            "41/41 [==============================] - 0s 744us/step\n",
            "41/41 [==============================] - 0s 758us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 876us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 723us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 801us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 922us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 765us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 771us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 709us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 984us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 732us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 769us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 739us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 708us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 708us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 613us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 708us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 613us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 750us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 746us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 721us/step\n",
            "41/41 [==============================] - 0s 792us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 611us/step\n",
            "41/41 [==============================] - 0s 722us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 610us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 732us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 617us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 720us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 731us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 612us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 735us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 612us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 738us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 736us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 717us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 616us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 742us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 732us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 748us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 746us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 741us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 614us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 735us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 720us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 616us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 724us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 751us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 729us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 611us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 615us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 710us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 690us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 736us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 749us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 717us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 613us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 736us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 813us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 795us/step\n",
            "41/41 [==============================] - 0s 734us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 757us/step\n",
            "41/41 [==============================] - 0s 728us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 722us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 781us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 739us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 755us/step\n",
            "41/41 [==============================] - 0s 696us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 777us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 759us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 808us/step\n",
            "41/41 [==============================] - 0s 757us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 742us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 739us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 717us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 763us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 743us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 737us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 702us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 706us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 610us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 611us/step\n",
            "41/41 [==============================] - 0s 745us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 741us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 701us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 740us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 620us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 708us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 613us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 705us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 603us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 710us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 711us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 725us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 723us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 692us/step\n",
            "41/41 [==============================] - 0s 623us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 2ms/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 708us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 715us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 695us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 698us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 615us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 609us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 780us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 727us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 700us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 712us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 667us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 687us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 613us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 697us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 775us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 713us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 684us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 720us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 714us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 621us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 754us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 618us/step\n",
            "41/41 [==============================] - 0s 639us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 679us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 755us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 681us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 654us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 707us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 616us/step\n",
            "41/41 [==============================] - 0s 617us/step\n",
            "41/41 [==============================] - 0s 622us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 853us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 726us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 643us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 607us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 706us/step\n",
            "41/41 [==============================] - 0s 693us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 680us/step\n",
            "41/41 [==============================] - 0s 632us/step\n",
            "41/41 [==============================] - 0s 624us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 611us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 689us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 691us/step\n",
            "41/41 [==============================] - 0s 674us/step\n",
            "41/41 [==============================] - 0s 716us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 670us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 608us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 678us/step\n",
            "41/41 [==============================] - 0s 703us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 627us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 694us/step\n",
            "41/41 [==============================] - 0s 677us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 675us/step\n",
            "41/41 [==============================] - 0s 664us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 617us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 630us/step\n",
            "41/41 [==============================] - 0s 788us/step\n",
            "41/41 [==============================] - 0s 652us/step\n",
            "41/41 [==============================] - 0s 619us/step\n",
            "41/41 [==============================] - 0s 699us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 651us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 688us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 686us/step\n",
            "41/41 [==============================] - 0s 756us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 683us/step\n",
            "41/41 [==============================] - 0s 676us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 704us/step\n",
            "41/41 [==============================] - 0s 659us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 642us/step\n",
            "41/41 [==============================] - 0s 743us/step\n",
            "41/41 [==============================] - 0s 669us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 685us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 673us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 646us/step\n",
            "41/41 [==============================] - 0s 629us/step\n",
            "41/41 [==============================] - 0s 634us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 625us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 653us/step\n",
            "41/41 [==============================] - 0s 635us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 671us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 660us/step\n",
            "41/41 [==============================] - 0s 1ms/step\n",
            "41/41 [==============================] - 0s 745us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 650us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 645us/step\n",
            "41/41 [==============================] - 0s 626us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 661us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 666us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 662us/step\n",
            "41/41 [==============================] - 0s 649us/step\n",
            "41/41 [==============================] - 0s 638us/step\n",
            "41/41 [==============================] - 0s 633us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 672us/step\n",
            "41/41 [==============================] - 0s 628us/step\n",
            "41/41 [==============================] - 0s 644us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 636us/step\n",
            "41/41 [==============================] - 0s 647us/step\n",
            "41/41 [==============================] - 0s 617us/step\n",
            "41/41 [==============================] - 0s 658us/step\n",
            "41/41 [==============================] - 0s 719us/step\n",
            "41/41 [==============================] - 0s 648us/step\n",
            "41/41 [==============================] - 0s 637us/step\n",
            "41/41 [==============================] - 0s 617us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 641us/step\n",
            "41/41 [==============================] - 0s 657us/step\n",
            "41/41 [==============================] - 0s 631us/step\n",
            "41/41 [==============================] - 0s 665us/step\n",
            "41/41 [==============================] - 0s 655us/step\n",
            "41/41 [==============================] - 0s 640us/step\n",
            "41/41 [==============================] - 0s 668us/step\n",
            "41/41 [==============================] - 0s 682us/step\n",
            "41/41 [==============================] - 0s 663us/step\n",
            "41/41 [==============================] - 0s 656us/step\n",
            "41/41 [==============================] - 0s 639us/step\n"
          ]
        }
      ],
      "source": [
        "r = permutation_importance(results.best_estimator_, X_val, y_val.values.reshape(-1,),n_repeats=30,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQk0LC1HitYz",
        "outputId": "998836d1-717d-458b-e7e7-00b59eb97a5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DayofMonth</td>\n",
              "      <td>0.048523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tmp_dew</td>\n",
              "      <td>0.034961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CRSDepHour</td>\n",
              "      <td>0.032982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dest</td>\n",
              "      <td>0.032810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tmp_air</td>\n",
              "      <td>0.030927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sky_c_hgt</td>\n",
              "      <td>0.029779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Month</td>\n",
              "      <td>0.025081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>w_speed_rate</td>\n",
              "      <td>0.024705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Year</td>\n",
              "      <td>0.024692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>DayOfWeek</td>\n",
              "      <td>0.021629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>OriginAirportSeqID</td>\n",
              "      <td>0.021488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>w_dir_angle</td>\n",
              "      <td>0.020186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>at_pres_altimeter_rate</td>\n",
              "      <td>0.019101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>sky_sum_hgt</td>\n",
              "      <td>0.017806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sky_sum_cov</td>\n",
              "      <td>0.017321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>DestStateFips</td>\n",
              "      <td>0.016606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Quarter</td>\n",
              "      <td>0.016204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>liq_precip_cond</td>\n",
              "      <td>0.012222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>sky_obs_tot_cov_02</td>\n",
              "      <td>0.011245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>sky_cov_cld</td>\n",
              "      <td>0.010588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   feature  importance\n",
              "0               DayofMonth    0.048523\n",
              "1                  tmp_dew    0.034961\n",
              "2               CRSDepHour    0.032982\n",
              "3                     Dest    0.032810\n",
              "4                  tmp_air    0.030927\n",
              "5                sky_c_hgt    0.029779\n",
              "6                    Month    0.025081\n",
              "7             w_speed_rate    0.024705\n",
              "8                     Year    0.024692\n",
              "9                DayOfWeek    0.021629\n",
              "10      OriginAirportSeqID    0.021488\n",
              "11             w_dir_angle    0.020186\n",
              "12  at_pres_altimeter_rate    0.019101\n",
              "13             sky_sum_hgt    0.017806\n",
              "14             sky_sum_cov    0.017321\n",
              "15           DestStateFips    0.016606\n",
              "16                 Quarter    0.016204\n",
              "17         liq_precip_cond    0.012222\n",
              "18      sky_obs_tot_cov_02    0.011245\n",
              "19             sky_cov_cld    0.010588"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feats = dict(zip(list(X_val.columns[np.argsort(r.importances_mean)[::-1]])\n",
        "                 ,r.importances_mean[np.argsort(r.importances_mean)[::-1]]))\n",
        "top_features = dict(sorted(feats.items(), key=lambda x: x[1], reverse=True)[:20])\n",
        "\n",
        "pd.DataFrame(data=top_features.items(),columns=['feature','importance'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivwOHDR6itYz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzf4tVyNitYz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}